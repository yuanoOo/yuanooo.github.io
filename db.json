{"meta":{"version":1,"warehouse":"4.0.1"},"models":{"Asset":[{"_id":"node_modules/hexo-theme-butterfly/source/css/index.styl","path":"css/index.styl","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-butterfly/source/css/var.styl","path":"css/var.styl","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-butterfly/source/img/404.jpg","path":"img/404.jpg","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-butterfly/source/img/favicon.png","path":"img/favicon.png","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-butterfly/source/img/friend_404.gif","path":"img/friend_404.gif","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-butterfly/source/js/main.js","path":"js/main.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-butterfly/source/js/tw_cn.js","path":"js/tw_cn.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-butterfly/source/js/utils.js","path":"js/utils.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-butterfly/source/js/search/algolia.js","path":"js/search/algolia.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-butterfly/source/js/search/local-search.js","path":"js/search/local-search.js","modified":1,"renderable":1},{"_id":"source/CNAME","path":"CNAME","modified":1,"renderable":0},{"_id":"source/robots.txt","path":"robots.txt","modified":1,"renderable":0},{"_id":"source/doc/Flink+Hudi构建实时仓湖一体化.pdf","path":"doc/Flink+Hudi构建实时仓湖一体化.pdf","modified":1,"renderable":0},{"_id":"source/img/animal1.jpg","path":"img/animal1.jpg","modified":1,"renderable":0},{"_id":"source/img/cat.png","path":"img/cat.png","modified":1,"renderable":0},{"_id":"source/script/1.jpg","path":"script/1.jpg","modified":1,"renderable":0},{"_id":"source/script/1.png","path":"script/1.png","modified":1,"renderable":0},{"_id":"source/script/img-to-webp.sh","path":"script/img-to-webp.sh","modified":1,"renderable":0},{"_id":"source/script/img-webp.sh","path":"script/img-webp.sh","modified":1,"renderable":0},{"_id":"source/sitemap_template/sitemap_template.txt","path":"sitemap_template/sitemap_template.txt","modified":1,"renderable":0},{"_id":"source/sitemap_template/sitemap_template.xml","path":"sitemap_template/sitemap_template.xml","modified":1,"renderable":0},{"_id":"source/img/bg/avatar.webp","path":"img/bg/avatar.webp","modified":1,"renderable":0},{"_id":"source/img/bg/banner.gif","path":"img/bg/banner.gif","modified":1,"renderable":0},{"_id":"source/img/bg/banner.webp","path":"img/bg/banner.webp","modified":1,"renderable":0},{"_id":"source/img/bg/banner1.webp","path":"img/bg/banner1.webp","modified":1,"renderable":0},{"_id":"source/img/bg/banner2.webp","path":"img/bg/banner2.webp","modified":1,"renderable":0},{"_id":"source/img/bg/clash.jpg","path":"img/bg/clash.jpg","modified":1,"renderable":0},{"_id":"source/img/bg/default.png","path":"img/bg/default.png","modified":1,"renderable":0},{"_id":"source/img/bg/default_top_img.png","path":"img/bg/default_top_img.png","modified":1,"renderable":0},{"_id":"source/img/bg/index_img.png","path":"img/bg/index_img.png","modified":1,"renderable":0},{"_id":"source/img/bg/poxiao.jpg","path":"img/bg/poxiao.jpg","modified":1,"renderable":0},{"_id":"source/img/bg/web-bg.webp","path":"img/bg/web-bg.webp","modified":1,"renderable":0},{"_id":"source/img/cut/cdn-test-1.webp","path":"img/cut/cdn-test-1.webp","modified":1,"renderable":0},{"_id":"source/img/cut/cdn-test-2.webp","path":"img/cut/cdn-test-2.webp","modified":1,"renderable":0},{"_id":"source/img/code/code.jpg","path":"img/code/code.jpg","modified":1,"renderable":0},{"_id":"source/img/code/linux.png","path":"img/code/linux.png","modified":1,"renderable":0},{"_id":"source/img/code/talk_code_to_me.webp","path":"img/code/talk_code_to_me.webp","modified":1,"renderable":0},{"_id":"source/img/img-link/img-link.txt","path":"img/img-link/img-link.txt","modified":1,"renderable":0}],"Cache":[{"_id":"source/script/1.jpg","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1656409201250},{"_id":"source/script/1.png","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1656409201250},{"_id":"source/CNAME","hash":"a44a2add0449f197dfcbdf8314c0005eb7e088d4","modified":1656412664400},{"_id":"source/_data/link.yml","hash":"4817d09193d8f06ce05f891b1540184227e9f609","modified":1665575826746},{"_id":"source/robots.txt","hash":"c443b65f80db1005b56899172a5e9451af639175","modified":1657008288802},{"_id":"source/_drafts/hadoop-native-lib和snappy.md","hash":"f20d43c6a316678cef404516e1e15234a384ac5f","modified":1665917918786},{"_id":"source/_drafts/Flink+Hudi构建实时仓湖一体化.md","hash":"e2e90b013d68f479eb8ff2e73c55b5b30180a326","modified":1661064792656},{"_id":"source/about/index.md","hash":"a71523c7fdaf64ce310aa6b55d7984b682bb06c9","modified":1656572126228},{"_id":"source/_posts/Hexo-github-pages-CloudFlare免费CDN最佳实践.md","hash":"345120af93c77ead681f1a89bd5527835947328a","modified":1656742742927},{"_id":"source/_posts/DNS命令指南.md","hash":"1357f522ace03819d8e8120091d0b2dd26bb83d7","modified":1656503902493},{"_id":"source/_posts/WSL中的骚操作.md","hash":"ba81f08deec8379f6ad21d84d4974623a75e54e5","modified":1656742656607},{"_id":"source/_posts/hexo+freenom+cloudflare遇到的一些坑.md","hash":"a53cc77fca6eded195b6444faa26ac09cbc87836","modified":1656409201250},{"_id":"source/_posts/hexo的front-matter中的分类问题.md","hash":"acad1e32a24c87e7fa23badf255db0383b3609d1","modified":1656509329590},{"_id":"source/_posts/记一次Kylin-Server的JVM-OOM事故排查复盘.md","hash":"f58588464be9de8bad83b93f6e3cfc30f0aa581c","modified":1663936603953},{"_id":"source/css/background.css","hash":"2b0f6b7fdd3c8b341f9cff58fd66825b35f6defe","modified":1656585255569},{"_id":"source/categories/index.md","hash":"b8fa542806eefa2a0c53ae2f258071268a29a728","modified":1656409201250},{"_id":"source/_posts/zhihu-emo-yulu.md","hash":"45b8d824aa5fb8bedcccb51a5763484ea1bcf37d","modified":1656742698357},{"_id":"source/css/custom.css","hash":"bf0872e7cd7c882a202342448e223b383ec2c2cf","modified":1656572187808},{"_id":"source/link/index.md","hash":"389721a6b49d481514c8927da3a434c98d0cc659","modified":1656834223539},{"_id":"source/img/animal1.jpg","hash":"e48cb3aeeb030ff094e35e61c52bbd73a662e0a5","modified":1656409201250},{"_id":"source/script/img-to-webp.sh","hash":"ade97b82a996d82be7b20693a4f95e9cba02592d","modified":1656409201250},{"_id":"source/script/img-webp.sh","hash":"b263a739e2c8f5acdb3c625d73e34d1e370079f2","modified":1656409201250},{"_id":"source/tags/index.md","hash":"ff8e7c4329113a8a5eeaec0aefeca67b139b0766","modified":1656409201250},{"_id":"source/sitemap_template/sitemap_template.txt","hash":"cbb0b7198d37b808e6e9bf4bd389743c07f8cf17","modified":1656409201250},{"_id":"source/sitemap_template/sitemap_template.xml","hash":"94026f74ab00f4398ee57381b6c3eaff9d475d35","modified":1656409201250},{"_id":"source/_posts/bigdata/Doris中的索引.md","hash":"c29539a4dc634b8e5d09d6c81559a4d0b450b62f","modified":1663399616709},{"_id":"source/_posts/bigdata/Doris Compaction从入门到跑路.md","hash":"4362f9aefd4260bc3d0dc2fac090c24561850576","modified":1663399624709},{"_id":"source/_posts/bigdata/Doris-Join最佳实践.md","hash":"714b595b6b04e1e82e3957565ae5931ec81443e0","modified":1664093294319},{"_id":"source/_posts/bigdata/Doris大查询实践与优化.md","hash":"0e06c9cda882bd153cc083e09c062daf01111694","modified":1664526740017},{"_id":"source/_posts/bigdata/Kyuubi-从入门到跑路.md","hash":"856e6bc99a18e3b3aad9a4fdbfafeb4cb5ee09cd","modified":1667223243688},{"_id":"source/_posts/bigdata/HBase如何实现MVCC.md","hash":"5f77fc1142aa84f8c9a52935b95958ffd934388b","modified":1663399633459},{"_id":"source/_posts/bigdata/Flink-SQL-Client与Hive集成问题指南.md","hash":"3ad9fc1be25d0483b56c9a434bac3d673b5ffd26","modified":1663399608849},{"_id":"source/_posts/bigdata/Flink调优.md","hash":"93357ec7f2c6f4b67d35265cfac68b6d59cc2ac5","modified":1662884376337},{"_id":"source/_posts/bigdata/doris性能优化（一）.md","hash":"352a602f0298fd49ae6cdece116f3da48c8904be","modified":1661060117646},{"_id":"source/_posts/bigdata/yarn公平和容量调度器的异同.md","hash":"9f157fae69415a4be92fa57c5d5553c1cb267620","modified":1657020300992},{"_id":"source/_posts/bigdata/When：何时需要进行Doris Compaction调优.md","hash":"d823fa691b88d781a3bfb5e098faf38892aaf6c8","modified":1662885888957},{"_id":"source/_posts/bigdata/一文搞懂Kudu的整体架构.md","hash":"e30c12784be699bcc03469109b43ca44af9cf99a","modified":1656743099377},{"_id":"source/_posts/bigdata/初入Flink-Table@SQL.md","hash":"2ea68c39d93fa2a04960964e1b28c544d4132152","modified":1660405632809},{"_id":"source/_posts/bigdata/初识Doris.md","hash":"27a906b10f3a1e49456208c904d66c009df77f4d","modified":1659841434952},{"_id":"source/_posts/bigdata/搭建Flink集群.md","hash":"e5864d5d14b68b924901bc5b6627e5e183d46051","modified":1659962592911},{"_id":"source/_posts/bigdata/测试Flink-Doris-Connector.md","hash":"4c4df6dfa2f869b0312a3e47b7cb38130af3029c","modified":1659963991091},{"_id":"source/_posts/hexo/从github恢复备份hexo博客hexo-git-backup.md","hash":"2d53fb0c0b54108fc610338aa2475708c36c424a","modified":1656485209963},{"_id":"source/_posts/hexo/hexo不显示语雀图床CDN图片的解决办法.md","hash":"d80573d81cae6539704fe7f93f79a8623479fe38","modified":1656734345130},{"_id":"source/_posts/bigdata/用户画像介绍.md","hash":"05665358aea2c5ad910c8bb6457eab001d6270eb","modified":1657973426551},{"_id":"source/_posts/rpc/thrift-从入门到放弃.md","hash":"4352be046d5b29eb1e1bd821fdef3fecc4f93263","modified":1662263701351},{"_id":"source/_posts/os/文件与IO.md","hash":"fcd8a44dcab78ac37bdf6c58d08e9f329d78e534","modified":1665312149067},{"_id":"source/_posts/bigdata/通过Flink-SQL，将Kafka中的Oracle-CDC-Log同步到Doris.md","hash":"231099024c6c093353a18635b94e26f923808d30","modified":1660490666141},{"_id":"source/_posts/os/虚拟内存.md","hash":"67f9fb9fb763372bd4d803284e1f7817b6699260","modified":1665294674431},{"_id":"source/img/bg/avatar.webp","hash":"253098016d490151a15192a99d73606607e2c15d","modified":1656409201250},{"_id":"source/_posts/data-structure/从SS-Table到LSM-Tree.md","hash":"b4af64253faab98f91e8028bea9eb50f63d7cb96","modified":1663399589199},{"_id":"source/img/bg/clash.jpg","hash":"a0388a2acdb319902a1b9a45fc48a836d8f5d07d","modified":1656409201250},{"_id":"source/img/bg/banner1.webp","hash":"24cfb05fcddfc300d9554b1e9d83e93282052300","modified":1656409201250},{"_id":"source/img/bg/index_img.png","hash":"8517f53cbd9416e8b8f16160936499b0b9c8b6dc","modified":1656409201250},{"_id":"source/img/bg/poxiao.jpg","hash":"dcdcaa64fa5817e52cef86ed69824e044105e3a7","modified":1656427443094},{"_id":"source/img/code/linux.png","hash":"cad82d89247115c29cb88e60f03d229bb1e4e8cd","modified":1656409201250},{"_id":"source/img/code/code.jpg","hash":"89b5ed059b850c72988b186751153e63bc3e9e6b","modified":1656409201250},{"_id":"source/_posts/bigdata/配置hadoop-snappy那些事.md","hash":"fb6bda55b7cb88870fbb254b6618216e9ec02c47","modified":1667299734019},{"_id":"source/_posts/SEO.md","hash":"557efdda15e443107c8f92b8510f0153c09c5d14","modified":1656409201250},{"_id":"source/img/img-link/img-link.txt","hash":"e5812babc02f71df9122496069016ed7b16e8168","modified":1656409201250},{"_id":"source/img/cat.png","hash":"764303a8a1ae8f7fa1fb6e9c21b852a5988882bb","modified":1656409201250},{"_id":"source/img/bg/banner2.webp","hash":"88377d64f128a09855066054fb74a290b0b26613","modified":1656492342953},{"_id":"source/img/bg/default_top_img.png","hash":"980912504113f64d6aaf5b99e9793b77d1511197","modified":1656409201250},{"_id":"source/img/bg/web-bg.webp","hash":"7902ecf0465380a7576910c92881f7d493cfe0dd","modified":1656409201250},{"_id":"source/img/cut/cdn-test-2.webp","hash":"a0121aa1ff44ecaba93ed3449b9a95ee0d9daf83","modified":1656409201250},{"_id":"node_modules/hexo-theme-butterfly/README_CN.md","hash":"08afd014fd27019909f341a2ad6162665958c6d6","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/package.json","hash":"bf1e7d13b179a17f1c851033eddf5944ea5993d4","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/README.md","hash":"66b4889591d0f36696c4d363412c753b6fe25519","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/.github/stale.yml","hash":"5e8ea535424e8112439135d21afc5262c0bc0b39","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/LICENSE","hash":"1128f8f91104ba9ef98d37eea6523a888dcfa5de","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/_config.yml","hash":"d5929d2e7fa55a74a089dd329bdae52cb6c12acc","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/languages/default.yml","hash":"1e37a3695d50e3e61d7c36e58a6dac872a4a56cd","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/languages/en.yml","hash":"d1bb560698eb8b0079495b7b18b44facb610f9fd","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/archive.pug","hash":"bd62286afb64a51c97e800c5945620d51605d5fa","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/languages/zh-TW.yml","hash":"947f794e862bb2813e36887f777bdb760f70a322","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/languages/zh-CN.yml","hash":"28b6f0c39155651d747eb595e0a283bc97be2e09","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/category.pug","hash":"710708cfdb436bc875602abf096c919ccdf544db","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/page.pug","hash":"baf469784aef227e4cc840550888554588e87a13","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/index.pug","hash":"e1c3146834c16e6077406180858add0a8183875a","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/post.pug","hash":"fc9f45252d78fcd15e4a82bfd144401cba5b169a","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/tag.pug","hash":"0440f42569df2676273c026a92384fa7729bc4e9","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/.github/ISSUE_TEMPLATE/config.yml","hash":"7dfe7189ffeaebb6db13842237f8e124649bea3d","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/.github/ISSUE_TEMPLATE/bug_report.yml","hash":"67e4f5a66d4b8cabadbaad0410628364ee75e0ae","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/.github/ISSUE_TEMPLATE/feature_request.yml","hash":"996640605ed1e8e35182f0fd9a60a88783b24b03","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/.github/workflows/publish.yml","hash":"05857c2f265246d8de00e31037f2720709540c09","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/footer.pug","hash":"02390a5b6ae1f57497b22ba2e6be9f13cfb7acac","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/additional-js.pug","hash":"594a977ebe8d97e60fa3d7cb40fc260ded4d8a58","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/404.pug","hash":"cb49f737aca272ccfeb62880bd651eccee72a129","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/pagination.pug","hash":"0b80f04950bd0fe5e6c4e7b7559adf4d0ce28436","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/layout.pug","hash":"da27c20f0e672103b984e135eb2fe7770ca7fcce","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/scripts/events/404.js","hash":"83cd7f73225ccad123afbd526ce1834eb1eb6a6d","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/scripts/events/config.js","hash":"a12b9f11d7d3f52de5b2090d2805d7303e0187a5","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/head.pug","hash":"b9d85155923314aa7e39b37395d875d7cddfabfe","modified":1656731225360},{"_id":"node_modules/hexo-theme-butterfly/scripts/events/init.js","hash":"b4940a5c73d3a5cd8bb5883e3041ecdd905a74e0","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/scripts/events/stylus.js","hash":"9819f0996234fbd80d6c50a9e526c56ebf22588d","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/rightside.pug","hash":"699d0d2cff233628752956c4434125c8203f7d63","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/scripts/events/welcome.js","hash":"3cfc46c749e2fd7ae9c2a17206238ed0e0e17e7d","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/scripts/filters/post_lazyload.js","hash":"932df912976261929f809b7dbd4eb473e7787345","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/scripts/filters/random_cover.js","hash":"21379ed2dccb69c43b893895c9d56238c11e5f43","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/scripts/helpers/aside_categories.js","hash":"e00efdb5d02bc5c6eb4159e498af69fa61a7dbb9","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/scripts/helpers/aside_archives.js","hash":"2ec66513d5322f185d2071acc052978ba9415a8e","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/scripts/helpers/inject_head_js.js","hash":"b4cd617c619d1a0df93603721a6fa1317526174b","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/scripts/helpers/page.js","hash":"c6611d97087c51845cb1ab4821696a62fa33daeb","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/scripts/tag/gallery.js","hash":"f79c99f6c5b626c272dc2bed2b0250d6b91bb28a","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/scripts/tag/hide.js","hash":"396c3ab1bcf1c7693ad7e506eadd13016c6769b6","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/scripts/tag/inlineImg.js","hash":"a43ee2c7871bdd93cb6beb804429e404570f7929","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/scripts/helpers/related_post.js","hash":"d368a8830e506c8b5eb6512b709ec8db354d5ea1","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/scripts/tag/label.js","hash":"03b2afef41d02bd1045c89578a02402c28356006","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/scripts/tag/mermaid.js","hash":"531808a290b8bdd66bac2faab211ada8e9646a37","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/scripts/tag/note.js","hash":"c16c6eb058af2b36bcd583b2591076c7ebdd51ad","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/scripts/tag/tabs.js","hash":"6c6e415623d0fd39da016d9e353bb4f5cca444f5","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/scripts/tag/timeline.js","hash":"300eb779588bf35a1b687d9f829d866074b707e3","modified":1656409201240},{"_id":"source/img/cut/cdn-test-1.webp","hash":"e8a063916ee46e49941081c8c4d0e241eaa0bd9f","modified":1656409201250},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/sidebar.pug","hash":"8d39473ed112d113674a0f689f63fae06c72abd2","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/source/css/index.styl","hash":"861998e4ac67a59529a8245a9130d68f826c9c12","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/source/css/var.styl","hash":"4890a40366d6443f8b8942a4e9a6dce9fe3494f5","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/source/img/404.jpg","hash":"fb4489bc1d30c93d28f7332158c1c6c1416148de","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/source/img/favicon.png","hash":"3cf89864b4f6c9b532522a4d260a2e887971c92d","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/source/img/friend_404.gif","hash":"8d2d0ebef70a8eb07329f57e645889b0e420fa48","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/source/js/main.js","hash":"04efcbd28b37875cfec88eb87cab7256a9ebb327","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/source/js/tw_cn.js","hash":"00053ce73210274b3679f42607edef1206eebc68","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/source/js/utils.js","hash":"0b95daada72abb5d64a1e3236049a60120e47cca","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/head/Open_Graph.pug","hash":"6c41f49a3e682067533dd9384e6e4511fc3a1349","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/head/analytics.pug","hash":"15530d9ac59c576d79af75dd687efe71e8d261b0","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/head/config.pug","hash":"8f41fa9732ea654a10f6e666d9c782c7e27e5ea6","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/head/google_adsense.pug","hash":"95a37e92b39c44bcbea4be7e29ddb3921c5b8220","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/head/config_site.pug","hash":"7df90c8e432e33716517ab918b0a125bc284041b","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/head/noscript.pug","hash":"d16ad2ee0ff5751fd7f8a5ce1b83935518674977","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/head/preconnect.pug","hash":"65a23b5170204e55b813ce13a79d799b66b7382c","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/head/pwa.pug","hash":"3d492cfe645d37c94d30512e0b230b0a09913148","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/header/index.pug","hash":"65fa23680af0daf64930a399c2f2ca37809a8149","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/head/site_verification.pug","hash":"e2e8d681f183f00ce5ee239c42d2e36b3744daad","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/scripts/tag/button.js","hash":"91d954f6e9fe6e571eb8ec9f8996294b2dc3688e","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/header/menu_item.pug","hash":"31346a210f4f9912c5b29f51d8f659913492f388","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/header/nav.pug","hash":"78a3abd90bb3c18cd773d3d5abac3541e7f415e5","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/header/post-info.pug","hash":"19a05dccfbffdf31cfa48c3208542b924637303d","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/header/social.pug","hash":"0d953e51d04a9294a64153c89c20f491a9ec42d4","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/loading/loading.pug","hash":"5276937fbcceb9d62879dc47be880cd469a27349","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/page/categories.pug","hash":"5276a8d2835e05bd535fedc9f593a0ce8c3e8437","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/loading/loading-js.pug","hash":"4cfcf0100e37ce91864703cd44f1cb99cb5493ea","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/mixins/post-ui.pug","hash":"b9ebb02af8ccf43e3f73be43db19254fa913c57b","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/page/tags.pug","hash":"6311eda08e4515281c51bd49f43902a51832383c","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/mixins/article-sort.pug","hash":"2fb74d0b0e4b98749427c5a1a1b0acb6c85fadc4","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/page/default-page.pug","hash":"12c65c174d26a41821df9bad26cdf1087ec5b0ca","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/page/flink.pug","hash":"fed069baa9b383f57db32bb631115071d29bdc60","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/effect.pug","hash":"6528e86656906117a1af6b90e0349c2c4651d5e1","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/post/post-copyright.pug","hash":"ebecba46a5f4efe1c98a386df06c56e26fbd07b9","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/aplayer.pug","hash":"c7cfade2b160380432c47eef4cd62273b6508c58","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/post/reward.pug","hash":"864869c43fe5b5bb6f4ac6b13dd4bfb16ea47550","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/pjax.pug","hash":"460c37caeed6e6e72c1e62292e6c5e9699dd5937","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/pangu.pug","hash":"0f024e36b8116118233e10118714bde304e01e12","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/subtitle.pug","hash":"bae2f32ac96cebef600c1e37eaa8467c9a7e5d92","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/prismjs.pug","hash":"ffb9ea15a2b54423cd4cd441e2d061b8233e9b58","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/widget/card_ad.pug","hash":"60dc48a7b5d89c2a49123c3fc5893ab9c57dd225","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/widget/card_archives.pug","hash":"86897010fe71503e239887fd8f6a4f5851737be9","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/widget/card_announcement.pug","hash":"ae392459ad401a083ca51ee0b27526b3c1e1faed","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/widget/card_author.pug","hash":"e37468e63db2a0ac09b65d21b7de3e62425bb455","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/widget/card_bottom_self.pug","hash":"13dc8ce922e2e2332fe6ad5856ebb5dbf9ea4444","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/widget/card_categories.pug","hash":"d1a416d0a8a7916d0b1a41d73adc66f8c811e493","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/widget/card_newest_comment.pug","hash":"6d93564a8bd13cb9b52ee5e178db3bcbf18b1bc6","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/widget/card_post_toc.pug","hash":"3057a2f6f051355e35d3b205121af8735100eacf","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/widget/card_webinfo.pug","hash":"0612aaee878f33ea8d3da0293c7dc3b6cd871466","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/widget/card_tags.pug","hash":"438aea3e713ed16b7559b9a80a9c5ec0221263df","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/widget/card_top_self.pug","hash":"ae67c6d4130a6c075058a9c1faea1648bcc6f83e","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/widget/card_recent_post.pug","hash":"9c1229af6ab48961021886882c473514101fba21","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/widget/index.pug","hash":"7fb096656c8a6c21a4b6a5100885b1081d6021ed","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/source/css/_global/function.styl","hash":"644d520fe80cc82058467708ab82ccad313b0c27","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/source/css/_global/index.styl","hash":"714f19e7d66df84938bd1b82b33d5667abe1f147","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/source/css/_highlight/highlight.styl","hash":"2f95e99b8351fbecd9037a1bbdc3fee9d6ea8a77","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/source/css/_layout/chat.styl","hash":"29f48f9370f245e6e575b5836bccf47eb5688d8b","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/source/css/_layout/comments.styl","hash":"c61dccca690d486c3d9c29cf028d87b777385141","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/source/css/_highlight/theme.styl","hash":"bcd384c8b2aa0390c9eb69ac1abbfd1240ce1da4","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/source/css/_layout/aside.styl","hash":"ca58af8903eb1d1d05edae54fc2e23aeac6da6c5","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/source/css/_layout/loading.styl","hash":"ef21990de28bd75dcd0f88b8d616e1a7a137502f","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/source/css/_layout/head.styl","hash":"d97c1722ce0fcc319f1f90ec2d51f9d746748e2b","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/source/css/_layout/footer.styl","hash":"26be2afa9d4e7016cf3c42a6cd166f01e8e4ad5c","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/source/css/_layout/pagination.styl","hash":"fb9f78bfbb79579f1d752cb73fb6d25c8418e0fd","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/source/css/_layout/relatedposts.styl","hash":"d53de408cb27a2e704aba7f7402b7caebe0410d8","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/source/css/_layout/reward.styl","hash":"c5cfed620708807a48076b5ee59b0ba84e29aa80","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/source/css/_layout/post.styl","hash":"15056fba0bd5a45ea8dc97eb557f6929ff16797a","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/source/css/_layout/rightside.styl","hash":"bd88ee30ebf8ca2e7b4d3a034c317fd61733921f","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/source/css/_mode/darkmode.styl","hash":"f67177310f5594954b25a591d186d28d5d450b18","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/source/css/_layout/sidebar.styl","hash":"631ca35a38bc4ac052e9caf47508ff1f99842fc7","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/source/css/_layout/third-party.styl","hash":"8314e9749eb1ae40c4bae9735b7a6638b2d6876a","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/source/css/_mode/readmode.styl","hash":"69f8e9414526dfda3af9a71c8e528fdd0ecbbfe5","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/source/css/_page/categories.styl","hash":"f01ee74948cedb44e53cd3bb1ef36b7d2778ede7","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/source/css/_page/404.styl","hash":"50dbb9e6d98c71ffe16741b8c1b0c1b9771efd2b","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/source/css/_page/archives.styl","hash":"6f4b4ede52305bce9b22c8c897dcbde8af6e2ce4","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/source/css/_page/common.styl","hash":"a58d35d698885f1034dedbe99f7dbc1a801412c6","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/source/css/_page/flink.styl","hash":"98d755b686ee833e9da10afaa40c4ec2bd66c19a","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/source/css/_page/homepage.styl","hash":"826dae759062d8f84eb2bf5ab8fdb80e0f79d58b","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/source/css/_search/algolia.styl","hash":"51e45625929d57c9df3ba9090af99b9b7bb9a15b","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/source/css/_page/tags.styl","hash":"580feb7e8b0822a1be48ac380f8c5c53b1523321","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/source/css/_search/index.styl","hash":"39d61cbe0c1e937f83ba3b147afaa29b4de2f87d","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/source/css/_search/local-search.styl","hash":"25e58a7a8bda4b73d0a0e551643ca01b09ccd7e5","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/source/css/_tags/button.styl","hash":"45f0c32bdea117540f6b14ebac6450d7142bd710","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/source/css/_tags/gallery.styl","hash":"a310e48f826a4cacc55d8e68f43806e5085554f6","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/source/css/_tags/hexo.styl","hash":"d76c38adf1d9c1279ef4241835667789f5b736e0","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/source/css/_tags/inlineImg.styl","hash":"df9d405c33a9a68946b530410f64096bcb72560c","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/source/css/_tags/hide.styl","hash":"ce489ca2e249e2a3cf71584e20d84bdb022e3475","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/source/css/_tags/label.styl","hash":"66c59e193d794cdb02cca7bd1dc4aea5a19d7e84","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/source/css/_tags/note.styl","hash":"08493b66b9f31f2bd3e9a3115017a0ce16142b20","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/source/css/_tags/tabs.styl","hash":"bf9568444dd54e39dc59b461323dcd38942f27d9","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/source/css/_third-party/normalize.min.css","hash":"2c18a1c9604af475b4749def8f1959df88d8b276","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/source/css/_tags/timeline.styl","hash":"f071156d439556e7463ed4bc61ceee87170d5d08","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/card-post-count/index.pug","hash":"e3bf847553515174f6085df982f0623e9783db7a","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/card-post-count/fb.pug","hash":"7848ec58c6ec03243abf80a3b22b4dc10f3edf53","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/source/js/search/algolia.js","hash":"ce8131b712dca80f289015aef75f86e727f62981","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/source/js/search/local-search.js","hash":"3071a4208fdf89ad7e0031536dd6ffa7bc951e4d","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/card-post-count/twikoo.pug","hash":"58406a7a3bf45815769f652bf3ef81e57dcd07eb","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/card-post-count/valine.pug","hash":"e4b7bf91a29bd03181593b63e1f3ee1103af2e48","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/card-post-count/disqus.pug","hash":"d85c3737b5c9548553a78b757a7698df126a52cf","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/card-post-count/waline.pug","hash":"5f648086a33a32d169a2f8d8c549c08aa02f67db","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/chat/crisp.pug","hash":"76634112c64023177260d1317ae39cef2a68e35f","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/chat/chatra.pug","hash":"481cd5053bafb1a19f623554a27d3aa077ea59c3","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/chat/gitter.pug","hash":"d1d2474420bf4edc2e43ccdff6f92b8b082143df","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/chat/daovoice.pug","hash":"cfe63e7d26a6665df6aa32ca90868ad48e05ec04","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/chat/index.pug","hash":"3f05f8311ae559d768ee3d0925e84ed767c314d3","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/chat/tidio.pug","hash":"24a926756c2300b9c561aaab6bd3a71fdd16e16d","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/comments/disqus.pug","hash":"a111407fdcafcf1099e26ffa69786f8822c5d9fb","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/comments/disqusjs.pug","hash":"693d999777dd16e0566d29ac3203d4c167b2f9a7","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/comments/gitalk.pug","hash":"22e2ef30fe5eb1db7566e89943c74ece029b2a8e","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/comments/giscus.pug","hash":"591ef23c583690bd74af0cafb09af64ba5bd8151","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/comments/index.pug","hash":"e4850f2c9ba5f6b2248808f7257662679e0fab0a","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/comments/facebook_comments.pug","hash":"2d8fc3fb8f9aec61400acf3c94070bd8539058f8","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/comments/js.pug","hash":"9302837f1e35f153323bb4f166514c7e96e8ecdd","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/comments/twikoo.pug","hash":"81c6070e06ecc2244040c7007566d7972f46ec4e","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/comments/livere.pug","hash":"52ea8aa26b84d3ad38ae28cdf0f163e9ca8dced7","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/comments/utterances.pug","hash":"a737046e730eb7264606ba0536218964044492f9","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/scripts/tag/flink.js","hash":"ab62919fa567b95fbe14889517abda649991b1ee","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/comments/waline.pug","hash":"15462d1ed04651ad3b430c682842ac400f6f9b47","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/comments/valine.pug","hash":"e55b9c0f8ced231f47eb88bd7f4ec99f29c5c29d","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/math/mermaid.pug","hash":"8e33aca36a4d3ae9e041ba05ced8eff56ae38f77","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/math/mathjax.pug","hash":"f4dc7d02c8192979404ae9e134c5048d3d0a76e2","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/newest-comments/disqus-comment.pug","hash":"04b2a5882e789a988e41d45abe606f0617b08e38","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/newest-comments/github-issues.pug","hash":"e846ddfe4a63b15d1416f6055f5756af5e3da7c6","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/newest-comments/index.pug","hash":"f6506ccfd1ce994b9e53aa95588d0b6dbad11411","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/newest-comments/valine.pug","hash":"d19e1c2c0a50f0e4547d71a17b9be88e8152f17c","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/newest-comments/twikoo-comment.pug","hash":"233907dd7f5b5f33412701d2ccffbc0bbae8707b","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/search/algolia.pug","hash":"e8245d0b4933129bb1c485d8de11a9e52e676348","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/search/local-search.pug","hash":"178c9cdcc4ce5a006885b24ce4a3d624e4734899","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/newest-comments/waline.pug","hash":"dd0bc119029b62dce5dc965d5de7377e438fa29a","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/search/index.pug","hash":"da3b9437d061ee68dbc383057db5c73034c49605","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/share/index.pug","hash":"4c4a9c15215ae8ac5eadb0e086b278f76db9ee92","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/share/addtoany.pug","hash":"85c92f8a7e44d7cd1c86f089a05be438535e5362","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/share/add-this.pug","hash":"2980f1889226ca981aa23b8eb1853fde26dcf89a","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/source/css/_highlight/highlight/diff.styl","hash":"cf1fae641c927621a4df1be5ca4a853b9b526e23","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/source/css/_highlight/highlight/index.styl","hash":"18804c58239d95798fa86d0597f32d7f7dd30051","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/source/css/_highlight/prismjs/index.styl","hash":"5dc2e0bcae9a54bfb9bdcc82d02ae5a3cf1ca97d","modified":1656409201230},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/share/share-js.pug","hash":"f61d63724ea5c5f352568b3a16bde023affefbe5","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/source/css/_highlight/prismjs/diff.styl","hash":"5972c61f5125068cbe0af279a0c93a54847fdc3b","modified":1656409201230},{"_id":"source/img/bg/banner.webp","hash":"365b38933dcfe641a370df16017aea6dddd3cee1","modified":1656409201250},{"_id":"source/img/bg/banner.gif","hash":"bb3261150b534f76eda7ece32c05fab1e53e265f","modified":1656406904184},{"_id":"source/img/code/talk_code_to_me.webp","hash":"a263e3b98ba7a56896369f97690882ce2f583691","modified":1656409201250},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/math/katex.pug","hash":"31b007dc0f3de52176f278012ecf17a4bcecde2c","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/math/index.pug","hash":"b8ae5fd7d74e1edcef21f5004fc96147e064d219","modified":1656409201240},{"_id":"node_modules/hexo-theme-butterfly/source/css/_highlight/prismjs/line-number.styl","hash":"8970cc1916c982b64a1478792b2822d1d31e276d","modified":1656409201230},{"_id":"source/img/bg/default.png","hash":"167a12978d80371cf578c8a2e45c24a2eb25b6fb","modified":1656409201250},{"_id":"source/doc/Flink+Hudi构建实时仓湖一体化.pdf","hash":"b3c11357ed7ef084450565db003b61676909c823","modified":1661063043286},{"_id":"public/css/background.css","hash":"2b0f6b7fdd3c8b341f9cff58fd66825b35f6defe","modified":1667299762835},{"_id":"public/css/custom.css","hash":"bf0872e7cd7c882a202342448e223b383ec2c2cf","modified":1667299762835},{"_id":"public/baidusitemap.xml","hash":"26a9877b6bd21bb4a91ff310d2c1e7313ff32400","modified":1667299762835},{"_id":"public/sitemap.xml","hash":"c585a89b84443d3b7272f18a416df8b8604bb98e","modified":1667299762835},{"_id":"public/sitemap.txt","hash":"7411708a4e8f86afbeb4d568f5c48380609e7510","modified":1667299762835},{"_id":"public/404.html","hash":"3ec4047f1479cdc0ca08eed3123c9d4abcbcb593","modified":1667299762835},{"_id":"public/about/index.html","hash":"5fa2200b2a89b61a91eeb4ec8d9de175a7196f44","modified":1667299762835},{"_id":"public/categories/index.html","hash":"48e4112f437f34cd6c8b84fe4adc45ae563a3514","modified":1667299762835},{"_id":"public/link/index.html","hash":"0c523b3179ae7d20279c12897a7a1d2ff311c8eb","modified":1667299762835},{"_id":"public/tags/index.html","hash":"5578312643e288300e169fbb4e5308b9fac1d1fa","modified":1667299762835},{"_id":"public/2022/11/bigdata/配置hadoop-snappy那些事/index.html","hash":"60cc16d4325109d94607fd1f0c6de35a1c8c516b","modified":1667299762835},{"_id":"public/2022/10/bigdata/Kyuubi-从入门到跑路/index.html","hash":"6c588e9ad1045df315685d7e2903eda1c0f7c539","modified":1667299762835},{"_id":"public/2022/10/os/文件与IO/index.html","hash":"8486fe4e6524fdfc3ee858bc561b4dacb5cbad38","modified":1667299762835},{"_id":"public/2022/10/os/虚拟内存/index.html","hash":"b312e66eb9ba3301f1b0b84d847f4e872825a300","modified":1667299762835},{"_id":"public/2022/09/bigdata/Doris大查询实践与优化/index.html","hash":"d53b45c8cdf8b6a2c2ad2170e0f6b43d498f2ba3","modified":1667299762835},{"_id":"public/2022/09/bigdata/Doris-Join最佳实践/index.html","hash":"00ac867b52033fd9f973ee0c328a5980061ac3e9","modified":1667299762835},{"_id":"public/2022/09/记一次Kylin-Server的JVM-OOM事故排查复盘/index.html","hash":"fee7ea63cb86968f2cceaee2186dbef1991d7f35","modified":1667299762835},{"_id":"public/2022/09/bigdata/Flink-SQL-Client与Hive集成问题指南/index.html","hash":"a490747926db4a1cab36a8fa1e53f87569b34a14","modified":1667299762835},{"_id":"public/2022/09/data-structure/从SS-Table到LSM-Tree/index.html","hash":"ea201a6b866824331528a949101d91cd1cdba6e5","modified":1667299762835},{"_id":"public/2022/09/bigdata/Doris Compaction从入门到跑路/index.html","hash":"090c0fca712a6a8dae31b0af9b2270b484c683f2","modified":1667299762835},{"_id":"public/2022/09/bigdata/When：何时需要进行Doris Compaction调优/index.html","hash":"a0a9671790725671be6de0ade6edfccf6250dbc8","modified":1667299762835},{"_id":"public/2022/08/rpc/thrift-从入门到放弃/index.html","hash":"5da2c234d0831cb21139637b629a7e8c9d0ec777","modified":1667299762835},{"_id":"public/2022/08/bigdata/doris性能优化（一）/index.html","hash":"72cc5f195b3a21b1e58dcd46e52b02b0384b6ca4","modified":1667299762835},{"_id":"public/2022/08/bigdata/通过Flink-SQL，将Kafka中的Oracle-CDC-Log同步到Doris/index.html","hash":"f1e390878a5f2575c4dae138161f4deef7d0a8c3","modified":1667299762835},{"_id":"public/2022/08/bigdata/初入Flink-Table@SQL/index.html","hash":"16309f87683e27f0b57ec032f60b01591671abb0","modified":1667299762835},{"_id":"public/2022/08/bigdata/Flink调优/index.html","hash":"0699549a4807446d3766712e9a2d7fcb8fb61085","modified":1667299762835},{"_id":"public/2022/08/bigdata/搭建Flink集群/index.html","hash":"19d772e5db5366ab3c64d6319c41d103c298c4e0","modified":1667299762835},{"_id":"public/2022/08/bigdata/Doris中的索引/index.html","hash":"a58744ec8132247a6e845ed7e126f8537e71e41f","modified":1667299762835},{"_id":"public/2022/08/bigdata/测试Flink-Doris-Connector/index.html","hash":"e2a24c1625f22f4ea88dd73efdd0a7986fc17b6a","modified":1667299762835},{"_id":"public/2022/07/bigdata/初识Doris/index.html","hash":"843159b74791bced8debb3331d8910a3b05cd2da","modified":1667299762835},{"_id":"public/2022/07/bigdata/用户画像介绍/index.html","hash":"e7cc1ccfff2f803fab418f3ce294ca8a63b416a8","modified":1667299762835},{"_id":"public/2022/07/bigdata/yarn公平和容量调度器的异同/index.html","hash":"f16d9f1b7f81f45c64d10a5392492cec3729bd5b","modified":1667299762835},{"_id":"public/2022/07/bigdata/HBase如何实现MVCC/index.html","hash":"804c60e5cf4df214decf801a7ada78a7c03c3e77","modified":1667299762835},{"_id":"public/2022/07/hexo/hexo不显示语雀图床CDN图片的解决办法/index.html","hash":"448dc923c4cbe254b71d5923f19087c15e462ae4","modified":1667299762835},{"_id":"public/2022/07/bigdata/一文搞懂Kudu的整体架构/index.html","hash":"c93e7dd974816d778f37b9fedfd6920ff3e30d87","modified":1667299762835},{"_id":"public/2022/06/hexo/从github恢复备份hexo博客hexo-git-backup/index.html","hash":"7f3cc776c3ff1bf3514c9e43cf1b76297bb8d27b","modified":1667299762835},{"_id":"public/2022/06/Hexo-github-pages-CloudFlare免费CDN最佳实践/index.html","hash":"679845f40da7b0f8b4b6b16512fb08cd65ba7034","modified":1667299762835},{"_id":"public/2022/06/SEO/index.html","hash":"d45a02e93907ed1d9251b8550806000ea4d6b8a3","modified":1667299762835},{"_id":"public/2022/06/DNS命令指南/index.html","hash":"feb5d93f3bc75f236fff20e142caf9d10a24b15d","modified":1667299762835},{"_id":"public/2022/06/hexo的front-matter中的分类问题/index.html","hash":"a64eaac9dd6dc418048fc799dbdb2ab498bcf6f1","modified":1667299762835},{"_id":"public/2022/06/WSL中的骚操作/index.html","hash":"f51979e46148b44248395c9e4ecfd75fa37648ab","modified":1667299762835},{"_id":"public/2022/06/hexo+freenom+cloudflare遇到的一些坑/index.html","hash":"a4061fe420886a24f03b7c5e9800b9d310846fea","modified":1667299762835},{"_id":"public/2022/06/zhihu-emo-yulu/index.html","hash":"7d5a2a5868afd19a1d7e723aa2e2433e508cbe85","modified":1667299762835},{"_id":"public/archives/index.html","hash":"4b5d378bac514734c614c535c63a5fa37830a18c","modified":1667299762835},{"_id":"public/archives/page/2/index.html","hash":"e9b8d7b714c14399cdc8f542e45edb3eeaf8fa3a","modified":1667299762835},{"_id":"public/archives/page/3/index.html","hash":"fe286ca3d014e3257660c1e3de91c63823d45e7d","modified":1667299762835},{"_id":"public/archives/page/4/index.html","hash":"304d811e8227f257db1a8671f0267d16f7ff5925","modified":1667299762835},{"_id":"public/archives/2022/index.html","hash":"fb581fa7a510f6d8d04e89f64b7d124c9d968fbb","modified":1667299762835},{"_id":"public/archives/2022/page/2/index.html","hash":"a68488a6995331510848e9aea6e324bd1a7a8d5c","modified":1667299762835},{"_id":"public/archives/2022/page/3/index.html","hash":"add967a56fedcb13182fb4ab1cf3f1fe8bfc5cfe","modified":1667299762835},{"_id":"public/archives/2022/page/4/index.html","hash":"375e150afe487f26d776e246781c1336f8cc030b","modified":1667299762835},{"_id":"public/archives/2022/06/index.html","hash":"aa0a178e803a0d012f88ef997997069cdcf7939b","modified":1667299762835},{"_id":"public/archives/2022/07/index.html","hash":"80240b68fff1cdf29bc4309df0949e4bccbca856","modified":1667299762835},{"_id":"public/archives/2022/08/index.html","hash":"9e941042a070362ec230a8354443d2c03403b871","modified":1667299762835},{"_id":"public/archives/2022/09/index.html","hash":"e5393778e34d600bd842fe5113c9fd238a60452a","modified":1667299762835},{"_id":"public/archives/2022/10/index.html","hash":"ab7a841ef71f0b5fe892febc339228637e62725f","modified":1667299762835},{"_id":"public/archives/2022/11/index.html","hash":"7a545e10dc3529c0a96ade7001375f1c95d61597","modified":1667299762835},{"_id":"public/categories/bigdata/index.html","hash":"c0b15896a2cc50b11fd5445b46b060a1f4df044e","modified":1667299762835},{"_id":"public/categories/bigdata/page/2/index.html","hash":"60d86359329a55e9fe2b820ded1e220c0b581f6d","modified":1667299762835},{"_id":"public/categories/dns/index.html","hash":"afb194f51f7524e8f7ea85034e5941cbc8e3b89f","modified":1667299762835},{"_id":"public/categories/hexo/index.html","hash":"fa36fa1b28902713809d8450aaa5f8f164bfc66a","modified":1667299762835},{"_id":"public/categories/SEO/index.html","hash":"449a1964384fc4ba7adac1211ae118ed85ab565c","modified":1667299762835},{"_id":"public/categories/Linux/index.html","hash":"65c7c86bd4717bb8d995e131eb115db467c819bb","modified":1667299762835},{"_id":"public/categories/linux/index.html","hash":"b436ac5bb72f5312091a94719864e913b4ba04f9","modified":1667299762835},{"_id":"public/categories/bigdata/Kylin/index.html","hash":"cc9c6041549a0ab2af60962b8c42cbcc9e372edd","modified":1667299762835},{"_id":"public/categories/Doris/index.html","hash":"004003430381dc11b4a366943795bb1f192b8491","modified":1667299762835},{"_id":"public/categories/bigdata/Doris/index.html","hash":"1aef3f5e2758d81ac3b89e076beaa5564feddbf7","modified":1667299762835},{"_id":"public/categories/bigdata/Flink/index.html","hash":"81db152447101f8a4cc5cef40d86cfe99e988bab","modified":1667299762835},{"_id":"public/categories/bigdata/HBase/index.html","hash":"72b5ca15638844cc37f3d7997c22b6acabd8253d","modified":1667299762835},{"_id":"public/categories/bigdata/Kyuubi/index.html","hash":"49d215729460f960825d77129a8f060027b8136f","modified":1667299762835},{"_id":"public/categories/bigdata/yarn/index.html","hash":"ee7d70ed5a0993173bceabdcd21666c277f92b28","modified":1667299762835},{"_id":"public/categories/bigdata/kudu/index.html","hash":"bbf4f75c9d1093f050085777cce63f3ffd33695a","modified":1667299762835},{"_id":"public/categories/bigdata/User-Profile/index.html","hash":"d855f49efddcc1fd0d8ebfc691b7815e1af4b39b","modified":1667299762835},{"_id":"public/categories/data-structure/index.html","hash":"0cdb2c6834bf1ed941aeadcdd000c30e5147b2c8","modified":1667299762835},{"_id":"public/categories/RPC/index.html","hash":"c006dc5f909eb243c86506b399ccdc83913efda6","modified":1667299762835},{"_id":"public/categories/os/index.html","hash":"2c32b9289d25d3a7970f2b79e974daf1e519634d","modified":1667299762835},{"_id":"public/categories/RPC/thrift/index.html","hash":"41a532e72fa9a0d7f6679265c86008ef22cad966","modified":1667299762835},{"_id":"public/index.html","hash":"9abe50a5b89027f3efdba4f9b4b3ee4c6fdaabf6","modified":1667299762835},{"_id":"public/page/2/index.html","hash":"03f65aae3323876cd3428efe350b254fe96901b1","modified":1667299762835},{"_id":"public/page/3/index.html","hash":"fa4e8c4d5485feb3bfbbeda48f2e0d77aa2c6bd9","modified":1667299762835},{"_id":"public/page/4/index.html","hash":"016bf55d95f216fb051dca6018cf94e9a452c6af","modified":1667299762835},{"_id":"public/tags/dns/index.html","hash":"9a217986e4ec0cf2848606d2ff19b034b969a909","modified":1667299762835},{"_id":"public/tags/CDN/index.html","hash":"3518000428452d5d3e946d8d8f0a2fc34c0bd229","modified":1667299762835},{"_id":"public/tags/hexo/index.html","hash":"77e422e71b8e3e3e8197b65cccf74ecf1fc2978e","modified":1667299762835},{"_id":"public/tags/cloudflare/index.html","hash":"c14afb639c588e7bbb2bc3a37541eb8e1654ac89","modified":1667299762835},{"_id":"public/tags/SEO/index.html","hash":"48a0c407ea137a38d3138844288097c8ee50c1bd","modified":1667299762835},{"_id":"public/tags/WSL/index.html","hash":"2cc0b60e9e1e35a0e844367b182938d4cc95c29e","modified":1667299762835},{"_id":"public/tags/Linxu/index.html","hash":"15f8be707f6cd0d2a84083a8d54d262067c2a788","modified":1667299762835},{"_id":"public/tags/github-pages/index.html","hash":"0e706c6ee69045fedea57ad9de6797b8da282ecf","modified":1667299762835},{"_id":"public/tags/CFW/index.html","hash":"a372a1c097d49685dfce0e8f40f54cb34c5d5c49","modified":1667299762835},{"_id":"public/tags/EMO语录/index.html","hash":"5dc05631a35ba3f486a866cf130bfd0870ed1cd3","modified":1667299762835},{"_id":"public/tags/Kylin/index.html","hash":"e89f3a3c9dcde33550961ef75ce5e4b7e87bdab4","modified":1667299762835},{"_id":"public/tags/JVM/index.html","hash":"9087458a0bfc881f10e3c223272bba0820f0c439","modified":1667299762835},{"_id":"public/tags/MAT/index.html","hash":"74a7ff4cda6f12f13c22d7fdcb1ae4eb188f5e56","modified":1667299762835},{"_id":"public/tags/Arthas/index.html","hash":"f65fc9625fc4db7740d58567bcf006c7f07a34ed","modified":1667299762835},{"_id":"public/tags/Doris/index.html","hash":"c6a4eb32a479347b35fa959b3731c44b191935ec","modified":1667299762835},{"_id":"public/tags/数据中台/index.html","hash":"667a2f36858edca5a2df12d1557c950001d4c036","modified":1667299762835},{"_id":"public/tags/Flink/index.html","hash":"300ae2c35d49db37d49a9f4f21a958f081ec6823","modified":1667299762835},{"_id":"public/tags/调优/index.html","hash":"c9bb563a5f45e0c6aa0c5232de274717526e03ac","modified":1667299762835},{"_id":"public/tags/HBase/index.html","hash":"cef35573ea341e8f0f424b53252d302cb9ab16b7","modified":1667299762835},{"_id":"public/tags/MVCC/index.html","hash":"3b5d2f4dda29f05fca34011f5a3def8d6f74ddd6","modified":1667299762835},{"_id":"public/tags/Kyuubi/index.html","hash":"08b3b6abe1c7c7da307f0dc753726dff5e176725","modified":1667299762835},{"_id":"public/tags/yarn/index.html","hash":"7ab5dd2822a68c27598e4e4c653df1871304e898","modified":1667299762835},{"_id":"public/tags/hadoop/index.html","hash":"d73d1f9da3bf0dcf8a2d100b6cfee156eb3f1579","modified":1667299762835},{"_id":"public/tags/kudu/index.html","hash":"f0f3eded81d30c289b7949ef93a0e2c5b5bb2522","modified":1667299762835},{"_id":"public/tags/用户画像/index.html","hash":"c8d43770788f04f1bc263e72c220f8d9e0bb4673","modified":1667299762835},{"_id":"public/tags/LSM-Tree/index.html","hash":"1c252e0d07145e803ba995153cbc46d9aeba29d1","modified":1667299762835},{"_id":"public/tags/thrift/index.html","hash":"4a69509dcf632a873783391cf99c9aaa86842fce","modified":1667299762835},{"_id":"public/tags/os/index.html","hash":"e57755312f35ad4e048a3bdcd83793b4242f481c","modified":1667299762835},{"_id":"public/script/1.jpg","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1667299762835},{"_id":"public/script/1.png","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1667299762835},{"_id":"public/img/404.jpg","hash":"fb4489bc1d30c93d28f7332158c1c6c1416148de","modified":1667299762835},{"_id":"public/img/favicon.png","hash":"3cf89864b4f6c9b532522a4d260a2e887971c92d","modified":1667299762835},{"_id":"public/img/friend_404.gif","hash":"8d2d0ebef70a8eb07329f57e645889b0e420fa48","modified":1667299762835},{"_id":"public/robots.txt","hash":"c443b65f80db1005b56899172a5e9451af639175","modified":1667299762835},{"_id":"public/CNAME","hash":"a44a2add0449f197dfcbdf8314c0005eb7e088d4","modified":1667299762835},{"_id":"public/img/animal1.jpg","hash":"e48cb3aeeb030ff094e35e61c52bbd73a662e0a5","modified":1667299762835},{"_id":"public/script/img-to-webp.sh","hash":"ade97b82a996d82be7b20693a4f95e9cba02592d","modified":1667299762835},{"_id":"public/script/img-webp.sh","hash":"b263a739e2c8f5acdb3c625d73e34d1e370079f2","modified":1667299762835},{"_id":"public/sitemap_template/sitemap_template.txt","hash":"cbb0b7198d37b808e6e9bf4bd389743c07f8cf17","modified":1667299762835},{"_id":"public/sitemap_template/sitemap_template.xml","hash":"94026f74ab00f4398ee57381b6c3eaff9d475d35","modified":1667299762835},{"_id":"public/img/bg/avatar.webp","hash":"253098016d490151a15192a99d73606607e2c15d","modified":1667299762835},{"_id":"public/img/bg/banner1.webp","hash":"24cfb05fcddfc300d9554b1e9d83e93282052300","modified":1667299762835},{"_id":"public/img/bg/clash.jpg","hash":"a0388a2acdb319902a1b9a45fc48a836d8f5d07d","modified":1667299762835},{"_id":"public/img/bg/index_img.png","hash":"8517f53cbd9416e8b8f16160936499b0b9c8b6dc","modified":1667299762835},{"_id":"public/img/bg/poxiao.jpg","hash":"dcdcaa64fa5817e52cef86ed69824e044105e3a7","modified":1667299762835},{"_id":"public/img/code/code.jpg","hash":"89b5ed059b850c72988b186751153e63bc3e9e6b","modified":1667299762835},{"_id":"public/img/code/linux.png","hash":"cad82d89247115c29cb88e60f03d229bb1e4e8cd","modified":1667299762835},{"_id":"public/img/img-link/img-link.txt","hash":"e5812babc02f71df9122496069016ed7b16e8168","modified":1667299762835},{"_id":"public/img/cat.png","hash":"764303a8a1ae8f7fa1fb6e9c21b852a5988882bb","modified":1667299762835},{"_id":"public/img/bg/banner2.webp","hash":"88377d64f128a09855066054fb74a290b0b26613","modified":1667299762835},{"_id":"public/img/bg/default_top_img.png","hash":"980912504113f64d6aaf5b99e9793b77d1511197","modified":1667299762835},{"_id":"public/img/bg/web-bg.webp","hash":"7902ecf0465380a7576910c92881f7d493cfe0dd","modified":1667299762835},{"_id":"public/img/cut/cdn-test-1.webp","hash":"e8a063916ee46e49941081c8c4d0e241eaa0bd9f","modified":1667299762835},{"_id":"public/img/cut/cdn-test-2.webp","hash":"a0121aa1ff44ecaba93ed3449b9a95ee0d9daf83","modified":1667299762835},{"_id":"public/css/var.css","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1667299762835},{"_id":"public/js/search/algolia.js","hash":"ce8131b712dca80f289015aef75f86e727f62981","modified":1667299762835},{"_id":"public/js/search/local-search.js","hash":"3071a4208fdf89ad7e0031536dd6ffa7bc951e4d","modified":1667299762835},{"_id":"public/js/utils.js","hash":"0b95daada72abb5d64a1e3236049a60120e47cca","modified":1667299762835},{"_id":"public/css/index.css","hash":"6fc9f09ffd41cd14b77c43000c3cdf2375a6b366","modified":1667299762835},{"_id":"public/js/main.js","hash":"04efcbd28b37875cfec88eb87cab7256a9ebb327","modified":1667299762835},{"_id":"public/js/tw_cn.js","hash":"00053ce73210274b3679f42607edef1206eebc68","modified":1667299762835},{"_id":"public/img/bg/banner.webp","hash":"365b38933dcfe641a370df16017aea6dddd3cee1","modified":1667299762835},{"_id":"public/img/bg/banner.gif","hash":"bb3261150b534f76eda7ece32c05fab1e53e265f","modified":1667299762835},{"_id":"public/img/code/talk_code_to_me.webp","hash":"a263e3b98ba7a56896369f97690882ce2f583691","modified":1667299762835},{"_id":"public/img/bg/default.png","hash":"167a12978d80371cf578c8a2e45c24a2eb25b6fb","modified":1667299762835},{"_id":"public/doc/Flink+Hudi构建实时仓湖一体化.pdf","hash":"b3c11357ed7ef084450565db003b61676909c823","modified":1667299762835}],"Category":[{"name":"bigdata","_id":"cl9y38drt0007fwuieqt2g39m"},{"name":"dns","_id":"cl9y38drx000dfwui54bt0vwh"},{"name":"hexo","_id":"cl9y38ds1000jfwuibc7zbrui"},{"name":"hudi","parent":"cl9y38drt0007fwuieqt2g39m","_id":"cl9y38ds4000ofwui4jfcd7w4"},{"name":"SEO","_id":"cl9y38ds7000ufwui15hb6p8f"},{"name":"Linux","_id":"cl9y38ds9000zfwuig1pggx5h"},{"name":"linux","_id":"cl9y38dsf001dfwui00d9gnzb"},{"name":"Kylin","parent":"cl9y38drt0007fwuieqt2g39m","_id":"cl9y38dsh001jfwuidp7c44ot"},{"name":"Doris","_id":"cl9y38dsk001pfwuib0m9dt13"},{"name":"Doris","parent":"cl9y38drt0007fwuieqt2g39m","_id":"cl9y38dsn001xfwui00vt63t3"},{"name":"Flink","parent":"cl9y38drt0007fwuieqt2g39m","_id":"cl9y38dsu002hfwui5vpe4ouq"},{"name":"HBase","parent":"cl9y38drt0007fwuieqt2g39m","_id":"cl9y38dt1002vfwui85hsdkhu"},{"name":"Kyuubi","parent":"cl9y38drt0007fwuieqt2g39m","_id":"cl9y38dt20030fwuif2983mr6"},{"name":"yarn","parent":"cl9y38drt0007fwuieqt2g39m","_id":"cl9y38dt5003efwuihcmb2d95"},{"name":"kudu","parent":"cl9y38drt0007fwuieqt2g39m","_id":"cl9y38dt7003lfwuicetu2n37"},{"name":"User-Profile","parent":"cl9y38drt0007fwuieqt2g39m","_id":"cl9y38dtb0045fwuib8da84or"},{"name":"data-structure","_id":"cl9y38dtd004ffwuiejmegwpi"},{"name":"RPC","_id":"cl9y38dte004lfwui9yfs6zen"},{"name":"os","_id":"cl9y38dtg004qfwui2fsy1g08"},{"name":"thrift","parent":"cl9y38dte004lfwui9yfs6zen","_id":"cl9y38dtg004vfwui15ur3yks"}],"Data":[{"_id":"link","data":[{"class_name":"友情链接","class_desc":"那些人，那些事","link_list":[{"name":"张洪Heo","link":"https://blog.zhheo.com/","avatar":"https://npm.elemecdn.com/guli-heo/img/avatar2.png","descr":"分享设计与科技生活"},{"name":"瞬間の筆記","link":"https://hikki.site","descr":"喜欢的东西就努力去追求，万一成功了呢!","avatar":"https://cdn.jsdelivr.net/gh/0000rookie/imgs/202206120315.png"}]}]}],"Page":[{"title":"关于","date":"2020-02-23T11:20:33.000Z","layout":"about","_content":"\n# 🎉🎉🎉关于博客\n\n本博客站点由**Hexo 、Github、Github Pages、ButterFly、Cloudflare、Freenom**等共同驱动，所用到的组件，不是开源就是免费，完全白嫖(￣▽￣)\"。\n\n因此国内的访问情况不容乐观 ! ! ! \n\n--------------------------------------------\n\n# 🎉🎉🎉关于我\n\n{% flink %}\n- class_name: \n  class_desc: \n  link_list:\n    - name: 破晓\n      link: https://poxiao.tk/\n      avatar: https://poxiao.tk/img/bg/avatar.webp\n      descr: 日拱一卒，功不唐捐\n      \n\n{% endflink %}\n\n-------------------------\n\n# 🎉🎉🎉博客备忘录\n- 添加Twikoo评论系统\n","source":"about/index.md","raw":"---\ntitle: 关于\ndate: 2020-02-23 19:20:33\nlayout: about\n---\n\n# 🎉🎉🎉关于博客\n\n本博客站点由**Hexo 、Github、Github Pages、ButterFly、Cloudflare、Freenom**等共同驱动，所用到的组件，不是开源就是免费，完全白嫖(￣▽￣)\"。\n\n因此国内的访问情况不容乐观 ! ! ! \n\n--------------------------------------------\n\n# 🎉🎉🎉关于我\n\n{% flink %}\n- class_name: \n  class_desc: \n  link_list:\n    - name: 破晓\n      link: https://poxiao.tk/\n      avatar: https://poxiao.tk/img/bg/avatar.webp\n      descr: 日拱一卒，功不唐捐\n      \n\n{% endflink %}\n\n-------------------------\n\n# 🎉🎉🎉博客备忘录\n- 添加Twikoo评论系统\n","updated":"2022-06-30T06:55:26.228Z","path":"about/index.html","comments":1,"_id":"cl9y38drf0000fwuihrmzfx4c","content":"<h1 id=\"🎉🎉🎉关于博客\"><a href=\"#🎉🎉🎉关于博客\" class=\"headerlink\" title=\"🎉🎉🎉关于博客\"></a>🎉🎉🎉关于博客</h1><p>本博客站点由<strong>Hexo 、Github、Github Pages、ButterFly、Cloudflare、Freenom</strong>等共同驱动，所用到的组件，不是开源就是免费，完全白嫖(￣▽￣)”。</p>\n<p>因此国内的访问情况不容乐观 ! ! ! </p>\n<hr>\n<h1 id=\"🎉🎉🎉关于我\"><a href=\"#🎉🎉🎉关于我\" class=\"headerlink\" title=\"🎉🎉🎉关于我\"></a>🎉🎉🎉关于我</h1><div class=\"flink\"> <div class=\"flink-list\">\n          <div class=\"flink-list-item\">\n            <a href=\"https://poxiao.tk/\" title=\"破晓\" target=\"_blank\">\n              <div class=\"flink-item-icon\">\n                <img class=\"no-lightbox\" src=\"https://poxiao.tk/img/bg/avatar.webp\" onerror='this.onerror=null;this.src=\"/img/friend_404.gif\"' alt=\"破晓\" />\n              </div>\n              <div class=\"flink-item-name\">破晓</div> \n              <div class=\"flink-item-desc\" title=\"日拱一卒，功不唐捐\">日拱一卒，功不唐捐</div>\n            </a>\n          </div></div></div>\n\n<hr>\n<h1 id=\"🎉🎉🎉博客备忘录\"><a href=\"#🎉🎉🎉博客备忘录\" class=\"headerlink\" title=\"🎉🎉🎉博客备忘录\"></a>🎉🎉🎉博客备忘录</h1><ul>\n<li>添加Twikoo评论系统</li>\n</ul>\n","site":{"data":{"link":[{"class_name":"友情链接","class_desc":"那些人，那些事","link_list":[{"name":"张洪Heo","link":"https://blog.zhheo.com/","avatar":"https://npm.elemecdn.com/guli-heo/img/avatar2.png","descr":"分享设计与科技生活"},{"name":"瞬間の筆記","link":"https://hikki.site","descr":"喜欢的东西就努力去追求，万一成功了呢!","avatar":"https://cdn.jsdelivr.net/gh/0000rookie/imgs/202206120315.png"}]}]}},"cover":"https://tvax3.sinaimg.cn/large/0084aYsLly1grnkfb3zyvj31hc0tndku.jpg","excerpt":"","more":"<h1 id=\"🎉🎉🎉关于博客\"><a href=\"#🎉🎉🎉关于博客\" class=\"headerlink\" title=\"🎉🎉🎉关于博客\"></a>🎉🎉🎉关于博客</h1><p>本博客站点由<strong>Hexo 、Github、Github Pages、ButterFly、Cloudflare、Freenom</strong>等共同驱动，所用到的组件，不是开源就是免费，完全白嫖(￣▽￣)”。</p>\n<p>因此国内的访问情况不容乐观 ! ! ! </p>\n<hr>\n<h1 id=\"🎉🎉🎉关于我\"><a href=\"#🎉🎉🎉关于我\" class=\"headerlink\" title=\"🎉🎉🎉关于我\"></a>🎉🎉🎉关于我</h1><div class=\"flink\"> <div class=\"flink-list\">\n          <div class=\"flink-list-item\">\n            <a href=\"https://poxiao.tk/\" title=\"破晓\" target=\"_blank\">\n              <div class=\"flink-item-icon\">\n                <img class=\"no-lightbox\" src=\"https://poxiao.tk/img/bg/avatar.webp\" onerror='this.onerror=null;this.src=\"/img/friend_404.gif\"' alt=\"破晓\" />\n              </div>\n              <div class=\"flink-item-name\">破晓</div> \n              <div class=\"flink-item-desc\" title=\"日拱一卒，功不唐捐\">日拱一卒，功不唐捐</div>\n            </a>\n          </div></div></div>\n\n<hr>\n<h1 id=\"🎉🎉🎉博客备忘录\"><a href=\"#🎉🎉🎉博客备忘录\" class=\"headerlink\" title=\"🎉🎉🎉博客备忘录\"></a>🎉🎉🎉博客备忘录</h1><ul>\n<li>添加Twikoo评论系统</li>\n</ul>\n"},{"title":"分类","date":"2022-06-25T12:12:38.000Z","type":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: 分类\ndate: 2022-06-25 20:12:38\ntype: \"categories\"\n---\n","updated":"2022-06-28T09:40:01.250Z","path":"categories/index.html","comments":1,"layout":"page","_id":"cl9y38drn0002fwuihb0y6uc7","content":"","site":{"data":{"link":[{"class_name":"友情链接","class_desc":"那些人，那些事","link_list":[{"name":"张洪Heo","link":"https://blog.zhheo.com/","avatar":"https://npm.elemecdn.com/guli-heo/img/avatar2.png","descr":"分享设计与科技生活"},{"name":"瞬間の筆記","link":"https://hikki.site","descr":"喜欢的东西就努力去追求，万一成功了呢!","avatar":"https://cdn.jsdelivr.net/gh/0000rookie/imgs/202206120315.png"}]}]}},"cover":"https://tvax3.sinaimg.cn/large/0084aYsLly1gnhmxy0hdlj31hc0u0gpt.jpg","excerpt":"","more":""},{"_content":"body {\n  background: linear-gradient(-45deg, #ee7752, #e73c7e, #23a6d5, #23d5ab);\n  background-size: 400% 400%;\n  animation: gradient 15s ease infinite;\n  height: 100vh;\n  background-attachment:fixed;\n}\t\n@keyframes gradient {\t\n  0% {\t\n    background-position: 0% 50%;\t\n  }\t\n  50% {\n    background-position: 100% 50%;\n  }\n  100% {\n    background-position: 0% 50%;\n  }\n}\n","source":"css/background.css","raw":"body {\n  background: linear-gradient(-45deg, #ee7752, #e73c7e, #23a6d5, #23d5ab);\n  background-size: 400% 400%;\n  animation: gradient 15s ease infinite;\n  height: 100vh;\n  background-attachment:fixed;\n}\t\n@keyframes gradient {\t\n  0% {\t\n    background-position: 0% 50%;\t\n  }\t\n  50% {\n    background-position: 100% 50%;\n  }\n  100% {\n    background-position: 0% 50%;\n  }\n}\n","date":"2022-06-30T10:34:15.569Z","updated":"2022-06-30T10:34:15.569Z","path":"css/background.css","layout":"false","title":"","comments":1,"_id":"cl9y38drr0005fwuifk6r1vxs","content":"body {\n  background: linear-gradient(-45deg, #ee7752, #e73c7e, #23a6d5, #23d5ab);\n  background-size: 400% 400%;\n  animation: gradient 15s ease infinite;\n  height: 100vh;\n  background-attachment:fixed;\n}\t\n@keyframes gradient {\t\n  0% {\t\n    background-position: 0% 50%;\t\n  }\t\n  50% {\n    background-position: 100% 50%;\n  }\n  100% {\n    background-position: 0% 50%;\n  }\n}\n","site":{"data":{"link":[{"class_name":"友情链接","class_desc":"那些人，那些事","link_list":[{"name":"张洪Heo","link":"https://blog.zhheo.com/","avatar":"https://npm.elemecdn.com/guli-heo/img/avatar2.png","descr":"分享设计与科技生活"},{"name":"瞬間の筆記","link":"https://hikki.site","descr":"喜欢的东西就努力去追求，万一成功了呢!","avatar":"https://cdn.jsdelivr.net/gh/0000rookie/imgs/202206120315.png"}]}]}},"cover":"https://tvax4.sinaimg.cn/large/0084aYsLgy1h3jum72m7kj31220e6jsc.jpg","excerpt":"","more":"body {\n  background: linear-gradient(-45deg, #ee7752, #e73c7e, #23a6d5, #23d5ab);\n  background-size: 400% 400%;\n  animation: gradient 15s ease infinite;\n  height: 100vh;\n  background-attachment:fixed;\n}\t\n@keyframes gradient {\t\n  0% {\t\n    background-position: 0% 50%;\t\n  }\t\n  50% {\n    background-position: 100% 50%;\n  }\n  100% {\n    background-position: 0% 50%;\n  }\n}\n"},{"_content":"#recent-posts>.recent-post-item,.layout_page>div:first-child:not(.recent-posts),.layout_post>#page,.layout_post>#post,.read-mode .layout_post>#post {\n    background: var(--light_bg_color)\n}\n\n#aside-content .card-widget {\n    background: var(--light_bg_color)\n}\n\n#web_bg {\n    background: linear-gradient(90deg,rgba(247,149,51,.1),rgba(243,112,85,.1) 15%,rgba(239,78,123,.1) 30%,rgba(161,102,171,.1) 44%,rgba(80,115,184,.1) 58%,rgba(16,152,173,.1) 72%,rgba(7,179,155,.1) 86%,rgba(109,186,130,.1))\n}\n\n#footer {\n    background: rgba(255,255,255,.15);\n    color: #000;\n    border-top-right-radius: 20px;\n    border-top-left-radius: 20px;\n    backdrop-filter: saturate(100%) blur(5px)\n}\n\n#footer::before {\n    background: rgba(255,255,255,.15)\n}\n\n#footer #footer-wrap {\n    color: var(--font-color)\n}\n\n#footer #footer-wrap a {\n    color: var(--font-color)\n}\n","source":"css/custom.css","raw":"#recent-posts>.recent-post-item,.layout_page>div:first-child:not(.recent-posts),.layout_post>#page,.layout_post>#post,.read-mode .layout_post>#post {\n    background: var(--light_bg_color)\n}\n\n#aside-content .card-widget {\n    background: var(--light_bg_color)\n}\n\n#web_bg {\n    background: linear-gradient(90deg,rgba(247,149,51,.1),rgba(243,112,85,.1) 15%,rgba(239,78,123,.1) 30%,rgba(161,102,171,.1) 44%,rgba(80,115,184,.1) 58%,rgba(16,152,173,.1) 72%,rgba(7,179,155,.1) 86%,rgba(109,186,130,.1))\n}\n\n#footer {\n    background: rgba(255,255,255,.15);\n    color: #000;\n    border-top-right-radius: 20px;\n    border-top-left-radius: 20px;\n    backdrop-filter: saturate(100%) blur(5px)\n}\n\n#footer::before {\n    background: rgba(255,255,255,.15)\n}\n\n#footer #footer-wrap {\n    color: var(--font-color)\n}\n\n#footer #footer-wrap a {\n    color: var(--font-color)\n}\n","date":"2022-06-30T06:56:27.808Z","updated":"2022-06-30T06:56:27.808Z","path":"css/custom.css","layout":"false","title":"","comments":1,"_id":"cl9y38dru0008fwui7bgs4c7g","content":"#recent-posts>.recent-post-item,.layout_page>div:first-child:not(.recent-posts),.layout_post>#page,.layout_post>#post,.read-mode .layout_post>#post {\n    background: var(--light_bg_color)\n}\n\n#aside-content .card-widget {\n    background: var(--light_bg_color)\n}\n\n#web_bg {\n    background: linear-gradient(90deg,rgba(247,149,51,.1),rgba(243,112,85,.1) 15%,rgba(239,78,123,.1) 30%,rgba(161,102,171,.1) 44%,rgba(80,115,184,.1) 58%,rgba(16,152,173,.1) 72%,rgba(7,179,155,.1) 86%,rgba(109,186,130,.1))\n}\n\n#footer {\n    background: rgba(255,255,255,.15);\n    color: #000;\n    border-top-right-radius: 20px;\n    border-top-left-radius: 20px;\n    backdrop-filter: saturate(100%) blur(5px)\n}\n\n#footer::before {\n    background: rgba(255,255,255,.15)\n}\n\n#footer #footer-wrap {\n    color: var(--font-color)\n}\n\n#footer #footer-wrap a {\n    color: var(--font-color)\n}\n","site":{"data":{"link":[{"class_name":"友情链接","class_desc":"那些人，那些事","link_list":[{"name":"张洪Heo","link":"https://blog.zhheo.com/","avatar":"https://npm.elemecdn.com/guli-heo/img/avatar2.png","descr":"分享设计与科技生活"},{"name":"瞬間の筆記","link":"https://hikki.site","descr":"喜欢的东西就努力去追求，万一成功了呢!","avatar":"https://cdn.jsdelivr.net/gh/0000rookie/imgs/202206120315.png"}]}]}},"cover":"https://tvax3.sinaimg.cn/large/0084aYsLly1grnkfb3zyvj31hc0tndku.jpg","excerpt":"","more":"#recent-posts>.recent-post-item,.layout_page>div:first-child:not(.recent-posts),.layout_post>#page,.layout_post>#post,.read-mode .layout_post>#post {\n    background: var(--light_bg_color)\n}\n\n#aside-content .card-widget {\n    background: var(--light_bg_color)\n}\n\n#web_bg {\n    background: linear-gradient(90deg,rgba(247,149,51,.1),rgba(243,112,85,.1) 15%,rgba(239,78,123,.1) 30%,rgba(161,102,171,.1) 44%,rgba(80,115,184,.1) 58%,rgba(16,152,173,.1) 72%,rgba(7,179,155,.1) 86%,rgba(109,186,130,.1))\n}\n\n#footer {\n    background: rgba(255,255,255,.15);\n    color: #000;\n    border-top-right-radius: 20px;\n    border-top-left-radius: 20px;\n    backdrop-filter: saturate(100%) blur(5px)\n}\n\n#footer::before {\n    background: rgba(255,255,255,.15)\n}\n\n#footer #footer-wrap {\n    color: var(--font-color)\n}\n\n#footer #footer-wrap a {\n    color: var(--font-color)\n}\n"},{"title":"友情链接","date":"2022-06-25T12:13:44.000Z","type":"link","_content":"\n\n------\n# 欢迎交换友链\n- 我的友链信息\n\n``` yml\n name: 破晓\n link: https://poxiao.tk/\n avatar: https://poxiao.tk/img/bg/avatar.webp\n descr: 日拱一卒，功不唐捐\n\n```\n","source":"link/index.md","raw":"---\ntitle: 友情链接\ndate: 2022-06-25 20:13:44\ntype: \"link\"\n---\n\n\n------\n# 欢迎交换友链\n- 我的友链信息\n\n``` yml\n name: 破晓\n link: https://poxiao.tk/\n avatar: https://poxiao.tk/img/bg/avatar.webp\n descr: 日拱一卒，功不唐捐\n\n```\n","updated":"2022-07-03T07:43:43.539Z","path":"link/index.html","comments":1,"layout":"page","_id":"cl9y38drv000afwui3ylrg4tl","content":"<hr>\n<h1 id=\"欢迎交换友链\"><a href=\"#欢迎交换友链\" class=\"headerlink\" title=\"欢迎交换友链\"></a>欢迎交换友链</h1><ul>\n<li>我的友链信息</li>\n</ul>\n<figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">name:</span> <span class=\"string\">破晓</span></span><br><span class=\"line\"><span class=\"attr\">link:</span> <span class=\"string\">https://poxiao.tk/</span></span><br><span class=\"line\"><span class=\"attr\">avatar:</span> <span class=\"string\">https://poxiao.tk/img/bg/avatar.webp</span></span><br><span class=\"line\"><span class=\"attr\">descr:</span> <span class=\"string\">日拱一卒，功不唐捐</span></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n","site":{"data":{"link":[{"class_name":"友情链接","class_desc":"那些人，那些事","link_list":[{"name":"张洪Heo","link":"https://blog.zhheo.com/","avatar":"https://npm.elemecdn.com/guli-heo/img/avatar2.png","descr":"分享设计与科技生活"},{"name":"瞬間の筆記","link":"https://hikki.site","descr":"喜欢的东西就努力去追求，万一成功了呢!","avatar":"https://cdn.jsdelivr.net/gh/0000rookie/imgs/202206120315.png"}]}]}},"cover":"https://tvax3.sinaimg.cn/large/0084aYsLly1grnkfb3zyvj31hc0tndku.jpg","excerpt":"","more":"<hr>\n<h1 id=\"欢迎交换友链\"><a href=\"#欢迎交换友链\" class=\"headerlink\" title=\"欢迎交换友链\"></a>欢迎交换友链</h1><ul>\n<li>我的友链信息</li>\n</ul>\n<figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">name:</span> <span class=\"string\">破晓</span></span><br><span class=\"line\"><span class=\"attr\">link:</span> <span class=\"string\">https://poxiao.tk/</span></span><br><span class=\"line\"><span class=\"attr\">avatar:</span> <span class=\"string\">https://poxiao.tk/img/bg/avatar.webp</span></span><br><span class=\"line\"><span class=\"attr\">descr:</span> <span class=\"string\">日拱一卒，功不唐捐</span></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n"},{"title":"标签","date":"2022-06-25T12:10:55.000Z","type":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: 标签\ndate: 2022-06-25 20:10:55\ntype: \"tags\"\n---\n","updated":"2022-06-28T09:40:01.250Z","path":"tags/index.html","comments":1,"layout":"page","_id":"cl9y38dry000ffwui57bubqkk","content":"","site":{"data":{"link":[{"class_name":"友情链接","class_desc":"那些人，那些事","link_list":[{"name":"张洪Heo","link":"https://blog.zhheo.com/","avatar":"https://npm.elemecdn.com/guli-heo/img/avatar2.png","descr":"分享设计与科技生活"},{"name":"瞬間の筆記","link":"https://hikki.site","descr":"喜欢的东西就努力去追求，万一成功了呢!","avatar":"https://cdn.jsdelivr.net/gh/0000rookie/imgs/202206120315.png"}]}]}},"cover":"https://tvax3.sinaimg.cn/large/0084aYsLly1grnkfb3zyvj31hc0tndku.jpg","excerpt":"","more":""}],"Post":[{"title":"Flink+Hudi构建实时仓湖一体化","top_img":"linear-gradient(20deg, #0062be, #925696, #cc426e, #fb0347)","date":"2022-08-21T06:22:15.000Z","updated":"2022-08-21T06:22:15.000Z","cover":"https://tvax4.sinaimg.cn/large/0084aYsLgy1h3jum72m7kj31220e6jsc.jpg","description":null,"keywords":null,"_content":"\n{% pdf /doc/Flink+Hudi构建实时仓湖一体化.pdf %}\n","source":"_drafts/Flink+Hudi构建实时仓湖一体化.md","raw":"---\ntitle: Flink+Hudi构建实时仓湖一体化\ntags:\n  - 'hudi'\ncategories:\n  - [bigdata,hudi]\ntop_img: 'linear-gradient(20deg, #0062be, #925696, #cc426e, #fb0347)'\ndate: 2022-08-21 14:22:15\nupdated: 2022-08-21 14:22:15\ncover:\ndescription:\nkeywords:\n---\n\n{% pdf /doc/Flink+Hudi构建实时仓湖一体化.pdf %}\n","slug":"Flink+Hudi构建实时仓湖一体化","published":0,"comments":1,"layout":"post","photos":[],"link":"","_id":"cl9y38dri0001fwuibowu94rx","content":"\n\n\t<div class=\"row\">\n    <embed src=\"/doc/Flink+Hudi构建实时仓湖一体化.pdf\" width=\"100%\" height=\"550\" type=\"application/pdf\">\n\t</div>\n\n\n\n","site":{"data":{"link":[{"class_name":"友情链接","class_desc":"那些人，那些事","link_list":[{"name":"张洪Heo","link":"https://blog.zhheo.com/","avatar":"https://npm.elemecdn.com/guli-heo/img/avatar2.png","descr":"分享设计与科技生活"},{"name":"瞬間の筆記","link":"https://hikki.site","descr":"喜欢的东西就努力去追求，万一成功了呢!","avatar":"https://cdn.jsdelivr.net/gh/0000rookie/imgs/202206120315.png"}]}]}},"excerpt":"","more":"\n\n\t<div class=\"row\">\n    <embed src=\"/doc/Flink+Hudi构建实时仓湖一体化.pdf\" width=\"100%\" height=\"550\" type=\"application/pdf\">\n\t</div>\n\n\n\n"},{"title":"配置hadoop native lib和snappy压缩遇到的问题","date":"2022-10-16T10:48:59.000Z","updated":"2022-10-16T10:48:59.000Z","cover":"https://tvax4.sinaimg.cn/large/0084aYsLgy1h3jum72m7kj31220e6jsc.jpg","top_img":null,"description":null,"keywords":null,"_content":"\n\n\n- `Unable to load native-hadoop library``\n\n  `2022-10-16 18:04:07.991 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable`\n\n添加环境变量：`export LD_LIBRARY_PATH=$HADOOP_HOME/lib/native`\n\n- 执行hadoop本地库检查` hadoop checknative -a`报错:`ERROR snappy.SnappyCompressor: failed to load SnappyCompressor`\n\n  安装snappy本地库，执行：`sudo apt install libsnappy-dev`\n","source":"_drafts/hadoop-native-lib和snappy.md","raw":"---\ntitle: 配置hadoop native lib和snappy压缩遇到的问题\ntags:\n  - ''\ncategories:\n  - []\ndate: 2022-10-16 18:48:59\nupdated: 2022-10-16 18:48:59\ncover:\ntop_img:\ndescription:\nkeywords:\n---\n\n\n\n- `Unable to load native-hadoop library``\n\n  `2022-10-16 18:04:07.991 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable`\n\n添加环境变量：`export LD_LIBRARY_PATH=$HADOOP_HOME/lib/native`\n\n- 执行hadoop本地库检查` hadoop checknative -a`报错:`ERROR snappy.SnappyCompressor: failed to load SnappyCompressor`\n\n  安装snappy本地库，执行：`sudo apt install libsnappy-dev`\n","slug":"hadoop-native-lib和snappy","published":0,"comments":1,"layout":"post","photos":[],"link":"","_id":"cl9y38drn0003fwuibkch8w7t","content":"<ul>\n<li><p>&#96;Unable to load native-hadoop library&#96;&#96;</p>\n<p><code>2022-10-16 18:04:07.991 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</code></p>\n</li>\n</ul>\n<p>添加环境变量：<code>export LD_LIBRARY_PATH=$HADOOP_HOME/lib/native</code></p>\n<ul>\n<li><p>执行hadoop本地库检查<code> hadoop checknative -a</code>报错:<code>ERROR snappy.SnappyCompressor: failed to load SnappyCompressor</code></p>\n<p>安装snappy本地库，执行：<code>sudo apt install libsnappy-dev</code></p>\n</li>\n</ul>\n","site":{"data":{"link":[{"class_name":"友情链接","class_desc":"那些人，那些事","link_list":[{"name":"张洪Heo","link":"https://blog.zhheo.com/","avatar":"https://npm.elemecdn.com/guli-heo/img/avatar2.png","descr":"分享设计与科技生活"},{"name":"瞬間の筆記","link":"https://hikki.site","descr":"喜欢的东西就努力去追求，万一成功了呢!","avatar":"https://cdn.jsdelivr.net/gh/0000rookie/imgs/202206120315.png"}]}]}},"excerpt":"","more":"<ul>\n<li><p>&#96;Unable to load native-hadoop library&#96;&#96;</p>\n<p><code>2022-10-16 18:04:07.991 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</code></p>\n</li>\n</ul>\n<p>添加环境变量：<code>export LD_LIBRARY_PATH=$HADOOP_HOME/lib/native</code></p>\n<ul>\n<li><p>执行hadoop本地库检查<code> hadoop checknative -a</code>报错:<code>ERROR snappy.SnappyCompressor: failed to load SnappyCompressor</code></p>\n<p>安装snappy本地库，执行：<code>sudo apt install libsnappy-dev</code></p>\n</li>\n</ul>\n"},{"title":"DNS命令指南。怎么验证是否遭遇DNS污染？查看域名是否解析成功？","cover":"https://tva3.sinaimg.cn/large/0084aYsLgy1h22161jezaj30xc0f0dh1.jpg","top_img":null,"date":"2022-06-27T10:24:43.000Z","updated":"2022-06-27T10:24:43.000Z","description":null,"keywords":"DNS","_content":"\n# DNS指南\n\n## 查询DNS服务器\n\n- linux：```cat /etc/resolv.conf``` \n\n- windows: ipconfig /all\n\n  ```\n  PS C:\\Users\\sssbb> ipconfig /all\n  \n  Windows IP 配置\n  \n     主机名  . . . . . . . . . . . . . : DESKTOP-KD33OT8\n     主 DNS 后缀 . . . . . . . . . . . :\n     节点类型  . . . . . . . . . . . . : 混合\n     IP 路由已启用 . . . . . . . . . . : 否\n     WINS 代理已启用 . . . . . . . . . : 否\n  \n  未知适配器 Clash:\n  \n     连接特定的 DNS 后缀 . . . . . . . :\n     描述. . . . . . . . . . . . . . . : Clash Tunnel\n     物理地址. . . . . . . . . . . . . :\n     DHCP 已启用 . . . . . . . . . . . : 否\n     自动配置已启用. . . . . . . . . . : 是\n     IPv4 地址 . . . . . . . . . . . . : 198.18.0.1(首选)\n     子网掩码  . . . . . . . . . . . . : 255.255.0.0\n     默认网关. . . . . . . . . . . . . :\n     DNS 服务器  . . . . . . . . . . . : 198.18.0.2\n     TCPIP 上的 NetBIOS  . . . . . . . : 已启用\n  \n  无线局域网适配器 本地连接* 1:\n  \n     媒体状态  . . . . . . . . . . . . : 媒体已断开连接\n     连接特定的 DNS 后缀 . . . . . . . :\n     描述. . . . . . . . . . . . . . . : Microsoft Wi-Fi Direct Virtual Adapter\n     物理地址. . . . . . . . . . . . . : 1A-4F-32-F7-BE-99\n     DHCP 已启用 . . . . . . . . . . . : 是\n     自动配置已启用. . . . . . . . . . : 是\n  \n  无线局域网适配器 本地连接* 10:\n  \n     媒体状态  . . . . . . . . . . . . : 媒体已断开连接\n     连接特定的 DNS 后缀 . . . . . . . :\n     描述. . . . . . . . . . . . . . . : Microsoft Wi-Fi Direct Virtual Adapter #2\n     物理地址. . . . . . . . . . . . . : 1A-4F-32-F7-B6-99\n     DHCP 已启用 . . . . . . . . . . . : 是\n     自动配置已启用. . . . . . . . . . : 是\n  \n  无线局域网适配器 WLAN:\n  \n     连接特定的 DNS 后缀 . . . . . . . :\n     描述. . . . . . . . . . . . . . . : Dell Wireless 1830 802.11ac\n     物理地址. . . . . . . . . . . . . : 18-4F-32-F7-BE-99\n     DHCP 已启用 . . . . . . . . . . . : 是\n     自动配置已启用. . . . . . . . . . : 是\n     本地链接 IPv6 地址. . . . . . . . : fe80::5d17:d6:2915:d43c%3(首选)\n     IPv4 地址 . . . . . . . . . . . . : 192.168.31.250(首选)\n     子网掩码  . . . . . . . . . . . . : 255.255.255.0\n     获得租约的时间  . . . . . . . . . : 2022年6月27日 13:00:31\n     租约过期的时间  . . . . . . . . . : 2022年6月28日 1:00:34\n     默认网关. . . . . . . . . . . . . : 192.168.31.1\n     DHCP 服务器 . . . . . . . . . . . : 192.168.31.1\n     DHCPv6 IAID . . . . . . . . . . . : 51924786\n     DHCPv6 客户端 DUID  . . . . . . . : 00-01-00-01-2A-3F-FD-A1-18-4F-32-F7-BE-99\n     DNS 服务器  . . . . . . . . . . . : 192.168.31.1\n     TCPIP 上的 NetBIOS  . . . . . . . : 已启用\n  \n  以太网适配器 蓝牙网络连接:\n  \n     媒体状态  . . . . . . . . . . . . : 媒体已断开连接\n     连接特定的 DNS 后缀 . . . . . . . :\n     描述. . . . . . . . . . . . . . . : Bluetooth Device (Personal Area Network)\n     物理地址. . . . . . . . . . . . . : 18-4F-32-F7-BE-9A\n     DHCP 已启用 . . . . . . . . . . . : 是\n     自动配置已启用. . . . . . . . . . : 是\n  \n  以太网适配器 vEthernet (WSL):\n  \n     连接特定的 DNS 后缀 . . . . . . . :\n     描述. . . . . . . . . . . . . . . : Hyper-V Virtual Ethernet Adapter\n     物理地址. . . . . . . . . . . . . : 00-15-5D-5C-2A-EA\n     DHCP 已启用 . . . . . . . . . . . : 否\n     自动配置已启用. . . . . . . . . . : 是\n     本地链接 IPv6 地址. . . . . . . . : fe80::d82d:5ba6:7b4b:9023%40(首选)\n     IPv4 地址 . . . . . . . . . . . . : 172.17.112.1(首选)\n     子网掩码  . . . . . . . . . . . . : 255.255.240.0\n     默认网关. . . . . . . . . . . . . :\n     DHCPv6 IAID . . . . . . . . . . . : 671094109\n     DHCPv6 客户端 DUID  . . . . . . . : 00-01-00-01-2A-3F-FD-A1-18-4F-32-F7-BE-99\n     DNS 服务器  . . . . . . . . . . . : fec0:0:0:ffff::1%1\n                                         fec0:0:0:ffff::2%1\n                                         fec0:0:0:ffff::3%1\n     TCPIP 上的 NetBIOS  . . . . . . . : 已启用\n  ```\n\n   \n\n## 查看域名是否解析成功：\n\n- 可以直接ping域名，也可以使用nslookup命令（NameServer Lookup）\n\n- 在用 nslookup 查询一个域名时，可能会看到有“非权威应答” 的提示，非权威应答（Non-authoritative answer）意味着answer来自于其他服务器的缓存，而不是权威的服务器（就是该域名配置的DNS解析服务器，如果你的域名解析配置在CF的DNS上，则权威服务器，就是CF的DNS）。缓存会根据 ttl（Time to Live）的值定时的进行更新。\n\n  ```\n  ➜  hexo-blog nslookup wohensha.tk 8.8.8.8\n  Server:         8.8.8.8\n  Address:        8.8.8.8#53\n  \n  Non-authoritative answer:\n  Name:   wohensha.tk\n  Address: 104.21.49.190\n  Name:   wohensha.tk\n  Address: 172.67.165.231\n  Name:   wohensha.tk\n  Address: 2606:4700:3031::ac43:a5e7\n  Name:   wohensha.tk\n  Address: 2606:4700:3031::6815:31be\n  ```\n\n- sds查找权威名字服务器\n\n  ```\n  ➜  hexo-blog nslookup -ty=ns clashdingyue.tk\n  Server:         172.17.112.1\n  Address:        172.17.112.1#53\n  \n  Non-authoritative answer:\n  clashdingyue.tk nameserver = ns04.freenom.com.\n  clashdingyue.tk nameserver = ns02.freenom.com.\n  clashdingyue.tk nameserver = ns01.freenom.com.\n  clashdingyue.tk nameserver = ns03.freenom.com.\n  \n  Authoritative answers can be found from:\n  \n  ➜  hexo-blog nslookup -ty=ns clashdingyue.tk ns04.freenom.com\n  Server:         ns04.freenom.com\n  Address:        104.155.29.241#53\n  \n  clashdingyue.tk nameserver = ns04.freenom.com.\n  clashdingyue.tk nameserver = ns03.freenom.com.\n  clashdingyue.tk nameserver = ns02.freenom.com.\n  clashdingyue.tk nameserver = ns01.freenom.com.\n  ```\n\n\n\n# 一些小技巧\n\n### 怎么验证是否遭遇DNS污染？\n\n​\t\t**DNS污染**即网域服务器缓存污染，又称域名服务器缓存投毒，是指一些刻意制造或无意中制造出来的域名服务器数据包，把域名指往不正确的IP地址。一般来说，在互联网上都有可信赖的网域服务器，但为减低网络上的流量压力，一般的域名服务器都会把从上游的域名服务器获得的解析记录暂存起来，待下次有其他机器要求解析域名时，可以立即提供服务。一旦有关网域的局域域名服务器的缓存受到污染，就会把网域内的计算机导引往错误的服务器。\n\n   \t我们应该怎么去验证自己域名是否遭遇DNS污染呢？输入命令dig +trace clashdingyue.tk（您自己需要检测域名）。**如果域名未被污染我们会得到权威DNS的应答**，如下所示:\n\n```cobol\n➜  hexo-blog dig +trace clashdingyue.tk\n;; Warning: Client COOKIE mismatch\n\n; <<>> DiG 9.16.1-Ubuntu <<>> +trace clashdingyue.tk\n;; global options: +cmd\n.                       200     IN      NS      g.root-servers.net.\n.                       200     IN      NS      j.root-servers.net.\n.                       200     IN      NS      d.root-servers.net.\n.                       200     IN      NS      h.root-servers.net.\n.                       200     IN      NS      m.root-servers.net.\n.                       200     IN      NS      k.root-servers.net.\n.                       200     IN      NS      a.root-servers.net.\n.                       200     IN      NS      i.root-servers.net.\n.                       200     IN      NS      b.root-servers.net.\n.                       200     IN      NS      f.root-servers.net.\n.                       200     IN      NS      c.root-servers.net.\n.                       200     IN      NS      l.root-servers.net.\n.                       200     IN      NS      e.root-servers.net.\n;; Received 443 bytes from 172.17.112.1#53(172.17.112.1) in 840 ms\n\ntk.                     172800  IN      NS      a.ns.tk.\ntk.                     172800  IN      NS      b.ns.tk.\ntk.                     172800  IN      NS      c.ns.tk.\ntk.                     172800  IN      NS      d.ns.tk.\ntk.                     86400   IN      NSEC    tkmaxx. NS RRSIG NSEC\ntk.                     86400   IN      RRSIG   NSEC 8 1 86400 20220710050000 20220627040000 47671 . HwO7QYzt3lI0k1w10qjM7oUf0B71yWgbUu9yCPcUdUng1icIu0lXSebp thdZpvOpLrjTE461RZJSlYaKIPavphtjpQHnUVxlH3Qznw9cBhql9Qnx cEtMo7vlCkCRST9sojkQxRqFW1oQMOoGG1j+SWpejRYwaudILcDCl0bP 4nPu1t5KmGR3Q8DKKO075O69w8MTauU+yfOsxEPvYgmHGzIyU7pBMWyt sUA+5ZpnrQ+0KLcXxnpUPQpBb55RlO1PhRqlJ9bT8qfYfvT+QUL5alwl xJxyZVcLTlGrpggW76yWjN3gq3zzynmd3D5cGeFQSon1+qMR5i6LoQix b4Jycg==\n;; Received 602 bytes from 193.0.14.129#53(k.root-servers.net) in 350 ms\n\nclashdingyue.tk.        300     IN      NS      ns01.freenom.com.\nclashdingyue.tk.        300     IN      NS      ns02.freenom.com.\nclashdingyue.tk.        300     IN      NS      ns03.freenom.com.\nclashdingyue.tk.        300     IN      NS      ns04.freenom.com.\n;; Received 131 bytes from 194.0.41.1#53(d.ns.tk) in 330 ms\n\nclashdingyue.tk.        3600    IN      A       185.199.108.153\nclashdingyue.tk.        3600    IN      A       185.199.110.153\nclashdingyue.tk.        3600    IN      A       185.199.109.153\nclashdingyue.tk.        3600    IN      A       185.199.111.153\nclashdingyue.tk.        300     IN      NS      ns03.freenom.com.\nclashdingyue.tk.        300     IN      NS      ns04.freenom.com.\nclashdingyue.tk.        300     IN      NS      ns02.freenom.com.\nclashdingyue.tk.        300     IN      NS      ns01.freenom.com.\n;; Received 248 bytes from 54.171.131.39#53(ns01.freenom.com) in 470 ms\n```\n\n**如果域名被污染会直接到的一个IP，并不会向权威DNS请求。**如下所示：\n\n```\n➜  hexo-blog dig +trace google.com\n;; Warning: Client COOKIE mismatch\n\n; <<>> DiG 9.16.1-Ubuntu <<>> +trace google.com\n;; global options: +cmd\n.                       1450    IN      NS      f.root-servers.net.\n.                       1450    IN      NS      k.root-servers.net.\n.                       1450    IN      NS      d.root-servers.net.\n.                       1450    IN      NS      j.root-servers.net.\n.                       1450    IN      NS      l.root-servers.net.\n.                       1450    IN      NS      m.root-servers.net.\n.                       1450    IN      NS      h.root-servers.net.\n.                       1450    IN      NS      i.root-servers.net.\n.                       1450    IN      NS      e.root-servers.net.\n.                       1450    IN      NS      c.root-servers.net.\n.                       1450    IN      NS      a.root-servers.net.\n.                       1450    IN      NS      b.root-servers.net.\n.                       1450    IN      NS      g.root-servers.net.\n;; Received 443 bytes from 172.17.112.1#53(172.17.112.1) in 840 ms\n\ngoogle.com.             60      IN      A       8.7.198.46\n;; Received 54 bytes from 192.33.4.12#53(c.root-servers.net) in 20 ms\n```\n\n","source":"_posts/DNS命令指南.md","raw":"---\ntitle: DNS命令指南。怎么验证是否遭遇DNS污染？查看域名是否解析成功？\ntags:\n  - dns\ncategories:\n  - [dns]\n  - [linux]\ncover: \ntop_img: \ndate: 2022-06-27 18:24:43\nupdated: 2022-06-27 18:24:43\ndescription:\nkeywords: DNS\n---\n\n# DNS指南\n\n## 查询DNS服务器\n\n- linux：```cat /etc/resolv.conf``` \n\n- windows: ipconfig /all\n\n  ```\n  PS C:\\Users\\sssbb> ipconfig /all\n  \n  Windows IP 配置\n  \n     主机名  . . . . . . . . . . . . . : DESKTOP-KD33OT8\n     主 DNS 后缀 . . . . . . . . . . . :\n     节点类型  . . . . . . . . . . . . : 混合\n     IP 路由已启用 . . . . . . . . . . : 否\n     WINS 代理已启用 . . . . . . . . . : 否\n  \n  未知适配器 Clash:\n  \n     连接特定的 DNS 后缀 . . . . . . . :\n     描述. . . . . . . . . . . . . . . : Clash Tunnel\n     物理地址. . . . . . . . . . . . . :\n     DHCP 已启用 . . . . . . . . . . . : 否\n     自动配置已启用. . . . . . . . . . : 是\n     IPv4 地址 . . . . . . . . . . . . : 198.18.0.1(首选)\n     子网掩码  . . . . . . . . . . . . : 255.255.0.0\n     默认网关. . . . . . . . . . . . . :\n     DNS 服务器  . . . . . . . . . . . : 198.18.0.2\n     TCPIP 上的 NetBIOS  . . . . . . . : 已启用\n  \n  无线局域网适配器 本地连接* 1:\n  \n     媒体状态  . . . . . . . . . . . . : 媒体已断开连接\n     连接特定的 DNS 后缀 . . . . . . . :\n     描述. . . . . . . . . . . . . . . : Microsoft Wi-Fi Direct Virtual Adapter\n     物理地址. . . . . . . . . . . . . : 1A-4F-32-F7-BE-99\n     DHCP 已启用 . . . . . . . . . . . : 是\n     自动配置已启用. . . . . . . . . . : 是\n  \n  无线局域网适配器 本地连接* 10:\n  \n     媒体状态  . . . . . . . . . . . . : 媒体已断开连接\n     连接特定的 DNS 后缀 . . . . . . . :\n     描述. . . . . . . . . . . . . . . : Microsoft Wi-Fi Direct Virtual Adapter #2\n     物理地址. . . . . . . . . . . . . : 1A-4F-32-F7-B6-99\n     DHCP 已启用 . . . . . . . . . . . : 是\n     自动配置已启用. . . . . . . . . . : 是\n  \n  无线局域网适配器 WLAN:\n  \n     连接特定的 DNS 后缀 . . . . . . . :\n     描述. . . . . . . . . . . . . . . : Dell Wireless 1830 802.11ac\n     物理地址. . . . . . . . . . . . . : 18-4F-32-F7-BE-99\n     DHCP 已启用 . . . . . . . . . . . : 是\n     自动配置已启用. . . . . . . . . . : 是\n     本地链接 IPv6 地址. . . . . . . . : fe80::5d17:d6:2915:d43c%3(首选)\n     IPv4 地址 . . . . . . . . . . . . : 192.168.31.250(首选)\n     子网掩码  . . . . . . . . . . . . : 255.255.255.0\n     获得租约的时间  . . . . . . . . . : 2022年6月27日 13:00:31\n     租约过期的时间  . . . . . . . . . : 2022年6月28日 1:00:34\n     默认网关. . . . . . . . . . . . . : 192.168.31.1\n     DHCP 服务器 . . . . . . . . . . . : 192.168.31.1\n     DHCPv6 IAID . . . . . . . . . . . : 51924786\n     DHCPv6 客户端 DUID  . . . . . . . : 00-01-00-01-2A-3F-FD-A1-18-4F-32-F7-BE-99\n     DNS 服务器  . . . . . . . . . . . : 192.168.31.1\n     TCPIP 上的 NetBIOS  . . . . . . . : 已启用\n  \n  以太网适配器 蓝牙网络连接:\n  \n     媒体状态  . . . . . . . . . . . . : 媒体已断开连接\n     连接特定的 DNS 后缀 . . . . . . . :\n     描述. . . . . . . . . . . . . . . : Bluetooth Device (Personal Area Network)\n     物理地址. . . . . . . . . . . . . : 18-4F-32-F7-BE-9A\n     DHCP 已启用 . . . . . . . . . . . : 是\n     自动配置已启用. . . . . . . . . . : 是\n  \n  以太网适配器 vEthernet (WSL):\n  \n     连接特定的 DNS 后缀 . . . . . . . :\n     描述. . . . . . . . . . . . . . . : Hyper-V Virtual Ethernet Adapter\n     物理地址. . . . . . . . . . . . . : 00-15-5D-5C-2A-EA\n     DHCP 已启用 . . . . . . . . . . . : 否\n     自动配置已启用. . . . . . . . . . : 是\n     本地链接 IPv6 地址. . . . . . . . : fe80::d82d:5ba6:7b4b:9023%40(首选)\n     IPv4 地址 . . . . . . . . . . . . : 172.17.112.1(首选)\n     子网掩码  . . . . . . . . . . . . : 255.255.240.0\n     默认网关. . . . . . . . . . . . . :\n     DHCPv6 IAID . . . . . . . . . . . : 671094109\n     DHCPv6 客户端 DUID  . . . . . . . : 00-01-00-01-2A-3F-FD-A1-18-4F-32-F7-BE-99\n     DNS 服务器  . . . . . . . . . . . : fec0:0:0:ffff::1%1\n                                         fec0:0:0:ffff::2%1\n                                         fec0:0:0:ffff::3%1\n     TCPIP 上的 NetBIOS  . . . . . . . : 已启用\n  ```\n\n   \n\n## 查看域名是否解析成功：\n\n- 可以直接ping域名，也可以使用nslookup命令（NameServer Lookup）\n\n- 在用 nslookup 查询一个域名时，可能会看到有“非权威应答” 的提示，非权威应答（Non-authoritative answer）意味着answer来自于其他服务器的缓存，而不是权威的服务器（就是该域名配置的DNS解析服务器，如果你的域名解析配置在CF的DNS上，则权威服务器，就是CF的DNS）。缓存会根据 ttl（Time to Live）的值定时的进行更新。\n\n  ```\n  ➜  hexo-blog nslookup wohensha.tk 8.8.8.8\n  Server:         8.8.8.8\n  Address:        8.8.8.8#53\n  \n  Non-authoritative answer:\n  Name:   wohensha.tk\n  Address: 104.21.49.190\n  Name:   wohensha.tk\n  Address: 172.67.165.231\n  Name:   wohensha.tk\n  Address: 2606:4700:3031::ac43:a5e7\n  Name:   wohensha.tk\n  Address: 2606:4700:3031::6815:31be\n  ```\n\n- sds查找权威名字服务器\n\n  ```\n  ➜  hexo-blog nslookup -ty=ns clashdingyue.tk\n  Server:         172.17.112.1\n  Address:        172.17.112.1#53\n  \n  Non-authoritative answer:\n  clashdingyue.tk nameserver = ns04.freenom.com.\n  clashdingyue.tk nameserver = ns02.freenom.com.\n  clashdingyue.tk nameserver = ns01.freenom.com.\n  clashdingyue.tk nameserver = ns03.freenom.com.\n  \n  Authoritative answers can be found from:\n  \n  ➜  hexo-blog nslookup -ty=ns clashdingyue.tk ns04.freenom.com\n  Server:         ns04.freenom.com\n  Address:        104.155.29.241#53\n  \n  clashdingyue.tk nameserver = ns04.freenom.com.\n  clashdingyue.tk nameserver = ns03.freenom.com.\n  clashdingyue.tk nameserver = ns02.freenom.com.\n  clashdingyue.tk nameserver = ns01.freenom.com.\n  ```\n\n\n\n# 一些小技巧\n\n### 怎么验证是否遭遇DNS污染？\n\n​\t\t**DNS污染**即网域服务器缓存污染，又称域名服务器缓存投毒，是指一些刻意制造或无意中制造出来的域名服务器数据包，把域名指往不正确的IP地址。一般来说，在互联网上都有可信赖的网域服务器，但为减低网络上的流量压力，一般的域名服务器都会把从上游的域名服务器获得的解析记录暂存起来，待下次有其他机器要求解析域名时，可以立即提供服务。一旦有关网域的局域域名服务器的缓存受到污染，就会把网域内的计算机导引往错误的服务器。\n\n   \t我们应该怎么去验证自己域名是否遭遇DNS污染呢？输入命令dig +trace clashdingyue.tk（您自己需要检测域名）。**如果域名未被污染我们会得到权威DNS的应答**，如下所示:\n\n```cobol\n➜  hexo-blog dig +trace clashdingyue.tk\n;; Warning: Client COOKIE mismatch\n\n; <<>> DiG 9.16.1-Ubuntu <<>> +trace clashdingyue.tk\n;; global options: +cmd\n.                       200     IN      NS      g.root-servers.net.\n.                       200     IN      NS      j.root-servers.net.\n.                       200     IN      NS      d.root-servers.net.\n.                       200     IN      NS      h.root-servers.net.\n.                       200     IN      NS      m.root-servers.net.\n.                       200     IN      NS      k.root-servers.net.\n.                       200     IN      NS      a.root-servers.net.\n.                       200     IN      NS      i.root-servers.net.\n.                       200     IN      NS      b.root-servers.net.\n.                       200     IN      NS      f.root-servers.net.\n.                       200     IN      NS      c.root-servers.net.\n.                       200     IN      NS      l.root-servers.net.\n.                       200     IN      NS      e.root-servers.net.\n;; Received 443 bytes from 172.17.112.1#53(172.17.112.1) in 840 ms\n\ntk.                     172800  IN      NS      a.ns.tk.\ntk.                     172800  IN      NS      b.ns.tk.\ntk.                     172800  IN      NS      c.ns.tk.\ntk.                     172800  IN      NS      d.ns.tk.\ntk.                     86400   IN      NSEC    tkmaxx. NS RRSIG NSEC\ntk.                     86400   IN      RRSIG   NSEC 8 1 86400 20220710050000 20220627040000 47671 . HwO7QYzt3lI0k1w10qjM7oUf0B71yWgbUu9yCPcUdUng1icIu0lXSebp thdZpvOpLrjTE461RZJSlYaKIPavphtjpQHnUVxlH3Qznw9cBhql9Qnx cEtMo7vlCkCRST9sojkQxRqFW1oQMOoGG1j+SWpejRYwaudILcDCl0bP 4nPu1t5KmGR3Q8DKKO075O69w8MTauU+yfOsxEPvYgmHGzIyU7pBMWyt sUA+5ZpnrQ+0KLcXxnpUPQpBb55RlO1PhRqlJ9bT8qfYfvT+QUL5alwl xJxyZVcLTlGrpggW76yWjN3gq3zzynmd3D5cGeFQSon1+qMR5i6LoQix b4Jycg==\n;; Received 602 bytes from 193.0.14.129#53(k.root-servers.net) in 350 ms\n\nclashdingyue.tk.        300     IN      NS      ns01.freenom.com.\nclashdingyue.tk.        300     IN      NS      ns02.freenom.com.\nclashdingyue.tk.        300     IN      NS      ns03.freenom.com.\nclashdingyue.tk.        300     IN      NS      ns04.freenom.com.\n;; Received 131 bytes from 194.0.41.1#53(d.ns.tk) in 330 ms\n\nclashdingyue.tk.        3600    IN      A       185.199.108.153\nclashdingyue.tk.        3600    IN      A       185.199.110.153\nclashdingyue.tk.        3600    IN      A       185.199.109.153\nclashdingyue.tk.        3600    IN      A       185.199.111.153\nclashdingyue.tk.        300     IN      NS      ns03.freenom.com.\nclashdingyue.tk.        300     IN      NS      ns04.freenom.com.\nclashdingyue.tk.        300     IN      NS      ns02.freenom.com.\nclashdingyue.tk.        300     IN      NS      ns01.freenom.com.\n;; Received 248 bytes from 54.171.131.39#53(ns01.freenom.com) in 470 ms\n```\n\n**如果域名被污染会直接到的一个IP，并不会向权威DNS请求。**如下所示：\n\n```\n➜  hexo-blog dig +trace google.com\n;; Warning: Client COOKIE mismatch\n\n; <<>> DiG 9.16.1-Ubuntu <<>> +trace google.com\n;; global options: +cmd\n.                       1450    IN      NS      f.root-servers.net.\n.                       1450    IN      NS      k.root-servers.net.\n.                       1450    IN      NS      d.root-servers.net.\n.                       1450    IN      NS      j.root-servers.net.\n.                       1450    IN      NS      l.root-servers.net.\n.                       1450    IN      NS      m.root-servers.net.\n.                       1450    IN      NS      h.root-servers.net.\n.                       1450    IN      NS      i.root-servers.net.\n.                       1450    IN      NS      e.root-servers.net.\n.                       1450    IN      NS      c.root-servers.net.\n.                       1450    IN      NS      a.root-servers.net.\n.                       1450    IN      NS      b.root-servers.net.\n.                       1450    IN      NS      g.root-servers.net.\n;; Received 443 bytes from 172.17.112.1#53(172.17.112.1) in 840 ms\n\ngoogle.com.             60      IN      A       8.7.198.46\n;; Received 54 bytes from 192.33.4.12#53(c.root-servers.net) in 20 ms\n```\n\n","slug":"DNS命令指南","published":1,"comments":1,"layout":"post","photos":[],"link":"","_id":"cl9y38drs0006fwuieh3p1a97","content":"<h1 id=\"DNS指南\"><a href=\"#DNS指南\" class=\"headerlink\" title=\"DNS指南\"></a>DNS指南</h1><h2 id=\"查询DNS服务器\"><a href=\"#查询DNS服务器\" class=\"headerlink\" title=\"查询DNS服务器\"></a>查询DNS服务器</h2><ul>\n<li><p>linux：<code>cat /etc/resolv.conf</code> </p>\n</li>\n<li><p>windows: ipconfig &#x2F;all</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">PS C:\\Users\\sssbb&gt; ipconfig /all</span><br><span class=\"line\"></span><br><span class=\"line\">Windows IP 配置</span><br><span class=\"line\"></span><br><span class=\"line\">   主机名  . . . . . . . . . . . . . : DESKTOP-KD33OT8</span><br><span class=\"line\">   主 DNS 后缀 . . . . . . . . . . . :</span><br><span class=\"line\">   节点类型  . . . . . . . . . . . . : 混合</span><br><span class=\"line\">   IP 路由已启用 . . . . . . . . . . : 否</span><br><span class=\"line\">   WINS 代理已启用 . . . . . . . . . : 否</span><br><span class=\"line\"></span><br><span class=\"line\">未知适配器 Clash:</span><br><span class=\"line\"></span><br><span class=\"line\">   连接特定的 DNS 后缀 . . . . . . . :</span><br><span class=\"line\">   描述. . . . . . . . . . . . . . . : Clash Tunnel</span><br><span class=\"line\">   物理地址. . . . . . . . . . . . . :</span><br><span class=\"line\">   DHCP 已启用 . . . . . . . . . . . : 否</span><br><span class=\"line\">   自动配置已启用. . . . . . . . . . : 是</span><br><span class=\"line\">   IPv4 地址 . . . . . . . . . . . . : 198.18.0.1(首选)</span><br><span class=\"line\">   子网掩码  . . . . . . . . . . . . : 255.255.0.0</span><br><span class=\"line\">   默认网关. . . . . . . . . . . . . :</span><br><span class=\"line\">   DNS 服务器  . . . . . . . . . . . : 198.18.0.2</span><br><span class=\"line\">   TCPIP 上的 NetBIOS  . . . . . . . : 已启用</span><br><span class=\"line\"></span><br><span class=\"line\">无线局域网适配器 本地连接* 1:</span><br><span class=\"line\"></span><br><span class=\"line\">   媒体状态  . . . . . . . . . . . . : 媒体已断开连接</span><br><span class=\"line\">   连接特定的 DNS 后缀 . . . . . . . :</span><br><span class=\"line\">   描述. . . . . . . . . . . . . . . : Microsoft Wi-Fi Direct Virtual Adapter</span><br><span class=\"line\">   物理地址. . . . . . . . . . . . . : 1A-4F-32-F7-BE-99</span><br><span class=\"line\">   DHCP 已启用 . . . . . . . . . . . : 是</span><br><span class=\"line\">   自动配置已启用. . . . . . . . . . : 是</span><br><span class=\"line\"></span><br><span class=\"line\">无线局域网适配器 本地连接* 10:</span><br><span class=\"line\"></span><br><span class=\"line\">   媒体状态  . . . . . . . . . . . . : 媒体已断开连接</span><br><span class=\"line\">   连接特定的 DNS 后缀 . . . . . . . :</span><br><span class=\"line\">   描述. . . . . . . . . . . . . . . : Microsoft Wi-Fi Direct Virtual Adapter #2</span><br><span class=\"line\">   物理地址. . . . . . . . . . . . . : 1A-4F-32-F7-B6-99</span><br><span class=\"line\">   DHCP 已启用 . . . . . . . . . . . : 是</span><br><span class=\"line\">   自动配置已启用. . . . . . . . . . : 是</span><br><span class=\"line\"></span><br><span class=\"line\">无线局域网适配器 WLAN:</span><br><span class=\"line\"></span><br><span class=\"line\">   连接特定的 DNS 后缀 . . . . . . . :</span><br><span class=\"line\">   描述. . . . . . . . . . . . . . . : Dell Wireless 1830 802.11ac</span><br><span class=\"line\">   物理地址. . . . . . . . . . . . . : 18-4F-32-F7-BE-99</span><br><span class=\"line\">   DHCP 已启用 . . . . . . . . . . . : 是</span><br><span class=\"line\">   自动配置已启用. . . . . . . . . . : 是</span><br><span class=\"line\">   本地链接 IPv6 地址. . . . . . . . : fe80::5d17:d6:2915:d43c%3(首选)</span><br><span class=\"line\">   IPv4 地址 . . . . . . . . . . . . : 192.168.31.250(首选)</span><br><span class=\"line\">   子网掩码  . . . . . . . . . . . . : 255.255.255.0</span><br><span class=\"line\">   获得租约的时间  . . . . . . . . . : 2022年6月27日 13:00:31</span><br><span class=\"line\">   租约过期的时间  . . . . . . . . . : 2022年6月28日 1:00:34</span><br><span class=\"line\">   默认网关. . . . . . . . . . . . . : 192.168.31.1</span><br><span class=\"line\">   DHCP 服务器 . . . . . . . . . . . : 192.168.31.1</span><br><span class=\"line\">   DHCPv6 IAID . . . . . . . . . . . : 51924786</span><br><span class=\"line\">   DHCPv6 客户端 DUID  . . . . . . . : 00-01-00-01-2A-3F-FD-A1-18-4F-32-F7-BE-99</span><br><span class=\"line\">   DNS 服务器  . . . . . . . . . . . : 192.168.31.1</span><br><span class=\"line\">   TCPIP 上的 NetBIOS  . . . . . . . : 已启用</span><br><span class=\"line\"></span><br><span class=\"line\">以太网适配器 蓝牙网络连接:</span><br><span class=\"line\"></span><br><span class=\"line\">   媒体状态  . . . . . . . . . . . . : 媒体已断开连接</span><br><span class=\"line\">   连接特定的 DNS 后缀 . . . . . . . :</span><br><span class=\"line\">   描述. . . . . . . . . . . . . . . : Bluetooth Device (Personal Area Network)</span><br><span class=\"line\">   物理地址. . . . . . . . . . . . . : 18-4F-32-F7-BE-9A</span><br><span class=\"line\">   DHCP 已启用 . . . . . . . . . . . : 是</span><br><span class=\"line\">   自动配置已启用. . . . . . . . . . : 是</span><br><span class=\"line\"></span><br><span class=\"line\">以太网适配器 vEthernet (WSL):</span><br><span class=\"line\"></span><br><span class=\"line\">   连接特定的 DNS 后缀 . . . . . . . :</span><br><span class=\"line\">   描述. . . . . . . . . . . . . . . : Hyper-V Virtual Ethernet Adapter</span><br><span class=\"line\">   物理地址. . . . . . . . . . . . . : 00-15-5D-5C-2A-EA</span><br><span class=\"line\">   DHCP 已启用 . . . . . . . . . . . : 否</span><br><span class=\"line\">   自动配置已启用. . . . . . . . . . : 是</span><br><span class=\"line\">   本地链接 IPv6 地址. . . . . . . . : fe80::d82d:5ba6:7b4b:9023%40(首选)</span><br><span class=\"line\">   IPv4 地址 . . . . . . . . . . . . : 172.17.112.1(首选)</span><br><span class=\"line\">   子网掩码  . . . . . . . . . . . . : 255.255.240.0</span><br><span class=\"line\">   默认网关. . . . . . . . . . . . . :</span><br><span class=\"line\">   DHCPv6 IAID . . . . . . . . . . . : 671094109</span><br><span class=\"line\">   DHCPv6 客户端 DUID  . . . . . . . : 00-01-00-01-2A-3F-FD-A1-18-4F-32-F7-BE-99</span><br><span class=\"line\">   DNS 服务器  . . . . . . . . . . . : fec0:0:0:ffff::1%1</span><br><span class=\"line\">                                       fec0:0:0:ffff::2%1</span><br><span class=\"line\">                                       fec0:0:0:ffff::3%1</span><br><span class=\"line\">   TCPIP 上的 NetBIOS  . . . . . . . : 已启用</span><br></pre></td></tr></table></figure></li>\n</ul>\n<h2 id=\"查看域名是否解析成功：\"><a href=\"#查看域名是否解析成功：\" class=\"headerlink\" title=\"查看域名是否解析成功：\"></a>查看域名是否解析成功：</h2><ul>\n<li><p>可以直接ping域名，也可以使用nslookup命令（NameServer Lookup）</p>\n</li>\n<li><p>在用 nslookup 查询一个域名时，可能会看到有“非权威应答” 的提示，非权威应答（Non-authoritative answer）意味着answer来自于其他服务器的缓存，而不是权威的服务器（就是该域名配置的DNS解析服务器，如果你的域名解析配置在CF的DNS上，则权威服务器，就是CF的DNS）。缓存会根据 ttl（Time to Live）的值定时的进行更新。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">➜  hexo-blog nslookup wohensha.tk 8.8.8.8</span><br><span class=\"line\">Server:         8.8.8.8</span><br><span class=\"line\">Address:        8.8.8.8#53</span><br><span class=\"line\"></span><br><span class=\"line\">Non-authoritative answer:</span><br><span class=\"line\">Name:   wohensha.tk</span><br><span class=\"line\">Address: 104.21.49.190</span><br><span class=\"line\">Name:   wohensha.tk</span><br><span class=\"line\">Address: 172.67.165.231</span><br><span class=\"line\">Name:   wohensha.tk</span><br><span class=\"line\">Address: 2606:4700:3031::ac43:a5e7</span><br><span class=\"line\">Name:   wohensha.tk</span><br><span class=\"line\">Address: 2606:4700:3031::6815:31be</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>sds查找权威名字服务器</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">➜  hexo-blog nslookup -ty=ns clashdingyue.tk</span><br><span class=\"line\">Server:         172.17.112.1</span><br><span class=\"line\">Address:        172.17.112.1#53</span><br><span class=\"line\"></span><br><span class=\"line\">Non-authoritative answer:</span><br><span class=\"line\">clashdingyue.tk nameserver = ns04.freenom.com.</span><br><span class=\"line\">clashdingyue.tk nameserver = ns02.freenom.com.</span><br><span class=\"line\">clashdingyue.tk nameserver = ns01.freenom.com.</span><br><span class=\"line\">clashdingyue.tk nameserver = ns03.freenom.com.</span><br><span class=\"line\"></span><br><span class=\"line\">Authoritative answers can be found from:</span><br><span class=\"line\"></span><br><span class=\"line\">➜  hexo-blog nslookup -ty=ns clashdingyue.tk ns04.freenom.com</span><br><span class=\"line\">Server:         ns04.freenom.com</span><br><span class=\"line\">Address:        104.155.29.241#53</span><br><span class=\"line\"></span><br><span class=\"line\">clashdingyue.tk nameserver = ns04.freenom.com.</span><br><span class=\"line\">clashdingyue.tk nameserver = ns03.freenom.com.</span><br><span class=\"line\">clashdingyue.tk nameserver = ns02.freenom.com.</span><br><span class=\"line\">clashdingyue.tk nameserver = ns01.freenom.com.</span><br></pre></td></tr></table></figure></li>\n</ul>\n<h1 id=\"一些小技巧\"><a href=\"#一些小技巧\" class=\"headerlink\" title=\"一些小技巧\"></a>一些小技巧</h1><h3 id=\"怎么验证是否遭遇DNS污染？\"><a href=\"#怎么验证是否遭遇DNS污染？\" class=\"headerlink\" title=\"怎么验证是否遭遇DNS污染？\"></a>怎么验证是否遭遇DNS污染？</h3><p>​\t\t<strong>DNS污染</strong>即网域服务器缓存污染，又称域名服务器缓存投毒，是指一些刻意制造或无意中制造出来的域名服务器数据包，把域名指往不正确的IP地址。一般来说，在互联网上都有可信赖的网域服务器，但为减低网络上的流量压力，一般的域名服务器都会把从上游的域名服务器获得的解析记录暂存起来，待下次有其他机器要求解析域名时，可以立即提供服务。一旦有关网域的局域域名服务器的缓存受到污染，就会把网域内的计算机导引往错误的服务器。</p>\n<pre><code>   我们应该怎么去验证自己域名是否遭遇DNS污染呢？输入命令dig +trace clashdingyue.tk（您自己需要检测域名）。**如果域名未被污染我们会得到权威DNS的应答**，如下所示:\n</code></pre>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">➜  hexo-blog dig +trace clashdingyue.tk</span><br><span class=\"line\">;; Warning: Client COOKIE mismatch</span><br><span class=\"line\"></span><br><span class=\"line\">; &lt;&lt;&gt;&gt; DiG 9.16.1-Ubuntu &lt;&lt;&gt;&gt; +trace clashdingyue.tk</span><br><span class=\"line\">;; global options: +cmd</span><br><span class=\"line\">.                       200     IN      NS      g.root-servers.net.</span><br><span class=\"line\">.                       200     IN      NS      j.root-servers.net.</span><br><span class=\"line\">.                       200     IN      NS      d.root-servers.net.</span><br><span class=\"line\">.                       200     IN      NS      h.root-servers.net.</span><br><span class=\"line\">.                       200     IN      NS      m.root-servers.net.</span><br><span class=\"line\">.                       200     IN      NS      k.root-servers.net.</span><br><span class=\"line\">.                       200     IN      NS      a.root-servers.net.</span><br><span class=\"line\">.                       200     IN      NS      i.root-servers.net.</span><br><span class=\"line\">.                       200     IN      NS      b.root-servers.net.</span><br><span class=\"line\">.                       200     IN      NS      f.root-servers.net.</span><br><span class=\"line\">.                       200     IN      NS      c.root-servers.net.</span><br><span class=\"line\">.                       200     IN      NS      l.root-servers.net.</span><br><span class=\"line\">.                       200     IN      NS      e.root-servers.net.</span><br><span class=\"line\">;; Received 443 bytes from 172.17.112.1#53(172.17.112.1) in 840 ms</span><br><span class=\"line\"></span><br><span class=\"line\">tk.                     172800  IN      NS      a.ns.tk.</span><br><span class=\"line\">tk.                     172800  IN      NS      b.ns.tk.</span><br><span class=\"line\">tk.                     172800  IN      NS      c.ns.tk.</span><br><span class=\"line\">tk.                     172800  IN      NS      d.ns.tk.</span><br><span class=\"line\">tk.                     86400   IN      NSEC    tkmaxx. NS RRSIG NSEC</span><br><span class=\"line\">tk.                     86400   IN      RRSIG   NSEC 8 1 86400 20220710050000 20220627040000 47671 . HwO7QYzt3lI0k1w10qjM7oUf0B71yWgbUu9yCPcUdUng1icIu0lXSebp thdZpvOpLrjTE461RZJSlYaKIPavphtjpQHnUVxlH3Qznw9cBhql9Qnx cEtMo7vlCkCRST9sojkQxRqFW1oQMOoGG1j+SWpejRYwaudILcDCl0bP 4nPu1t5KmGR3Q8DKKO075O69w8MTauU+yfOsxEPvYgmHGzIyU7pBMWyt sUA+5ZpnrQ+0KLcXxnpUPQpBb55RlO1PhRqlJ9bT8qfYfvT+QUL5alwl xJxyZVcLTlGrpggW76yWjN3gq3zzynmd3D5cGeFQSon1+qMR5i6LoQix b4Jycg==</span><br><span class=\"line\">;; Received 602 bytes from 193.0.14.129#53(k.root-servers.net) in 350 ms</span><br><span class=\"line\"></span><br><span class=\"line\">clashdingyue.tk.        300     IN      NS      ns01.freenom.com.</span><br><span class=\"line\">clashdingyue.tk.        300     IN      NS      ns02.freenom.com.</span><br><span class=\"line\">clashdingyue.tk.        300     IN      NS      ns03.freenom.com.</span><br><span class=\"line\">clashdingyue.tk.        300     IN      NS      ns04.freenom.com.</span><br><span class=\"line\">;; Received 131 bytes from 194.0.41.1#53(d.ns.tk) in 330 ms</span><br><span class=\"line\"></span><br><span class=\"line\">clashdingyue.tk.        3600    IN      A       185.199.108.153</span><br><span class=\"line\">clashdingyue.tk.        3600    IN      A       185.199.110.153</span><br><span class=\"line\">clashdingyue.tk.        3600    IN      A       185.199.109.153</span><br><span class=\"line\">clashdingyue.tk.        3600    IN      A       185.199.111.153</span><br><span class=\"line\">clashdingyue.tk.        300     IN      NS      ns03.freenom.com.</span><br><span class=\"line\">clashdingyue.tk.        300     IN      NS      ns04.freenom.com.</span><br><span class=\"line\">clashdingyue.tk.        300     IN      NS      ns02.freenom.com.</span><br><span class=\"line\">clashdingyue.tk.        300     IN      NS      ns01.freenom.com.</span><br><span class=\"line\">;; Received 248 bytes from 54.171.131.39#53(ns01.freenom.com) in 470 ms</span><br></pre></td></tr></table></figure>\n\n<p><strong>如果域名被污染会直接到的一个IP，并不会向权威DNS请求。</strong>如下所示：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">➜  hexo-blog dig +trace google.com</span><br><span class=\"line\">;; Warning: Client COOKIE mismatch</span><br><span class=\"line\"></span><br><span class=\"line\">; &lt;&lt;&gt;&gt; DiG 9.16.1-Ubuntu &lt;&lt;&gt;&gt; +trace google.com</span><br><span class=\"line\">;; global options: +cmd</span><br><span class=\"line\">.                       1450    IN      NS      f.root-servers.net.</span><br><span class=\"line\">.                       1450    IN      NS      k.root-servers.net.</span><br><span class=\"line\">.                       1450    IN      NS      d.root-servers.net.</span><br><span class=\"line\">.                       1450    IN      NS      j.root-servers.net.</span><br><span class=\"line\">.                       1450    IN      NS      l.root-servers.net.</span><br><span class=\"line\">.                       1450    IN      NS      m.root-servers.net.</span><br><span class=\"line\">.                       1450    IN      NS      h.root-servers.net.</span><br><span class=\"line\">.                       1450    IN      NS      i.root-servers.net.</span><br><span class=\"line\">.                       1450    IN      NS      e.root-servers.net.</span><br><span class=\"line\">.                       1450    IN      NS      c.root-servers.net.</span><br><span class=\"line\">.                       1450    IN      NS      a.root-servers.net.</span><br><span class=\"line\">.                       1450    IN      NS      b.root-servers.net.</span><br><span class=\"line\">.                       1450    IN      NS      g.root-servers.net.</span><br><span class=\"line\">;; Received 443 bytes from 172.17.112.1#53(172.17.112.1) in 840 ms</span><br><span class=\"line\"></span><br><span class=\"line\">google.com.             60      IN      A       8.7.198.46</span><br><span class=\"line\">;; Received 54 bytes from 192.33.4.12#53(c.root-servers.net) in 20 ms</span><br></pre></td></tr></table></figure>\n\n","site":{"data":{"link":[{"class_name":"友情链接","class_desc":"那些人，那些事","link_list":[{"name":"张洪Heo","link":"https://blog.zhheo.com/","avatar":"https://npm.elemecdn.com/guli-heo/img/avatar2.png","descr":"分享设计与科技生活"},{"name":"瞬間の筆記","link":"https://hikki.site","descr":"喜欢的东西就努力去追求，万一成功了呢!","avatar":"https://cdn.jsdelivr.net/gh/0000rookie/imgs/202206120315.png"}]}]}},"excerpt":"","more":"<h1 id=\"DNS指南\"><a href=\"#DNS指南\" class=\"headerlink\" title=\"DNS指南\"></a>DNS指南</h1><h2 id=\"查询DNS服务器\"><a href=\"#查询DNS服务器\" class=\"headerlink\" title=\"查询DNS服务器\"></a>查询DNS服务器</h2><ul>\n<li><p>linux：<code>cat /etc/resolv.conf</code> </p>\n</li>\n<li><p>windows: ipconfig &#x2F;all</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">PS C:\\Users\\sssbb&gt; ipconfig /all</span><br><span class=\"line\"></span><br><span class=\"line\">Windows IP 配置</span><br><span class=\"line\"></span><br><span class=\"line\">   主机名  . . . . . . . . . . . . . : DESKTOP-KD33OT8</span><br><span class=\"line\">   主 DNS 后缀 . . . . . . . . . . . :</span><br><span class=\"line\">   节点类型  . . . . . . . . . . . . : 混合</span><br><span class=\"line\">   IP 路由已启用 . . . . . . . . . . : 否</span><br><span class=\"line\">   WINS 代理已启用 . . . . . . . . . : 否</span><br><span class=\"line\"></span><br><span class=\"line\">未知适配器 Clash:</span><br><span class=\"line\"></span><br><span class=\"line\">   连接特定的 DNS 后缀 . . . . . . . :</span><br><span class=\"line\">   描述. . . . . . . . . . . . . . . : Clash Tunnel</span><br><span class=\"line\">   物理地址. . . . . . . . . . . . . :</span><br><span class=\"line\">   DHCP 已启用 . . . . . . . . . . . : 否</span><br><span class=\"line\">   自动配置已启用. . . . . . . . . . : 是</span><br><span class=\"line\">   IPv4 地址 . . . . . . . . . . . . : 198.18.0.1(首选)</span><br><span class=\"line\">   子网掩码  . . . . . . . . . . . . : 255.255.0.0</span><br><span class=\"line\">   默认网关. . . . . . . . . . . . . :</span><br><span class=\"line\">   DNS 服务器  . . . . . . . . . . . : 198.18.0.2</span><br><span class=\"line\">   TCPIP 上的 NetBIOS  . . . . . . . : 已启用</span><br><span class=\"line\"></span><br><span class=\"line\">无线局域网适配器 本地连接* 1:</span><br><span class=\"line\"></span><br><span class=\"line\">   媒体状态  . . . . . . . . . . . . : 媒体已断开连接</span><br><span class=\"line\">   连接特定的 DNS 后缀 . . . . . . . :</span><br><span class=\"line\">   描述. . . . . . . . . . . . . . . : Microsoft Wi-Fi Direct Virtual Adapter</span><br><span class=\"line\">   物理地址. . . . . . . . . . . . . : 1A-4F-32-F7-BE-99</span><br><span class=\"line\">   DHCP 已启用 . . . . . . . . . . . : 是</span><br><span class=\"line\">   自动配置已启用. . . . . . . . . . : 是</span><br><span class=\"line\"></span><br><span class=\"line\">无线局域网适配器 本地连接* 10:</span><br><span class=\"line\"></span><br><span class=\"line\">   媒体状态  . . . . . . . . . . . . : 媒体已断开连接</span><br><span class=\"line\">   连接特定的 DNS 后缀 . . . . . . . :</span><br><span class=\"line\">   描述. . . . . . . . . . . . . . . : Microsoft Wi-Fi Direct Virtual Adapter #2</span><br><span class=\"line\">   物理地址. . . . . . . . . . . . . : 1A-4F-32-F7-B6-99</span><br><span class=\"line\">   DHCP 已启用 . . . . . . . . . . . : 是</span><br><span class=\"line\">   自动配置已启用. . . . . . . . . . : 是</span><br><span class=\"line\"></span><br><span class=\"line\">无线局域网适配器 WLAN:</span><br><span class=\"line\"></span><br><span class=\"line\">   连接特定的 DNS 后缀 . . . . . . . :</span><br><span class=\"line\">   描述. . . . . . . . . . . . . . . : Dell Wireless 1830 802.11ac</span><br><span class=\"line\">   物理地址. . . . . . . . . . . . . : 18-4F-32-F7-BE-99</span><br><span class=\"line\">   DHCP 已启用 . . . . . . . . . . . : 是</span><br><span class=\"line\">   自动配置已启用. . . . . . . . . . : 是</span><br><span class=\"line\">   本地链接 IPv6 地址. . . . . . . . : fe80::5d17:d6:2915:d43c%3(首选)</span><br><span class=\"line\">   IPv4 地址 . . . . . . . . . . . . : 192.168.31.250(首选)</span><br><span class=\"line\">   子网掩码  . . . . . . . . . . . . : 255.255.255.0</span><br><span class=\"line\">   获得租约的时间  . . . . . . . . . : 2022年6月27日 13:00:31</span><br><span class=\"line\">   租约过期的时间  . . . . . . . . . : 2022年6月28日 1:00:34</span><br><span class=\"line\">   默认网关. . . . . . . . . . . . . : 192.168.31.1</span><br><span class=\"line\">   DHCP 服务器 . . . . . . . . . . . : 192.168.31.1</span><br><span class=\"line\">   DHCPv6 IAID . . . . . . . . . . . : 51924786</span><br><span class=\"line\">   DHCPv6 客户端 DUID  . . . . . . . : 00-01-00-01-2A-3F-FD-A1-18-4F-32-F7-BE-99</span><br><span class=\"line\">   DNS 服务器  . . . . . . . . . . . : 192.168.31.1</span><br><span class=\"line\">   TCPIP 上的 NetBIOS  . . . . . . . : 已启用</span><br><span class=\"line\"></span><br><span class=\"line\">以太网适配器 蓝牙网络连接:</span><br><span class=\"line\"></span><br><span class=\"line\">   媒体状态  . . . . . . . . . . . . : 媒体已断开连接</span><br><span class=\"line\">   连接特定的 DNS 后缀 . . . . . . . :</span><br><span class=\"line\">   描述. . . . . . . . . . . . . . . : Bluetooth Device (Personal Area Network)</span><br><span class=\"line\">   物理地址. . . . . . . . . . . . . : 18-4F-32-F7-BE-9A</span><br><span class=\"line\">   DHCP 已启用 . . . . . . . . . . . : 是</span><br><span class=\"line\">   自动配置已启用. . . . . . . . . . : 是</span><br><span class=\"line\"></span><br><span class=\"line\">以太网适配器 vEthernet (WSL):</span><br><span class=\"line\"></span><br><span class=\"line\">   连接特定的 DNS 后缀 . . . . . . . :</span><br><span class=\"line\">   描述. . . . . . . . . . . . . . . : Hyper-V Virtual Ethernet Adapter</span><br><span class=\"line\">   物理地址. . . . . . . . . . . . . : 00-15-5D-5C-2A-EA</span><br><span class=\"line\">   DHCP 已启用 . . . . . . . . . . . : 否</span><br><span class=\"line\">   自动配置已启用. . . . . . . . . . : 是</span><br><span class=\"line\">   本地链接 IPv6 地址. . . . . . . . : fe80::d82d:5ba6:7b4b:9023%40(首选)</span><br><span class=\"line\">   IPv4 地址 . . . . . . . . . . . . : 172.17.112.1(首选)</span><br><span class=\"line\">   子网掩码  . . . . . . . . . . . . : 255.255.240.0</span><br><span class=\"line\">   默认网关. . . . . . . . . . . . . :</span><br><span class=\"line\">   DHCPv6 IAID . . . . . . . . . . . : 671094109</span><br><span class=\"line\">   DHCPv6 客户端 DUID  . . . . . . . : 00-01-00-01-2A-3F-FD-A1-18-4F-32-F7-BE-99</span><br><span class=\"line\">   DNS 服务器  . . . . . . . . . . . : fec0:0:0:ffff::1%1</span><br><span class=\"line\">                                       fec0:0:0:ffff::2%1</span><br><span class=\"line\">                                       fec0:0:0:ffff::3%1</span><br><span class=\"line\">   TCPIP 上的 NetBIOS  . . . . . . . : 已启用</span><br></pre></td></tr></table></figure></li>\n</ul>\n<h2 id=\"查看域名是否解析成功：\"><a href=\"#查看域名是否解析成功：\" class=\"headerlink\" title=\"查看域名是否解析成功：\"></a>查看域名是否解析成功：</h2><ul>\n<li><p>可以直接ping域名，也可以使用nslookup命令（NameServer Lookup）</p>\n</li>\n<li><p>在用 nslookup 查询一个域名时，可能会看到有“非权威应答” 的提示，非权威应答（Non-authoritative answer）意味着answer来自于其他服务器的缓存，而不是权威的服务器（就是该域名配置的DNS解析服务器，如果你的域名解析配置在CF的DNS上，则权威服务器，就是CF的DNS）。缓存会根据 ttl（Time to Live）的值定时的进行更新。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">➜  hexo-blog nslookup wohensha.tk 8.8.8.8</span><br><span class=\"line\">Server:         8.8.8.8</span><br><span class=\"line\">Address:        8.8.8.8#53</span><br><span class=\"line\"></span><br><span class=\"line\">Non-authoritative answer:</span><br><span class=\"line\">Name:   wohensha.tk</span><br><span class=\"line\">Address: 104.21.49.190</span><br><span class=\"line\">Name:   wohensha.tk</span><br><span class=\"line\">Address: 172.67.165.231</span><br><span class=\"line\">Name:   wohensha.tk</span><br><span class=\"line\">Address: 2606:4700:3031::ac43:a5e7</span><br><span class=\"line\">Name:   wohensha.tk</span><br><span class=\"line\">Address: 2606:4700:3031::6815:31be</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>sds查找权威名字服务器</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">➜  hexo-blog nslookup -ty=ns clashdingyue.tk</span><br><span class=\"line\">Server:         172.17.112.1</span><br><span class=\"line\">Address:        172.17.112.1#53</span><br><span class=\"line\"></span><br><span class=\"line\">Non-authoritative answer:</span><br><span class=\"line\">clashdingyue.tk nameserver = ns04.freenom.com.</span><br><span class=\"line\">clashdingyue.tk nameserver = ns02.freenom.com.</span><br><span class=\"line\">clashdingyue.tk nameserver = ns01.freenom.com.</span><br><span class=\"line\">clashdingyue.tk nameserver = ns03.freenom.com.</span><br><span class=\"line\"></span><br><span class=\"line\">Authoritative answers can be found from:</span><br><span class=\"line\"></span><br><span class=\"line\">➜  hexo-blog nslookup -ty=ns clashdingyue.tk ns04.freenom.com</span><br><span class=\"line\">Server:         ns04.freenom.com</span><br><span class=\"line\">Address:        104.155.29.241#53</span><br><span class=\"line\"></span><br><span class=\"line\">clashdingyue.tk nameserver = ns04.freenom.com.</span><br><span class=\"line\">clashdingyue.tk nameserver = ns03.freenom.com.</span><br><span class=\"line\">clashdingyue.tk nameserver = ns02.freenom.com.</span><br><span class=\"line\">clashdingyue.tk nameserver = ns01.freenom.com.</span><br></pre></td></tr></table></figure></li>\n</ul>\n<h1 id=\"一些小技巧\"><a href=\"#一些小技巧\" class=\"headerlink\" title=\"一些小技巧\"></a>一些小技巧</h1><h3 id=\"怎么验证是否遭遇DNS污染？\"><a href=\"#怎么验证是否遭遇DNS污染？\" class=\"headerlink\" title=\"怎么验证是否遭遇DNS污染？\"></a>怎么验证是否遭遇DNS污染？</h3><p>​\t\t<strong>DNS污染</strong>即网域服务器缓存污染，又称域名服务器缓存投毒，是指一些刻意制造或无意中制造出来的域名服务器数据包，把域名指往不正确的IP地址。一般来说，在互联网上都有可信赖的网域服务器，但为减低网络上的流量压力，一般的域名服务器都会把从上游的域名服务器获得的解析记录暂存起来，待下次有其他机器要求解析域名时，可以立即提供服务。一旦有关网域的局域域名服务器的缓存受到污染，就会把网域内的计算机导引往错误的服务器。</p>\n<pre><code>   我们应该怎么去验证自己域名是否遭遇DNS污染呢？输入命令dig +trace clashdingyue.tk（您自己需要检测域名）。**如果域名未被污染我们会得到权威DNS的应答**，如下所示:\n</code></pre>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">➜  hexo-blog dig +trace clashdingyue.tk</span><br><span class=\"line\">;; Warning: Client COOKIE mismatch</span><br><span class=\"line\"></span><br><span class=\"line\">; &lt;&lt;&gt;&gt; DiG 9.16.1-Ubuntu &lt;&lt;&gt;&gt; +trace clashdingyue.tk</span><br><span class=\"line\">;; global options: +cmd</span><br><span class=\"line\">.                       200     IN      NS      g.root-servers.net.</span><br><span class=\"line\">.                       200     IN      NS      j.root-servers.net.</span><br><span class=\"line\">.                       200     IN      NS      d.root-servers.net.</span><br><span class=\"line\">.                       200     IN      NS      h.root-servers.net.</span><br><span class=\"line\">.                       200     IN      NS      m.root-servers.net.</span><br><span class=\"line\">.                       200     IN      NS      k.root-servers.net.</span><br><span class=\"line\">.                       200     IN      NS      a.root-servers.net.</span><br><span class=\"line\">.                       200     IN      NS      i.root-servers.net.</span><br><span class=\"line\">.                       200     IN      NS      b.root-servers.net.</span><br><span class=\"line\">.                       200     IN      NS      f.root-servers.net.</span><br><span class=\"line\">.                       200     IN      NS      c.root-servers.net.</span><br><span class=\"line\">.                       200     IN      NS      l.root-servers.net.</span><br><span class=\"line\">.                       200     IN      NS      e.root-servers.net.</span><br><span class=\"line\">;; Received 443 bytes from 172.17.112.1#53(172.17.112.1) in 840 ms</span><br><span class=\"line\"></span><br><span class=\"line\">tk.                     172800  IN      NS      a.ns.tk.</span><br><span class=\"line\">tk.                     172800  IN      NS      b.ns.tk.</span><br><span class=\"line\">tk.                     172800  IN      NS      c.ns.tk.</span><br><span class=\"line\">tk.                     172800  IN      NS      d.ns.tk.</span><br><span class=\"line\">tk.                     86400   IN      NSEC    tkmaxx. NS RRSIG NSEC</span><br><span class=\"line\">tk.                     86400   IN      RRSIG   NSEC 8 1 86400 20220710050000 20220627040000 47671 . HwO7QYzt3lI0k1w10qjM7oUf0B71yWgbUu9yCPcUdUng1icIu0lXSebp thdZpvOpLrjTE461RZJSlYaKIPavphtjpQHnUVxlH3Qznw9cBhql9Qnx cEtMo7vlCkCRST9sojkQxRqFW1oQMOoGG1j+SWpejRYwaudILcDCl0bP 4nPu1t5KmGR3Q8DKKO075O69w8MTauU+yfOsxEPvYgmHGzIyU7pBMWyt sUA+5ZpnrQ+0KLcXxnpUPQpBb55RlO1PhRqlJ9bT8qfYfvT+QUL5alwl xJxyZVcLTlGrpggW76yWjN3gq3zzynmd3D5cGeFQSon1+qMR5i6LoQix b4Jycg==</span><br><span class=\"line\">;; Received 602 bytes from 193.0.14.129#53(k.root-servers.net) in 350 ms</span><br><span class=\"line\"></span><br><span class=\"line\">clashdingyue.tk.        300     IN      NS      ns01.freenom.com.</span><br><span class=\"line\">clashdingyue.tk.        300     IN      NS      ns02.freenom.com.</span><br><span class=\"line\">clashdingyue.tk.        300     IN      NS      ns03.freenom.com.</span><br><span class=\"line\">clashdingyue.tk.        300     IN      NS      ns04.freenom.com.</span><br><span class=\"line\">;; Received 131 bytes from 194.0.41.1#53(d.ns.tk) in 330 ms</span><br><span class=\"line\"></span><br><span class=\"line\">clashdingyue.tk.        3600    IN      A       185.199.108.153</span><br><span class=\"line\">clashdingyue.tk.        3600    IN      A       185.199.110.153</span><br><span class=\"line\">clashdingyue.tk.        3600    IN      A       185.199.109.153</span><br><span class=\"line\">clashdingyue.tk.        3600    IN      A       185.199.111.153</span><br><span class=\"line\">clashdingyue.tk.        300     IN      NS      ns03.freenom.com.</span><br><span class=\"line\">clashdingyue.tk.        300     IN      NS      ns04.freenom.com.</span><br><span class=\"line\">clashdingyue.tk.        300     IN      NS      ns02.freenom.com.</span><br><span class=\"line\">clashdingyue.tk.        300     IN      NS      ns01.freenom.com.</span><br><span class=\"line\">;; Received 248 bytes from 54.171.131.39#53(ns01.freenom.com) in 470 ms</span><br></pre></td></tr></table></figure>\n\n<p><strong>如果域名被污染会直接到的一个IP，并不会向权威DNS请求。</strong>如下所示：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">➜  hexo-blog dig +trace google.com</span><br><span class=\"line\">;; Warning: Client COOKIE mismatch</span><br><span class=\"line\"></span><br><span class=\"line\">; &lt;&lt;&gt;&gt; DiG 9.16.1-Ubuntu &lt;&lt;&gt;&gt; +trace google.com</span><br><span class=\"line\">;; global options: +cmd</span><br><span class=\"line\">.                       1450    IN      NS      f.root-servers.net.</span><br><span class=\"line\">.                       1450    IN      NS      k.root-servers.net.</span><br><span class=\"line\">.                       1450    IN      NS      d.root-servers.net.</span><br><span class=\"line\">.                       1450    IN      NS      j.root-servers.net.</span><br><span class=\"line\">.                       1450    IN      NS      l.root-servers.net.</span><br><span class=\"line\">.                       1450    IN      NS      m.root-servers.net.</span><br><span class=\"line\">.                       1450    IN      NS      h.root-servers.net.</span><br><span class=\"line\">.                       1450    IN      NS      i.root-servers.net.</span><br><span class=\"line\">.                       1450    IN      NS      e.root-servers.net.</span><br><span class=\"line\">.                       1450    IN      NS      c.root-servers.net.</span><br><span class=\"line\">.                       1450    IN      NS      a.root-servers.net.</span><br><span class=\"line\">.                       1450    IN      NS      b.root-servers.net.</span><br><span class=\"line\">.                       1450    IN      NS      g.root-servers.net.</span><br><span class=\"line\">;; Received 443 bytes from 172.17.112.1#53(172.17.112.1) in 840 ms</span><br><span class=\"line\"></span><br><span class=\"line\">google.com.             60      IN      A       8.7.198.46</span><br><span class=\"line\">;; Received 54 bytes from 192.33.4.12#53(c.root-servers.net) in 20 ms</span><br></pre></td></tr></table></figure>\n\n"},{"title":"github pages-Hexo-CloudFlare免费CDN最佳实践","cover":"https://tva4.sinaimg.cn/large/0084aYsLgy1gy51ogkzs9j31hc0m843g.jpg","top_img":null,"date":"2022-06-27T13:14:01.000Z","updated":"2022-06-27T13:19:32.000Z","description":null,"keywords":null,"typora-copy-images-to":"..\\img\\cut","_content":"\n## 一、查看网站是否使用了CDN\n\n执行：nslookup  XXX 命令\n\n```\n➜  hexo-blog nslookup clashdingyue.tk\nServer:         172.17.112.1\nAddress:        172.17.112.1#53\n\nNon-authoritative answer:\nName:   clashdingyue.tk\nAddress: 185.199.110.153\nName:   clashdingyue.tk\nAddress: 185.199.109.153\nName:   clashdingyue.tk\nAddress: 185.199.111.153\nName:   clashdingyue.tk\nAddress: 185.199.108.153\n```\n\n```\n➜  hexo-blog nslookup wohensha.tk\nServer:         172.17.112.1\nAddress:        172.17.112.1#53\n\nNon-authoritative answer:\nName:   wohensha.tk\nAddress: 172.67.165.231\nName:   wohensha.tk\nAddress: 104.21.49.190\n```\n\n**两个或两个以上Server IP，则表明使用了CDN，只有一个则表明没有。**\n\n- Github CDN：185.199.110.153、185.199.108.153...\n- CloudFlare CDN：172.67.165.231、104.21.49.190\n\n\n\n## 二、测试两个CDN哪一个在墙内，速度更好\n\n### CloudFlare CDN\n\n略\n\n### Github CDN\n\n![image-cdn](/img/cut/cdn-test-1.webp)\n\n![image-cdn](/img/cut/cdn-test-2.webp)\n\n(￣▽￣)，半斤八两，感觉Github CDN好点\n","source":"_posts/Hexo-github-pages-CloudFlare免费CDN最佳实践.md","raw":"---\ntitle: github pages-Hexo-CloudFlare免费CDN最佳实践\ntags:\n  - CDN\n  - hexo\n  - cloudflare\ncategories:\n  - [hexo]\ncover: \ntop_img: \ndate: 2022-06-27 21:14:01\nupdated: 2022-06-27 21:19:32\ndescription:\nkeywords:\ntypora-copy-images-to: ..\\img\\cut\n---\n\n## 一、查看网站是否使用了CDN\n\n执行：nslookup  XXX 命令\n\n```\n➜  hexo-blog nslookup clashdingyue.tk\nServer:         172.17.112.1\nAddress:        172.17.112.1#53\n\nNon-authoritative answer:\nName:   clashdingyue.tk\nAddress: 185.199.110.153\nName:   clashdingyue.tk\nAddress: 185.199.109.153\nName:   clashdingyue.tk\nAddress: 185.199.111.153\nName:   clashdingyue.tk\nAddress: 185.199.108.153\n```\n\n```\n➜  hexo-blog nslookup wohensha.tk\nServer:         172.17.112.1\nAddress:        172.17.112.1#53\n\nNon-authoritative answer:\nName:   wohensha.tk\nAddress: 172.67.165.231\nName:   wohensha.tk\nAddress: 104.21.49.190\n```\n\n**两个或两个以上Server IP，则表明使用了CDN，只有一个则表明没有。**\n\n- Github CDN：185.199.110.153、185.199.108.153...\n- CloudFlare CDN：172.67.165.231、104.21.49.190\n\n\n\n## 二、测试两个CDN哪一个在墙内，速度更好\n\n### CloudFlare CDN\n\n略\n\n### Github CDN\n\n![image-cdn](/img/cut/cdn-test-1.webp)\n\n![image-cdn](/img/cut/cdn-test-2.webp)\n\n(￣▽￣)，半斤八两，感觉Github CDN好点\n","slug":"Hexo-github-pages-CloudFlare免费CDN最佳实践","published":1,"comments":1,"layout":"post","photos":[],"link":"","_id":"cl9y38dru0009fwuiclnb4y8p","content":"<h2 id=\"一、查看网站是否使用了CDN\"><a href=\"#一、查看网站是否使用了CDN\" class=\"headerlink\" title=\"一、查看网站是否使用了CDN\"></a>一、查看网站是否使用了CDN</h2><p>执行：nslookup  XXX 命令</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">➜  hexo-blog nslookup clashdingyue.tk</span><br><span class=\"line\">Server:         172.17.112.1</span><br><span class=\"line\">Address:        172.17.112.1#53</span><br><span class=\"line\"></span><br><span class=\"line\">Non-authoritative answer:</span><br><span class=\"line\">Name:   clashdingyue.tk</span><br><span class=\"line\">Address: 185.199.110.153</span><br><span class=\"line\">Name:   clashdingyue.tk</span><br><span class=\"line\">Address: 185.199.109.153</span><br><span class=\"line\">Name:   clashdingyue.tk</span><br><span class=\"line\">Address: 185.199.111.153</span><br><span class=\"line\">Name:   clashdingyue.tk</span><br><span class=\"line\">Address: 185.199.108.153</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">➜  hexo-blog nslookup wohensha.tk</span><br><span class=\"line\">Server:         172.17.112.1</span><br><span class=\"line\">Address:        172.17.112.1#53</span><br><span class=\"line\"></span><br><span class=\"line\">Non-authoritative answer:</span><br><span class=\"line\">Name:   wohensha.tk</span><br><span class=\"line\">Address: 172.67.165.231</span><br><span class=\"line\">Name:   wohensha.tk</span><br><span class=\"line\">Address: 104.21.49.190</span><br></pre></td></tr></table></figure>\n\n<p><strong>两个或两个以上Server IP，则表明使用了CDN，只有一个则表明没有。</strong></p>\n<ul>\n<li>Github CDN：185.199.110.153、185.199.108.153…</li>\n<li>CloudFlare CDN：172.67.165.231、104.21.49.190</li>\n</ul>\n<h2 id=\"二、测试两个CDN哪一个在墙内，速度更好\"><a href=\"#二、测试两个CDN哪一个在墙内，速度更好\" class=\"headerlink\" title=\"二、测试两个CDN哪一个在墙内，速度更好\"></a>二、测试两个CDN哪一个在墙内，速度更好</h2><h3 id=\"CloudFlare-CDN\"><a href=\"#CloudFlare-CDN\" class=\"headerlink\" title=\"CloudFlare CDN\"></a>CloudFlare CDN</h3><p>略</p>\n<h3 id=\"Github-CDN\"><a href=\"#Github-CDN\" class=\"headerlink\" title=\"Github CDN\"></a>Github CDN</h3><p><img src=\"/img/cut/cdn-test-1.webp\" alt=\"image-cdn\"></p>\n<p><img src=\"/img/cut/cdn-test-2.webp\" alt=\"image-cdn\"></p>\n<p>(￣▽￣)，半斤八两，感觉Github CDN好点</p>\n","site":{"data":{"link":[{"class_name":"友情链接","class_desc":"那些人，那些事","link_list":[{"name":"张洪Heo","link":"https://blog.zhheo.com/","avatar":"https://npm.elemecdn.com/guli-heo/img/avatar2.png","descr":"分享设计与科技生活"},{"name":"瞬間の筆記","link":"https://hikki.site","descr":"喜欢的东西就努力去追求，万一成功了呢!","avatar":"https://cdn.jsdelivr.net/gh/0000rookie/imgs/202206120315.png"}]}]}},"excerpt":"","more":"<h2 id=\"一、查看网站是否使用了CDN\"><a href=\"#一、查看网站是否使用了CDN\" class=\"headerlink\" title=\"一、查看网站是否使用了CDN\"></a>一、查看网站是否使用了CDN</h2><p>执行：nslookup  XXX 命令</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">➜  hexo-blog nslookup clashdingyue.tk</span><br><span class=\"line\">Server:         172.17.112.1</span><br><span class=\"line\">Address:        172.17.112.1#53</span><br><span class=\"line\"></span><br><span class=\"line\">Non-authoritative answer:</span><br><span class=\"line\">Name:   clashdingyue.tk</span><br><span class=\"line\">Address: 185.199.110.153</span><br><span class=\"line\">Name:   clashdingyue.tk</span><br><span class=\"line\">Address: 185.199.109.153</span><br><span class=\"line\">Name:   clashdingyue.tk</span><br><span class=\"line\">Address: 185.199.111.153</span><br><span class=\"line\">Name:   clashdingyue.tk</span><br><span class=\"line\">Address: 185.199.108.153</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">➜  hexo-blog nslookup wohensha.tk</span><br><span class=\"line\">Server:         172.17.112.1</span><br><span class=\"line\">Address:        172.17.112.1#53</span><br><span class=\"line\"></span><br><span class=\"line\">Non-authoritative answer:</span><br><span class=\"line\">Name:   wohensha.tk</span><br><span class=\"line\">Address: 172.67.165.231</span><br><span class=\"line\">Name:   wohensha.tk</span><br><span class=\"line\">Address: 104.21.49.190</span><br></pre></td></tr></table></figure>\n\n<p><strong>两个或两个以上Server IP，则表明使用了CDN，只有一个则表明没有。</strong></p>\n<ul>\n<li>Github CDN：185.199.110.153、185.199.108.153…</li>\n<li>CloudFlare CDN：172.67.165.231、104.21.49.190</li>\n</ul>\n<h2 id=\"二、测试两个CDN哪一个在墙内，速度更好\"><a href=\"#二、测试两个CDN哪一个在墙内，速度更好\" class=\"headerlink\" title=\"二、测试两个CDN哪一个在墙内，速度更好\"></a>二、测试两个CDN哪一个在墙内，速度更好</h2><h3 id=\"CloudFlare-CDN\"><a href=\"#CloudFlare-CDN\" class=\"headerlink\" title=\"CloudFlare CDN\"></a>CloudFlare CDN</h3><p>略</p>\n<h3 id=\"Github-CDN\"><a href=\"#Github-CDN\" class=\"headerlink\" title=\"Github CDN\"></a>Github CDN</h3><p><img src=\"/img/cut/cdn-test-1.webp\" alt=\"image-cdn\"></p>\n<p><img src=\"/img/cut/cdn-test-2.webp\" alt=\"image-cdn\"></p>\n<p>(￣▽￣)，半斤八两，感觉Github CDN好点</p>\n"},{"title":"网站、DNS速度测试和性能分析","cover":"https://zfh-tuchuang.oss-cn-shanghai.aliyuncs.com/img/site-backgound.jpg","top_img":null,"date":"2022-06-27T11:57:25.000Z","updated":"2022-06-27T11:57:25.000Z","description":"网站、DNS速度测试和性能分析","keywords":null,"_content":"\n### 常用国内外网站测速及性能分析工具\n\n网站多地测速工具/网站，通常是**同时测试并列出众多监测点到网站的主要速度指标**(如解析时间、连接时间、下载速度等)，一般**不用于**检测网站代码及服务器性能优化的情况，而是主要用于选购服务器/VPS、服务器/CDN在各地的网速排查、CDN部署等。\n\n- [**17ce**](https://www.17ce.com/) *(国内网站)*\n  - 60+个国内及香港监测点,适用于**国内**各地访问网站的速度测试\n  - 提供 Get, Ping, 路由追踪, Dns, Cdn等多维度速度测试\n  - 提供监控API(付费)\n- [**卡卡网 Webkaka**](http://www.webkaka.com/) *(国内网站)*\n  - 60+个国内监测点, 30+个海外监测点，适用于**国内**或**全球**各地访问网站的速度测试\n  - 提供 Get, ping, 路由追踪, Dns等多维度速度测试\n  - 提供网站速度诊断功能\n- [**Sucuri Load Time Tester**](https://performance.sucuri.net/) *(国外网站)*\n  - 15+个全球监测点, 适用于**全球**各地访问网站(如外贸网站)的速度测试\n  - 提供网页连接时间、首字节时间、总时间等数据\n- [**Dotcom-Tools Website Speed Test**](https://www.dotcom-tools.com/website-speed-test.aspx) *(国外网站)*\n  - 20+个全球监测点, 适用于**全球**各地访问网站(如外贸网站)的速度测试\n  - 提供两次(首次及重复访问)网页加载速度，且可按节点查看详细信息\n\n\n\n**一、Think with Google**\n\n工具地址：www.thinkwithgoogle.com/feature/testmysite/\n\n这是谷歌推出专门针对移动端访问速测试的工具，该工具模似4G访问网站，而结果也会出现相对应的优化建议，与竞争对手的打开速度比较，这是一款针对TO C移动端用户的专业测速工具。\n\n**二、Webuup**\n\n工具地址：www.webuup.com\n\nWebuup是新出的免费的在线网站质量检测工具，目前知道它的人还不是很多，但它的功能却十分强大，非常好用。它不仅能根据各项关键指标，如页面性能、移动表现、SEO优化和安全隐私来判断网站的质量，还能给出网站优化和提升的建议，Webuup检测工具，可以在页面速度检测栏，清晰的显示全球不同的测速区域与测速服务器状态下，该网站首字节返回时间、页面展示延迟时间、页面完整加载时间。\n\n**三、PageSpeed Insights**\n\n工具地址：pagespeed.web.dev\n\nPageSpeed这款测速工具出自Google，它可以直接总结出测试网站所存在的问题，并提出相应的优化建议，且指示很清晰，而最近谷歌推出的页面体验算法，也是根据这里的三项页面指标（LCP、FID、CLS）优化，此外，PageSpeed的测速包括移动设备和桌面设备两方面，并分别从这两个不同的设备端提出了提升网站加载速度的建议，用起来十分方便。\n\n**四、Gtmetrix**\n\n工具地址：gtmetrix.com\n\nGTmetrix现在由Lighthouse提供技术支持，有网站打开速度和网站性能评测工具，也成为网站用户体验的检测工具，Lighthouse是Google提供的一种开源工具，可以通过多种方式对网页进行评估。它被认为是现代Web性能指标的标准，因此将Lighthouse分析和性能数据集成到GTmetrix中，所以也是这次我们放在推荐网站速度测试工具之一。\n\n**五、Dotcom-tools**\n\n工具地址：www.dotcom-tools.com\n\nDotcom网站全球访问测试工具，主要是分析外贸网站在全球各地的速度测试，输入网址后，会出现每个地区节点的载入时间、重复测试后的载入时间、下载页面大小及遭遇到的错误记录，可以查看页面大小、加载时间和下载速度等前端元素，还可以查看HTML、JavaScript和CSS等后端元素，可以对网站针对性优化。\n\n​\t\t以上五款是不错的免费网站打开速度测试工具，也比较实用，当然还有一些其他的测试工具，但这五款工具已经够用了。正常一个网站，打开速度应该在2~3秒是比较理想的，同时大家在优化好web端的打开速度时，也要注重对于移动端的优化。\n\n","source":"_posts/SEO.md","raw":"---\ntitle: 网站、DNS速度测试和性能分析\ntags:\n  - SEO\ncategories:\n  - [SEO]\ncover: \ntop_img: \ndate: 2022-06-27 19:57:25\nupdated: 2022-06-27 19:57:25 \ndescription: 网站、DNS速度测试和性能分析\nkeywords:\n---\n\n### 常用国内外网站测速及性能分析工具\n\n网站多地测速工具/网站，通常是**同时测试并列出众多监测点到网站的主要速度指标**(如解析时间、连接时间、下载速度等)，一般**不用于**检测网站代码及服务器性能优化的情况，而是主要用于选购服务器/VPS、服务器/CDN在各地的网速排查、CDN部署等。\n\n- [**17ce**](https://www.17ce.com/) *(国内网站)*\n  - 60+个国内及香港监测点,适用于**国内**各地访问网站的速度测试\n  - 提供 Get, Ping, 路由追踪, Dns, Cdn等多维度速度测试\n  - 提供监控API(付费)\n- [**卡卡网 Webkaka**](http://www.webkaka.com/) *(国内网站)*\n  - 60+个国内监测点, 30+个海外监测点，适用于**国内**或**全球**各地访问网站的速度测试\n  - 提供 Get, ping, 路由追踪, Dns等多维度速度测试\n  - 提供网站速度诊断功能\n- [**Sucuri Load Time Tester**](https://performance.sucuri.net/) *(国外网站)*\n  - 15+个全球监测点, 适用于**全球**各地访问网站(如外贸网站)的速度测试\n  - 提供网页连接时间、首字节时间、总时间等数据\n- [**Dotcom-Tools Website Speed Test**](https://www.dotcom-tools.com/website-speed-test.aspx) *(国外网站)*\n  - 20+个全球监测点, 适用于**全球**各地访问网站(如外贸网站)的速度测试\n  - 提供两次(首次及重复访问)网页加载速度，且可按节点查看详细信息\n\n\n\n**一、Think with Google**\n\n工具地址：www.thinkwithgoogle.com/feature/testmysite/\n\n这是谷歌推出专门针对移动端访问速测试的工具，该工具模似4G访问网站，而结果也会出现相对应的优化建议，与竞争对手的打开速度比较，这是一款针对TO C移动端用户的专业测速工具。\n\n**二、Webuup**\n\n工具地址：www.webuup.com\n\nWebuup是新出的免费的在线网站质量检测工具，目前知道它的人还不是很多，但它的功能却十分强大，非常好用。它不仅能根据各项关键指标，如页面性能、移动表现、SEO优化和安全隐私来判断网站的质量，还能给出网站优化和提升的建议，Webuup检测工具，可以在页面速度检测栏，清晰的显示全球不同的测速区域与测速服务器状态下，该网站首字节返回时间、页面展示延迟时间、页面完整加载时间。\n\n**三、PageSpeed Insights**\n\n工具地址：pagespeed.web.dev\n\nPageSpeed这款测速工具出自Google，它可以直接总结出测试网站所存在的问题，并提出相应的优化建议，且指示很清晰，而最近谷歌推出的页面体验算法，也是根据这里的三项页面指标（LCP、FID、CLS）优化，此外，PageSpeed的测速包括移动设备和桌面设备两方面，并分别从这两个不同的设备端提出了提升网站加载速度的建议，用起来十分方便。\n\n**四、Gtmetrix**\n\n工具地址：gtmetrix.com\n\nGTmetrix现在由Lighthouse提供技术支持，有网站打开速度和网站性能评测工具，也成为网站用户体验的检测工具，Lighthouse是Google提供的一种开源工具，可以通过多种方式对网页进行评估。它被认为是现代Web性能指标的标准，因此将Lighthouse分析和性能数据集成到GTmetrix中，所以也是这次我们放在推荐网站速度测试工具之一。\n\n**五、Dotcom-tools**\n\n工具地址：www.dotcom-tools.com\n\nDotcom网站全球访问测试工具，主要是分析外贸网站在全球各地的速度测试，输入网址后，会出现每个地区节点的载入时间、重复测试后的载入时间、下载页面大小及遭遇到的错误记录，可以查看页面大小、加载时间和下载速度等前端元素，还可以查看HTML、JavaScript和CSS等后端元素，可以对网站针对性优化。\n\n​\t\t以上五款是不错的免费网站打开速度测试工具，也比较实用，当然还有一些其他的测试工具，但这五款工具已经够用了。正常一个网站，打开速度应该在2~3秒是比较理想的，同时大家在优化好web端的打开速度时，也要注重对于移动端的优化。\n\n","slug":"SEO","published":1,"comments":1,"layout":"post","photos":[],"link":"","_id":"cl9y38drw000bfwuih4u57kr1","content":"<h3 id=\"常用国内外网站测速及性能分析工具\"><a href=\"#常用国内外网站测速及性能分析工具\" class=\"headerlink\" title=\"常用国内外网站测速及性能分析工具\"></a>常用国内外网站测速及性能分析工具</h3><p>网站多地测速工具&#x2F;网站，通常是<strong>同时测试并列出众多监测点到网站的主要速度指标</strong>(如解析时间、连接时间、下载速度等)，一般<strong>不用于</strong>检测网站代码及服务器性能优化的情况，而是主要用于选购服务器&#x2F;VPS、服务器&#x2F;CDN在各地的网速排查、CDN部署等。</p>\n<ul>\n<li><a href=\"https://www.17ce.com/\"><strong>17ce</strong></a> <em>(国内网站)</em><ul>\n<li>60+个国内及香港监测点,适用于<strong>国内</strong>各地访问网站的速度测试</li>\n<li>提供 Get, Ping, 路由追踪, Dns, Cdn等多维度速度测试</li>\n<li>提供监控API(付费)</li>\n</ul>\n</li>\n<li><a href=\"http://www.webkaka.com/\"><strong>卡卡网 Webkaka</strong></a> <em>(国内网站)</em><ul>\n<li>60+个国内监测点, 30+个海外监测点，适用于<strong>国内</strong>或<strong>全球</strong>各地访问网站的速度测试</li>\n<li>提供 Get, ping, 路由追踪, Dns等多维度速度测试</li>\n<li>提供网站速度诊断功能</li>\n</ul>\n</li>\n<li><a href=\"https://performance.sucuri.net/\"><strong>Sucuri Load Time Tester</strong></a> <em>(国外网站)</em><ul>\n<li>15+个全球监测点, 适用于<strong>全球</strong>各地访问网站(如外贸网站)的速度测试</li>\n<li>提供网页连接时间、首字节时间、总时间等数据</li>\n</ul>\n</li>\n<li><a href=\"https://www.dotcom-tools.com/website-speed-test.aspx\"><strong>Dotcom-Tools Website Speed Test</strong></a> <em>(国外网站)</em><ul>\n<li>20+个全球监测点, 适用于<strong>全球</strong>各地访问网站(如外贸网站)的速度测试</li>\n<li>提供两次(首次及重复访问)网页加载速度，且可按节点查看详细信息</li>\n</ul>\n</li>\n</ul>\n<p><strong>一、Think with Google</strong></p>\n<p>工具地址：<a href=\"http://www.thinkwithgoogle.com/feature/testmysite/\">www.thinkwithgoogle.com/feature/testmysite/</a></p>\n<p>这是谷歌推出专门针对移动端访问速测试的工具，该工具模似4G访问网站，而结果也会出现相对应的优化建议，与竞争对手的打开速度比较，这是一款针对TO C移动端用户的专业测速工具。</p>\n<p><strong>二、Webuup</strong></p>\n<p>工具地址：<a href=\"http://www.webuup.com/\">www.webuup.com</a></p>\n<p>Webuup是新出的免费的在线网站质量检测工具，目前知道它的人还不是很多，但它的功能却十分强大，非常好用。它不仅能根据各项关键指标，如页面性能、移动表现、SEO优化和安全隐私来判断网站的质量，还能给出网站优化和提升的建议，Webuup检测工具，可以在页面速度检测栏，清晰的显示全球不同的测速区域与测速服务器状态下，该网站首字节返回时间、页面展示延迟时间、页面完整加载时间。</p>\n<p><strong>三、PageSpeed Insights</strong></p>\n<p>工具地址：pagespeed.web.dev</p>\n<p>PageSpeed这款测速工具出自Google，它可以直接总结出测试网站所存在的问题，并提出相应的优化建议，且指示很清晰，而最近谷歌推出的页面体验算法，也是根据这里的三项页面指标（LCP、FID、CLS）优化，此外，PageSpeed的测速包括移动设备和桌面设备两方面，并分别从这两个不同的设备端提出了提升网站加载速度的建议，用起来十分方便。</p>\n<p><strong>四、Gtmetrix</strong></p>\n<p>工具地址：gtmetrix.com</p>\n<p>GTmetrix现在由Lighthouse提供技术支持，有网站打开速度和网站性能评测工具，也成为网站用户体验的检测工具，Lighthouse是Google提供的一种开源工具，可以通过多种方式对网页进行评估。它被认为是现代Web性能指标的标准，因此将Lighthouse分析和性能数据集成到GTmetrix中，所以也是这次我们放在推荐网站速度测试工具之一。</p>\n<p><strong>五、Dotcom-tools</strong></p>\n<p>工具地址：<a href=\"http://www.dotcom-tools.com/\">www.dotcom-tools.com</a></p>\n<p>Dotcom网站全球访问测试工具，主要是分析外贸网站在全球各地的速度测试，输入网址后，会出现每个地区节点的载入时间、重复测试后的载入时间、下载页面大小及遭遇到的错误记录，可以查看页面大小、加载时间和下载速度等前端元素，还可以查看HTML、JavaScript和CSS等后端元素，可以对网站针对性优化。</p>\n<p>​\t\t以上五款是不错的免费网站打开速度测试工具，也比较实用，当然还有一些其他的测试工具，但这五款工具已经够用了。正常一个网站，打开速度应该在2~3秒是比较理想的，同时大家在优化好web端的打开速度时，也要注重对于移动端的优化。</p>\n","site":{"data":{"link":[{"class_name":"友情链接","class_desc":"那些人，那些事","link_list":[{"name":"张洪Heo","link":"https://blog.zhheo.com/","avatar":"https://npm.elemecdn.com/guli-heo/img/avatar2.png","descr":"分享设计与科技生活"},{"name":"瞬間の筆記","link":"https://hikki.site","descr":"喜欢的东西就努力去追求，万一成功了呢!","avatar":"https://cdn.jsdelivr.net/gh/0000rookie/imgs/202206120315.png"}]}]}},"excerpt":"","more":"<h3 id=\"常用国内外网站测速及性能分析工具\"><a href=\"#常用国内外网站测速及性能分析工具\" class=\"headerlink\" title=\"常用国内外网站测速及性能分析工具\"></a>常用国内外网站测速及性能分析工具</h3><p>网站多地测速工具&#x2F;网站，通常是<strong>同时测试并列出众多监测点到网站的主要速度指标</strong>(如解析时间、连接时间、下载速度等)，一般<strong>不用于</strong>检测网站代码及服务器性能优化的情况，而是主要用于选购服务器&#x2F;VPS、服务器&#x2F;CDN在各地的网速排查、CDN部署等。</p>\n<ul>\n<li><a href=\"https://www.17ce.com/\"><strong>17ce</strong></a> <em>(国内网站)</em><ul>\n<li>60+个国内及香港监测点,适用于<strong>国内</strong>各地访问网站的速度测试</li>\n<li>提供 Get, Ping, 路由追踪, Dns, Cdn等多维度速度测试</li>\n<li>提供监控API(付费)</li>\n</ul>\n</li>\n<li><a href=\"http://www.webkaka.com/\"><strong>卡卡网 Webkaka</strong></a> <em>(国内网站)</em><ul>\n<li>60+个国内监测点, 30+个海外监测点，适用于<strong>国内</strong>或<strong>全球</strong>各地访问网站的速度测试</li>\n<li>提供 Get, ping, 路由追踪, Dns等多维度速度测试</li>\n<li>提供网站速度诊断功能</li>\n</ul>\n</li>\n<li><a href=\"https://performance.sucuri.net/\"><strong>Sucuri Load Time Tester</strong></a> <em>(国外网站)</em><ul>\n<li>15+个全球监测点, 适用于<strong>全球</strong>各地访问网站(如外贸网站)的速度测试</li>\n<li>提供网页连接时间、首字节时间、总时间等数据</li>\n</ul>\n</li>\n<li><a href=\"https://www.dotcom-tools.com/website-speed-test.aspx\"><strong>Dotcom-Tools Website Speed Test</strong></a> <em>(国外网站)</em><ul>\n<li>20+个全球监测点, 适用于<strong>全球</strong>各地访问网站(如外贸网站)的速度测试</li>\n<li>提供两次(首次及重复访问)网页加载速度，且可按节点查看详细信息</li>\n</ul>\n</li>\n</ul>\n<p><strong>一、Think with Google</strong></p>\n<p>工具地址：<a href=\"http://www.thinkwithgoogle.com/feature/testmysite/\">www.thinkwithgoogle.com/feature/testmysite/</a></p>\n<p>这是谷歌推出专门针对移动端访问速测试的工具，该工具模似4G访问网站，而结果也会出现相对应的优化建议，与竞争对手的打开速度比较，这是一款针对TO C移动端用户的专业测速工具。</p>\n<p><strong>二、Webuup</strong></p>\n<p>工具地址：<a href=\"http://www.webuup.com/\">www.webuup.com</a></p>\n<p>Webuup是新出的免费的在线网站质量检测工具，目前知道它的人还不是很多，但它的功能却十分强大，非常好用。它不仅能根据各项关键指标，如页面性能、移动表现、SEO优化和安全隐私来判断网站的质量，还能给出网站优化和提升的建议，Webuup检测工具，可以在页面速度检测栏，清晰的显示全球不同的测速区域与测速服务器状态下，该网站首字节返回时间、页面展示延迟时间、页面完整加载时间。</p>\n<p><strong>三、PageSpeed Insights</strong></p>\n<p>工具地址：pagespeed.web.dev</p>\n<p>PageSpeed这款测速工具出自Google，它可以直接总结出测试网站所存在的问题，并提出相应的优化建议，且指示很清晰，而最近谷歌推出的页面体验算法，也是根据这里的三项页面指标（LCP、FID、CLS）优化，此外，PageSpeed的测速包括移动设备和桌面设备两方面，并分别从这两个不同的设备端提出了提升网站加载速度的建议，用起来十分方便。</p>\n<p><strong>四、Gtmetrix</strong></p>\n<p>工具地址：gtmetrix.com</p>\n<p>GTmetrix现在由Lighthouse提供技术支持，有网站打开速度和网站性能评测工具，也成为网站用户体验的检测工具，Lighthouse是Google提供的一种开源工具，可以通过多种方式对网页进行评估。它被认为是现代Web性能指标的标准，因此将Lighthouse分析和性能数据集成到GTmetrix中，所以也是这次我们放在推荐网站速度测试工具之一。</p>\n<p><strong>五、Dotcom-tools</strong></p>\n<p>工具地址：<a href=\"http://www.dotcom-tools.com/\">www.dotcom-tools.com</a></p>\n<p>Dotcom网站全球访问测试工具，主要是分析外贸网站在全球各地的速度测试，输入网址后，会出现每个地区节点的载入时间、重复测试后的载入时间、下载页面大小及遭遇到的错误记录，可以查看页面大小、加载时间和下载速度等前端元素，还可以查看HTML、JavaScript和CSS等后端元素，可以对网站针对性优化。</p>\n<p>​\t\t以上五款是不错的免费网站打开速度测试工具，也比较实用，当然还有一些其他的测试工具，但这五款工具已经够用了。正常一个网站，打开速度应该在2~3秒是比较理想的，同时大家在优化好web端的打开速度时，也要注重对于移动端的优化。</p>\n"},{"title":"WSL中的骚操作","cover":"https://tva4.sinaimg.cn/large/0084aYsLgy1gy51ogkzs9j31hc0m843g.jpg","top_img":null,"date":"2022-06-27T06:27:44.000Z","updated":"2022-06-27T06:27:44.000Z","description":null,"keywords":null,"_content":"\n## 配置oh-my-zsh\n\n- 启用zsh，并配上一系列插件，可以极大的提升工作效率。\n\n  ```shell\n  plugins=(z vi-mode zsh-completions web-search git zsh-autosuggestions zsh-syntax-highlighting rand-quote themes cp)\n  ```\n\n  特别是z 、 zsh-completions、zsh-autosuggestions、git都是特别好用的神器。\n\n\n\n\n\n# 关于Hexo\n\n​\t\t由于Linux出色的命令行终端体验，在Linux中部署Hexo静态博客比Windows方便太多了，在加上一些骚操作，体验非常完美！！！\n\n- 配置一些hexo相关的快捷键（zsh）\n\n  ```shell\n  # alias hexo\n  alias hd=\"hexo clean && hexo g && hexo d\"\n  # alias hs=\"hexo clean && hexo g && hexo d && hexo s\"\n  alias hs=\"hexo clean && hexo g && hexo s\"\n  alias hnp=\"hexo new post $1\"\n  ```\n\n  敲上两个字母，就可以完成hexo的远程部署或者本地调试，体验非常良好。\n\n- 借助Windows和Hexo的互操作性，配置typora用linux命令启动\n\n  ```shell\n  # alias windows app\n  alias tp='func() { /mnt/d/Typora/Typora.exe $1 &;}; func'\n  ```\n\n  敲下tp，就可以直接启动typora.exe，在windows环境下书写markdown了。\n","source":"_posts/WSL中的骚操作.md","raw":"---\ntitle: WSL中的骚操作\ntags:\n  - WSL\n  - Linxu\n  - hexo\ncategories:\n  - [Linux]\ncover: \ntop_img: \ndate: 2022-06-27 14:27:44\nupdated: 2022-06-27 14:27:44\ndescription:\nkeywords:\n---\n\n## 配置oh-my-zsh\n\n- 启用zsh，并配上一系列插件，可以极大的提升工作效率。\n\n  ```shell\n  plugins=(z vi-mode zsh-completions web-search git zsh-autosuggestions zsh-syntax-highlighting rand-quote themes cp)\n  ```\n\n  特别是z 、 zsh-completions、zsh-autosuggestions、git都是特别好用的神器。\n\n\n\n\n\n# 关于Hexo\n\n​\t\t由于Linux出色的命令行终端体验，在Linux中部署Hexo静态博客比Windows方便太多了，在加上一些骚操作，体验非常完美！！！\n\n- 配置一些hexo相关的快捷键（zsh）\n\n  ```shell\n  # alias hexo\n  alias hd=\"hexo clean && hexo g && hexo d\"\n  # alias hs=\"hexo clean && hexo g && hexo d && hexo s\"\n  alias hs=\"hexo clean && hexo g && hexo s\"\n  alias hnp=\"hexo new post $1\"\n  ```\n\n  敲上两个字母，就可以完成hexo的远程部署或者本地调试，体验非常良好。\n\n- 借助Windows和Hexo的互操作性，配置typora用linux命令启动\n\n  ```shell\n  # alias windows app\n  alias tp='func() { /mnt/d/Typora/Typora.exe $1 &;}; func'\n  ```\n\n  敲下tp，就可以直接启动typora.exe，在windows环境下书写markdown了。\n","slug":"WSL中的骚操作","published":1,"comments":1,"layout":"post","photos":[],"link":"","_id":"cl9y38drz000gfwuihdgpad2t","content":"<h2 id=\"配置oh-my-zsh\"><a href=\"#配置oh-my-zsh\" class=\"headerlink\" title=\"配置oh-my-zsh\"></a>配置oh-my-zsh</h2><ul>\n<li><p>启用zsh，并配上一系列插件，可以极大的提升工作效率。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">plugins=(z vi-mode zsh-completions web-search git zsh-autosuggestions zsh-syntax-highlighting rand-quote themes cp)</span><br></pre></td></tr></table></figure>\n\n<p>特别是z 、 zsh-completions、zsh-autosuggestions、git都是特别好用的神器。</p>\n</li>\n</ul>\n<h1 id=\"关于Hexo\"><a href=\"#关于Hexo\" class=\"headerlink\" title=\"关于Hexo\"></a>关于Hexo</h1><p>​\t\t由于Linux出色的命令行终端体验，在Linux中部署Hexo静态博客比Windows方便太多了，在加上一些骚操作，体验非常完美！！！</p>\n<ul>\n<li><p>配置一些hexo相关的快捷键（zsh）</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\"><span class=\"built_in\">alias</span> hexo</span></span><br><span class=\"line\">alias hd=&quot;hexo clean &amp;&amp; hexo g &amp;&amp; hexo d&quot;</span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\"><span class=\"built_in\">alias</span> hs=<span class=\"string\">&quot;hexo clean &amp;&amp; hexo g &amp;&amp; hexo d &amp;&amp; hexo s&quot;</span></span></span><br><span class=\"line\">alias hs=&quot;hexo clean &amp;&amp; hexo g &amp;&amp; hexo s&quot;</span><br><span class=\"line\">alias hnp=&quot;hexo new post $1&quot;</span><br></pre></td></tr></table></figure>\n\n<p>敲上两个字母，就可以完成hexo的远程部署或者本地调试，体验非常良好。</p>\n</li>\n<li><p>借助Windows和Hexo的互操作性，配置typora用linux命令启动</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\"><span class=\"built_in\">alias</span> windows app</span></span><br><span class=\"line\">alias tp=&#x27;func() &#123; /mnt/d/Typora/Typora.exe $1 &amp;;&#125;; func&#x27;</span><br></pre></td></tr></table></figure>\n\n<p>敲下tp，就可以直接启动typora.exe，在windows环境下书写markdown了。</p>\n</li>\n</ul>\n","site":{"data":{"link":[{"class_name":"友情链接","class_desc":"那些人，那些事","link_list":[{"name":"张洪Heo","link":"https://blog.zhheo.com/","avatar":"https://npm.elemecdn.com/guli-heo/img/avatar2.png","descr":"分享设计与科技生活"},{"name":"瞬間の筆記","link":"https://hikki.site","descr":"喜欢的东西就努力去追求，万一成功了呢!","avatar":"https://cdn.jsdelivr.net/gh/0000rookie/imgs/202206120315.png"}]}]}},"excerpt":"","more":"<h2 id=\"配置oh-my-zsh\"><a href=\"#配置oh-my-zsh\" class=\"headerlink\" title=\"配置oh-my-zsh\"></a>配置oh-my-zsh</h2><ul>\n<li><p>启用zsh，并配上一系列插件，可以极大的提升工作效率。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">plugins=(z vi-mode zsh-completions web-search git zsh-autosuggestions zsh-syntax-highlighting rand-quote themes cp)</span><br></pre></td></tr></table></figure>\n\n<p>特别是z 、 zsh-completions、zsh-autosuggestions、git都是特别好用的神器。</p>\n</li>\n</ul>\n<h1 id=\"关于Hexo\"><a href=\"#关于Hexo\" class=\"headerlink\" title=\"关于Hexo\"></a>关于Hexo</h1><p>​\t\t由于Linux出色的命令行终端体验，在Linux中部署Hexo静态博客比Windows方便太多了，在加上一些骚操作，体验非常完美！！！</p>\n<ul>\n<li><p>配置一些hexo相关的快捷键（zsh）</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\"><span class=\"built_in\">alias</span> hexo</span></span><br><span class=\"line\">alias hd=&quot;hexo clean &amp;&amp; hexo g &amp;&amp; hexo d&quot;</span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\"><span class=\"built_in\">alias</span> hs=<span class=\"string\">&quot;hexo clean &amp;&amp; hexo g &amp;&amp; hexo d &amp;&amp; hexo s&quot;</span></span></span><br><span class=\"line\">alias hs=&quot;hexo clean &amp;&amp; hexo g &amp;&amp; hexo s&quot;</span><br><span class=\"line\">alias hnp=&quot;hexo new post $1&quot;</span><br></pre></td></tr></table></figure>\n\n<p>敲上两个字母，就可以完成hexo的远程部署或者本地调试，体验非常良好。</p>\n</li>\n<li><p>借助Windows和Hexo的互操作性，配置typora用linux命令启动</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\"><span class=\"built_in\">alias</span> windows app</span></span><br><span class=\"line\">alias tp=&#x27;func() &#123; /mnt/d/Typora/Typora.exe $1 &amp;;&#125;; func&#x27;</span><br></pre></td></tr></table></figure>\n\n<p>敲下tp，就可以直接启动typora.exe，在windows环境下书写markdown了。</p>\n</li>\n</ul>\n"},{"title":"hexo+freenom+cloudflare遇到的一些坑","cover":"https://tva3.sinaimg.cn/large/0084aYsLgy1h22161jezaj30xc0f0dh1.jpg","top_img":"linear-gradient(20deg, #0062be, #925696, #cc426e, #fb0347)","date":"2022-06-27T03:30:32.000Z","updated":"2022-06-27T03:30:32.000Z","description":null,"keywords":"freenom、CloudFlare、clash","_content":"\n\n\n#### 使用CloudFlare进行DNS解析，并启用CloudFlare的代理和CDN后，github pages无法访问\n\n> ​\t\t原因就是 CloudFlare到 GitHub Pages这段 回源没有采用 TLS访问，解决的办法也很简单，在 CloudFlare中找到 SSL/TLS中的 概述，把默认的 灵活（加密浏览器与 Cloudflare 之间的流量）改为 完全（端到端加密，使用服务器上的自签名证书）即可。\n\n\n\n#### CFW（Clash For Windows）TUN 模式\n\n> 对于不遵循系统代理的软件，TUN 模式可以接管其流量并交由 CFW 处理，在 Windows 中，TUN 模式性能比 TAP 模式好\n\n> **NOTICE**\n\n> 近期大部分浏览器默认已经开启“**安全 DNS**”功能，此功能会影响 TUN 模式劫持 DNS 请求导致反推域名失败，请在浏览器设置中关闭此功能以保证 TUN 模式正常运行\n\n\n\n","source":"_posts/hexo+freenom+cloudflare遇到的一些坑.md","raw":"---\ntitle: hexo+freenom+cloudflare遇到的一些坑\ntags:\n  - hexo\n  - github pages\n  - CFW\ncategories:\n  - hexo\ncover: \ntop_img: 'linear-gradient(20deg, #0062be, #925696, #cc426e, #fb0347)'\ndate: 2022-06-27 11:30:32\nupdated: 2022-06-27 11:30:32\ndescription:\nkeywords: freenom、CloudFlare、clash\n---\n\n\n\n#### 使用CloudFlare进行DNS解析，并启用CloudFlare的代理和CDN后，github pages无法访问\n\n> ​\t\t原因就是 CloudFlare到 GitHub Pages这段 回源没有采用 TLS访问，解决的办法也很简单，在 CloudFlare中找到 SSL/TLS中的 概述，把默认的 灵活（加密浏览器与 Cloudflare 之间的流量）改为 完全（端到端加密，使用服务器上的自签名证书）即可。\n\n\n\n#### CFW（Clash For Windows）TUN 模式\n\n> 对于不遵循系统代理的软件，TUN 模式可以接管其流量并交由 CFW 处理，在 Windows 中，TUN 模式性能比 TAP 模式好\n\n> **NOTICE**\n\n> 近期大部分浏览器默认已经开启“**安全 DNS**”功能，此功能会影响 TUN 模式劫持 DNS 请求导致反推域名失败，请在浏览器设置中关闭此功能以保证 TUN 模式正常运行\n\n\n\n","slug":"hexo+freenom+cloudflare遇到的一些坑","published":1,"comments":1,"layout":"post","photos":[],"link":"","_id":"cl9y38ds0000hfwui24z3f3i9","content":"<h4 id=\"使用CloudFlare进行DNS解析，并启用CloudFlare的代理和CDN后，github-pages无法访问\"><a href=\"#使用CloudFlare进行DNS解析，并启用CloudFlare的代理和CDN后，github-pages无法访问\" class=\"headerlink\" title=\"使用CloudFlare进行DNS解析，并启用CloudFlare的代理和CDN后，github pages无法访问\"></a>使用CloudFlare进行DNS解析，并启用CloudFlare的代理和CDN后，github pages无法访问</h4><blockquote>\n<p>​\t\t原因就是 CloudFlare到 GitHub Pages这段 回源没有采用 TLS访问，解决的办法也很简单，在 CloudFlare中找到 SSL&#x2F;TLS中的 概述，把默认的 灵活（加密浏览器与 Cloudflare 之间的流量）改为 完全（端到端加密，使用服务器上的自签名证书）即可。</p>\n</blockquote>\n<h4 id=\"CFW（Clash-For-Windows）TUN-模式\"><a href=\"#CFW（Clash-For-Windows）TUN-模式\" class=\"headerlink\" title=\"CFW（Clash For Windows）TUN 模式\"></a>CFW（Clash For Windows）TUN 模式</h4><blockquote>\n<p>对于不遵循系统代理的软件，TUN 模式可以接管其流量并交由 CFW 处理，在 Windows 中，TUN 模式性能比 TAP 模式好</p>\n</blockquote>\n<blockquote>\n<p><strong>NOTICE</strong></p>\n</blockquote>\n<blockquote>\n<p>近期大部分浏览器默认已经开启“<strong>安全 DNS</strong>”功能，此功能会影响 TUN 模式劫持 DNS 请求导致反推域名失败，请在浏览器设置中关闭此功能以保证 TUN 模式正常运行</p>\n</blockquote>\n","site":{"data":{"link":[{"class_name":"友情链接","class_desc":"那些人，那些事","link_list":[{"name":"张洪Heo","link":"https://blog.zhheo.com/","avatar":"https://npm.elemecdn.com/guli-heo/img/avatar2.png","descr":"分享设计与科技生活"},{"name":"瞬間の筆記","link":"https://hikki.site","descr":"喜欢的东西就努力去追求，万一成功了呢!","avatar":"https://cdn.jsdelivr.net/gh/0000rookie/imgs/202206120315.png"}]}]}},"excerpt":"","more":"<h4 id=\"使用CloudFlare进行DNS解析，并启用CloudFlare的代理和CDN后，github-pages无法访问\"><a href=\"#使用CloudFlare进行DNS解析，并启用CloudFlare的代理和CDN后，github-pages无法访问\" class=\"headerlink\" title=\"使用CloudFlare进行DNS解析，并启用CloudFlare的代理和CDN后，github pages无法访问\"></a>使用CloudFlare进行DNS解析，并启用CloudFlare的代理和CDN后，github pages无法访问</h4><blockquote>\n<p>​\t\t原因就是 CloudFlare到 GitHub Pages这段 回源没有采用 TLS访问，解决的办法也很简单，在 CloudFlare中找到 SSL&#x2F;TLS中的 概述，把默认的 灵活（加密浏览器与 Cloudflare 之间的流量）改为 完全（端到端加密，使用服务器上的自签名证书）即可。</p>\n</blockquote>\n<h4 id=\"CFW（Clash-For-Windows）TUN-模式\"><a href=\"#CFW（Clash-For-Windows）TUN-模式\" class=\"headerlink\" title=\"CFW（Clash For Windows）TUN 模式\"></a>CFW（Clash For Windows）TUN 模式</h4><blockquote>\n<p>对于不遵循系统代理的软件，TUN 模式可以接管其流量并交由 CFW 处理，在 Windows 中，TUN 模式性能比 TAP 模式好</p>\n</blockquote>\n<blockquote>\n<p><strong>NOTICE</strong></p>\n</blockquote>\n<blockquote>\n<p>近期大部分浏览器默认已经开启“<strong>安全 DNS</strong>”功能，此功能会影响 TUN 模式劫持 DNS 请求导致反推域名失败，请在浏览器设置中关闭此功能以保证 TUN 模式正常运行</p>\n</blockquote>\n"},{"title":"hexo的front-matter中的tags和categories","cover":"https://tva4.sinaimg.cn/large/0084aYsLgy1gy51ogkzs9j31hc0m843g.jpg","top_img":null,"date":"2022-06-27T06:44:40.000Z","updated":"2022-06-27T06:44:40.000Z","description":null,"keywords":null,"_content":"\n## 分类和标签\n\n​\t\t只有文章支持分类和标签，您可以在 Front-matter 中设置。在其他系统中，分类和标签听起来很接近，但是在 Hexo 中两者有着明显的差别：分类具有顺序性和层次性，也就是说 `Foo, Bar` 不等于 `Bar, Foo`；而标签没有顺序和层次。\n\n```\ncategories:\n- Diary\ntags:\n- PS3\n- Games\n```\n\n> 分类方法的分歧\n>\n> 如果您有过使用 WordPress 的经验，就很容易误解 Hexo 的分类方式。WordPress 支持对一篇文章设置多个分类，而且这些分类可以是同级的，也可以是父子分类。但是 Hexo 不支持指定多个同级分类。下面的指定方法：\n>\n> ```\n> categories:\n>   - Diary\n>   - Life\n> ```\n>\n> 会使分类`Life`成为`Diary`的子分类，而不是并列分类。因此，有必要为您的文章选择尽可能准确的分类。\n>\n> 如果你需要为文章添加多个分类，可以尝试以下 list 中的方法。\n>\n> ```\n> categories:\n> - [Diary, PlayStation]\n> - [Diary, Games]\n> - [Life]\n> ```\n>\n> 此时这篇文章同时包括三个分类： `PlayStation` 和 `Games` 分别都是父分类 `Diary` 的子分类，同时 `Life` 是一个没有子分类的分类。\n","source":"_posts/hexo的front-matter中的分类问题.md","raw":"---\ntitle: hexo的front-matter中的tags和categories\ntags:\n  - hexo \ncategories:\n  - [hexo]\ncover: \ntop_img: \ndate: 2022-06-27 14:44:40\nupdated: 2022-06-27 14:44:40\ndescription:\nkeywords:\n---\n\n## 分类和标签\n\n​\t\t只有文章支持分类和标签，您可以在 Front-matter 中设置。在其他系统中，分类和标签听起来很接近，但是在 Hexo 中两者有着明显的差别：分类具有顺序性和层次性，也就是说 `Foo, Bar` 不等于 `Bar, Foo`；而标签没有顺序和层次。\n\n```\ncategories:\n- Diary\ntags:\n- PS3\n- Games\n```\n\n> 分类方法的分歧\n>\n> 如果您有过使用 WordPress 的经验，就很容易误解 Hexo 的分类方式。WordPress 支持对一篇文章设置多个分类，而且这些分类可以是同级的，也可以是父子分类。但是 Hexo 不支持指定多个同级分类。下面的指定方法：\n>\n> ```\n> categories:\n>   - Diary\n>   - Life\n> ```\n>\n> 会使分类`Life`成为`Diary`的子分类，而不是并列分类。因此，有必要为您的文章选择尽可能准确的分类。\n>\n> 如果你需要为文章添加多个分类，可以尝试以下 list 中的方法。\n>\n> ```\n> categories:\n> - [Diary, PlayStation]\n> - [Diary, Games]\n> - [Life]\n> ```\n>\n> 此时这篇文章同时包括三个分类： `PlayStation` 和 `Games` 分别都是父分类 `Diary` 的子分类，同时 `Life` 是一个没有子分类的分类。\n","slug":"hexo的front-matter中的分类问题","published":1,"comments":1,"layout":"post","photos":[],"link":"","_id":"cl9y38ds2000kfwuih8vq6lc5","content":"<h2 id=\"分类和标签\"><a href=\"#分类和标签\" class=\"headerlink\" title=\"分类和标签\"></a>分类和标签</h2><p>​\t\t只有文章支持分类和标签，您可以在 Front-matter 中设置。在其他系统中，分类和标签听起来很接近，但是在 Hexo 中两者有着明显的差别：分类具有顺序性和层次性，也就是说 <code>Foo, Bar</code> 不等于 <code>Bar, Foo</code>；而标签没有顺序和层次。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">categories:</span><br><span class=\"line\">- Diary</span><br><span class=\"line\">tags:</span><br><span class=\"line\">- PS3</span><br><span class=\"line\">- Games</span><br></pre></td></tr></table></figure>\n\n<blockquote>\n<p>分类方法的分歧</p>\n<p>如果您有过使用 WordPress 的经验，就很容易误解 Hexo 的分类方式。WordPress 支持对一篇文章设置多个分类，而且这些分类可以是同级的，也可以是父子分类。但是 Hexo 不支持指定多个同级分类。下面的指定方法：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">categories:</span><br><span class=\"line\">  - Diary</span><br><span class=\"line\">  - Life</span><br></pre></td></tr></table></figure>\n\n<p>会使分类<code>Life</code>成为<code>Diary</code>的子分类，而不是并列分类。因此，有必要为您的文章选择尽可能准确的分类。</p>\n<p>如果你需要为文章添加多个分类，可以尝试以下 list 中的方法。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">categories:</span><br><span class=\"line\">- [Diary, PlayStation]</span><br><span class=\"line\">- [Diary, Games]</span><br><span class=\"line\">- [Life]</span><br></pre></td></tr></table></figure>\n\n<p>此时这篇文章同时包括三个分类： <code>PlayStation</code> 和 <code>Games</code> 分别都是父分类 <code>Diary</code> 的子分类，同时 <code>Life</code> 是一个没有子分类的分类。</p>\n</blockquote>\n","site":{"data":{"link":[{"class_name":"友情链接","class_desc":"那些人，那些事","link_list":[{"name":"张洪Heo","link":"https://blog.zhheo.com/","avatar":"https://npm.elemecdn.com/guli-heo/img/avatar2.png","descr":"分享设计与科技生活"},{"name":"瞬間の筆記","link":"https://hikki.site","descr":"喜欢的东西就努力去追求，万一成功了呢!","avatar":"https://cdn.jsdelivr.net/gh/0000rookie/imgs/202206120315.png"}]}]}},"excerpt":"","more":"<h2 id=\"分类和标签\"><a href=\"#分类和标签\" class=\"headerlink\" title=\"分类和标签\"></a>分类和标签</h2><p>​\t\t只有文章支持分类和标签，您可以在 Front-matter 中设置。在其他系统中，分类和标签听起来很接近，但是在 Hexo 中两者有着明显的差别：分类具有顺序性和层次性，也就是说 <code>Foo, Bar</code> 不等于 <code>Bar, Foo</code>；而标签没有顺序和层次。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">categories:</span><br><span class=\"line\">- Diary</span><br><span class=\"line\">tags:</span><br><span class=\"line\">- PS3</span><br><span class=\"line\">- Games</span><br></pre></td></tr></table></figure>\n\n<blockquote>\n<p>分类方法的分歧</p>\n<p>如果您有过使用 WordPress 的经验，就很容易误解 Hexo 的分类方式。WordPress 支持对一篇文章设置多个分类，而且这些分类可以是同级的，也可以是父子分类。但是 Hexo 不支持指定多个同级分类。下面的指定方法：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">categories:</span><br><span class=\"line\">  - Diary</span><br><span class=\"line\">  - Life</span><br></pre></td></tr></table></figure>\n\n<p>会使分类<code>Life</code>成为<code>Diary</code>的子分类，而不是并列分类。因此，有必要为您的文章选择尽可能准确的分类。</p>\n<p>如果你需要为文章添加多个分类，可以尝试以下 list 中的方法。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">categories:</span><br><span class=\"line\">- [Diary, PlayStation]</span><br><span class=\"line\">- [Diary, Games]</span><br><span class=\"line\">- [Life]</span><br></pre></td></tr></table></figure>\n\n<p>此时这篇文章同时包括三个分类： <code>PlayStation</code> 和 <code>Games</code> 分别都是父分类 <code>Diary</code> 的子分类，同时 <code>Life</code> 是一个没有子分类的分类。</p>\n</blockquote>\n"},{"title":"网易云音乐EMO语录","date":"2022-06-25T09:00:28.000Z","cover":"https://tva4.sinaimg.cn/large/0084aYsLgy1gy51ogkzs9j31hc0m843g.jpg","top_img":null,"_content":"\n\n\n![cat](/img/cat.png)\n\n## 网易云EMO语录 - 纯属好玩\n\n\n\n- 小时候不理解老人晒太阳，一坐就是半天。长大了才明白，目之所及皆是回忆，心之所想皆是过往，眼之所看皆是遗憾。                                                   \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t——网易云热评《红莓花儿开》  \n\n- 未成定局的事就不要弄的人尽皆知 \n\n- 大胆点生活 你没那么多观众\n\n- 一个人在离家2000公里外的山沟里当兵，我坐在山坡上，看着田埂上的小孩放着风筝，大人在屁股后面跟着跑，笑容不知不觉爬上嘴角，太阳很刺眼，我很想家                                                                             ——网易云《Town of Windmill 》\n\n- 陪领导吃饭，把领导全部喝趴了，然后每个人都有人接回家，唯独我没有，一个人走到地铁站。当时走着去路边打车，被风一吹，终于忍不住了，直到吐干净，劲过去了，已经是凌晨四点。\n  摸摸手机，零条短信，零条来电。\n  只有那棵树整整支撑了我五个小时.\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  ——《身后的故乡》\n- 有一段时间觉得爸爸很古板很烦，后来有一天看到一句话“中年以后的男人，时常会觉得孤独，因为他一睁开眼睛，周围都是要依靠他的人，却没有他可以依靠的人”。 \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t ——网易云音乐热评 《体温》\n","source":"_posts/zhihu-emo-yulu.md","raw":"---\ntitle: 网易云音乐EMO语录\ndate: 2022-06-25 17:00:28\n\ncover: \ntop_img: \n\ntags: \n- EMO语录\ncategories:\n- \n\n---\n\n\n\n![cat](/img/cat.png)\n\n## 网易云EMO语录 - 纯属好玩\n\n\n\n- 小时候不理解老人晒太阳，一坐就是半天。长大了才明白，目之所及皆是回忆，心之所想皆是过往，眼之所看皆是遗憾。                                                   \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t——网易云热评《红莓花儿开》  \n\n- 未成定局的事就不要弄的人尽皆知 \n\n- 大胆点生活 你没那么多观众\n\n- 一个人在离家2000公里外的山沟里当兵，我坐在山坡上，看着田埂上的小孩放着风筝，大人在屁股后面跟着跑，笑容不知不觉爬上嘴角，太阳很刺眼，我很想家                                                                             ——网易云《Town of Windmill 》\n\n- 陪领导吃饭，把领导全部喝趴了，然后每个人都有人接回家，唯独我没有，一个人走到地铁站。当时走着去路边打车，被风一吹，终于忍不住了，直到吐干净，劲过去了，已经是凌晨四点。\n  摸摸手机，零条短信，零条来电。\n  只有那棵树整整支撑了我五个小时.\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  ——《身后的故乡》\n- 有一段时间觉得爸爸很古板很烦，后来有一天看到一句话“中年以后的男人，时常会觉得孤独，因为他一睁开眼睛，周围都是要依靠他的人，却没有他可以依靠的人”。 \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t ——网易云音乐热评 《体温》\n","slug":"zhihu-emo-yulu","published":1,"updated":"2022-07-02T06:18:18.357Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9y38ds3000mfwui7mnidfjp","content":"<p><img src=\"/img/cat.png\" alt=\"cat\"></p>\n<h2 id=\"网易云EMO语录-纯属好玩\"><a href=\"#网易云EMO语录-纯属好玩\" class=\"headerlink\" title=\"网易云EMO语录 - 纯属好玩\"></a>网易云EMO语录 - 纯属好玩</h2><ul>\n<li><p>小时候不理解老人晒太阳，一坐就是半天。长大了才明白，目之所及皆是回忆，心之所想皆是过往，眼之所看皆是遗憾。                                                   \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t——网易云热评《红莓花儿开》  </p>\n</li>\n<li><p>未成定局的事就不要弄的人尽皆知 </p>\n</li>\n<li><p>大胆点生活 你没那么多观众</p>\n</li>\n<li><p>一个人在离家2000公里外的山沟里当兵，我坐在山坡上，看着田埂上的小孩放着风筝，大人在屁股后面跟着跑，笑容不知不觉爬上嘴角，太阳很刺眼，我很想家                                                                             ——网易云《Town of Windmill 》</p>\n</li>\n<li><p>陪领导吃饭，把领导全部喝趴了，然后每个人都有人接回家，唯独我没有，一个人走到地铁站。当时走着去路边打车，被风一吹，终于忍不住了，直到吐干净，劲过去了，已经是凌晨四点。<br>摸摸手机，零条短信，零条来电。<br>只有那棵树整整支撑了我五个小时.\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  ——《身后的故乡》</p>\n</li>\n<li><p>有一段时间觉得爸爸很古板很烦，后来有一天看到一句话“中年以后的男人，时常会觉得孤独，因为他一睁开眼睛，周围都是要依靠他的人，却没有他可以依靠的人”。 \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t ——网易云音乐热评 《体温》</p>\n</li>\n</ul>\n","site":{"data":{"link":[{"class_name":"友情链接","class_desc":"那些人，那些事","link_list":[{"name":"张洪Heo","link":"https://blog.zhheo.com/","avatar":"https://npm.elemecdn.com/guli-heo/img/avatar2.png","descr":"分享设计与科技生活"},{"name":"瞬間の筆記","link":"https://hikki.site","descr":"喜欢的东西就努力去追求，万一成功了呢!","avatar":"https://cdn.jsdelivr.net/gh/0000rookie/imgs/202206120315.png"}]}]}},"excerpt":"","more":"<p><img src=\"/img/cat.png\" alt=\"cat\"></p>\n<h2 id=\"网易云EMO语录-纯属好玩\"><a href=\"#网易云EMO语录-纯属好玩\" class=\"headerlink\" title=\"网易云EMO语录 - 纯属好玩\"></a>网易云EMO语录 - 纯属好玩</h2><ul>\n<li><p>小时候不理解老人晒太阳，一坐就是半天。长大了才明白，目之所及皆是回忆，心之所想皆是过往，眼之所看皆是遗憾。                                                   \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t——网易云热评《红莓花儿开》  </p>\n</li>\n<li><p>未成定局的事就不要弄的人尽皆知 </p>\n</li>\n<li><p>大胆点生活 你没那么多观众</p>\n</li>\n<li><p>一个人在离家2000公里外的山沟里当兵，我坐在山坡上，看着田埂上的小孩放着风筝，大人在屁股后面跟着跑，笑容不知不觉爬上嘴角，太阳很刺眼，我很想家                                                                             ——网易云《Town of Windmill 》</p>\n</li>\n<li><p>陪领导吃饭，把领导全部喝趴了，然后每个人都有人接回家，唯独我没有，一个人走到地铁站。当时走着去路边打车，被风一吹，终于忍不住了，直到吐干净，劲过去了，已经是凌晨四点。<br>摸摸手机，零条短信，零条来电。<br>只有那棵树整整支撑了我五个小时.\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  ——《身后的故乡》</p>\n</li>\n<li><p>有一段时间觉得爸爸很古板很烦，后来有一天看到一句话“中年以后的男人，时常会觉得孤独，因为他一睁开眼睛，周围都是要依靠他的人，却没有他可以依靠的人”。 \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t ——网易云音乐热评 《体温》</p>\n</li>\n</ul>\n"},{"title":"记一次Kylin Server JVM OOM事故排查复盘","date":"2022-09-23T11:35:27.000Z","updated":"2022-09-23T11:35:27.000Z","cover":"https://tvax3.sinaimg.cn/large/0084aYsLly1grnkfb3zyvj31hc0tndku.jpg","top_img":null,"description":null,"keywords":null,"_content":"\n## 问题\n\n在使用Tableau连接Kylin进行多维分析的时候，偶现查询失败，连接超时的问题，由此开始排查事故出现的原因。\n\n- 1、在Kylin的logs里面定位到有JVM OOM的情况，然后查看Kylin Server的JVM GC日志，发现在某个时间段会频繁的发生Full GC，Full GC可以持续十几分钟，同时GC后，老年代空间没有任何变化，这次Full GC无法回收一个对象，开始怀疑发生了内存泄漏。\n- 2、生产中部署了三个Kylin Server节点，前面由Nginx进行反向代理，进行负载均衡。查看Nginx日志，发现只有其中一个节点有Timeout的错误日志，于是怀疑Nginx负载均衡配置有问题，大部分流量分到一个节点，导致OOM。但是查看nginx配置，发现没有任何问题，同时Count Nginx请求日志，发现流量也不大，因此和Nginx与大流量高负载可能没有关系。\n- 3、到这里，只能利用MAT对JVM的Heap Dump文件*.hprof进行分析，文件有20G大，分析过程中一度导致服务器CPU狂飙至99%，顺利完成后，得到三个zip压缩文件，查看后，检测到内存泄漏，是由两个超大List大对象引起的。\n- 4、查看这两个超大List对象的全类名，发现是Kylin hold在内存中的查询结果集，由于查询结果集太大，Kylin Server JVM装不下，直接导致OOM的发生。\n\n\n\n> 正常情况下，查询Kylin的都应该是Group By语句，因此结果集应该很小，不会出现大对象，因此排查是哪一个查询语句查出来如此巨大的结果集。\n>\n> 根据Query id，查找日志，发现是Tableau发出的类似`select tmp.a from tmp;`的这种奇怪且没有意义的查询语句。但是Tableau是闭源的，完全搞不懂为什么会发出这种查询，在Tableau各种实验，也没有办法拖拽出这种查询SQL，但是确实又会时不时发出，导致Kylin Server OOM。\n\n\n\n- 5、为了快速的解决问题，保证服务的SLA，因此决定利用Arthas直接线上不停机运行时修改Kylin的源码，为不是Group By的每一条SQL加上limit，保证不会有大的结果集导致OOM。\n\n## 解决方法\n\n> 利用Arthas attach到线上Kylin Server的JVM\n>\n> 1、利用`jad命令`将QueryUtil类进行反编译，并保存下来，然后用vim修改源码中添加limit的判断逻辑，为不是Group By的每一条SQL加上limit，修改完以后需要将类重新加载到JVM\n>\n> $ jad --source--only com.example.demo.DemoApplication > /data/DemoApplication.java\n>\n> 2、`SC命令` 查找QueryUtil类是哪个classLoader加载的\n>\n> $ sc -d *DemoApplication | grep classLoader\n>\n> classLoaderHash   20ad9418 #类加载器  编号   \n>\n> 3、`MC命令` 用指定的classloader将修改后类在内存中编译（MC：内存编译器）\n>\n> $ mc -c 20ad9418 /data/DemoApplication.java -d /data  \n>\n> Memory compiler output: /data/com/example/demo/DemoApplication.class\n>\n> 4、`redefine命令` 将编译后的类加载到JVM\n>\n> $ redefine /data/com/example/demo/DemoApplication.class   redefine success, size: 1\n\n- 一顿操作猛如虎后，Kylin的源码已经在不停机、运行时完成了更改，最后问题解决，用户完全无感。\n","source":"_posts/记一次Kylin-Server的JVM-OOM事故排查复盘.md","raw":"---\ntitle: 记一次Kylin Server JVM OOM事故排查复盘\ntags:\n  - 'Kylin'\n  - 'JVM'\n  - 'MAT'\n  - 'Arthas'\ncategories:\n  - [bigdata,Kylin]\ndate: 2022-09-23 19:35:27\nupdated: 2022-09-23 19:35:27\ncover:\ntop_img:\ndescription:\nkeywords:\n---\n\n## 问题\n\n在使用Tableau连接Kylin进行多维分析的时候，偶现查询失败，连接超时的问题，由此开始排查事故出现的原因。\n\n- 1、在Kylin的logs里面定位到有JVM OOM的情况，然后查看Kylin Server的JVM GC日志，发现在某个时间段会频繁的发生Full GC，Full GC可以持续十几分钟，同时GC后，老年代空间没有任何变化，这次Full GC无法回收一个对象，开始怀疑发生了内存泄漏。\n- 2、生产中部署了三个Kylin Server节点，前面由Nginx进行反向代理，进行负载均衡。查看Nginx日志，发现只有其中一个节点有Timeout的错误日志，于是怀疑Nginx负载均衡配置有问题，大部分流量分到一个节点，导致OOM。但是查看nginx配置，发现没有任何问题，同时Count Nginx请求日志，发现流量也不大，因此和Nginx与大流量高负载可能没有关系。\n- 3、到这里，只能利用MAT对JVM的Heap Dump文件*.hprof进行分析，文件有20G大，分析过程中一度导致服务器CPU狂飙至99%，顺利完成后，得到三个zip压缩文件，查看后，检测到内存泄漏，是由两个超大List大对象引起的。\n- 4、查看这两个超大List对象的全类名，发现是Kylin hold在内存中的查询结果集，由于查询结果集太大，Kylin Server JVM装不下，直接导致OOM的发生。\n\n\n\n> 正常情况下，查询Kylin的都应该是Group By语句，因此结果集应该很小，不会出现大对象，因此排查是哪一个查询语句查出来如此巨大的结果集。\n>\n> 根据Query id，查找日志，发现是Tableau发出的类似`select tmp.a from tmp;`的这种奇怪且没有意义的查询语句。但是Tableau是闭源的，完全搞不懂为什么会发出这种查询，在Tableau各种实验，也没有办法拖拽出这种查询SQL，但是确实又会时不时发出，导致Kylin Server OOM。\n\n\n\n- 5、为了快速的解决问题，保证服务的SLA，因此决定利用Arthas直接线上不停机运行时修改Kylin的源码，为不是Group By的每一条SQL加上limit，保证不会有大的结果集导致OOM。\n\n## 解决方法\n\n> 利用Arthas attach到线上Kylin Server的JVM\n>\n> 1、利用`jad命令`将QueryUtil类进行反编译，并保存下来，然后用vim修改源码中添加limit的判断逻辑，为不是Group By的每一条SQL加上limit，修改完以后需要将类重新加载到JVM\n>\n> $ jad --source--only com.example.demo.DemoApplication > /data/DemoApplication.java\n>\n> 2、`SC命令` 查找QueryUtil类是哪个classLoader加载的\n>\n> $ sc -d *DemoApplication | grep classLoader\n>\n> classLoaderHash   20ad9418 #类加载器  编号   \n>\n> 3、`MC命令` 用指定的classloader将修改后类在内存中编译（MC：内存编译器）\n>\n> $ mc -c 20ad9418 /data/DemoApplication.java -d /data  \n>\n> Memory compiler output: /data/com/example/demo/DemoApplication.class\n>\n> 4、`redefine命令` 将编译后的类加载到JVM\n>\n> $ redefine /data/com/example/demo/DemoApplication.class   redefine success, size: 1\n\n- 一顿操作猛如虎后，Kylin的源码已经在不停机、运行时完成了更改，最后问题解决，用户完全无感。\n","slug":"记一次Kylin-Server的JVM-OOM事故排查复盘","published":1,"comments":1,"layout":"post","photos":[],"link":"","_id":"cl9y38ds5000pfwui8zd33j5t","content":"<h2 id=\"问题\"><a href=\"#问题\" class=\"headerlink\" title=\"问题\"></a>问题</h2><p>在使用Tableau连接Kylin进行多维分析的时候，偶现查询失败，连接超时的问题，由此开始排查事故出现的原因。</p>\n<ul>\n<li>1、在Kylin的logs里面定位到有JVM OOM的情况，然后查看Kylin Server的JVM GC日志，发现在某个时间段会频繁的发生Full GC，Full GC可以持续十几分钟，同时GC后，老年代空间没有任何变化，这次Full GC无法回收一个对象，开始怀疑发生了内存泄漏。</li>\n<li>2、生产中部署了三个Kylin Server节点，前面由Nginx进行反向代理，进行负载均衡。查看Nginx日志，发现只有其中一个节点有Timeout的错误日志，于是怀疑Nginx负载均衡配置有问题，大部分流量分到一个节点，导致OOM。但是查看nginx配置，发现没有任何问题，同时Count Nginx请求日志，发现流量也不大，因此和Nginx与大流量高负载可能没有关系。</li>\n<li>3、到这里，只能利用MAT对JVM的Heap Dump文件*.hprof进行分析，文件有20G大，分析过程中一度导致服务器CPU狂飙至99%，顺利完成后，得到三个zip压缩文件，查看后，检测到内存泄漏，是由两个超大List大对象引起的。</li>\n<li>4、查看这两个超大List对象的全类名，发现是Kylin hold在内存中的查询结果集，由于查询结果集太大，Kylin Server JVM装不下，直接导致OOM的发生。</li>\n</ul>\n<blockquote>\n<p>正常情况下，查询Kylin的都应该是Group By语句，因此结果集应该很小，不会出现大对象，因此排查是哪一个查询语句查出来如此巨大的结果集。</p>\n<p>根据Query id，查找日志，发现是Tableau发出的类似<code>select tmp.a from tmp;</code>的这种奇怪且没有意义的查询语句。但是Tableau是闭源的，完全搞不懂为什么会发出这种查询，在Tableau各种实验，也没有办法拖拽出这种查询SQL，但是确实又会时不时发出，导致Kylin Server OOM。</p>\n</blockquote>\n<ul>\n<li>5、为了快速的解决问题，保证服务的SLA，因此决定利用Arthas直接线上不停机运行时修改Kylin的源码，为不是Group By的每一条SQL加上limit，保证不会有大的结果集导致OOM。</li>\n</ul>\n<h2 id=\"解决方法\"><a href=\"#解决方法\" class=\"headerlink\" title=\"解决方法\"></a>解决方法</h2><blockquote>\n<p>利用Arthas attach到线上Kylin Server的JVM</p>\n<p>1、利用<code>jad命令</code>将QueryUtil类进行反编译，并保存下来，然后用vim修改源码中添加limit的判断逻辑，为不是Group By的每一条SQL加上limit，修改完以后需要将类重新加载到JVM</p>\n<p>$ jad –source–only com.example.demo.DemoApplication &gt; &#x2F;data&#x2F;DemoApplication.java</p>\n<p>2、<code>SC命令</code> 查找QueryUtil类是哪个classLoader加载的</p>\n<p>$ sc -d *DemoApplication | grep classLoader</p>\n<p>classLoaderHash   20ad9418 #类加载器  编号   </p>\n<p>3、<code>MC命令</code> 用指定的classloader将修改后类在内存中编译（MC：内存编译器）</p>\n<p>$ mc -c 20ad9418 &#x2F;data&#x2F;DemoApplication.java -d &#x2F;data  </p>\n<p>Memory compiler output: &#x2F;data&#x2F;com&#x2F;example&#x2F;demo&#x2F;DemoApplication.class</p>\n<p>4、<code>redefine命令</code> 将编译后的类加载到JVM</p>\n<p>$ redefine &#x2F;data&#x2F;com&#x2F;example&#x2F;demo&#x2F;DemoApplication.class   redefine success, size: 1</p>\n</blockquote>\n<ul>\n<li>一顿操作猛如虎后，Kylin的源码已经在不停机、运行时完成了更改，最后问题解决，用户完全无感。</li>\n</ul>\n","site":{"data":{"link":[{"class_name":"友情链接","class_desc":"那些人，那些事","link_list":[{"name":"张洪Heo","link":"https://blog.zhheo.com/","avatar":"https://npm.elemecdn.com/guli-heo/img/avatar2.png","descr":"分享设计与科技生活"},{"name":"瞬間の筆記","link":"https://hikki.site","descr":"喜欢的东西就努力去追求，万一成功了呢!","avatar":"https://cdn.jsdelivr.net/gh/0000rookie/imgs/202206120315.png"}]}]}},"excerpt":"","more":"<h2 id=\"问题\"><a href=\"#问题\" class=\"headerlink\" title=\"问题\"></a>问题</h2><p>在使用Tableau连接Kylin进行多维分析的时候，偶现查询失败，连接超时的问题，由此开始排查事故出现的原因。</p>\n<ul>\n<li>1、在Kylin的logs里面定位到有JVM OOM的情况，然后查看Kylin Server的JVM GC日志，发现在某个时间段会频繁的发生Full GC，Full GC可以持续十几分钟，同时GC后，老年代空间没有任何变化，这次Full GC无法回收一个对象，开始怀疑发生了内存泄漏。</li>\n<li>2、生产中部署了三个Kylin Server节点，前面由Nginx进行反向代理，进行负载均衡。查看Nginx日志，发现只有其中一个节点有Timeout的错误日志，于是怀疑Nginx负载均衡配置有问题，大部分流量分到一个节点，导致OOM。但是查看nginx配置，发现没有任何问题，同时Count Nginx请求日志，发现流量也不大，因此和Nginx与大流量高负载可能没有关系。</li>\n<li>3、到这里，只能利用MAT对JVM的Heap Dump文件*.hprof进行分析，文件有20G大，分析过程中一度导致服务器CPU狂飙至99%，顺利完成后，得到三个zip压缩文件，查看后，检测到内存泄漏，是由两个超大List大对象引起的。</li>\n<li>4、查看这两个超大List对象的全类名，发现是Kylin hold在内存中的查询结果集，由于查询结果集太大，Kylin Server JVM装不下，直接导致OOM的发生。</li>\n</ul>\n<blockquote>\n<p>正常情况下，查询Kylin的都应该是Group By语句，因此结果集应该很小，不会出现大对象，因此排查是哪一个查询语句查出来如此巨大的结果集。</p>\n<p>根据Query id，查找日志，发现是Tableau发出的类似<code>select tmp.a from tmp;</code>的这种奇怪且没有意义的查询语句。但是Tableau是闭源的，完全搞不懂为什么会发出这种查询，在Tableau各种实验，也没有办法拖拽出这种查询SQL，但是确实又会时不时发出，导致Kylin Server OOM。</p>\n</blockquote>\n<ul>\n<li>5、为了快速的解决问题，保证服务的SLA，因此决定利用Arthas直接线上不停机运行时修改Kylin的源码，为不是Group By的每一条SQL加上limit，保证不会有大的结果集导致OOM。</li>\n</ul>\n<h2 id=\"解决方法\"><a href=\"#解决方法\" class=\"headerlink\" title=\"解决方法\"></a>解决方法</h2><blockquote>\n<p>利用Arthas attach到线上Kylin Server的JVM</p>\n<p>1、利用<code>jad命令</code>将QueryUtil类进行反编译，并保存下来，然后用vim修改源码中添加limit的判断逻辑，为不是Group By的每一条SQL加上limit，修改完以后需要将类重新加载到JVM</p>\n<p>$ jad –source–only com.example.demo.DemoApplication &gt; &#x2F;data&#x2F;DemoApplication.java</p>\n<p>2、<code>SC命令</code> 查找QueryUtil类是哪个classLoader加载的</p>\n<p>$ sc -d *DemoApplication | grep classLoader</p>\n<p>classLoaderHash   20ad9418 #类加载器  编号   </p>\n<p>3、<code>MC命令</code> 用指定的classloader将修改后类在内存中编译（MC：内存编译器）</p>\n<p>$ mc -c 20ad9418 &#x2F;data&#x2F;DemoApplication.java -d &#x2F;data  </p>\n<p>Memory compiler output: &#x2F;data&#x2F;com&#x2F;example&#x2F;demo&#x2F;DemoApplication.class</p>\n<p>4、<code>redefine命令</code> 将编译后的类加载到JVM</p>\n<p>$ redefine &#x2F;data&#x2F;com&#x2F;example&#x2F;demo&#x2F;DemoApplication.class   redefine success, size: 1</p>\n</blockquote>\n<ul>\n<li>一顿操作猛如虎后，Kylin的源码已经在不停机、运行时完成了更改，最后问题解决，用户完全无感。</li>\n</ul>\n"},{"title":"Doris Compaction从入门到跑路","top_img":null,"date":"2022-09-03T15:40:51.000Z","updated":"2022-09-03T15:40:51.000Z","cover":"https://tvax3.sinaimg.cn/large/0084aYsLly1grnkfb3zyvj31hc0tndku.jpg","description":null,"keywords":null,"_content":"\n>\n>\n>Doris 中用于控制Compaction的参数非常多。本文尝试以下方面，介绍这些参数的含义以及如果通过调整参数来适配场景。\n>\n>\n>\n>1. 数据版本是如何产生的，哪些因素影响数据版本的产出。\n>2. 为什么需要 Base 和 Cumulative 两种类型的 Compaction。\n>3. Compaction 机制是如何挑选数据分片进行 Compaction 的。\n>4. 对于一个数据分片，Compaction 机制是如何确定哪些数据版本参与 Compaction 的。\n>5. 在高频导入场景下，可以修改哪些参数来优化 Compaction 逻辑。\n>6. Compaction 相关的查看和管理命令。\n\n# Why  need Compaction\n\nDoris 的数据写入模型使用了 LSM-Tree 类似的数据结构。数据都是以追加（Append）的方式写入磁盘的。这种数据结构可以将随机写变为顺序写。这是一种面向写优化的数据结构，他能增强系统的写入吞吐，但是在读逻辑中，需要通过 Merge-on-Read 的方式，在读取时合并多次写入的数据，从而处理写入时的数据变更。\n\nMerge-on-Read 会影响读取的效率，为了降低读取时需要合并的数据量，基于 LSM-Tree 的系统都会引入后台数据合并的逻辑，以一定策略定期的对数据进行合并。Doris 中这种机制被称为 Compaction。\n\nDoris 中每次数据写入会生成一个数据版本。Compaction的过程就是讲多个数据版本合并成一个更大的版本。Compaction 可以带来以下好处：\n\n> - 1.数据更加有序\n>\n>   每个数据版本内的数据是按主键有序的，但是版本之间的数据是无序的。Compaction后形成的大版本将多个小版本的数据变成有序数据。在有序数据中进行数据检索的效率更高。\n>\n> - 2.消除数据变更\n>\n>   数据都是以追加的方式写入的，因此 Delete、Update 等操作都是写入一个标记。Compaction 操作可以处理这些标记，进行真正的数据删除或更新，从而在读取时，不再需要根据这些标记来过滤数据。\n>\n> - 3.增加数据聚合度\n> 在聚合模型下，Compaction 能进一步聚合不同数据版本中相同 key 的数据行，从而增加数据聚合度，减少读取时需要实时进行的聚合计算。\n\n# Compaction 的问题\n\n用户可能需要根据实际的使用场景来调整 Compaction 的策略，否则可能遇到如下问题：\n\n1. Compaction 速度低于数据写入速度\n\n   在高频写入场景下，短时间内会产生大量的数据版本。如果 Compaction 不及时，就会造成大量版本堆积，最终严重影响写入速度。\n\n2. 写放大问题\n\n   Compaction 本质上是将已经写入的数据读取后重写写回的过程，这种数据重复写入被称为写放大。一个好的Compaction策略应该在保证效率的前提下，尽量降低写放大系数。过多的 Compaction 会占用大量的磁盘IO资源，影响系统整体效率。\n\n# Something about Compaction(How)\n\n## 数据版本的产生\n\n首先，用户的数据表会按照分区和分桶规则，切分成若干个数据分片（Tablet）存储在不同 BE 节点上。每个 Tablet 都有多个副本（默认为3副本）。Compaction 是在每个 BE 上独立进行的，Compaction 逻辑处理的就是一个 BE 节点上所有的数据分片。\n\nDoris的数据都是以追加的方式写入系统的。Doris目前的写入依然是以微批的方式进行的，每一批次的数据针对每个 Tablet 都会形成一个 rowset。而一个 Tablet 是由多个Rowset 组成的。每个 Rowset 都有一个对应的起始版本和终止版本。对于新增Rowset，起始版本和终止版本相同，表示为 [6-6]、[7-7] 等。多个Rowset经过 Compaction 形成一个大的 Rowset，起始版本和终止版本为多个版本的并集，如 [6-6]、[7-7]、[8-8] 合并后变成 [6-8]。\n\nRowset 的数量直接影响到 Compaction 是否能够及时完成。那么一批次导入会生成多少个 Rowset 呢？这里我们举一个例子：\n\n假设集群有3个 BE 节点。每个BE节点2块盘。只有一张表，2个分区，每个分区3个分桶，默认3副本。那么总分片数量是（2 * 3 * 3）18 个，如果均匀分布在所有节点上，则每个盘上3个tablet。假设一次导入涉及到其中一个分区，则一次导入总共产生9个Rowset，即平均每块盘产生1-2个 Rowset。（这里仅考虑数据完全均匀分布的情况下，实际情况中，可能多个 Tablet 集中在某一块磁盘上。）\n\n从上面的例子我们可以得出，rowset的数量直接取决于表的分片数量。举个极端的例子，如果一个Doris集群只有3个BE节点，但是一个表有9000个分片。那么一次导入，每个BE节点就会新增3000个rowset，则至少要进行3000次compaction，才能处理完所有的分片。所以：\n\n> **合理的设置表的分区、分桶和副本数量，避免过多的分片，可以降低Compaction的开销。**\n\n## Base & Cumulative Compaction\n\nDoris 中有两种 Compaction 操作，分别称为 Base Compaction(BC) 和 Cumulative Compaction(CC)。BC 是将基线数据版本（以0为起始版本的数据）和增量数据版本合并的过程，而CC是增量数据间的合并过程。BC操作因为涉及到基线数据，而基线数据通常比较大，所以操作耗时会比CC长。\n\n如果只有 Base Compaction，则每次增量数据都要和全量的基线数据合并，写放大问题会非常严重，并且每次 Compaction 都相当耗时。因此我们需要引入 Cumulative Compaction 来先对增量数据进行合并，当增量数据合并后的大小达到一定阈值后，再和基线数据合并。这里我们有一个比较通用的 Compaction 调优策略：\n\n> **在合理范围内，尽量减少 Base Compaction 操作。**\n\nBC 和 CC 之间的分界线成为 Cumulative Point（CP），这是一个动态变化的版本号。比CP小的数据版本会只会触发 BC，而比CP大的数据版本，只会触发CC。\n\n\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1662219046764-f9891cea-fe8d-4eb2-89a4-911ffb10e7e2.png)\n\n\n\n整个过程有点类似 2048 小游戏：只有合并后大小足够，才能继续和更大的数据版本合并。\n\n\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1662219046833-aa0766ec-9852-4766-b57d-5b24448cd2b4.png)\n\n## 数据分片选择策略\n\n**Compaction 的目的是合并多个数据版本，一是避免在读取时大量的 Merge 操作，二是避免大量的数据版本导致的随机IO。**因此，Compaction 策略的重点问题，就是如何选择合适的 tablet，以保证节点上不会出现数据版本过多的数据分片。\n\n### Compaction 分数\n\n一个自然的想法，就是每次都选择数据版本最多的数据分片进行 Compaction。这个策略也是 Doris 的默认策略。这个策略在大部分场景下都能很好的工作。但是考虑到一种情况，就是版本多的分片，可能并不是最频繁访问的分片。而 Compaction 的目的就是优化读性能。那么有可能某一张 “写多读少” 表一直在 Compaction，而另一张 “读多写少” 的表不能及时的 Compaction，导致读性能变差。\n\n因此，Doris 在选择数据分片时还引入了 “读取频率” 的因素。“读取频率” 和 “版本数量” 会根据各自的权重，综合计算出一个 Compaction 分数，分数越高的分片，优先做 Compaction。这两个因素的权重由以下 BE 参数控制（取值越大，权重越高）：\n\n> **compaction_tablet_scan_frequency_factor：“读取频率” 的权重值，默认为 0。**\n>\n> **compaction_tablet_compaction_score_factor：“版本数量” 的权重，默认为 1。**\n\n> “读取频率” 的权重值默认为0，即默认仅考虑 “版本数量” 这个因素。*\n\n### 生产者与消费者\n\nCompaction 是一个 生产者-消费者 模型。由一个生产者线程负责选择需要做 Compaction 的数据分片，而多个消费者负责执行 Compaction 操作。\n\n生产者线程只有一个，会定期扫描所有 tablet 来选择合适的 compaction 对象。因为 Base Compaction 和 Cumulative Compaction 是不同类型的任务，因此目前的策略是每生成 9 个 CC 任务，生成一个 BC 任务。任务生成的频率由以下两个参数控制：\n\n> **cumulative_compaction_rounds_for_each_base_compaction_round：多少个CC任务后生成一个BC任务。**\n>\n> **generate_compaction_tasks_min_interval_ms：任务生成的间隔。**\n\n> *这两个参数通常情况下不需要调整。*\n\n生产者线程产生的任务会被提交到消费者线程池。因为 Compaction 是一个IO密集型的任务，为了保证 Compaction 任务不会过多的占用IO资源，Doris 限制了每个磁盘上能够同时进行的 Compaction 任务数量，以及节点整体的任务数量，这些限制由以下参数控制：\n\n> compaction_task_num_per_disk：每个磁盘上的任务数，默认为2。该参数必须大于等于2，以保证 BC 和 CC 任务各自至少有一个线程。\n>\n> max_compaction_threads：消费者线程，即Compaction线程的总数。默认为 10。\n>\n\n举个例子，假设一个 BE 节点配置了3个数据目录（即3块磁盘），每个磁盘上的任务数配置为2，总线程数为5。则同一时间，最多有5个 Compaction 任务在进行，而每块磁盘上最多有2个任务在进行。并且最多有3个 BC 任务在进行，因为每块盘上会自动预留一个线程给CC任务。\n\n**另一方面，Compaction 任务同时也是一个内存密集型任务，因为其本质是一个多路归并排序的过程，每一路是一个数据版本。**如果一个 Compaction 任务涉及的数据版本很多，则会占用更多的内存，如果仅限制任务数，而不考虑任务的内存开销，则有可能导致系统内存超限。因此，Doris 在上述任务个数限制之外，还增加了一个任务配额限制：\n\n> total_permits_for_compaction_score：Compaction 任务配额，默认 10000。\n\n每个 Compaction 任务都有一个配额，其数值就是任务涉及的数据版本数量。假设一个任务需要合并100个版本，则其配额为100。当正在运行的任务配额总和超过配置后，新的任务将被拒绝。\n\n三个配置共同决定了节点所能承受的 Compaction 任务数量。\n\n### 数据版本选择策略\n\n一个 Compaction 任务对应的是一个数据分片（Tablet）。消费线程拿到一个 Compaction 任务后，会根据 Compaction 的任务类型，选择 tablet 中合适的数据版本（Rowset）进行数据合并。下面分别介绍 Base Compaction 和 Cumulative Compaction 的数据分片选择策略。\n\n#### Base Compaction\n\n前文说过，BC 任务是增量数据和基线数据的合并任务。并且只有比 Cumulative Point（CP） 小的数据版本才会参与 BC 任务。因此，BC 任务的数据版本选取策略比较简单。\n\n首先，会选取所有版本在 0到 CP之间的 rowset。然后根据以下几个配置参数，判断是否启动一个 BC 任务：\n\n> base_compaction_num_cumulative_deltas：一次 BC 任务最小版本数量限制。默认为5。该参数主要为了避免过多 BC 任务。当数据版本数量较少时，BC 是没有必要的。\n>\n> base_compaction_interval_seconds_since_last_operation：第一个参数限制了当版本数量少时，不会进行 BC 任务。但我们需要避免另一种情况，即某些 tablet 可能仅会导入少量批次的数据，因此当 Doris 发现一个 tablet 长时间没有执行过 BC 任务时，也会触发 BC 任务。这个参数就是控制这个时间的，默认是 86400，单位是秒。\n>\n\n*> 以上两个参数通常情况下不需要修改，在某些情况下如何需要想尽快合并基线数据，可以尝试改小 **base_compaction_num_cumulative_deltas 参数。但这个参数只会影响到 “被选中的 tablet”。而 “被选中” 的前提是这个 tablet 的数据版本数量是最多的。***\n\n#### Cumulative Compaction\n\nCC 任务只会选取版本比 CP 大的数据版本。其本身的选取策略也比较简单，即从 CP 版本开始，依次向后选取数据版本。最终的数据版本集合由以下参数控制：\n\n> min_cumulative_compaction_num_singleton_deltas：一次 CC 任务最少的版本数量限制。这个配置是和 cumulative_size_based_compaction_lower_size_mbytes 配置同时判断的。即如果版本数量小于阈值，并且数据量也小于阈值，则不会触发 CC 任务。以避免过多不必要的 CC 任务。默认是5。\n>\n> max_cumulative_compaction_num_singleton_deltas：一次 CC 任务最大的版本数量限制。以防止一次 CC 任务合并的版本数量过多，占用过多资源。默认是1000。\n>\n> cumulative_size_based_compaction_lower_size_mbytes：一次 CC 任务最少的数据量，和min_cumulative_compaction_num_singleton_delta 同时判断。默认是 64，单位是 MB。\n>\n\n简单来说，默认配置下，就是从 CP 版本开始往后选取 rowset。最少选5个，最多选 1000 个，然后判断数据量是否大于阈值即可。\n\nCC 任务还有一个重要步骤，就是在合并任务结束后，设置新的 Cumulative Point。CC 任务合并完成后，会产生一个合并后的新的数据版本，而我们要做的就是判断这个新的数据版是 “晋升” 到 BC 任务区，还是依然保留在 CC 任务区。举个例子：\n\n假设当前 CP 是 10。有一个 CC 任务合并了 [10-13] [14-14] [15-15] 后生成了 [10-15] 这个版本。如果决定将 [10-15] 版本移动到 BC 任务区，则需修改 CP 为 15，否则 CP 保持不变，依然为 10。\n\n**CP 只会增加，不会减少。** 以下参数决定了是否更新 CP：\n\n> cumulative_size_based_promotion_ratio：晋升比率。默认 0.05。\n>\n> cumulative_size_based_promotion_min_size_mbytes：最小晋升大小，默认 64，单位 MB。\n>\n> cumulative_size_based_promotion_size_mbytes：最大晋升大小，默认 1024，单位 MB。\n>\n\n以上参数比较难理解，这里我们先解释下 “晋升” 的原则。一个 CC 任务生成的 rowset 的晋升原则，是其数据大小和基线数据的大小在 “同一量级”。这个类似 2048 小游戏，只有相同的数字才能合并形成更大的数字。而上面三个参数，就是用于判断一个新的rowset是否匹配基线数据的数量级。举例说明：\n\n在默认配置下，假设当前基线数据（即所有 CP 之前的数据版本）的数据量为 10GB，则晋升量级为 （10GB * 0.05）512MB。这个数值大于 64 MB 小于 1024 MB，满足条件。所以如果 CC 任务生成的新的 rowset 的大小大于 512 MB，则可以晋升，即 CP 增加。而假设基线数据为 50GB，则晋升量级为（50GB * 0.05）2.5GB。这个数值大于 64 MB 也大于 1024 MB，因此晋升量级会被调整为 1024 MB。所以如果 CC 任务生成的新的 rowset 的大小大于 1024 MB，则可以晋升，即 CP 增加。\n\n从上面的例子可以看出，cumulative_size_based_promotion_ratio 用于定义 “同一量级”，0.05 即表示数据量大于基线数据的 5% 的 rowset 都有晋升的可能，而 cumulative_size_based_promotion_min_size_mbytes 和 cumulative_size_based_promotion_size_mbytes 用于保证晋升不会过于频繁或过于严格。\n\n> *这三个参数会直接影响 BC 和 CC 任务的频率，尤其在高频导入场景下需要适当调整。我们会在后续文章中举例说明。*\n\n### 其他 Compaction 参数和注意事项\n\n还有一些参数和 Compaction 相关，在某些情况下需要修改：\n\ndisable_auto_compaction：默认为 false，修改为 true 则会禁止 Compaction 操作。该参数仅在一些调试情况，或者 compaction 异常需要临时关闭的情况下才需使用。\n\n#### Delete 灾难\n\n通过 DELETE FROM 语句执行的数据删除操作，在 Doris 中也会生成一个数据版本用于标记删除。这种类型的数据版本比较特殊，我们成为 “删除版本”。删除版本只能通过 Base Compaction 任务处理。因此在在遇到删除版本时，Cumulative Point 会强制增加，将删除版本移动到 BC 任务区。**因此数据导入和删除交替发生的场景通常会导致 Compaction 灾难**。比如以下版本序列：\n\n```\n[0-10]\n[11-11] 删除版本\n[12-12]\n[13-13] 删除版本\n[14-14]\n[15-15] 删除版本\n[16-16]\n[17-17] 删除版本\n...\n```\n\n在这种情况下，CC 任务几乎不会被触发（因为CC任务只能选择一个版本，而无法处理删除版本），所有版本都会交给 Base Compaction 处理，导致 Compaction 进度缓慢。目前Doris还无法很好的处理这种场景，因此需要在业务上尽量避免。\n","source":"_posts/bigdata/Doris Compaction从入门到跑路.md","raw":"---\ntitle: Doris Compaction从入门到跑路\ntags:\n  - 'Doris'\ncategories:\n  - [Doris]\ntop_img: \ndate: 2022-09-03 23:40:51\nupdated: 2022-09-03 23:40:51\ncover:\ndescription:\nkeywords:\n---\n\n>\n>\n>Doris 中用于控制Compaction的参数非常多。本文尝试以下方面，介绍这些参数的含义以及如果通过调整参数来适配场景。\n>\n>\n>\n>1. 数据版本是如何产生的，哪些因素影响数据版本的产出。\n>2. 为什么需要 Base 和 Cumulative 两种类型的 Compaction。\n>3. Compaction 机制是如何挑选数据分片进行 Compaction 的。\n>4. 对于一个数据分片，Compaction 机制是如何确定哪些数据版本参与 Compaction 的。\n>5. 在高频导入场景下，可以修改哪些参数来优化 Compaction 逻辑。\n>6. Compaction 相关的查看和管理命令。\n\n# Why  need Compaction\n\nDoris 的数据写入模型使用了 LSM-Tree 类似的数据结构。数据都是以追加（Append）的方式写入磁盘的。这种数据结构可以将随机写变为顺序写。这是一种面向写优化的数据结构，他能增强系统的写入吞吐，但是在读逻辑中，需要通过 Merge-on-Read 的方式，在读取时合并多次写入的数据，从而处理写入时的数据变更。\n\nMerge-on-Read 会影响读取的效率，为了降低读取时需要合并的数据量，基于 LSM-Tree 的系统都会引入后台数据合并的逻辑，以一定策略定期的对数据进行合并。Doris 中这种机制被称为 Compaction。\n\nDoris 中每次数据写入会生成一个数据版本。Compaction的过程就是讲多个数据版本合并成一个更大的版本。Compaction 可以带来以下好处：\n\n> - 1.数据更加有序\n>\n>   每个数据版本内的数据是按主键有序的，但是版本之间的数据是无序的。Compaction后形成的大版本将多个小版本的数据变成有序数据。在有序数据中进行数据检索的效率更高。\n>\n> - 2.消除数据变更\n>\n>   数据都是以追加的方式写入的，因此 Delete、Update 等操作都是写入一个标记。Compaction 操作可以处理这些标记，进行真正的数据删除或更新，从而在读取时，不再需要根据这些标记来过滤数据。\n>\n> - 3.增加数据聚合度\n> 在聚合模型下，Compaction 能进一步聚合不同数据版本中相同 key 的数据行，从而增加数据聚合度，减少读取时需要实时进行的聚合计算。\n\n# Compaction 的问题\n\n用户可能需要根据实际的使用场景来调整 Compaction 的策略，否则可能遇到如下问题：\n\n1. Compaction 速度低于数据写入速度\n\n   在高频写入场景下，短时间内会产生大量的数据版本。如果 Compaction 不及时，就会造成大量版本堆积，最终严重影响写入速度。\n\n2. 写放大问题\n\n   Compaction 本质上是将已经写入的数据读取后重写写回的过程，这种数据重复写入被称为写放大。一个好的Compaction策略应该在保证效率的前提下，尽量降低写放大系数。过多的 Compaction 会占用大量的磁盘IO资源，影响系统整体效率。\n\n# Something about Compaction(How)\n\n## 数据版本的产生\n\n首先，用户的数据表会按照分区和分桶规则，切分成若干个数据分片（Tablet）存储在不同 BE 节点上。每个 Tablet 都有多个副本（默认为3副本）。Compaction 是在每个 BE 上独立进行的，Compaction 逻辑处理的就是一个 BE 节点上所有的数据分片。\n\nDoris的数据都是以追加的方式写入系统的。Doris目前的写入依然是以微批的方式进行的，每一批次的数据针对每个 Tablet 都会形成一个 rowset。而一个 Tablet 是由多个Rowset 组成的。每个 Rowset 都有一个对应的起始版本和终止版本。对于新增Rowset，起始版本和终止版本相同，表示为 [6-6]、[7-7] 等。多个Rowset经过 Compaction 形成一个大的 Rowset，起始版本和终止版本为多个版本的并集，如 [6-6]、[7-7]、[8-8] 合并后变成 [6-8]。\n\nRowset 的数量直接影响到 Compaction 是否能够及时完成。那么一批次导入会生成多少个 Rowset 呢？这里我们举一个例子：\n\n假设集群有3个 BE 节点。每个BE节点2块盘。只有一张表，2个分区，每个分区3个分桶，默认3副本。那么总分片数量是（2 * 3 * 3）18 个，如果均匀分布在所有节点上，则每个盘上3个tablet。假设一次导入涉及到其中一个分区，则一次导入总共产生9个Rowset，即平均每块盘产生1-2个 Rowset。（这里仅考虑数据完全均匀分布的情况下，实际情况中，可能多个 Tablet 集中在某一块磁盘上。）\n\n从上面的例子我们可以得出，rowset的数量直接取决于表的分片数量。举个极端的例子，如果一个Doris集群只有3个BE节点，但是一个表有9000个分片。那么一次导入，每个BE节点就会新增3000个rowset，则至少要进行3000次compaction，才能处理完所有的分片。所以：\n\n> **合理的设置表的分区、分桶和副本数量，避免过多的分片，可以降低Compaction的开销。**\n\n## Base & Cumulative Compaction\n\nDoris 中有两种 Compaction 操作，分别称为 Base Compaction(BC) 和 Cumulative Compaction(CC)。BC 是将基线数据版本（以0为起始版本的数据）和增量数据版本合并的过程，而CC是增量数据间的合并过程。BC操作因为涉及到基线数据，而基线数据通常比较大，所以操作耗时会比CC长。\n\n如果只有 Base Compaction，则每次增量数据都要和全量的基线数据合并，写放大问题会非常严重，并且每次 Compaction 都相当耗时。因此我们需要引入 Cumulative Compaction 来先对增量数据进行合并，当增量数据合并后的大小达到一定阈值后，再和基线数据合并。这里我们有一个比较通用的 Compaction 调优策略：\n\n> **在合理范围内，尽量减少 Base Compaction 操作。**\n\nBC 和 CC 之间的分界线成为 Cumulative Point（CP），这是一个动态变化的版本号。比CP小的数据版本会只会触发 BC，而比CP大的数据版本，只会触发CC。\n\n\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1662219046764-f9891cea-fe8d-4eb2-89a4-911ffb10e7e2.png)\n\n\n\n整个过程有点类似 2048 小游戏：只有合并后大小足够，才能继续和更大的数据版本合并。\n\n\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1662219046833-aa0766ec-9852-4766-b57d-5b24448cd2b4.png)\n\n## 数据分片选择策略\n\n**Compaction 的目的是合并多个数据版本，一是避免在读取时大量的 Merge 操作，二是避免大量的数据版本导致的随机IO。**因此，Compaction 策略的重点问题，就是如何选择合适的 tablet，以保证节点上不会出现数据版本过多的数据分片。\n\n### Compaction 分数\n\n一个自然的想法，就是每次都选择数据版本最多的数据分片进行 Compaction。这个策略也是 Doris 的默认策略。这个策略在大部分场景下都能很好的工作。但是考虑到一种情况，就是版本多的分片，可能并不是最频繁访问的分片。而 Compaction 的目的就是优化读性能。那么有可能某一张 “写多读少” 表一直在 Compaction，而另一张 “读多写少” 的表不能及时的 Compaction，导致读性能变差。\n\n因此，Doris 在选择数据分片时还引入了 “读取频率” 的因素。“读取频率” 和 “版本数量” 会根据各自的权重，综合计算出一个 Compaction 分数，分数越高的分片，优先做 Compaction。这两个因素的权重由以下 BE 参数控制（取值越大，权重越高）：\n\n> **compaction_tablet_scan_frequency_factor：“读取频率” 的权重值，默认为 0。**\n>\n> **compaction_tablet_compaction_score_factor：“版本数量” 的权重，默认为 1。**\n\n> “读取频率” 的权重值默认为0，即默认仅考虑 “版本数量” 这个因素。*\n\n### 生产者与消费者\n\nCompaction 是一个 生产者-消费者 模型。由一个生产者线程负责选择需要做 Compaction 的数据分片，而多个消费者负责执行 Compaction 操作。\n\n生产者线程只有一个，会定期扫描所有 tablet 来选择合适的 compaction 对象。因为 Base Compaction 和 Cumulative Compaction 是不同类型的任务，因此目前的策略是每生成 9 个 CC 任务，生成一个 BC 任务。任务生成的频率由以下两个参数控制：\n\n> **cumulative_compaction_rounds_for_each_base_compaction_round：多少个CC任务后生成一个BC任务。**\n>\n> **generate_compaction_tasks_min_interval_ms：任务生成的间隔。**\n\n> *这两个参数通常情况下不需要调整。*\n\n生产者线程产生的任务会被提交到消费者线程池。因为 Compaction 是一个IO密集型的任务，为了保证 Compaction 任务不会过多的占用IO资源，Doris 限制了每个磁盘上能够同时进行的 Compaction 任务数量，以及节点整体的任务数量，这些限制由以下参数控制：\n\n> compaction_task_num_per_disk：每个磁盘上的任务数，默认为2。该参数必须大于等于2，以保证 BC 和 CC 任务各自至少有一个线程。\n>\n> max_compaction_threads：消费者线程，即Compaction线程的总数。默认为 10。\n>\n\n举个例子，假设一个 BE 节点配置了3个数据目录（即3块磁盘），每个磁盘上的任务数配置为2，总线程数为5。则同一时间，最多有5个 Compaction 任务在进行，而每块磁盘上最多有2个任务在进行。并且最多有3个 BC 任务在进行，因为每块盘上会自动预留一个线程给CC任务。\n\n**另一方面，Compaction 任务同时也是一个内存密集型任务，因为其本质是一个多路归并排序的过程，每一路是一个数据版本。**如果一个 Compaction 任务涉及的数据版本很多，则会占用更多的内存，如果仅限制任务数，而不考虑任务的内存开销，则有可能导致系统内存超限。因此，Doris 在上述任务个数限制之外，还增加了一个任务配额限制：\n\n> total_permits_for_compaction_score：Compaction 任务配额，默认 10000。\n\n每个 Compaction 任务都有一个配额，其数值就是任务涉及的数据版本数量。假设一个任务需要合并100个版本，则其配额为100。当正在运行的任务配额总和超过配置后，新的任务将被拒绝。\n\n三个配置共同决定了节点所能承受的 Compaction 任务数量。\n\n### 数据版本选择策略\n\n一个 Compaction 任务对应的是一个数据分片（Tablet）。消费线程拿到一个 Compaction 任务后，会根据 Compaction 的任务类型，选择 tablet 中合适的数据版本（Rowset）进行数据合并。下面分别介绍 Base Compaction 和 Cumulative Compaction 的数据分片选择策略。\n\n#### Base Compaction\n\n前文说过，BC 任务是增量数据和基线数据的合并任务。并且只有比 Cumulative Point（CP） 小的数据版本才会参与 BC 任务。因此，BC 任务的数据版本选取策略比较简单。\n\n首先，会选取所有版本在 0到 CP之间的 rowset。然后根据以下几个配置参数，判断是否启动一个 BC 任务：\n\n> base_compaction_num_cumulative_deltas：一次 BC 任务最小版本数量限制。默认为5。该参数主要为了避免过多 BC 任务。当数据版本数量较少时，BC 是没有必要的。\n>\n> base_compaction_interval_seconds_since_last_operation：第一个参数限制了当版本数量少时，不会进行 BC 任务。但我们需要避免另一种情况，即某些 tablet 可能仅会导入少量批次的数据，因此当 Doris 发现一个 tablet 长时间没有执行过 BC 任务时，也会触发 BC 任务。这个参数就是控制这个时间的，默认是 86400，单位是秒。\n>\n\n*> 以上两个参数通常情况下不需要修改，在某些情况下如何需要想尽快合并基线数据，可以尝试改小 **base_compaction_num_cumulative_deltas 参数。但这个参数只会影响到 “被选中的 tablet”。而 “被选中” 的前提是这个 tablet 的数据版本数量是最多的。***\n\n#### Cumulative Compaction\n\nCC 任务只会选取版本比 CP 大的数据版本。其本身的选取策略也比较简单，即从 CP 版本开始，依次向后选取数据版本。最终的数据版本集合由以下参数控制：\n\n> min_cumulative_compaction_num_singleton_deltas：一次 CC 任务最少的版本数量限制。这个配置是和 cumulative_size_based_compaction_lower_size_mbytes 配置同时判断的。即如果版本数量小于阈值，并且数据量也小于阈值，则不会触发 CC 任务。以避免过多不必要的 CC 任务。默认是5。\n>\n> max_cumulative_compaction_num_singleton_deltas：一次 CC 任务最大的版本数量限制。以防止一次 CC 任务合并的版本数量过多，占用过多资源。默认是1000。\n>\n> cumulative_size_based_compaction_lower_size_mbytes：一次 CC 任务最少的数据量，和min_cumulative_compaction_num_singleton_delta 同时判断。默认是 64，单位是 MB。\n>\n\n简单来说，默认配置下，就是从 CP 版本开始往后选取 rowset。最少选5个，最多选 1000 个，然后判断数据量是否大于阈值即可。\n\nCC 任务还有一个重要步骤，就是在合并任务结束后，设置新的 Cumulative Point。CC 任务合并完成后，会产生一个合并后的新的数据版本，而我们要做的就是判断这个新的数据版是 “晋升” 到 BC 任务区，还是依然保留在 CC 任务区。举个例子：\n\n假设当前 CP 是 10。有一个 CC 任务合并了 [10-13] [14-14] [15-15] 后生成了 [10-15] 这个版本。如果决定将 [10-15] 版本移动到 BC 任务区，则需修改 CP 为 15，否则 CP 保持不变，依然为 10。\n\n**CP 只会增加，不会减少。** 以下参数决定了是否更新 CP：\n\n> cumulative_size_based_promotion_ratio：晋升比率。默认 0.05。\n>\n> cumulative_size_based_promotion_min_size_mbytes：最小晋升大小，默认 64，单位 MB。\n>\n> cumulative_size_based_promotion_size_mbytes：最大晋升大小，默认 1024，单位 MB。\n>\n\n以上参数比较难理解，这里我们先解释下 “晋升” 的原则。一个 CC 任务生成的 rowset 的晋升原则，是其数据大小和基线数据的大小在 “同一量级”。这个类似 2048 小游戏，只有相同的数字才能合并形成更大的数字。而上面三个参数，就是用于判断一个新的rowset是否匹配基线数据的数量级。举例说明：\n\n在默认配置下，假设当前基线数据（即所有 CP 之前的数据版本）的数据量为 10GB，则晋升量级为 （10GB * 0.05）512MB。这个数值大于 64 MB 小于 1024 MB，满足条件。所以如果 CC 任务生成的新的 rowset 的大小大于 512 MB，则可以晋升，即 CP 增加。而假设基线数据为 50GB，则晋升量级为（50GB * 0.05）2.5GB。这个数值大于 64 MB 也大于 1024 MB，因此晋升量级会被调整为 1024 MB。所以如果 CC 任务生成的新的 rowset 的大小大于 1024 MB，则可以晋升，即 CP 增加。\n\n从上面的例子可以看出，cumulative_size_based_promotion_ratio 用于定义 “同一量级”，0.05 即表示数据量大于基线数据的 5% 的 rowset 都有晋升的可能，而 cumulative_size_based_promotion_min_size_mbytes 和 cumulative_size_based_promotion_size_mbytes 用于保证晋升不会过于频繁或过于严格。\n\n> *这三个参数会直接影响 BC 和 CC 任务的频率，尤其在高频导入场景下需要适当调整。我们会在后续文章中举例说明。*\n\n### 其他 Compaction 参数和注意事项\n\n还有一些参数和 Compaction 相关，在某些情况下需要修改：\n\ndisable_auto_compaction：默认为 false，修改为 true 则会禁止 Compaction 操作。该参数仅在一些调试情况，或者 compaction 异常需要临时关闭的情况下才需使用。\n\n#### Delete 灾难\n\n通过 DELETE FROM 语句执行的数据删除操作，在 Doris 中也会生成一个数据版本用于标记删除。这种类型的数据版本比较特殊，我们成为 “删除版本”。删除版本只能通过 Base Compaction 任务处理。因此在在遇到删除版本时，Cumulative Point 会强制增加，将删除版本移动到 BC 任务区。**因此数据导入和删除交替发生的场景通常会导致 Compaction 灾难**。比如以下版本序列：\n\n```\n[0-10]\n[11-11] 删除版本\n[12-12]\n[13-13] 删除版本\n[14-14]\n[15-15] 删除版本\n[16-16]\n[17-17] 删除版本\n...\n```\n\n在这种情况下，CC 任务几乎不会被触发（因为CC任务只能选择一个版本，而无法处理删除版本），所有版本都会交给 Base Compaction 处理，导致 Compaction 进度缓慢。目前Doris还无法很好的处理这种场景，因此需要在业务上尽量避免。\n","slug":"bigdata/Doris Compaction从入门到跑路","published":1,"comments":1,"layout":"post","photos":[],"link":"","_id":"cl9y38ds6000qfwuidtpbfbg1","content":"<blockquote>\n<p>Doris 中用于控制Compaction的参数非常多。本文尝试以下方面，介绍这些参数的含义以及如果通过调整参数来适配场景。</p>\n<ol>\n<li>数据版本是如何产生的，哪些因素影响数据版本的产出。</li>\n<li>为什么需要 Base 和 Cumulative 两种类型的 Compaction。</li>\n<li>Compaction 机制是如何挑选数据分片进行 Compaction 的。</li>\n<li>对于一个数据分片，Compaction 机制是如何确定哪些数据版本参与 Compaction 的。</li>\n<li>在高频导入场景下，可以修改哪些参数来优化 Compaction 逻辑。</li>\n<li>Compaction 相关的查看和管理命令。</li>\n</ol>\n</blockquote>\n<h1 id=\"Why-need-Compaction\"><a href=\"#Why-need-Compaction\" class=\"headerlink\" title=\"Why  need Compaction\"></a>Why  need Compaction</h1><p>Doris 的数据写入模型使用了 LSM-Tree 类似的数据结构。数据都是以追加（Append）的方式写入磁盘的。这种数据结构可以将随机写变为顺序写。这是一种面向写优化的数据结构，他能增强系统的写入吞吐，但是在读逻辑中，需要通过 Merge-on-Read 的方式，在读取时合并多次写入的数据，从而处理写入时的数据变更。</p>\n<p>Merge-on-Read 会影响读取的效率，为了降低读取时需要合并的数据量，基于 LSM-Tree 的系统都会引入后台数据合并的逻辑，以一定策略定期的对数据进行合并。Doris 中这种机制被称为 Compaction。</p>\n<p>Doris 中每次数据写入会生成一个数据版本。Compaction的过程就是讲多个数据版本合并成一个更大的版本。Compaction 可以带来以下好处：</p>\n<blockquote>\n<ul>\n<li><p>1.数据更加有序</p>\n<p>每个数据版本内的数据是按主键有序的，但是版本之间的数据是无序的。Compaction后形成的大版本将多个小版本的数据变成有序数据。在有序数据中进行数据检索的效率更高。</p>\n</li>\n<li><p>2.消除数据变更</p>\n<p>数据都是以追加的方式写入的，因此 Delete、Update 等操作都是写入一个标记。Compaction 操作可以处理这些标记，进行真正的数据删除或更新，从而在读取时，不再需要根据这些标记来过滤数据。</p>\n</li>\n<li><p>3.增加数据聚合度<br>在聚合模型下，Compaction 能进一步聚合不同数据版本中相同 key 的数据行，从而增加数据聚合度，减少读取时需要实时进行的聚合计算。</p>\n</li>\n</ul>\n</blockquote>\n<h1 id=\"Compaction-的问题\"><a href=\"#Compaction-的问题\" class=\"headerlink\" title=\"Compaction 的问题\"></a>Compaction 的问题</h1><p>用户可能需要根据实际的使用场景来调整 Compaction 的策略，否则可能遇到如下问题：</p>\n<ol>\n<li><p>Compaction 速度低于数据写入速度</p>\n<p>在高频写入场景下，短时间内会产生大量的数据版本。如果 Compaction 不及时，就会造成大量版本堆积，最终严重影响写入速度。</p>\n</li>\n<li><p>写放大问题</p>\n<p>Compaction 本质上是将已经写入的数据读取后重写写回的过程，这种数据重复写入被称为写放大。一个好的Compaction策略应该在保证效率的前提下，尽量降低写放大系数。过多的 Compaction 会占用大量的磁盘IO资源，影响系统整体效率。</p>\n</li>\n</ol>\n<h1 id=\"Something-about-Compaction-How\"><a href=\"#Something-about-Compaction-How\" class=\"headerlink\" title=\"Something about Compaction(How)\"></a>Something about Compaction(How)</h1><h2 id=\"数据版本的产生\"><a href=\"#数据版本的产生\" class=\"headerlink\" title=\"数据版本的产生\"></a>数据版本的产生</h2><p>首先，用户的数据表会按照分区和分桶规则，切分成若干个数据分片（Tablet）存储在不同 BE 节点上。每个 Tablet 都有多个副本（默认为3副本）。Compaction 是在每个 BE 上独立进行的，Compaction 逻辑处理的就是一个 BE 节点上所有的数据分片。</p>\n<p>Doris的数据都是以追加的方式写入系统的。Doris目前的写入依然是以微批的方式进行的，每一批次的数据针对每个 Tablet 都会形成一个 rowset。而一个 Tablet 是由多个Rowset 组成的。每个 Rowset 都有一个对应的起始版本和终止版本。对于新增Rowset，起始版本和终止版本相同，表示为 [6-6]、[7-7] 等。多个Rowset经过 Compaction 形成一个大的 Rowset，起始版本和终止版本为多个版本的并集，如 [6-6]、[7-7]、[8-8] 合并后变成 [6-8]。</p>\n<p>Rowset 的数量直接影响到 Compaction 是否能够及时完成。那么一批次导入会生成多少个 Rowset 呢？这里我们举一个例子：</p>\n<p>假设集群有3个 BE 节点。每个BE节点2块盘。只有一张表，2个分区，每个分区3个分桶，默认3副本。那么总分片数量是（2 * 3 * 3）18 个，如果均匀分布在所有节点上，则每个盘上3个tablet。假设一次导入涉及到其中一个分区，则一次导入总共产生9个Rowset，即平均每块盘产生1-2个 Rowset。（这里仅考虑数据完全均匀分布的情况下，实际情况中，可能多个 Tablet 集中在某一块磁盘上。）</p>\n<p>从上面的例子我们可以得出，rowset的数量直接取决于表的分片数量。举个极端的例子，如果一个Doris集群只有3个BE节点，但是一个表有9000个分片。那么一次导入，每个BE节点就会新增3000个rowset，则至少要进行3000次compaction，才能处理完所有的分片。所以：</p>\n<blockquote>\n<p><strong>合理的设置表的分区、分桶和副本数量，避免过多的分片，可以降低Compaction的开销。</strong></p>\n</blockquote>\n<h2 id=\"Base-amp-Cumulative-Compaction\"><a href=\"#Base-amp-Cumulative-Compaction\" class=\"headerlink\" title=\"Base &amp; Cumulative Compaction\"></a>Base &amp; Cumulative Compaction</h2><p>Doris 中有两种 Compaction 操作，分别称为 Base Compaction(BC) 和 Cumulative Compaction(CC)。BC 是将基线数据版本（以0为起始版本的数据）和增量数据版本合并的过程，而CC是增量数据间的合并过程。BC操作因为涉及到基线数据，而基线数据通常比较大，所以操作耗时会比CC长。</p>\n<p>如果只有 Base Compaction，则每次增量数据都要和全量的基线数据合并，写放大问题会非常严重，并且每次 Compaction 都相当耗时。因此我们需要引入 Cumulative Compaction 来先对增量数据进行合并，当增量数据合并后的大小达到一定阈值后，再和基线数据合并。这里我们有一个比较通用的 Compaction 调优策略：</p>\n<blockquote>\n<p><strong>在合理范围内，尽量减少 Base Compaction 操作。</strong></p>\n</blockquote>\n<p>BC 和 CC 之间的分界线成为 Cumulative Point（CP），这是一个动态变化的版本号。比CP小的数据版本会只会触发 BC，而比CP大的数据版本，只会触发CC。</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1662219046764-f9891cea-fe8d-4eb2-89a4-911ffb10e7e2.png\" alt=\"img\"></p>\n<p>整个过程有点类似 2048 小游戏：只有合并后大小足够，才能继续和更大的数据版本合并。</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1662219046833-aa0766ec-9852-4766-b57d-5b24448cd2b4.png\" alt=\"img\"></p>\n<h2 id=\"数据分片选择策略\"><a href=\"#数据分片选择策略\" class=\"headerlink\" title=\"数据分片选择策略\"></a>数据分片选择策略</h2><p><strong>Compaction 的目的是合并多个数据版本，一是避免在读取时大量的 Merge 操作，二是避免大量的数据版本导致的随机IO。</strong>因此，Compaction 策略的重点问题，就是如何选择合适的 tablet，以保证节点上不会出现数据版本过多的数据分片。</p>\n<h3 id=\"Compaction-分数\"><a href=\"#Compaction-分数\" class=\"headerlink\" title=\"Compaction 分数\"></a>Compaction 分数</h3><p>一个自然的想法，就是每次都选择数据版本最多的数据分片进行 Compaction。这个策略也是 Doris 的默认策略。这个策略在大部分场景下都能很好的工作。但是考虑到一种情况，就是版本多的分片，可能并不是最频繁访问的分片。而 Compaction 的目的就是优化读性能。那么有可能某一张 “写多读少” 表一直在 Compaction，而另一张 “读多写少” 的表不能及时的 Compaction，导致读性能变差。</p>\n<p>因此，Doris 在选择数据分片时还引入了 “读取频率” 的因素。“读取频率” 和 “版本数量” 会根据各自的权重，综合计算出一个 Compaction 分数，分数越高的分片，优先做 Compaction。这两个因素的权重由以下 BE 参数控制（取值越大，权重越高）：</p>\n<blockquote>\n<p><strong>compaction_tablet_scan_frequency_factor：“读取频率” 的权重值，默认为 0。</strong></p>\n<p><strong>compaction_tablet_compaction_score_factor：“版本数量” 的权重，默认为 1。</strong></p>\n</blockquote>\n<blockquote>\n<p>“读取频率” 的权重值默认为0，即默认仅考虑 “版本数量” 这个因素。*</p>\n</blockquote>\n<h3 id=\"生产者与消费者\"><a href=\"#生产者与消费者\" class=\"headerlink\" title=\"生产者与消费者\"></a>生产者与消费者</h3><p>Compaction 是一个 生产者-消费者 模型。由一个生产者线程负责选择需要做 Compaction 的数据分片，而多个消费者负责执行 Compaction 操作。</p>\n<p>生产者线程只有一个，会定期扫描所有 tablet 来选择合适的 compaction 对象。因为 Base Compaction 和 Cumulative Compaction 是不同类型的任务，因此目前的策略是每生成 9 个 CC 任务，生成一个 BC 任务。任务生成的频率由以下两个参数控制：</p>\n<blockquote>\n<p><strong>cumulative_compaction_rounds_for_each_base_compaction_round：多少个CC任务后生成一个BC任务。</strong></p>\n<p><strong>generate_compaction_tasks_min_interval_ms：任务生成的间隔。</strong></p>\n</blockquote>\n<blockquote>\n<p><em>这两个参数通常情况下不需要调整。</em></p>\n</blockquote>\n<p>生产者线程产生的任务会被提交到消费者线程池。因为 Compaction 是一个IO密集型的任务，为了保证 Compaction 任务不会过多的占用IO资源，Doris 限制了每个磁盘上能够同时进行的 Compaction 任务数量，以及节点整体的任务数量，这些限制由以下参数控制：</p>\n<blockquote>\n<p>compaction_task_num_per_disk：每个磁盘上的任务数，默认为2。该参数必须大于等于2，以保证 BC 和 CC 任务各自至少有一个线程。</p>\n<p>max_compaction_threads：消费者线程，即Compaction线程的总数。默认为 10。</p>\n</blockquote>\n<p>举个例子，假设一个 BE 节点配置了3个数据目录（即3块磁盘），每个磁盘上的任务数配置为2，总线程数为5。则同一时间，最多有5个 Compaction 任务在进行，而每块磁盘上最多有2个任务在进行。并且最多有3个 BC 任务在进行，因为每块盘上会自动预留一个线程给CC任务。</p>\n<p><strong>另一方面，Compaction 任务同时也是一个内存密集型任务，因为其本质是一个多路归并排序的过程，每一路是一个数据版本。</strong>如果一个 Compaction 任务涉及的数据版本很多，则会占用更多的内存，如果仅限制任务数，而不考虑任务的内存开销，则有可能导致系统内存超限。因此，Doris 在上述任务个数限制之外，还增加了一个任务配额限制：</p>\n<blockquote>\n<p>total_permits_for_compaction_score：Compaction 任务配额，默认 10000。</p>\n</blockquote>\n<p>每个 Compaction 任务都有一个配额，其数值就是任务涉及的数据版本数量。假设一个任务需要合并100个版本，则其配额为100。当正在运行的任务配额总和超过配置后，新的任务将被拒绝。</p>\n<p>三个配置共同决定了节点所能承受的 Compaction 任务数量。</p>\n<h3 id=\"数据版本选择策略\"><a href=\"#数据版本选择策略\" class=\"headerlink\" title=\"数据版本选择策略\"></a>数据版本选择策略</h3><p>一个 Compaction 任务对应的是一个数据分片（Tablet）。消费线程拿到一个 Compaction 任务后，会根据 Compaction 的任务类型，选择 tablet 中合适的数据版本（Rowset）进行数据合并。下面分别介绍 Base Compaction 和 Cumulative Compaction 的数据分片选择策略。</p>\n<h4 id=\"Base-Compaction\"><a href=\"#Base-Compaction\" class=\"headerlink\" title=\"Base Compaction\"></a>Base Compaction</h4><p>前文说过，BC 任务是增量数据和基线数据的合并任务。并且只有比 Cumulative Point（CP） 小的数据版本才会参与 BC 任务。因此，BC 任务的数据版本选取策略比较简单。</p>\n<p>首先，会选取所有版本在 0到 CP之间的 rowset。然后根据以下几个配置参数，判断是否启动一个 BC 任务：</p>\n<blockquote>\n<p>base_compaction_num_cumulative_deltas：一次 BC 任务最小版本数量限制。默认为5。该参数主要为了避免过多 BC 任务。当数据版本数量较少时，BC 是没有必要的。</p>\n<p>base_compaction_interval_seconds_since_last_operation：第一个参数限制了当版本数量少时，不会进行 BC 任务。但我们需要避免另一种情况，即某些 tablet 可能仅会导入少量批次的数据，因此当 Doris 发现一个 tablet 长时间没有执行过 BC 任务时，也会触发 BC 任务。这个参数就是控制这个时间的，默认是 86400，单位是秒。</p>\n</blockquote>\n<p><em>&gt; 以上两个参数通常情况下不需要修改，在某些情况下如何需要想尽快合并基线数据，可以尝试改小 <strong>base_compaction_num_cumulative_deltas 参数。但这个参数只会影响到 “被选中的 tablet”。而 “被选中” 的前提是这个 tablet 的数据版本数量是最多的。</strong></em></p>\n<h4 id=\"Cumulative-Compaction\"><a href=\"#Cumulative-Compaction\" class=\"headerlink\" title=\"Cumulative Compaction\"></a>Cumulative Compaction</h4><p>CC 任务只会选取版本比 CP 大的数据版本。其本身的选取策略也比较简单，即从 CP 版本开始，依次向后选取数据版本。最终的数据版本集合由以下参数控制：</p>\n<blockquote>\n<p>min_cumulative_compaction_num_singleton_deltas：一次 CC 任务最少的版本数量限制。这个配置是和 cumulative_size_based_compaction_lower_size_mbytes 配置同时判断的。即如果版本数量小于阈值，并且数据量也小于阈值，则不会触发 CC 任务。以避免过多不必要的 CC 任务。默认是5。</p>\n<p>max_cumulative_compaction_num_singleton_deltas：一次 CC 任务最大的版本数量限制。以防止一次 CC 任务合并的版本数量过多，占用过多资源。默认是1000。</p>\n<p>cumulative_size_based_compaction_lower_size_mbytes：一次 CC 任务最少的数据量，和min_cumulative_compaction_num_singleton_delta 同时判断。默认是 64，单位是 MB。</p>\n</blockquote>\n<p>简单来说，默认配置下，就是从 CP 版本开始往后选取 rowset。最少选5个，最多选 1000 个，然后判断数据量是否大于阈值即可。</p>\n<p>CC 任务还有一个重要步骤，就是在合并任务结束后，设置新的 Cumulative Point。CC 任务合并完成后，会产生一个合并后的新的数据版本，而我们要做的就是判断这个新的数据版是 “晋升” 到 BC 任务区，还是依然保留在 CC 任务区。举个例子：</p>\n<p>假设当前 CP 是 10。有一个 CC 任务合并了 [10-13] [14-14] [15-15] 后生成了 [10-15] 这个版本。如果决定将 [10-15] 版本移动到 BC 任务区，则需修改 CP 为 15，否则 CP 保持不变，依然为 10。</p>\n<p><strong>CP 只会增加，不会减少。</strong> 以下参数决定了是否更新 CP：</p>\n<blockquote>\n<p>cumulative_size_based_promotion_ratio：晋升比率。默认 0.05。</p>\n<p>cumulative_size_based_promotion_min_size_mbytes：最小晋升大小，默认 64，单位 MB。</p>\n<p>cumulative_size_based_promotion_size_mbytes：最大晋升大小，默认 1024，单位 MB。</p>\n</blockquote>\n<p>以上参数比较难理解，这里我们先解释下 “晋升” 的原则。一个 CC 任务生成的 rowset 的晋升原则，是其数据大小和基线数据的大小在 “同一量级”。这个类似 2048 小游戏，只有相同的数字才能合并形成更大的数字。而上面三个参数，就是用于判断一个新的rowset是否匹配基线数据的数量级。举例说明：</p>\n<p>在默认配置下，假设当前基线数据（即所有 CP 之前的数据版本）的数据量为 10GB，则晋升量级为 （10GB * 0.05）512MB。这个数值大于 64 MB 小于 1024 MB，满足条件。所以如果 CC 任务生成的新的 rowset 的大小大于 512 MB，则可以晋升，即 CP 增加。而假设基线数据为 50GB，则晋升量级为（50GB * 0.05）2.5GB。这个数值大于 64 MB 也大于 1024 MB，因此晋升量级会被调整为 1024 MB。所以如果 CC 任务生成的新的 rowset 的大小大于 1024 MB，则可以晋升，即 CP 增加。</p>\n<p>从上面的例子可以看出，cumulative_size_based_promotion_ratio 用于定义 “同一量级”，0.05 即表示数据量大于基线数据的 5% 的 rowset 都有晋升的可能，而 cumulative_size_based_promotion_min_size_mbytes 和 cumulative_size_based_promotion_size_mbytes 用于保证晋升不会过于频繁或过于严格。</p>\n<blockquote>\n<p><em>这三个参数会直接影响 BC 和 CC 任务的频率，尤其在高频导入场景下需要适当调整。我们会在后续文章中举例说明。</em></p>\n</blockquote>\n<h3 id=\"其他-Compaction-参数和注意事项\"><a href=\"#其他-Compaction-参数和注意事项\" class=\"headerlink\" title=\"其他 Compaction 参数和注意事项\"></a>其他 Compaction 参数和注意事项</h3><p>还有一些参数和 Compaction 相关，在某些情况下需要修改：</p>\n<p>disable_auto_compaction：默认为 false，修改为 true 则会禁止 Compaction 操作。该参数仅在一些调试情况，或者 compaction 异常需要临时关闭的情况下才需使用。</p>\n<h4 id=\"Delete-灾难\"><a href=\"#Delete-灾难\" class=\"headerlink\" title=\"Delete 灾难\"></a>Delete 灾难</h4><p>通过 DELETE FROM 语句执行的数据删除操作，在 Doris 中也会生成一个数据版本用于标记删除。这种类型的数据版本比较特殊，我们成为 “删除版本”。删除版本只能通过 Base Compaction 任务处理。因此在在遇到删除版本时，Cumulative Point 会强制增加，将删除版本移动到 BC 任务区。<strong>因此数据导入和删除交替发生的场景通常会导致 Compaction 灾难</strong>。比如以下版本序列：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[0-10]</span><br><span class=\"line\">[11-11] 删除版本</span><br><span class=\"line\">[12-12]</span><br><span class=\"line\">[13-13] 删除版本</span><br><span class=\"line\">[14-14]</span><br><span class=\"line\">[15-15] 删除版本</span><br><span class=\"line\">[16-16]</span><br><span class=\"line\">[17-17] 删除版本</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n\n<p>在这种情况下，CC 任务几乎不会被触发（因为CC任务只能选择一个版本，而无法处理删除版本），所有版本都会交给 Base Compaction 处理，导致 Compaction 进度缓慢。目前Doris还无法很好的处理这种场景，因此需要在业务上尽量避免。</p>\n","site":{"data":{"link":[{"class_name":"友情链接","class_desc":"那些人，那些事","link_list":[{"name":"张洪Heo","link":"https://blog.zhheo.com/","avatar":"https://npm.elemecdn.com/guli-heo/img/avatar2.png","descr":"分享设计与科技生活"},{"name":"瞬間の筆記","link":"https://hikki.site","descr":"喜欢的东西就努力去追求，万一成功了呢!","avatar":"https://cdn.jsdelivr.net/gh/0000rookie/imgs/202206120315.png"}]}]}},"excerpt":"","more":"<blockquote>\n<p>Doris 中用于控制Compaction的参数非常多。本文尝试以下方面，介绍这些参数的含义以及如果通过调整参数来适配场景。</p>\n<ol>\n<li>数据版本是如何产生的，哪些因素影响数据版本的产出。</li>\n<li>为什么需要 Base 和 Cumulative 两种类型的 Compaction。</li>\n<li>Compaction 机制是如何挑选数据分片进行 Compaction 的。</li>\n<li>对于一个数据分片，Compaction 机制是如何确定哪些数据版本参与 Compaction 的。</li>\n<li>在高频导入场景下，可以修改哪些参数来优化 Compaction 逻辑。</li>\n<li>Compaction 相关的查看和管理命令。</li>\n</ol>\n</blockquote>\n<h1 id=\"Why-need-Compaction\"><a href=\"#Why-need-Compaction\" class=\"headerlink\" title=\"Why  need Compaction\"></a>Why  need Compaction</h1><p>Doris 的数据写入模型使用了 LSM-Tree 类似的数据结构。数据都是以追加（Append）的方式写入磁盘的。这种数据结构可以将随机写变为顺序写。这是一种面向写优化的数据结构，他能增强系统的写入吞吐，但是在读逻辑中，需要通过 Merge-on-Read 的方式，在读取时合并多次写入的数据，从而处理写入时的数据变更。</p>\n<p>Merge-on-Read 会影响读取的效率，为了降低读取时需要合并的数据量，基于 LSM-Tree 的系统都会引入后台数据合并的逻辑，以一定策略定期的对数据进行合并。Doris 中这种机制被称为 Compaction。</p>\n<p>Doris 中每次数据写入会生成一个数据版本。Compaction的过程就是讲多个数据版本合并成一个更大的版本。Compaction 可以带来以下好处：</p>\n<blockquote>\n<ul>\n<li><p>1.数据更加有序</p>\n<p>每个数据版本内的数据是按主键有序的，但是版本之间的数据是无序的。Compaction后形成的大版本将多个小版本的数据变成有序数据。在有序数据中进行数据检索的效率更高。</p>\n</li>\n<li><p>2.消除数据变更</p>\n<p>数据都是以追加的方式写入的，因此 Delete、Update 等操作都是写入一个标记。Compaction 操作可以处理这些标记，进行真正的数据删除或更新，从而在读取时，不再需要根据这些标记来过滤数据。</p>\n</li>\n<li><p>3.增加数据聚合度<br>在聚合模型下，Compaction 能进一步聚合不同数据版本中相同 key 的数据行，从而增加数据聚合度，减少读取时需要实时进行的聚合计算。</p>\n</li>\n</ul>\n</blockquote>\n<h1 id=\"Compaction-的问题\"><a href=\"#Compaction-的问题\" class=\"headerlink\" title=\"Compaction 的问题\"></a>Compaction 的问题</h1><p>用户可能需要根据实际的使用场景来调整 Compaction 的策略，否则可能遇到如下问题：</p>\n<ol>\n<li><p>Compaction 速度低于数据写入速度</p>\n<p>在高频写入场景下，短时间内会产生大量的数据版本。如果 Compaction 不及时，就会造成大量版本堆积，最终严重影响写入速度。</p>\n</li>\n<li><p>写放大问题</p>\n<p>Compaction 本质上是将已经写入的数据读取后重写写回的过程，这种数据重复写入被称为写放大。一个好的Compaction策略应该在保证效率的前提下，尽量降低写放大系数。过多的 Compaction 会占用大量的磁盘IO资源，影响系统整体效率。</p>\n</li>\n</ol>\n<h1 id=\"Something-about-Compaction-How\"><a href=\"#Something-about-Compaction-How\" class=\"headerlink\" title=\"Something about Compaction(How)\"></a>Something about Compaction(How)</h1><h2 id=\"数据版本的产生\"><a href=\"#数据版本的产生\" class=\"headerlink\" title=\"数据版本的产生\"></a>数据版本的产生</h2><p>首先，用户的数据表会按照分区和分桶规则，切分成若干个数据分片（Tablet）存储在不同 BE 节点上。每个 Tablet 都有多个副本（默认为3副本）。Compaction 是在每个 BE 上独立进行的，Compaction 逻辑处理的就是一个 BE 节点上所有的数据分片。</p>\n<p>Doris的数据都是以追加的方式写入系统的。Doris目前的写入依然是以微批的方式进行的，每一批次的数据针对每个 Tablet 都会形成一个 rowset。而一个 Tablet 是由多个Rowset 组成的。每个 Rowset 都有一个对应的起始版本和终止版本。对于新增Rowset，起始版本和终止版本相同，表示为 [6-6]、[7-7] 等。多个Rowset经过 Compaction 形成一个大的 Rowset，起始版本和终止版本为多个版本的并集，如 [6-6]、[7-7]、[8-8] 合并后变成 [6-8]。</p>\n<p>Rowset 的数量直接影响到 Compaction 是否能够及时完成。那么一批次导入会生成多少个 Rowset 呢？这里我们举一个例子：</p>\n<p>假设集群有3个 BE 节点。每个BE节点2块盘。只有一张表，2个分区，每个分区3个分桶，默认3副本。那么总分片数量是（2 * 3 * 3）18 个，如果均匀分布在所有节点上，则每个盘上3个tablet。假设一次导入涉及到其中一个分区，则一次导入总共产生9个Rowset，即平均每块盘产生1-2个 Rowset。（这里仅考虑数据完全均匀分布的情况下，实际情况中，可能多个 Tablet 集中在某一块磁盘上。）</p>\n<p>从上面的例子我们可以得出，rowset的数量直接取决于表的分片数量。举个极端的例子，如果一个Doris集群只有3个BE节点，但是一个表有9000个分片。那么一次导入，每个BE节点就会新增3000个rowset，则至少要进行3000次compaction，才能处理完所有的分片。所以：</p>\n<blockquote>\n<p><strong>合理的设置表的分区、分桶和副本数量，避免过多的分片，可以降低Compaction的开销。</strong></p>\n</blockquote>\n<h2 id=\"Base-amp-Cumulative-Compaction\"><a href=\"#Base-amp-Cumulative-Compaction\" class=\"headerlink\" title=\"Base &amp; Cumulative Compaction\"></a>Base &amp; Cumulative Compaction</h2><p>Doris 中有两种 Compaction 操作，分别称为 Base Compaction(BC) 和 Cumulative Compaction(CC)。BC 是将基线数据版本（以0为起始版本的数据）和增量数据版本合并的过程，而CC是增量数据间的合并过程。BC操作因为涉及到基线数据，而基线数据通常比较大，所以操作耗时会比CC长。</p>\n<p>如果只有 Base Compaction，则每次增量数据都要和全量的基线数据合并，写放大问题会非常严重，并且每次 Compaction 都相当耗时。因此我们需要引入 Cumulative Compaction 来先对增量数据进行合并，当增量数据合并后的大小达到一定阈值后，再和基线数据合并。这里我们有一个比较通用的 Compaction 调优策略：</p>\n<blockquote>\n<p><strong>在合理范围内，尽量减少 Base Compaction 操作。</strong></p>\n</blockquote>\n<p>BC 和 CC 之间的分界线成为 Cumulative Point（CP），这是一个动态变化的版本号。比CP小的数据版本会只会触发 BC，而比CP大的数据版本，只会触发CC。</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1662219046764-f9891cea-fe8d-4eb2-89a4-911ffb10e7e2.png\" alt=\"img\"></p>\n<p>整个过程有点类似 2048 小游戏：只有合并后大小足够，才能继续和更大的数据版本合并。</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1662219046833-aa0766ec-9852-4766-b57d-5b24448cd2b4.png\" alt=\"img\"></p>\n<h2 id=\"数据分片选择策略\"><a href=\"#数据分片选择策略\" class=\"headerlink\" title=\"数据分片选择策略\"></a>数据分片选择策略</h2><p><strong>Compaction 的目的是合并多个数据版本，一是避免在读取时大量的 Merge 操作，二是避免大量的数据版本导致的随机IO。</strong>因此，Compaction 策略的重点问题，就是如何选择合适的 tablet，以保证节点上不会出现数据版本过多的数据分片。</p>\n<h3 id=\"Compaction-分数\"><a href=\"#Compaction-分数\" class=\"headerlink\" title=\"Compaction 分数\"></a>Compaction 分数</h3><p>一个自然的想法，就是每次都选择数据版本最多的数据分片进行 Compaction。这个策略也是 Doris 的默认策略。这个策略在大部分场景下都能很好的工作。但是考虑到一种情况，就是版本多的分片，可能并不是最频繁访问的分片。而 Compaction 的目的就是优化读性能。那么有可能某一张 “写多读少” 表一直在 Compaction，而另一张 “读多写少” 的表不能及时的 Compaction，导致读性能变差。</p>\n<p>因此，Doris 在选择数据分片时还引入了 “读取频率” 的因素。“读取频率” 和 “版本数量” 会根据各自的权重，综合计算出一个 Compaction 分数，分数越高的分片，优先做 Compaction。这两个因素的权重由以下 BE 参数控制（取值越大，权重越高）：</p>\n<blockquote>\n<p><strong>compaction_tablet_scan_frequency_factor：“读取频率” 的权重值，默认为 0。</strong></p>\n<p><strong>compaction_tablet_compaction_score_factor：“版本数量” 的权重，默认为 1。</strong></p>\n</blockquote>\n<blockquote>\n<p>“读取频率” 的权重值默认为0，即默认仅考虑 “版本数量” 这个因素。*</p>\n</blockquote>\n<h3 id=\"生产者与消费者\"><a href=\"#生产者与消费者\" class=\"headerlink\" title=\"生产者与消费者\"></a>生产者与消费者</h3><p>Compaction 是一个 生产者-消费者 模型。由一个生产者线程负责选择需要做 Compaction 的数据分片，而多个消费者负责执行 Compaction 操作。</p>\n<p>生产者线程只有一个，会定期扫描所有 tablet 来选择合适的 compaction 对象。因为 Base Compaction 和 Cumulative Compaction 是不同类型的任务，因此目前的策略是每生成 9 个 CC 任务，生成一个 BC 任务。任务生成的频率由以下两个参数控制：</p>\n<blockquote>\n<p><strong>cumulative_compaction_rounds_for_each_base_compaction_round：多少个CC任务后生成一个BC任务。</strong></p>\n<p><strong>generate_compaction_tasks_min_interval_ms：任务生成的间隔。</strong></p>\n</blockquote>\n<blockquote>\n<p><em>这两个参数通常情况下不需要调整。</em></p>\n</blockquote>\n<p>生产者线程产生的任务会被提交到消费者线程池。因为 Compaction 是一个IO密集型的任务，为了保证 Compaction 任务不会过多的占用IO资源，Doris 限制了每个磁盘上能够同时进行的 Compaction 任务数量，以及节点整体的任务数量，这些限制由以下参数控制：</p>\n<blockquote>\n<p>compaction_task_num_per_disk：每个磁盘上的任务数，默认为2。该参数必须大于等于2，以保证 BC 和 CC 任务各自至少有一个线程。</p>\n<p>max_compaction_threads：消费者线程，即Compaction线程的总数。默认为 10。</p>\n</blockquote>\n<p>举个例子，假设一个 BE 节点配置了3个数据目录（即3块磁盘），每个磁盘上的任务数配置为2，总线程数为5。则同一时间，最多有5个 Compaction 任务在进行，而每块磁盘上最多有2个任务在进行。并且最多有3个 BC 任务在进行，因为每块盘上会自动预留一个线程给CC任务。</p>\n<p><strong>另一方面，Compaction 任务同时也是一个内存密集型任务，因为其本质是一个多路归并排序的过程，每一路是一个数据版本。</strong>如果一个 Compaction 任务涉及的数据版本很多，则会占用更多的内存，如果仅限制任务数，而不考虑任务的内存开销，则有可能导致系统内存超限。因此，Doris 在上述任务个数限制之外，还增加了一个任务配额限制：</p>\n<blockquote>\n<p>total_permits_for_compaction_score：Compaction 任务配额，默认 10000。</p>\n</blockquote>\n<p>每个 Compaction 任务都有一个配额，其数值就是任务涉及的数据版本数量。假设一个任务需要合并100个版本，则其配额为100。当正在运行的任务配额总和超过配置后，新的任务将被拒绝。</p>\n<p>三个配置共同决定了节点所能承受的 Compaction 任务数量。</p>\n<h3 id=\"数据版本选择策略\"><a href=\"#数据版本选择策略\" class=\"headerlink\" title=\"数据版本选择策略\"></a>数据版本选择策略</h3><p>一个 Compaction 任务对应的是一个数据分片（Tablet）。消费线程拿到一个 Compaction 任务后，会根据 Compaction 的任务类型，选择 tablet 中合适的数据版本（Rowset）进行数据合并。下面分别介绍 Base Compaction 和 Cumulative Compaction 的数据分片选择策略。</p>\n<h4 id=\"Base-Compaction\"><a href=\"#Base-Compaction\" class=\"headerlink\" title=\"Base Compaction\"></a>Base Compaction</h4><p>前文说过，BC 任务是增量数据和基线数据的合并任务。并且只有比 Cumulative Point（CP） 小的数据版本才会参与 BC 任务。因此，BC 任务的数据版本选取策略比较简单。</p>\n<p>首先，会选取所有版本在 0到 CP之间的 rowset。然后根据以下几个配置参数，判断是否启动一个 BC 任务：</p>\n<blockquote>\n<p>base_compaction_num_cumulative_deltas：一次 BC 任务最小版本数量限制。默认为5。该参数主要为了避免过多 BC 任务。当数据版本数量较少时，BC 是没有必要的。</p>\n<p>base_compaction_interval_seconds_since_last_operation：第一个参数限制了当版本数量少时，不会进行 BC 任务。但我们需要避免另一种情况，即某些 tablet 可能仅会导入少量批次的数据，因此当 Doris 发现一个 tablet 长时间没有执行过 BC 任务时，也会触发 BC 任务。这个参数就是控制这个时间的，默认是 86400，单位是秒。</p>\n</blockquote>\n<p><em>&gt; 以上两个参数通常情况下不需要修改，在某些情况下如何需要想尽快合并基线数据，可以尝试改小 <strong>base_compaction_num_cumulative_deltas 参数。但这个参数只会影响到 “被选中的 tablet”。而 “被选中” 的前提是这个 tablet 的数据版本数量是最多的。</strong></em></p>\n<h4 id=\"Cumulative-Compaction\"><a href=\"#Cumulative-Compaction\" class=\"headerlink\" title=\"Cumulative Compaction\"></a>Cumulative Compaction</h4><p>CC 任务只会选取版本比 CP 大的数据版本。其本身的选取策略也比较简单，即从 CP 版本开始，依次向后选取数据版本。最终的数据版本集合由以下参数控制：</p>\n<blockquote>\n<p>min_cumulative_compaction_num_singleton_deltas：一次 CC 任务最少的版本数量限制。这个配置是和 cumulative_size_based_compaction_lower_size_mbytes 配置同时判断的。即如果版本数量小于阈值，并且数据量也小于阈值，则不会触发 CC 任务。以避免过多不必要的 CC 任务。默认是5。</p>\n<p>max_cumulative_compaction_num_singleton_deltas：一次 CC 任务最大的版本数量限制。以防止一次 CC 任务合并的版本数量过多，占用过多资源。默认是1000。</p>\n<p>cumulative_size_based_compaction_lower_size_mbytes：一次 CC 任务最少的数据量，和min_cumulative_compaction_num_singleton_delta 同时判断。默认是 64，单位是 MB。</p>\n</blockquote>\n<p>简单来说，默认配置下，就是从 CP 版本开始往后选取 rowset。最少选5个，最多选 1000 个，然后判断数据量是否大于阈值即可。</p>\n<p>CC 任务还有一个重要步骤，就是在合并任务结束后，设置新的 Cumulative Point。CC 任务合并完成后，会产生一个合并后的新的数据版本，而我们要做的就是判断这个新的数据版是 “晋升” 到 BC 任务区，还是依然保留在 CC 任务区。举个例子：</p>\n<p>假设当前 CP 是 10。有一个 CC 任务合并了 [10-13] [14-14] [15-15] 后生成了 [10-15] 这个版本。如果决定将 [10-15] 版本移动到 BC 任务区，则需修改 CP 为 15，否则 CP 保持不变，依然为 10。</p>\n<p><strong>CP 只会增加，不会减少。</strong> 以下参数决定了是否更新 CP：</p>\n<blockquote>\n<p>cumulative_size_based_promotion_ratio：晋升比率。默认 0.05。</p>\n<p>cumulative_size_based_promotion_min_size_mbytes：最小晋升大小，默认 64，单位 MB。</p>\n<p>cumulative_size_based_promotion_size_mbytes：最大晋升大小，默认 1024，单位 MB。</p>\n</blockquote>\n<p>以上参数比较难理解，这里我们先解释下 “晋升” 的原则。一个 CC 任务生成的 rowset 的晋升原则，是其数据大小和基线数据的大小在 “同一量级”。这个类似 2048 小游戏，只有相同的数字才能合并形成更大的数字。而上面三个参数，就是用于判断一个新的rowset是否匹配基线数据的数量级。举例说明：</p>\n<p>在默认配置下，假设当前基线数据（即所有 CP 之前的数据版本）的数据量为 10GB，则晋升量级为 （10GB * 0.05）512MB。这个数值大于 64 MB 小于 1024 MB，满足条件。所以如果 CC 任务生成的新的 rowset 的大小大于 512 MB，则可以晋升，即 CP 增加。而假设基线数据为 50GB，则晋升量级为（50GB * 0.05）2.5GB。这个数值大于 64 MB 也大于 1024 MB，因此晋升量级会被调整为 1024 MB。所以如果 CC 任务生成的新的 rowset 的大小大于 1024 MB，则可以晋升，即 CP 增加。</p>\n<p>从上面的例子可以看出，cumulative_size_based_promotion_ratio 用于定义 “同一量级”，0.05 即表示数据量大于基线数据的 5% 的 rowset 都有晋升的可能，而 cumulative_size_based_promotion_min_size_mbytes 和 cumulative_size_based_promotion_size_mbytes 用于保证晋升不会过于频繁或过于严格。</p>\n<blockquote>\n<p><em>这三个参数会直接影响 BC 和 CC 任务的频率，尤其在高频导入场景下需要适当调整。我们会在后续文章中举例说明。</em></p>\n</blockquote>\n<h3 id=\"其他-Compaction-参数和注意事项\"><a href=\"#其他-Compaction-参数和注意事项\" class=\"headerlink\" title=\"其他 Compaction 参数和注意事项\"></a>其他 Compaction 参数和注意事项</h3><p>还有一些参数和 Compaction 相关，在某些情况下需要修改：</p>\n<p>disable_auto_compaction：默认为 false，修改为 true 则会禁止 Compaction 操作。该参数仅在一些调试情况，或者 compaction 异常需要临时关闭的情况下才需使用。</p>\n<h4 id=\"Delete-灾难\"><a href=\"#Delete-灾难\" class=\"headerlink\" title=\"Delete 灾难\"></a>Delete 灾难</h4><p>通过 DELETE FROM 语句执行的数据删除操作，在 Doris 中也会生成一个数据版本用于标记删除。这种类型的数据版本比较特殊，我们成为 “删除版本”。删除版本只能通过 Base Compaction 任务处理。因此在在遇到删除版本时，Cumulative Point 会强制增加，将删除版本移动到 BC 任务区。<strong>因此数据导入和删除交替发生的场景通常会导致 Compaction 灾难</strong>。比如以下版本序列：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[0-10]</span><br><span class=\"line\">[11-11] 删除版本</span><br><span class=\"line\">[12-12]</span><br><span class=\"line\">[13-13] 删除版本</span><br><span class=\"line\">[14-14]</span><br><span class=\"line\">[15-15] 删除版本</span><br><span class=\"line\">[16-16]</span><br><span class=\"line\">[17-17] 删除版本</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n\n<p>在这种情况下，CC 任务几乎不会被触发（因为CC任务只能选择一个版本，而无法处理删除版本），所有版本都会交给 Base Compaction 处理，导致 Compaction 进度缓慢。目前Doris还无法很好的处理这种场景，因此需要在业务上尽量避免。</p>\n"},{"title":"Doris Join最佳实践","date":"2022-09-25T06:51:43.000Z","updated":"2022-09-25T06:51:43.000Z","cover":"https://tvax4.sinaimg.cn/large/0084aYsLgy1h3jum72m7kj31220e6jsc.jpg","top_img":null,"description":null,"keywords":null,"_content":"\n## 前言\n\n Doris 支持两种物理算子，一类是 **Hash Join**，另一类是 **Nest Loop Join**。\n\n- Hash Join：在右表上根据等值 Join 列建立哈希表，左表流式的利用哈希表进行 Join 计算，它的限制是只能适用于等值 Join。\n- Nest Loop Join：通过两个 for 循环，很直观。然后它适用的场景就是不等值的 Join，例如：大于小于或者是需要求笛卡尔积的场景。它是一个通用的 Join 算子，但是性能表现差。\n\n作为分布式的 MPP 数据库， 在 Join 的过程中是需要进行数据的 Shuffle。数据需要进行拆分调度，才能保证最终的 Join 结果是正确的。举个简单的例子，假设关系S 和 R 进行Join，N 表示参与 Join 计算的节点的数量；T 则表示关系的 Tuple 数目。\n\n![image.png](https://cdn.nlark.com/yuque/0/2022/png/2500465/1664090756329-d7a09f4c-4837-414c-8910-8f5efe1eb247.png?x-oss-process=image%2Fresize%2Cw_1875%2Climit_0)\n\n## Doris Join 调优方法\n\nDoris Join 调优的方法：\n\n- 利用 Doris 本身提供的 Profile，去定位查询的瓶颈。Profile 会记录 Doris 整个查询当中各种信息，这是进行性能调优的一手资料。\n- 了解 Doris 的 Join 机制。知其然知其所以然、了解它的机制，才能分析它为什么比较慢。\n- 利用 Session 变量去改变 Join 的一些行为，从而实现 Join 的调优。\n- 查看 Query Plan 去分析这个调优是否生效。\n\n上面的 4 步基本上完成了一个标准的 Join 调优流程，接着就是实际去查询验证它，看看效果到底怎么样。\n\n如果前面 4 种方式串联起来之后，还是不奏效。这时候可能就需要去做 Join 语句的改写，或者是数据分布的调整、需要重新去 Recheck 整个数据分布是否合理，包括查询 Join 语句，可能需要做一些手动的调整。当然这种方式是心智成本是比较高的，也就是说要在尝试前面方式不奏效的情况下，才需要去做进一步的分析。\n\n## Doris Join 调优建议\n\n最后我们总结 Doris Join 优化调优的四点建议：\n\n- 第一点：在做 Join 的时候，要尽量选择同类型或者简单类型的列，同类型的话就减少它的数据 Cast，简单类型本身 Join 计算就很快。\n- 第二点：尽量选择 Key 列进行 Join， 原因前面在 Runtime Filter 的时候也介绍了，Key 列在延迟物化上能起到一个比较好的效果。\n- 第三点：大表之间的 Join ，尽量让它 Co-location ，因为大表之间的网络开销是很大的，如果需要去做 Shuffle 的话，代价是很高的。\n- 第四点：合理的使用 Runtime Filter，它在 Join 过滤率高的场景下效果是非常显著的。但是它并不是万灵药，而是有一定副作用的，所以需要根据具体的 SQL 的粒度做开关。\n- 最后：要涉及到多表 Join 的时候，需要去判断 Join 的合理性。尽量保证左表为大表，右表为小表，然后 Hash Join 会优于 Nest Loop Join。必要的时可以通过 SQL Rewrite，利用 Hint 去调整 Join 的顺序。\n\n\n\n## 调优案例实战\n\n### 案例一\n\n一个四张表 Join 的查询，通过 Profile 的时候发现第二个 Join 耗时很高，耗时 14 秒。\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1664092799212-d06d6eeb-01fa-41a7-8a74-614d99a626fd.png)\n\n进一步分析 Profile 之后，发现 BuildRows，就是右表的数据量是大概 2500 万。而 ProbeRows （ ProbeRows 是左表的数据量）只有 1 万多。这种场景下右表是远远大于左表，这显然是个不合理的情况。这显然说明 Join 的顺序出现了一些问题。这时候尝试改变 Session 变量，开启 Join Reorder。\n\n```text\nset enable_cost_based_join_reorder = true\n```\n\n\n\n这次耗时从 14 秒降到了 4 秒，性能提升了 3 倍多。\n\n此时再 Check Profile 的时候，左右表的顺序已经调整正确，即右表是大表，左表是小表。基于小表去构建哈希表，开销是很小的，这就是典型的一个利用 Join Reorder 去提升 Join 性能的一个场景\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1664092799211-2556ed2c-a041-48b3-b32c-d4fac1ab7ace.png)\n\n### 案例二\n\n存在一个慢查询，查看 Profile 之后，整个 Join 节点耗时大概44秒。它的右表有 1000 万，左表有 6000 万，最终返回的结果也只有 6000 万。\n\n![image.png](https://cdn.nlark.com/yuque/0/2022/png/2500465/1664092799211-6289e219-dd31-495b-967f-dd6400b945f0.png)\n\n这里可以大致的估算出过滤率是很高的，那为什么 Runtime Filter 没有生效呢？通过 Query Plan 去查看它，发现它只开启了 IN 的 Runtime Filter。\n\n![image.png](https://cdn.nlark.com/yuque/0/2022/png/2500465/1664092799132-41ae2249-b72d-43f0-b6fc-e2d9ddc07ae8.png)\n\n当右表超过1024行的话， IN 是不生效的，所以根本起不到什么过滤的效果，所以尝试调整 RuntimeFilter 的类型。\n\n这里改为了 BloomFilter，左表的 6000 万条数据过滤了 5900 万条。基本上 99% 的数据都被过滤掉了，这个效果是很显著的。查询也从原来的 44 秒降到了 13 秒，性能提升了大概也是三倍多。\n\n### 案例三\n\n下面是一个比较极端的 Case，通过一些环境变量调优也没有办法解决，因为它涉及到 SQL Rewrite，所以这里列出来了原始的 SQL 。\n\n```sql\nselect 100.00 * sum (case\n        when P_type like 'PROMOS'\n        then 1 extendedprice * (1 - 1 discount)\n        else 0\n        end ) / sum(1 extendedprice * (1 - 1 discount)) as promo revenue\nfrom lineitem, part\nwhere\n    1_partkey = p_partkey\n    and 1_shipdate >= date '1997-06-01'\n    and 1 shipdate < date '1997-06-01' + interval '1' month\n```\n\n\n\n这个 Join 查询是很简单的，单纯的一个左右表的 Join 。当然它上面有一些过滤条件，打开 Profile 的时候，发现整个查询 Hash Join 执行了三分多钟，它是一个 BroadCast 的 Join，它的右表有 2 亿条，左表只有 70 万。在这种情况下选择了 Broadcast Join 是不合理的，这相当于要把 2 亿条做一个 Hash Table，然后用 70 万条遍历两亿条的 Hash Table ，这显然是不合理的。\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1664092798965-5f747810-f38d-468f-8f5b-2846a8dc8928.png)\n\n为什么会产生不合理的 Join 顺序呢？其实这个左表是一个 10 亿条级别的大表，它上面加了两个过滤条件，加完这两个过滤条件之后， 10 亿条的数据就剩 70 万条了。但 Doris 目前没有一个好的统计信息收集的框架，所以它不知道这个过滤条件的过滤率到底怎么样。所以这个 Join 顺序安排的时候，就选择了错误的 Join 的左右表顺序，导致它的性能是极其低下的。\n\n下图是改写完成之后的一个 SQL 语句，在 Join 后面添加了一个Join Hint，在Join 后面加一个方括号，然后把需要的 Join 方式写入。这里选择了 Shuffle Join，可以看到右边它实际查询计划里面看到这个数据确实是做了 Partition ，原先 3 分钟的耗时通过这样的改写完之后只剩下 7 秒，性能提升明显\n\n![image.png](https://cdn.nlark.com/yuque/0/2022/png/2500465/1664092800013-fc558dfd-5923-447e-aceb-4b97111f9fc2.png)\n","source":"_posts/bigdata/Doris-Join最佳实践.md","raw":"---\ntitle: Doris Join最佳实践\ntags:\n  - 'Doris'\ncategories:\n  - [bigdata,Doris]\ndate: 2022-09-25 14:51:43\nupdated: 2022-09-25 14:51:43\ncover:\ntop_img:\ndescription:\nkeywords:\n---\n\n## 前言\n\n Doris 支持两种物理算子，一类是 **Hash Join**，另一类是 **Nest Loop Join**。\n\n- Hash Join：在右表上根据等值 Join 列建立哈希表，左表流式的利用哈希表进行 Join 计算，它的限制是只能适用于等值 Join。\n- Nest Loop Join：通过两个 for 循环，很直观。然后它适用的场景就是不等值的 Join，例如：大于小于或者是需要求笛卡尔积的场景。它是一个通用的 Join 算子，但是性能表现差。\n\n作为分布式的 MPP 数据库， 在 Join 的过程中是需要进行数据的 Shuffle。数据需要进行拆分调度，才能保证最终的 Join 结果是正确的。举个简单的例子，假设关系S 和 R 进行Join，N 表示参与 Join 计算的节点的数量；T 则表示关系的 Tuple 数目。\n\n![image.png](https://cdn.nlark.com/yuque/0/2022/png/2500465/1664090756329-d7a09f4c-4837-414c-8910-8f5efe1eb247.png?x-oss-process=image%2Fresize%2Cw_1875%2Climit_0)\n\n## Doris Join 调优方法\n\nDoris Join 调优的方法：\n\n- 利用 Doris 本身提供的 Profile，去定位查询的瓶颈。Profile 会记录 Doris 整个查询当中各种信息，这是进行性能调优的一手资料。\n- 了解 Doris 的 Join 机制。知其然知其所以然、了解它的机制，才能分析它为什么比较慢。\n- 利用 Session 变量去改变 Join 的一些行为，从而实现 Join 的调优。\n- 查看 Query Plan 去分析这个调优是否生效。\n\n上面的 4 步基本上完成了一个标准的 Join 调优流程，接着就是实际去查询验证它，看看效果到底怎么样。\n\n如果前面 4 种方式串联起来之后，还是不奏效。这时候可能就需要去做 Join 语句的改写，或者是数据分布的调整、需要重新去 Recheck 整个数据分布是否合理，包括查询 Join 语句，可能需要做一些手动的调整。当然这种方式是心智成本是比较高的，也就是说要在尝试前面方式不奏效的情况下，才需要去做进一步的分析。\n\n## Doris Join 调优建议\n\n最后我们总结 Doris Join 优化调优的四点建议：\n\n- 第一点：在做 Join 的时候，要尽量选择同类型或者简单类型的列，同类型的话就减少它的数据 Cast，简单类型本身 Join 计算就很快。\n- 第二点：尽量选择 Key 列进行 Join， 原因前面在 Runtime Filter 的时候也介绍了，Key 列在延迟物化上能起到一个比较好的效果。\n- 第三点：大表之间的 Join ，尽量让它 Co-location ，因为大表之间的网络开销是很大的，如果需要去做 Shuffle 的话，代价是很高的。\n- 第四点：合理的使用 Runtime Filter，它在 Join 过滤率高的场景下效果是非常显著的。但是它并不是万灵药，而是有一定副作用的，所以需要根据具体的 SQL 的粒度做开关。\n- 最后：要涉及到多表 Join 的时候，需要去判断 Join 的合理性。尽量保证左表为大表，右表为小表，然后 Hash Join 会优于 Nest Loop Join。必要的时可以通过 SQL Rewrite，利用 Hint 去调整 Join 的顺序。\n\n\n\n## 调优案例实战\n\n### 案例一\n\n一个四张表 Join 的查询，通过 Profile 的时候发现第二个 Join 耗时很高，耗时 14 秒。\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1664092799212-d06d6eeb-01fa-41a7-8a74-614d99a626fd.png)\n\n进一步分析 Profile 之后，发现 BuildRows，就是右表的数据量是大概 2500 万。而 ProbeRows （ ProbeRows 是左表的数据量）只有 1 万多。这种场景下右表是远远大于左表，这显然是个不合理的情况。这显然说明 Join 的顺序出现了一些问题。这时候尝试改变 Session 变量，开启 Join Reorder。\n\n```text\nset enable_cost_based_join_reorder = true\n```\n\n\n\n这次耗时从 14 秒降到了 4 秒，性能提升了 3 倍多。\n\n此时再 Check Profile 的时候，左右表的顺序已经调整正确，即右表是大表，左表是小表。基于小表去构建哈希表，开销是很小的，这就是典型的一个利用 Join Reorder 去提升 Join 性能的一个场景\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1664092799211-2556ed2c-a041-48b3-b32c-d4fac1ab7ace.png)\n\n### 案例二\n\n存在一个慢查询，查看 Profile 之后，整个 Join 节点耗时大概44秒。它的右表有 1000 万，左表有 6000 万，最终返回的结果也只有 6000 万。\n\n![image.png](https://cdn.nlark.com/yuque/0/2022/png/2500465/1664092799211-6289e219-dd31-495b-967f-dd6400b945f0.png)\n\n这里可以大致的估算出过滤率是很高的，那为什么 Runtime Filter 没有生效呢？通过 Query Plan 去查看它，发现它只开启了 IN 的 Runtime Filter。\n\n![image.png](https://cdn.nlark.com/yuque/0/2022/png/2500465/1664092799132-41ae2249-b72d-43f0-b6fc-e2d9ddc07ae8.png)\n\n当右表超过1024行的话， IN 是不生效的，所以根本起不到什么过滤的效果，所以尝试调整 RuntimeFilter 的类型。\n\n这里改为了 BloomFilter，左表的 6000 万条数据过滤了 5900 万条。基本上 99% 的数据都被过滤掉了，这个效果是很显著的。查询也从原来的 44 秒降到了 13 秒，性能提升了大概也是三倍多。\n\n### 案例三\n\n下面是一个比较极端的 Case，通过一些环境变量调优也没有办法解决，因为它涉及到 SQL Rewrite，所以这里列出来了原始的 SQL 。\n\n```sql\nselect 100.00 * sum (case\n        when P_type like 'PROMOS'\n        then 1 extendedprice * (1 - 1 discount)\n        else 0\n        end ) / sum(1 extendedprice * (1 - 1 discount)) as promo revenue\nfrom lineitem, part\nwhere\n    1_partkey = p_partkey\n    and 1_shipdate >= date '1997-06-01'\n    and 1 shipdate < date '1997-06-01' + interval '1' month\n```\n\n\n\n这个 Join 查询是很简单的，单纯的一个左右表的 Join 。当然它上面有一些过滤条件，打开 Profile 的时候，发现整个查询 Hash Join 执行了三分多钟，它是一个 BroadCast 的 Join，它的右表有 2 亿条，左表只有 70 万。在这种情况下选择了 Broadcast Join 是不合理的，这相当于要把 2 亿条做一个 Hash Table，然后用 70 万条遍历两亿条的 Hash Table ，这显然是不合理的。\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1664092798965-5f747810-f38d-468f-8f5b-2846a8dc8928.png)\n\n为什么会产生不合理的 Join 顺序呢？其实这个左表是一个 10 亿条级别的大表，它上面加了两个过滤条件，加完这两个过滤条件之后， 10 亿条的数据就剩 70 万条了。但 Doris 目前没有一个好的统计信息收集的框架，所以它不知道这个过滤条件的过滤率到底怎么样。所以这个 Join 顺序安排的时候，就选择了错误的 Join 的左右表顺序，导致它的性能是极其低下的。\n\n下图是改写完成之后的一个 SQL 语句，在 Join 后面添加了一个Join Hint，在Join 后面加一个方括号，然后把需要的 Join 方式写入。这里选择了 Shuffle Join，可以看到右边它实际查询计划里面看到这个数据确实是做了 Partition ，原先 3 分钟的耗时通过这样的改写完之后只剩下 7 秒，性能提升明显\n\n![image.png](https://cdn.nlark.com/yuque/0/2022/png/2500465/1664092800013-fc558dfd-5923-447e-aceb-4b97111f9fc2.png)\n","slug":"bigdata/Doris-Join最佳实践","published":1,"comments":1,"layout":"post","photos":[],"link":"","_id":"cl9y38ds7000sfwui2julcsst","content":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p> Doris 支持两种物理算子，一类是 <strong>Hash Join</strong>，另一类是 <strong>Nest Loop Join</strong>。</p>\n<ul>\n<li>Hash Join：在右表上根据等值 Join 列建立哈希表，左表流式的利用哈希表进行 Join 计算，它的限制是只能适用于等值 Join。</li>\n<li>Nest Loop Join：通过两个 for 循环，很直观。然后它适用的场景就是不等值的 Join，例如：大于小于或者是需要求笛卡尔积的场景。它是一个通用的 Join 算子，但是性能表现差。</li>\n</ul>\n<p>作为分布式的 MPP 数据库， 在 Join 的过程中是需要进行数据的 Shuffle。数据需要进行拆分调度，才能保证最终的 Join 结果是正确的。举个简单的例子，假设关系S 和 R 进行Join，N 表示参与 Join 计算的节点的数量；T 则表示关系的 Tuple 数目。</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1664090756329-d7a09f4c-4837-414c-8910-8f5efe1eb247.png?x-oss-process=image/resize,w_1875,limit_0\" alt=\"image.png\"></p>\n<h2 id=\"Doris-Join-调优方法\"><a href=\"#Doris-Join-调优方法\" class=\"headerlink\" title=\"Doris Join 调优方法\"></a>Doris Join 调优方法</h2><p>Doris Join 调优的方法：</p>\n<ul>\n<li>利用 Doris 本身提供的 Profile，去定位查询的瓶颈。Profile 会记录 Doris 整个查询当中各种信息，这是进行性能调优的一手资料。</li>\n<li>了解 Doris 的 Join 机制。知其然知其所以然、了解它的机制，才能分析它为什么比较慢。</li>\n<li>利用 Session 变量去改变 Join 的一些行为，从而实现 Join 的调优。</li>\n<li>查看 Query Plan 去分析这个调优是否生效。</li>\n</ul>\n<p>上面的 4 步基本上完成了一个标准的 Join 调优流程，接着就是实际去查询验证它，看看效果到底怎么样。</p>\n<p>如果前面 4 种方式串联起来之后，还是不奏效。这时候可能就需要去做 Join 语句的改写，或者是数据分布的调整、需要重新去 Recheck 整个数据分布是否合理，包括查询 Join 语句，可能需要做一些手动的调整。当然这种方式是心智成本是比较高的，也就是说要在尝试前面方式不奏效的情况下，才需要去做进一步的分析。</p>\n<h2 id=\"Doris-Join-调优建议\"><a href=\"#Doris-Join-调优建议\" class=\"headerlink\" title=\"Doris Join 调优建议\"></a>Doris Join 调优建议</h2><p>最后我们总结 Doris Join 优化调优的四点建议：</p>\n<ul>\n<li>第一点：在做 Join 的时候，要尽量选择同类型或者简单类型的列，同类型的话就减少它的数据 Cast，简单类型本身 Join 计算就很快。</li>\n<li>第二点：尽量选择 Key 列进行 Join， 原因前面在 Runtime Filter 的时候也介绍了，Key 列在延迟物化上能起到一个比较好的效果。</li>\n<li>第三点：大表之间的 Join ，尽量让它 Co-location ，因为大表之间的网络开销是很大的，如果需要去做 Shuffle 的话，代价是很高的。</li>\n<li>第四点：合理的使用 Runtime Filter，它在 Join 过滤率高的场景下效果是非常显著的。但是它并不是万灵药，而是有一定副作用的，所以需要根据具体的 SQL 的粒度做开关。</li>\n<li>最后：要涉及到多表 Join 的时候，需要去判断 Join 的合理性。尽量保证左表为大表，右表为小表，然后 Hash Join 会优于 Nest Loop Join。必要的时可以通过 SQL Rewrite，利用 Hint 去调整 Join 的顺序。</li>\n</ul>\n<h2 id=\"调优案例实战\"><a href=\"#调优案例实战\" class=\"headerlink\" title=\"调优案例实战\"></a>调优案例实战</h2><h3 id=\"案例一\"><a href=\"#案例一\" class=\"headerlink\" title=\"案例一\"></a>案例一</h3><p>一个四张表 Join 的查询，通过 Profile 的时候发现第二个 Join 耗时很高，耗时 14 秒。</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1664092799212-d06d6eeb-01fa-41a7-8a74-614d99a626fd.png\" alt=\"img\"></p>\n<p>进一步分析 Profile 之后，发现 BuildRows，就是右表的数据量是大概 2500 万。而 ProbeRows （ ProbeRows 是左表的数据量）只有 1 万多。这种场景下右表是远远大于左表，这显然是个不合理的情况。这显然说明 Join 的顺序出现了一些问题。这时候尝试改变 Session 变量，开启 Join Reorder。</p>\n<figure class=\"highlight text\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">set enable_cost_based_join_reorder = true</span><br></pre></td></tr></table></figure>\n\n\n\n<p>这次耗时从 14 秒降到了 4 秒，性能提升了 3 倍多。</p>\n<p>此时再 Check Profile 的时候，左右表的顺序已经调整正确，即右表是大表，左表是小表。基于小表去构建哈希表，开销是很小的，这就是典型的一个利用 Join Reorder 去提升 Join 性能的一个场景</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1664092799211-2556ed2c-a041-48b3-b32c-d4fac1ab7ace.png\" alt=\"img\"></p>\n<h3 id=\"案例二\"><a href=\"#案例二\" class=\"headerlink\" title=\"案例二\"></a>案例二</h3><p>存在一个慢查询，查看 Profile 之后，整个 Join 节点耗时大概44秒。它的右表有 1000 万，左表有 6000 万，最终返回的结果也只有 6000 万。</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1664092799211-6289e219-dd31-495b-967f-dd6400b945f0.png\" alt=\"image.png\"></p>\n<p>这里可以大致的估算出过滤率是很高的，那为什么 Runtime Filter 没有生效呢？通过 Query Plan 去查看它，发现它只开启了 IN 的 Runtime Filter。</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1664092799132-41ae2249-b72d-43f0-b6fc-e2d9ddc07ae8.png\" alt=\"image.png\"></p>\n<p>当右表超过1024行的话， IN 是不生效的，所以根本起不到什么过滤的效果，所以尝试调整 RuntimeFilter 的类型。</p>\n<p>这里改为了 BloomFilter，左表的 6000 万条数据过滤了 5900 万条。基本上 99% 的数据都被过滤掉了，这个效果是很显著的。查询也从原来的 44 秒降到了 13 秒，性能提升了大概也是三倍多。</p>\n<h3 id=\"案例三\"><a href=\"#案例三\" class=\"headerlink\" title=\"案例三\"></a>案例三</h3><p>下面是一个比较极端的 Case，通过一些环境变量调优也没有办法解决，因为它涉及到 SQL Rewrite，所以这里列出来了原始的 SQL 。</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">select</span> <span class=\"number\">100.00</span> <span class=\"operator\">*</span> <span class=\"built_in\">sum</span> (<span class=\"keyword\">case</span></span><br><span class=\"line\">        <span class=\"keyword\">when</span> P_type <span class=\"keyword\">like</span> <span class=\"string\">&#x27;PROMOS&#x27;</span></span><br><span class=\"line\">        <span class=\"keyword\">then</span> <span class=\"number\">1</span> extendedprice <span class=\"operator\">*</span> (<span class=\"number\">1</span> <span class=\"operator\">-</span> <span class=\"number\">1</span> discount)</span><br><span class=\"line\">        <span class=\"keyword\">else</span> <span class=\"number\">0</span></span><br><span class=\"line\">        <span class=\"keyword\">end</span> ) <span class=\"operator\">/</span> <span class=\"built_in\">sum</span>(<span class=\"number\">1</span> extendedprice <span class=\"operator\">*</span> (<span class=\"number\">1</span> <span class=\"operator\">-</span> <span class=\"number\">1</span> discount)) <span class=\"keyword\">as</span> promo revenue</span><br><span class=\"line\"><span class=\"keyword\">from</span> lineitem, part</span><br><span class=\"line\"><span class=\"keyword\">where</span></span><br><span class=\"line\">    <span class=\"number\">1</span>_partkey <span class=\"operator\">=</span> p_partkey</span><br><span class=\"line\">    <span class=\"keyword\">and</span> <span class=\"number\">1</span>_shipdate <span class=\"operator\">&gt;=</span> <span class=\"type\">date</span> <span class=\"string\">&#x27;1997-06-01&#x27;</span></span><br><span class=\"line\">    <span class=\"keyword\">and</span> <span class=\"number\">1</span> shipdate <span class=\"operator\">&lt;</span> <span class=\"type\">date</span> <span class=\"string\">&#x27;1997-06-01&#x27;</span> <span class=\"operator\">+</span> <span class=\"type\">interval</span> <span class=\"string\">&#x27;1&#x27;</span> <span class=\"keyword\">month</span></span><br></pre></td></tr></table></figure>\n\n\n\n<p>这个 Join 查询是很简单的，单纯的一个左右表的 Join 。当然它上面有一些过滤条件，打开 Profile 的时候，发现整个查询 Hash Join 执行了三分多钟，它是一个 BroadCast 的 Join，它的右表有 2 亿条，左表只有 70 万。在这种情况下选择了 Broadcast Join 是不合理的，这相当于要把 2 亿条做一个 Hash Table，然后用 70 万条遍历两亿条的 Hash Table ，这显然是不合理的。</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1664092798965-5f747810-f38d-468f-8f5b-2846a8dc8928.png\" alt=\"img\"></p>\n<p>为什么会产生不合理的 Join 顺序呢？其实这个左表是一个 10 亿条级别的大表，它上面加了两个过滤条件，加完这两个过滤条件之后， 10 亿条的数据就剩 70 万条了。但 Doris 目前没有一个好的统计信息收集的框架，所以它不知道这个过滤条件的过滤率到底怎么样。所以这个 Join 顺序安排的时候，就选择了错误的 Join 的左右表顺序，导致它的性能是极其低下的。</p>\n<p>下图是改写完成之后的一个 SQL 语句，在 Join 后面添加了一个Join Hint，在Join 后面加一个方括号，然后把需要的 Join 方式写入。这里选择了 Shuffle Join，可以看到右边它实际查询计划里面看到这个数据确实是做了 Partition ，原先 3 分钟的耗时通过这样的改写完之后只剩下 7 秒，性能提升明显</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1664092800013-fc558dfd-5923-447e-aceb-4b97111f9fc2.png\" alt=\"image.png\"></p>\n","site":{"data":{"link":[{"class_name":"友情链接","class_desc":"那些人，那些事","link_list":[{"name":"张洪Heo","link":"https://blog.zhheo.com/","avatar":"https://npm.elemecdn.com/guli-heo/img/avatar2.png","descr":"分享设计与科技生活"},{"name":"瞬間の筆記","link":"https://hikki.site","descr":"喜欢的东西就努力去追求，万一成功了呢!","avatar":"https://cdn.jsdelivr.net/gh/0000rookie/imgs/202206120315.png"}]}]}},"excerpt":"","more":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p> Doris 支持两种物理算子，一类是 <strong>Hash Join</strong>，另一类是 <strong>Nest Loop Join</strong>。</p>\n<ul>\n<li>Hash Join：在右表上根据等值 Join 列建立哈希表，左表流式的利用哈希表进行 Join 计算，它的限制是只能适用于等值 Join。</li>\n<li>Nest Loop Join：通过两个 for 循环，很直观。然后它适用的场景就是不等值的 Join，例如：大于小于或者是需要求笛卡尔积的场景。它是一个通用的 Join 算子，但是性能表现差。</li>\n</ul>\n<p>作为分布式的 MPP 数据库， 在 Join 的过程中是需要进行数据的 Shuffle。数据需要进行拆分调度，才能保证最终的 Join 结果是正确的。举个简单的例子，假设关系S 和 R 进行Join，N 表示参与 Join 计算的节点的数量；T 则表示关系的 Tuple 数目。</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1664090756329-d7a09f4c-4837-414c-8910-8f5efe1eb247.png?x-oss-process=image/resize,w_1875,limit_0\" alt=\"image.png\"></p>\n<h2 id=\"Doris-Join-调优方法\"><a href=\"#Doris-Join-调优方法\" class=\"headerlink\" title=\"Doris Join 调优方法\"></a>Doris Join 调优方法</h2><p>Doris Join 调优的方法：</p>\n<ul>\n<li>利用 Doris 本身提供的 Profile，去定位查询的瓶颈。Profile 会记录 Doris 整个查询当中各种信息，这是进行性能调优的一手资料。</li>\n<li>了解 Doris 的 Join 机制。知其然知其所以然、了解它的机制，才能分析它为什么比较慢。</li>\n<li>利用 Session 变量去改变 Join 的一些行为，从而实现 Join 的调优。</li>\n<li>查看 Query Plan 去分析这个调优是否生效。</li>\n</ul>\n<p>上面的 4 步基本上完成了一个标准的 Join 调优流程，接着就是实际去查询验证它，看看效果到底怎么样。</p>\n<p>如果前面 4 种方式串联起来之后，还是不奏效。这时候可能就需要去做 Join 语句的改写，或者是数据分布的调整、需要重新去 Recheck 整个数据分布是否合理，包括查询 Join 语句，可能需要做一些手动的调整。当然这种方式是心智成本是比较高的，也就是说要在尝试前面方式不奏效的情况下，才需要去做进一步的分析。</p>\n<h2 id=\"Doris-Join-调优建议\"><a href=\"#Doris-Join-调优建议\" class=\"headerlink\" title=\"Doris Join 调优建议\"></a>Doris Join 调优建议</h2><p>最后我们总结 Doris Join 优化调优的四点建议：</p>\n<ul>\n<li>第一点：在做 Join 的时候，要尽量选择同类型或者简单类型的列，同类型的话就减少它的数据 Cast，简单类型本身 Join 计算就很快。</li>\n<li>第二点：尽量选择 Key 列进行 Join， 原因前面在 Runtime Filter 的时候也介绍了，Key 列在延迟物化上能起到一个比较好的效果。</li>\n<li>第三点：大表之间的 Join ，尽量让它 Co-location ，因为大表之间的网络开销是很大的，如果需要去做 Shuffle 的话，代价是很高的。</li>\n<li>第四点：合理的使用 Runtime Filter，它在 Join 过滤率高的场景下效果是非常显著的。但是它并不是万灵药，而是有一定副作用的，所以需要根据具体的 SQL 的粒度做开关。</li>\n<li>最后：要涉及到多表 Join 的时候，需要去判断 Join 的合理性。尽量保证左表为大表，右表为小表，然后 Hash Join 会优于 Nest Loop Join。必要的时可以通过 SQL Rewrite，利用 Hint 去调整 Join 的顺序。</li>\n</ul>\n<h2 id=\"调优案例实战\"><a href=\"#调优案例实战\" class=\"headerlink\" title=\"调优案例实战\"></a>调优案例实战</h2><h3 id=\"案例一\"><a href=\"#案例一\" class=\"headerlink\" title=\"案例一\"></a>案例一</h3><p>一个四张表 Join 的查询，通过 Profile 的时候发现第二个 Join 耗时很高，耗时 14 秒。</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1664092799212-d06d6eeb-01fa-41a7-8a74-614d99a626fd.png\" alt=\"img\"></p>\n<p>进一步分析 Profile 之后，发现 BuildRows，就是右表的数据量是大概 2500 万。而 ProbeRows （ ProbeRows 是左表的数据量）只有 1 万多。这种场景下右表是远远大于左表，这显然是个不合理的情况。这显然说明 Join 的顺序出现了一些问题。这时候尝试改变 Session 变量，开启 Join Reorder。</p>\n<figure class=\"highlight text\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">set enable_cost_based_join_reorder = true</span><br></pre></td></tr></table></figure>\n\n\n\n<p>这次耗时从 14 秒降到了 4 秒，性能提升了 3 倍多。</p>\n<p>此时再 Check Profile 的时候，左右表的顺序已经调整正确，即右表是大表，左表是小表。基于小表去构建哈希表，开销是很小的，这就是典型的一个利用 Join Reorder 去提升 Join 性能的一个场景</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1664092799211-2556ed2c-a041-48b3-b32c-d4fac1ab7ace.png\" alt=\"img\"></p>\n<h3 id=\"案例二\"><a href=\"#案例二\" class=\"headerlink\" title=\"案例二\"></a>案例二</h3><p>存在一个慢查询，查看 Profile 之后，整个 Join 节点耗时大概44秒。它的右表有 1000 万，左表有 6000 万，最终返回的结果也只有 6000 万。</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1664092799211-6289e219-dd31-495b-967f-dd6400b945f0.png\" alt=\"image.png\"></p>\n<p>这里可以大致的估算出过滤率是很高的，那为什么 Runtime Filter 没有生效呢？通过 Query Plan 去查看它，发现它只开启了 IN 的 Runtime Filter。</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1664092799132-41ae2249-b72d-43f0-b6fc-e2d9ddc07ae8.png\" alt=\"image.png\"></p>\n<p>当右表超过1024行的话， IN 是不生效的，所以根本起不到什么过滤的效果，所以尝试调整 RuntimeFilter 的类型。</p>\n<p>这里改为了 BloomFilter，左表的 6000 万条数据过滤了 5900 万条。基本上 99% 的数据都被过滤掉了，这个效果是很显著的。查询也从原来的 44 秒降到了 13 秒，性能提升了大概也是三倍多。</p>\n<h3 id=\"案例三\"><a href=\"#案例三\" class=\"headerlink\" title=\"案例三\"></a>案例三</h3><p>下面是一个比较极端的 Case，通过一些环境变量调优也没有办法解决，因为它涉及到 SQL Rewrite，所以这里列出来了原始的 SQL 。</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">select</span> <span class=\"number\">100.00</span> <span class=\"operator\">*</span> <span class=\"built_in\">sum</span> (<span class=\"keyword\">case</span></span><br><span class=\"line\">        <span class=\"keyword\">when</span> P_type <span class=\"keyword\">like</span> <span class=\"string\">&#x27;PROMOS&#x27;</span></span><br><span class=\"line\">        <span class=\"keyword\">then</span> <span class=\"number\">1</span> extendedprice <span class=\"operator\">*</span> (<span class=\"number\">1</span> <span class=\"operator\">-</span> <span class=\"number\">1</span> discount)</span><br><span class=\"line\">        <span class=\"keyword\">else</span> <span class=\"number\">0</span></span><br><span class=\"line\">        <span class=\"keyword\">end</span> ) <span class=\"operator\">/</span> <span class=\"built_in\">sum</span>(<span class=\"number\">1</span> extendedprice <span class=\"operator\">*</span> (<span class=\"number\">1</span> <span class=\"operator\">-</span> <span class=\"number\">1</span> discount)) <span class=\"keyword\">as</span> promo revenue</span><br><span class=\"line\"><span class=\"keyword\">from</span> lineitem, part</span><br><span class=\"line\"><span class=\"keyword\">where</span></span><br><span class=\"line\">    <span class=\"number\">1</span>_partkey <span class=\"operator\">=</span> p_partkey</span><br><span class=\"line\">    <span class=\"keyword\">and</span> <span class=\"number\">1</span>_shipdate <span class=\"operator\">&gt;=</span> <span class=\"type\">date</span> <span class=\"string\">&#x27;1997-06-01&#x27;</span></span><br><span class=\"line\">    <span class=\"keyword\">and</span> <span class=\"number\">1</span> shipdate <span class=\"operator\">&lt;</span> <span class=\"type\">date</span> <span class=\"string\">&#x27;1997-06-01&#x27;</span> <span class=\"operator\">+</span> <span class=\"type\">interval</span> <span class=\"string\">&#x27;1&#x27;</span> <span class=\"keyword\">month</span></span><br></pre></td></tr></table></figure>\n\n\n\n<p>这个 Join 查询是很简单的，单纯的一个左右表的 Join 。当然它上面有一些过滤条件，打开 Profile 的时候，发现整个查询 Hash Join 执行了三分多钟，它是一个 BroadCast 的 Join，它的右表有 2 亿条，左表只有 70 万。在这种情况下选择了 Broadcast Join 是不合理的，这相当于要把 2 亿条做一个 Hash Table，然后用 70 万条遍历两亿条的 Hash Table ，这显然是不合理的。</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1664092798965-5f747810-f38d-468f-8f5b-2846a8dc8928.png\" alt=\"img\"></p>\n<p>为什么会产生不合理的 Join 顺序呢？其实这个左表是一个 10 亿条级别的大表，它上面加了两个过滤条件，加完这两个过滤条件之后， 10 亿条的数据就剩 70 万条了。但 Doris 目前没有一个好的统计信息收集的框架，所以它不知道这个过滤条件的过滤率到底怎么样。所以这个 Join 顺序安排的时候，就选择了错误的 Join 的左右表顺序，导致它的性能是极其低下的。</p>\n<p>下图是改写完成之后的一个 SQL 语句，在 Join 后面添加了一个Join Hint，在Join 后面加一个方括号，然后把需要的 Join 方式写入。这里选择了 Shuffle Join，可以看到右边它实际查询计划里面看到这个数据确实是做了 Partition ，原先 3 分钟的耗时通过这样的改写完之后只剩下 7 秒，性能提升明显</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1664092800013-fc558dfd-5923-447e-aceb-4b97111f9fc2.png\" alt=\"image.png\"></p>\n"},{"title":"Doris中的索引","top_img":null,"date":"2022-08-07T02:51:08.000Z","updated":"2022-08-07T02:51:08.000Z","cover":"https://tvax3.sinaimg.cn/large/0084aYsLly1gnhmxy0hdlj31hc0u0gpt.jpg","description":null,"keywords":null,"_content":"\n> **不同于传统的数据库设计，Doris 不支持在任意列上创建索引。**Doris 这类 MPP 架构的 OLAP 数据库，通常都是通过提高并发，来处理大量数据的。\n>\n> Doris 支持比较丰富的索引结构，来减少数据的扫描：\n>\n> - Sorted Compound Key Index，可以最多指定三个列组成复合排序键，通过该索引，能够有效进行数据裁剪，从而能够更好支持高并发的报表场景\n> - Z-order Index ：使用 Z-order 索引，可以高效对数据模型中的任意字段组合进行范围查询\n> - Min/Max ：有效过滤数值类型的等值和范围查询\n> - Bloom Filter ：对高基数列的等值过滤裁剪非常有效\n> - Invert Index ：能够对任意字段实现快速检索\n\n\n\n# 前缀索引\n\n## 基本概念\n\n不同于传统的数据库设计，Doris 不支持在任意列上创建索引。Doris 这类 MPP 架构的 OLAP 数据库，通常都是通过提高并发，来处理大量数据的。\n\n本质上，Doris 的数据存储在类似 SSTable（Sorted String Table）的数据结构中。该结构是一种有序的数据结构，可以按照指定的列进行排序存储。在这种数据结构上，以排序列作为条件进行查找，会非常的高效。\n\n在 Aggregate、Unique 和 Duplicate 三种数据模型中。底层的数据存储，是按照各自建表语句中，AGGREGATE KEY、UNIQUE KEY 和 DUPLICATE KEY 中指定的列进行排序存储的。\n\n而前缀索引，即在排序的基础上，实现的一种根据给定前缀列，快速查询数据的索引方式。\n\n## 示例\n\n我们将一行数据的前 **36 个字节** 作为这行数据的前缀索引。当遇到 VARCHAR 类型时，前缀索引会直接截断。我们举例说明：\n\n1. 以下表结构的前缀索引为 user_id(8 Bytes) + age(4 Bytes) + message(prefix 20 Bytes)。\n\n   | ColumnName     | Type         |\n   | -------------- | ------------ |\n   | user_id        | BIGINT       |\n   | age            | INT          |\n   | message        | VARCHAR(100) |\n   | max_dwell_time | DATETIME     |\n   | min_dwell_time | DATETIME     |\n\n2. 以下表结构的前缀索引为 user_name(20 Bytes)。即使没有达到 36 个字节，因为遇到 VARCHAR，所以直接截断，不再往后继续。\n\n   | ColumnName     | Type         |\n   | -------------- | ------------ |\n   | user_name      | VARCHAR(20)  |\n   | age            | INT          |\n   | message        | VARCHAR(100) |\n   | max_dwell_time | DATETIME     |\n   | min_dwell_time | DATETIME     |\n\n当我们的查询条件，是**前缀索引的前缀**时，可以极大的加快查询速度。比如在第一个例子中，我们执行如下查询：\n\n```sql\nSELECT * FROM table WHERE user_id=1829239 and age=20；\n```\n\n该查询的效率会**远高于**如下查询：\n\n```sql\nSELECT * FROM table WHERE age=20；\n```\n\n所以在建表时，**正确的选择列顺序，能够极大地提高查询效率**。\n\n## 通过ROLLUP来调整前缀索引\n\n因为建表时已经指定了列顺序，所以一个表只有一种前缀索引。这对于使用其他不能命中前缀索引的列作为条件进行的查询来说，效率上可能无法满足需求。因此，我们可以通过创建 ROLLUP 来人为的调整列顺序。详情可参考[ROLLUP](https://doris.apache.org/zh-CN/docs/data-table/hit-the-rollup)。\n\n\n\n# BloomFilter索引\n\n## Doris BloomFilter索引及使用使用场景\n\n举个例子：如果要查找一个占用100字节存储空间大小的短行，一个64KB的HFile数据块应该包含(64 * 1024)/100 = 655.53 = ~700行，如果仅能在整个数据块的起始行键上建立索引，那么它是无法给你提供细粒度的索引信息的。因为要查找的行数据可能会落在该数据块的行区间上，也可能行数据没在该数据块上，也可能是表中根本就不存在该行数据，也或者是行数据在另一个HFile里，甚至在MemStore里。以上这几种情况，都会导致从磁盘读取数据块时带来额外的IO开销，也会滥用数据块的缓存，当面对一个巨大的数据集且处于高并发读时，会严重影响性能。\n\n因此，HBase提供了布隆过滤器，它允许你对存储在每个数据块的数据做一个反向测试。当某行被请求时，通过布隆过滤器先检查该行是否不在这个数据块，布隆过滤器要么确定回答该行不在，要么回答它不知道。这就是为什么我们称它是反向测试。布隆过滤器同样也可以应用到行里的单元上，当访问某列标识符时可以先使用同样的反向测试。\n\n但布隆过滤器也不是没有代价。存储这个额外的索引层次会占用额外的空间。布隆过滤器随着它们的索引对象数据增长而增长，所以行级布隆过滤器比列标识符级布隆过滤器占用空间要少。当空间不是问题时，它们可以帮助你榨干系统的性能潜力。 Doris的BloomFilter索引可以通过建表的时候指定，或者通过表的ALTER操作来完成。Bloom Filter本质上是一种位图结构，用于快速的判断一个给定的值是否在一个集合中。这种判断会产生小概率的误判。即如果返回false，则一定不在这个集合内。而如果范围true，则有可能在这个集合内。\n\nBloomFilter索引也是以Block为粒度创建的。每个Block中，指定列的值作为一个集合生成一个BloomFilter索引条目，用于在查询是快速过滤不满足条件的数据。\n\n下面我们通过实例来看看Doris怎么创建BloomFilter索引。\n\n## 创建BloomFilter索引\n\nDoris BloomFilter索引的创建是通过在建表语句的PROPERTIES里加上\"bloom_filter_columns\"=\"k1,k2,k3\",这个属性，k1,k2,k3是你要创建的BloomFilter索引的Key列名称，例如下面我们对表里的saler_id,category_id创建了BloomFilter索引。\n\n```sql\nCREATE TABLE IF NOT EXISTS sale_detail_bloom  (\n    sale_date date NOT NULL COMMENT \"销售时间\",\n    customer_id int NOT NULL COMMENT \"客户编号\",\n    saler_id int NOT NULL COMMENT \"销售员\",\n    sku_id int NOT NULL COMMENT \"商品编号\",\n    category_id int NOT NULL COMMENT \"商品分类\",\n    sale_count int NOT NULL COMMENT \"销售数量\",\n    sale_price DECIMAL(12,2) NOT NULL COMMENT \"单价\",\n    sale_amt DECIMAL(20,2)  COMMENT \"销售总金额\"\n)\nDuplicate  KEY(sale_date, customer_id,saler_id,sku_id,category_id)\nPARTITION BY RANGE(sale_date)\n(\nPARTITION P_202111 VALUES [('2021-11-01'), ('2021-12-01'))\n)\nDISTRIBUTED BY HASH(saler_id) BUCKETS 10\nPROPERTIES (\n\"replication_num\" = \"3\",\n\"bloom_filter_columns\"=\"saler_id,category_id\",\n\"dynamic_partition.enable\" = \"true\",\n\"dynamic_partition.time_unit\" = \"MONTH\",\n\"dynamic_partition.time_zone\" = \"Asia/Shanghai\",\n\"dynamic_partition.start\" = \"-2147483648\",\n\"dynamic_partition.end\" = \"2\",\n\"dynamic_partition.prefix\" = \"P_\",\n\"dynamic_partition.replication_num\" = \"3\",\n\"dynamic_partition.buckets\" = \"3\"\n);\n```\n\n\n\n## 查看BloomFilter索引\n\n查看我们在表上建立的BloomFilter索引是使用:\n\n```sql\nSHOW CREATE TABLE <table_name>\n```\n\n## 删除BloomFilter索引\n\n删除索引即为将索引列从bloom_filter_columns属性中移除：\n\n```sql\nALTER TABLE <db.table_name> SET (\"bloom_filter_columns\" = \"\");\n```\n\n## 修改BloomFilter索引\n\n修改索引即为修改表的bloom_filter_columns属性：\n\n```sql\nALTER TABLE <db.table_name> SET (\"bloom_filter_columns\" = \"k1,k3\");\n```\n\n## **Doris BloomFilter使用场景**\n\n满足以下几个条件时可以考虑对某列建立Bloom Filter 索引：\n\n1. 首先BloomFilter适用于非前缀过滤.\n2. 查询会根据该列高频过滤，而且查询条件大多是in和 = 过滤.\n3. 不同于Bitmap, BloomFilter适用于高基数列。比如UserID。因为如果创建在低基数的列上，比如”性别“列，则每个Block几乎都会包含所有取值，导致BloomFilter索引失去意义\n\n## **Doris BloomFilter使用注意事项**\n\n1. 不支持对Tinyint、Float、Double 类型的列建Bloom Filter索引。\n2. Bloom Filter索引只对in和 = 过滤查询有加速效果。\n3. 如果要查看某个查询是否命中了Bloom Filter索引，可以通过查询的Profile信息查看\n\n\n\n# Bitmap 索引\n\n","source":"_posts/bigdata/Doris中的索引.md","raw":"---\ntitle: Doris中的索引\ntags:\n  - 'Doris'\ncategories:\n  - [bigdata,Doris]\ntop_img: \ndate: 2022-08-07 10:51:08\nupdated: 2022-08-07 10:51:08\ncover:\ndescription:\nkeywords:\n---\n\n> **不同于传统的数据库设计，Doris 不支持在任意列上创建索引。**Doris 这类 MPP 架构的 OLAP 数据库，通常都是通过提高并发，来处理大量数据的。\n>\n> Doris 支持比较丰富的索引结构，来减少数据的扫描：\n>\n> - Sorted Compound Key Index，可以最多指定三个列组成复合排序键，通过该索引，能够有效进行数据裁剪，从而能够更好支持高并发的报表场景\n> - Z-order Index ：使用 Z-order 索引，可以高效对数据模型中的任意字段组合进行范围查询\n> - Min/Max ：有效过滤数值类型的等值和范围查询\n> - Bloom Filter ：对高基数列的等值过滤裁剪非常有效\n> - Invert Index ：能够对任意字段实现快速检索\n\n\n\n# 前缀索引\n\n## 基本概念\n\n不同于传统的数据库设计，Doris 不支持在任意列上创建索引。Doris 这类 MPP 架构的 OLAP 数据库，通常都是通过提高并发，来处理大量数据的。\n\n本质上，Doris 的数据存储在类似 SSTable（Sorted String Table）的数据结构中。该结构是一种有序的数据结构，可以按照指定的列进行排序存储。在这种数据结构上，以排序列作为条件进行查找，会非常的高效。\n\n在 Aggregate、Unique 和 Duplicate 三种数据模型中。底层的数据存储，是按照各自建表语句中，AGGREGATE KEY、UNIQUE KEY 和 DUPLICATE KEY 中指定的列进行排序存储的。\n\n而前缀索引，即在排序的基础上，实现的一种根据给定前缀列，快速查询数据的索引方式。\n\n## 示例\n\n我们将一行数据的前 **36 个字节** 作为这行数据的前缀索引。当遇到 VARCHAR 类型时，前缀索引会直接截断。我们举例说明：\n\n1. 以下表结构的前缀索引为 user_id(8 Bytes) + age(4 Bytes) + message(prefix 20 Bytes)。\n\n   | ColumnName     | Type         |\n   | -------------- | ------------ |\n   | user_id        | BIGINT       |\n   | age            | INT          |\n   | message        | VARCHAR(100) |\n   | max_dwell_time | DATETIME     |\n   | min_dwell_time | DATETIME     |\n\n2. 以下表结构的前缀索引为 user_name(20 Bytes)。即使没有达到 36 个字节，因为遇到 VARCHAR，所以直接截断，不再往后继续。\n\n   | ColumnName     | Type         |\n   | -------------- | ------------ |\n   | user_name      | VARCHAR(20)  |\n   | age            | INT          |\n   | message        | VARCHAR(100) |\n   | max_dwell_time | DATETIME     |\n   | min_dwell_time | DATETIME     |\n\n当我们的查询条件，是**前缀索引的前缀**时，可以极大的加快查询速度。比如在第一个例子中，我们执行如下查询：\n\n```sql\nSELECT * FROM table WHERE user_id=1829239 and age=20；\n```\n\n该查询的效率会**远高于**如下查询：\n\n```sql\nSELECT * FROM table WHERE age=20；\n```\n\n所以在建表时，**正确的选择列顺序，能够极大地提高查询效率**。\n\n## 通过ROLLUP来调整前缀索引\n\n因为建表时已经指定了列顺序，所以一个表只有一种前缀索引。这对于使用其他不能命中前缀索引的列作为条件进行的查询来说，效率上可能无法满足需求。因此，我们可以通过创建 ROLLUP 来人为的调整列顺序。详情可参考[ROLLUP](https://doris.apache.org/zh-CN/docs/data-table/hit-the-rollup)。\n\n\n\n# BloomFilter索引\n\n## Doris BloomFilter索引及使用使用场景\n\n举个例子：如果要查找一个占用100字节存储空间大小的短行，一个64KB的HFile数据块应该包含(64 * 1024)/100 = 655.53 = ~700行，如果仅能在整个数据块的起始行键上建立索引，那么它是无法给你提供细粒度的索引信息的。因为要查找的行数据可能会落在该数据块的行区间上，也可能行数据没在该数据块上，也可能是表中根本就不存在该行数据，也或者是行数据在另一个HFile里，甚至在MemStore里。以上这几种情况，都会导致从磁盘读取数据块时带来额外的IO开销，也会滥用数据块的缓存，当面对一个巨大的数据集且处于高并发读时，会严重影响性能。\n\n因此，HBase提供了布隆过滤器，它允许你对存储在每个数据块的数据做一个反向测试。当某行被请求时，通过布隆过滤器先检查该行是否不在这个数据块，布隆过滤器要么确定回答该行不在，要么回答它不知道。这就是为什么我们称它是反向测试。布隆过滤器同样也可以应用到行里的单元上，当访问某列标识符时可以先使用同样的反向测试。\n\n但布隆过滤器也不是没有代价。存储这个额外的索引层次会占用额外的空间。布隆过滤器随着它们的索引对象数据增长而增长，所以行级布隆过滤器比列标识符级布隆过滤器占用空间要少。当空间不是问题时，它们可以帮助你榨干系统的性能潜力。 Doris的BloomFilter索引可以通过建表的时候指定，或者通过表的ALTER操作来完成。Bloom Filter本质上是一种位图结构，用于快速的判断一个给定的值是否在一个集合中。这种判断会产生小概率的误判。即如果返回false，则一定不在这个集合内。而如果范围true，则有可能在这个集合内。\n\nBloomFilter索引也是以Block为粒度创建的。每个Block中，指定列的值作为一个集合生成一个BloomFilter索引条目，用于在查询是快速过滤不满足条件的数据。\n\n下面我们通过实例来看看Doris怎么创建BloomFilter索引。\n\n## 创建BloomFilter索引\n\nDoris BloomFilter索引的创建是通过在建表语句的PROPERTIES里加上\"bloom_filter_columns\"=\"k1,k2,k3\",这个属性，k1,k2,k3是你要创建的BloomFilter索引的Key列名称，例如下面我们对表里的saler_id,category_id创建了BloomFilter索引。\n\n```sql\nCREATE TABLE IF NOT EXISTS sale_detail_bloom  (\n    sale_date date NOT NULL COMMENT \"销售时间\",\n    customer_id int NOT NULL COMMENT \"客户编号\",\n    saler_id int NOT NULL COMMENT \"销售员\",\n    sku_id int NOT NULL COMMENT \"商品编号\",\n    category_id int NOT NULL COMMENT \"商品分类\",\n    sale_count int NOT NULL COMMENT \"销售数量\",\n    sale_price DECIMAL(12,2) NOT NULL COMMENT \"单价\",\n    sale_amt DECIMAL(20,2)  COMMENT \"销售总金额\"\n)\nDuplicate  KEY(sale_date, customer_id,saler_id,sku_id,category_id)\nPARTITION BY RANGE(sale_date)\n(\nPARTITION P_202111 VALUES [('2021-11-01'), ('2021-12-01'))\n)\nDISTRIBUTED BY HASH(saler_id) BUCKETS 10\nPROPERTIES (\n\"replication_num\" = \"3\",\n\"bloom_filter_columns\"=\"saler_id,category_id\",\n\"dynamic_partition.enable\" = \"true\",\n\"dynamic_partition.time_unit\" = \"MONTH\",\n\"dynamic_partition.time_zone\" = \"Asia/Shanghai\",\n\"dynamic_partition.start\" = \"-2147483648\",\n\"dynamic_partition.end\" = \"2\",\n\"dynamic_partition.prefix\" = \"P_\",\n\"dynamic_partition.replication_num\" = \"3\",\n\"dynamic_partition.buckets\" = \"3\"\n);\n```\n\n\n\n## 查看BloomFilter索引\n\n查看我们在表上建立的BloomFilter索引是使用:\n\n```sql\nSHOW CREATE TABLE <table_name>\n```\n\n## 删除BloomFilter索引\n\n删除索引即为将索引列从bloom_filter_columns属性中移除：\n\n```sql\nALTER TABLE <db.table_name> SET (\"bloom_filter_columns\" = \"\");\n```\n\n## 修改BloomFilter索引\n\n修改索引即为修改表的bloom_filter_columns属性：\n\n```sql\nALTER TABLE <db.table_name> SET (\"bloom_filter_columns\" = \"k1,k3\");\n```\n\n## **Doris BloomFilter使用场景**\n\n满足以下几个条件时可以考虑对某列建立Bloom Filter 索引：\n\n1. 首先BloomFilter适用于非前缀过滤.\n2. 查询会根据该列高频过滤，而且查询条件大多是in和 = 过滤.\n3. 不同于Bitmap, BloomFilter适用于高基数列。比如UserID。因为如果创建在低基数的列上，比如”性别“列，则每个Block几乎都会包含所有取值，导致BloomFilter索引失去意义\n\n## **Doris BloomFilter使用注意事项**\n\n1. 不支持对Tinyint、Float、Double 类型的列建Bloom Filter索引。\n2. Bloom Filter索引只对in和 = 过滤查询有加速效果。\n3. 如果要查看某个查询是否命中了Bloom Filter索引，可以通过查询的Profile信息查看\n\n\n\n# Bitmap 索引\n\n","slug":"bigdata/Doris中的索引","published":1,"comments":1,"layout":"post","photos":[],"link":"","_id":"cl9y38ds8000vfwui8tf4g64t","content":"<blockquote>\n<p><strong>不同于传统的数据库设计，Doris 不支持在任意列上创建索引。</strong>Doris 这类 MPP 架构的 OLAP 数据库，通常都是通过提高并发，来处理大量数据的。</p>\n<p>Doris 支持比较丰富的索引结构，来减少数据的扫描：</p>\n<ul>\n<li>Sorted Compound Key Index，可以最多指定三个列组成复合排序键，通过该索引，能够有效进行数据裁剪，从而能够更好支持高并发的报表场景</li>\n<li>Z-order Index ：使用 Z-order 索引，可以高效对数据模型中的任意字段组合进行范围查询</li>\n<li>Min&#x2F;Max ：有效过滤数值类型的等值和范围查询</li>\n<li>Bloom Filter ：对高基数列的等值过滤裁剪非常有效</li>\n<li>Invert Index ：能够对任意字段实现快速检索</li>\n</ul>\n</blockquote>\n<h1 id=\"前缀索引\"><a href=\"#前缀索引\" class=\"headerlink\" title=\"前缀索引\"></a>前缀索引</h1><h2 id=\"基本概念\"><a href=\"#基本概念\" class=\"headerlink\" title=\"基本概念\"></a>基本概念</h2><p>不同于传统的数据库设计，Doris 不支持在任意列上创建索引。Doris 这类 MPP 架构的 OLAP 数据库，通常都是通过提高并发，来处理大量数据的。</p>\n<p>本质上，Doris 的数据存储在类似 SSTable（Sorted String Table）的数据结构中。该结构是一种有序的数据结构，可以按照指定的列进行排序存储。在这种数据结构上，以排序列作为条件进行查找，会非常的高效。</p>\n<p>在 Aggregate、Unique 和 Duplicate 三种数据模型中。底层的数据存储，是按照各自建表语句中，AGGREGATE KEY、UNIQUE KEY 和 DUPLICATE KEY 中指定的列进行排序存储的。</p>\n<p>而前缀索引，即在排序的基础上，实现的一种根据给定前缀列，快速查询数据的索引方式。</p>\n<h2 id=\"示例\"><a href=\"#示例\" class=\"headerlink\" title=\"示例\"></a>示例</h2><p>我们将一行数据的前 <strong>36 个字节</strong> 作为这行数据的前缀索引。当遇到 VARCHAR 类型时，前缀索引会直接截断。我们举例说明：</p>\n<ol>\n<li><p>以下表结构的前缀索引为 user_id(8 Bytes) + age(4 Bytes) + message(prefix 20 Bytes)。</p>\n<table>\n<thead>\n<tr>\n<th>ColumnName</th>\n<th>Type</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>user_id</td>\n<td>BIGINT</td>\n</tr>\n<tr>\n<td>age</td>\n<td>INT</td>\n</tr>\n<tr>\n<td>message</td>\n<td>VARCHAR(100)</td>\n</tr>\n<tr>\n<td>max_dwell_time</td>\n<td>DATETIME</td>\n</tr>\n<tr>\n<td>min_dwell_time</td>\n<td>DATETIME</td>\n</tr>\n</tbody></table>\n</li>\n<li><p>以下表结构的前缀索引为 user_name(20 Bytes)。即使没有达到 36 个字节，因为遇到 VARCHAR，所以直接截断，不再往后继续。</p>\n<table>\n<thead>\n<tr>\n<th>ColumnName</th>\n<th>Type</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>user_name</td>\n<td>VARCHAR(20)</td>\n</tr>\n<tr>\n<td>age</td>\n<td>INT</td>\n</tr>\n<tr>\n<td>message</td>\n<td>VARCHAR(100)</td>\n</tr>\n<tr>\n<td>max_dwell_time</td>\n<td>DATETIME</td>\n</tr>\n<tr>\n<td>min_dwell_time</td>\n<td>DATETIME</td>\n</tr>\n</tbody></table>\n</li>\n</ol>\n<p>当我们的查询条件，是<strong>前缀索引的前缀</strong>时，可以极大的加快查询速度。比如在第一个例子中，我们执行如下查询：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">SELECT</span> <span class=\"operator\">*</span> <span class=\"keyword\">FROM</span> <span class=\"keyword\">table</span> <span class=\"keyword\">WHERE</span> user_id<span class=\"operator\">=</span><span class=\"number\">1829239</span> <span class=\"keyword\">and</span> age<span class=\"operator\">=</span><span class=\"number\">20</span>；</span><br></pre></td></tr></table></figure>\n\n<p>该查询的效率会<strong>远高于</strong>如下查询：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">SELECT</span> <span class=\"operator\">*</span> <span class=\"keyword\">FROM</span> <span class=\"keyword\">table</span> <span class=\"keyword\">WHERE</span> age<span class=\"operator\">=</span><span class=\"number\">20</span>；</span><br></pre></td></tr></table></figure>\n\n<p>所以在建表时，<strong>正确的选择列顺序，能够极大地提高查询效率</strong>。</p>\n<h2 id=\"通过ROLLUP来调整前缀索引\"><a href=\"#通过ROLLUP来调整前缀索引\" class=\"headerlink\" title=\"通过ROLLUP来调整前缀索引\"></a>通过ROLLUP来调整前缀索引</h2><p>因为建表时已经指定了列顺序，所以一个表只有一种前缀索引。这对于使用其他不能命中前缀索引的列作为条件进行的查询来说，效率上可能无法满足需求。因此，我们可以通过创建 ROLLUP 来人为的调整列顺序。详情可参考<a href=\"https://doris.apache.org/zh-CN/docs/data-table/hit-the-rollup\">ROLLUP</a>。</p>\n<h1 id=\"BloomFilter索引\"><a href=\"#BloomFilter索引\" class=\"headerlink\" title=\"BloomFilter索引\"></a>BloomFilter索引</h1><h2 id=\"Doris-BloomFilter索引及使用使用场景\"><a href=\"#Doris-BloomFilter索引及使用使用场景\" class=\"headerlink\" title=\"Doris BloomFilter索引及使用使用场景\"></a>Doris BloomFilter索引及使用使用场景</h2><p>举个例子：如果要查找一个占用100字节存储空间大小的短行，一个64KB的HFile数据块应该包含(64 * 1024)&#x2F;100 &#x3D; 655.53 &#x3D; ~700行，如果仅能在整个数据块的起始行键上建立索引，那么它是无法给你提供细粒度的索引信息的。因为要查找的行数据可能会落在该数据块的行区间上，也可能行数据没在该数据块上，也可能是表中根本就不存在该行数据，也或者是行数据在另一个HFile里，甚至在MemStore里。以上这几种情况，都会导致从磁盘读取数据块时带来额外的IO开销，也会滥用数据块的缓存，当面对一个巨大的数据集且处于高并发读时，会严重影响性能。</p>\n<p>因此，HBase提供了布隆过滤器，它允许你对存储在每个数据块的数据做一个反向测试。当某行被请求时，通过布隆过滤器先检查该行是否不在这个数据块，布隆过滤器要么确定回答该行不在，要么回答它不知道。这就是为什么我们称它是反向测试。布隆过滤器同样也可以应用到行里的单元上，当访问某列标识符时可以先使用同样的反向测试。</p>\n<p>但布隆过滤器也不是没有代价。存储这个额外的索引层次会占用额外的空间。布隆过滤器随着它们的索引对象数据增长而增长，所以行级布隆过滤器比列标识符级布隆过滤器占用空间要少。当空间不是问题时，它们可以帮助你榨干系统的性能潜力。 Doris的BloomFilter索引可以通过建表的时候指定，或者通过表的ALTER操作来完成。Bloom Filter本质上是一种位图结构，用于快速的判断一个给定的值是否在一个集合中。这种判断会产生小概率的误判。即如果返回false，则一定不在这个集合内。而如果范围true，则有可能在这个集合内。</p>\n<p>BloomFilter索引也是以Block为粒度创建的。每个Block中，指定列的值作为一个集合生成一个BloomFilter索引条目，用于在查询是快速过滤不满足条件的数据。</p>\n<p>下面我们通过实例来看看Doris怎么创建BloomFilter索引。</p>\n<h2 id=\"创建BloomFilter索引\"><a href=\"#创建BloomFilter索引\" class=\"headerlink\" title=\"创建BloomFilter索引\"></a>创建BloomFilter索引</h2><p>Doris BloomFilter索引的创建是通过在建表语句的PROPERTIES里加上”bloom_filter_columns”&#x3D;”k1,k2,k3”,这个属性，k1,k2,k3是你要创建的BloomFilter索引的Key列名称，例如下面我们对表里的saler_id,category_id创建了BloomFilter索引。</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">CREATE</span> <span class=\"keyword\">TABLE</span> IF <span class=\"keyword\">NOT</span> <span class=\"keyword\">EXISTS</span> sale_detail_bloom  (</span><br><span class=\"line\">    sale_date <span class=\"type\">date</span> <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span> COMMENT &quot;销售时间&quot;,</span><br><span class=\"line\">    customer_id <span class=\"type\">int</span> <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span> COMMENT &quot;客户编号&quot;,</span><br><span class=\"line\">    saler_id <span class=\"type\">int</span> <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span> COMMENT &quot;销售员&quot;,</span><br><span class=\"line\">    sku_id <span class=\"type\">int</span> <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span> COMMENT &quot;商品编号&quot;,</span><br><span class=\"line\">    category_id <span class=\"type\">int</span> <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span> COMMENT &quot;商品分类&quot;,</span><br><span class=\"line\">    sale_count <span class=\"type\">int</span> <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span> COMMENT &quot;销售数量&quot;,</span><br><span class=\"line\">    sale_price <span class=\"type\">DECIMAL</span>(<span class=\"number\">12</span>,<span class=\"number\">2</span>) <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span> COMMENT &quot;单价&quot;,</span><br><span class=\"line\">    sale_amt <span class=\"type\">DECIMAL</span>(<span class=\"number\">20</span>,<span class=\"number\">2</span>)  COMMENT &quot;销售总金额&quot;</span><br><span class=\"line\">)</span><br><span class=\"line\">Duplicate  KEY(sale_date, customer_id,saler_id,sku_id,category_id)</span><br><span class=\"line\"><span class=\"keyword\">PARTITION</span> <span class=\"keyword\">BY</span> <span class=\"keyword\">RANGE</span>(sale_date)</span><br><span class=\"line\">(</span><br><span class=\"line\"><span class=\"keyword\">PARTITION</span> P_202111 <span class=\"keyword\">VALUES</span> [(<span class=\"string\">&#x27;2021-11-01&#x27;</span>), (<span class=\"string\">&#x27;2021-12-01&#x27;</span>))</span><br><span class=\"line\">)</span><br><span class=\"line\">DISTRIBUTED <span class=\"keyword\">BY</span> HASH(saler_id) BUCKETS <span class=\"number\">10</span></span><br><span class=\"line\">PROPERTIES (</span><br><span class=\"line\">&quot;replication_num&quot; <span class=\"operator\">=</span> &quot;3&quot;,</span><br><span class=\"line\">&quot;bloom_filter_columns&quot;<span class=\"operator\">=</span>&quot;saler_id,category_id&quot;,</span><br><span class=\"line\">&quot;dynamic_partition.enable&quot; <span class=\"operator\">=</span> &quot;true&quot;,</span><br><span class=\"line\">&quot;dynamic_partition.time_unit&quot; <span class=\"operator\">=</span> &quot;MONTH&quot;,</span><br><span class=\"line\">&quot;dynamic_partition.time_zone&quot; <span class=\"operator\">=</span> &quot;Asia/Shanghai&quot;,</span><br><span class=\"line\">&quot;dynamic_partition.start&quot; <span class=\"operator\">=</span> &quot;-2147483648&quot;,</span><br><span class=\"line\">&quot;dynamic_partition.end&quot; <span class=\"operator\">=</span> &quot;2&quot;,</span><br><span class=\"line\">&quot;dynamic_partition.prefix&quot; <span class=\"operator\">=</span> &quot;P_&quot;,</span><br><span class=\"line\">&quot;dynamic_partition.replication_num&quot; <span class=\"operator\">=</span> &quot;3&quot;,</span><br><span class=\"line\">&quot;dynamic_partition.buckets&quot; <span class=\"operator\">=</span> &quot;3&quot;</span><br><span class=\"line\">);</span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"查看BloomFilter索引\"><a href=\"#查看BloomFilter索引\" class=\"headerlink\" title=\"查看BloomFilter索引\"></a>查看BloomFilter索引</h2><p>查看我们在表上建立的BloomFilter索引是使用:</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">SHOW</span> <span class=\"keyword\">CREATE</span> <span class=\"keyword\">TABLE</span> <span class=\"operator\">&lt;</span>table_name<span class=\"operator\">&gt;</span></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"删除BloomFilter索引\"><a href=\"#删除BloomFilter索引\" class=\"headerlink\" title=\"删除BloomFilter索引\"></a>删除BloomFilter索引</h2><p>删除索引即为将索引列从bloom_filter_columns属性中移除：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">ALTER</span> <span class=\"keyword\">TABLE</span> <span class=\"operator\">&lt;</span>db.table_name<span class=\"operator\">&gt;</span> <span class=\"keyword\">SET</span> (&quot;bloom_filter_columns&quot; <span class=\"operator\">=</span> &quot;&quot;);</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"修改BloomFilter索引\"><a href=\"#修改BloomFilter索引\" class=\"headerlink\" title=\"修改BloomFilter索引\"></a>修改BloomFilter索引</h2><p>修改索引即为修改表的bloom_filter_columns属性：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">ALTER</span> <span class=\"keyword\">TABLE</span> <span class=\"operator\">&lt;</span>db.table_name<span class=\"operator\">&gt;</span> <span class=\"keyword\">SET</span> (&quot;bloom_filter_columns&quot; <span class=\"operator\">=</span> &quot;k1,k3&quot;);</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Doris-BloomFilter使用场景\"><a href=\"#Doris-BloomFilter使用场景\" class=\"headerlink\" title=\"Doris BloomFilter使用场景\"></a><strong>Doris BloomFilter使用场景</strong></h2><p>满足以下几个条件时可以考虑对某列建立Bloom Filter 索引：</p>\n<ol>\n<li>首先BloomFilter适用于非前缀过滤.</li>\n<li>查询会根据该列高频过滤，而且查询条件大多是in和 &#x3D; 过滤.</li>\n<li>不同于Bitmap, BloomFilter适用于高基数列。比如UserID。因为如果创建在低基数的列上，比如”性别“列，则每个Block几乎都会包含所有取值，导致BloomFilter索引失去意义</li>\n</ol>\n<h2 id=\"Doris-BloomFilter使用注意事项\"><a href=\"#Doris-BloomFilter使用注意事项\" class=\"headerlink\" title=\"Doris BloomFilter使用注意事项\"></a><strong>Doris BloomFilter使用注意事项</strong></h2><ol>\n<li>不支持对Tinyint、Float、Double 类型的列建Bloom Filter索引。</li>\n<li>Bloom Filter索引只对in和 &#x3D; 过滤查询有加速效果。</li>\n<li>如果要查看某个查询是否命中了Bloom Filter索引，可以通过查询的Profile信息查看</li>\n</ol>\n<h1 id=\"Bitmap-索引\"><a href=\"#Bitmap-索引\" class=\"headerlink\" title=\"Bitmap 索引\"></a>Bitmap 索引</h1>","site":{"data":{"link":[{"class_name":"友情链接","class_desc":"那些人，那些事","link_list":[{"name":"张洪Heo","link":"https://blog.zhheo.com/","avatar":"https://npm.elemecdn.com/guli-heo/img/avatar2.png","descr":"分享设计与科技生活"},{"name":"瞬間の筆記","link":"https://hikki.site","descr":"喜欢的东西就努力去追求，万一成功了呢!","avatar":"https://cdn.jsdelivr.net/gh/0000rookie/imgs/202206120315.png"}]}]}},"excerpt":"","more":"<blockquote>\n<p><strong>不同于传统的数据库设计，Doris 不支持在任意列上创建索引。</strong>Doris 这类 MPP 架构的 OLAP 数据库，通常都是通过提高并发，来处理大量数据的。</p>\n<p>Doris 支持比较丰富的索引结构，来减少数据的扫描：</p>\n<ul>\n<li>Sorted Compound Key Index，可以最多指定三个列组成复合排序键，通过该索引，能够有效进行数据裁剪，从而能够更好支持高并发的报表场景</li>\n<li>Z-order Index ：使用 Z-order 索引，可以高效对数据模型中的任意字段组合进行范围查询</li>\n<li>Min&#x2F;Max ：有效过滤数值类型的等值和范围查询</li>\n<li>Bloom Filter ：对高基数列的等值过滤裁剪非常有效</li>\n<li>Invert Index ：能够对任意字段实现快速检索</li>\n</ul>\n</blockquote>\n<h1 id=\"前缀索引\"><a href=\"#前缀索引\" class=\"headerlink\" title=\"前缀索引\"></a>前缀索引</h1><h2 id=\"基本概念\"><a href=\"#基本概念\" class=\"headerlink\" title=\"基本概念\"></a>基本概念</h2><p>不同于传统的数据库设计，Doris 不支持在任意列上创建索引。Doris 这类 MPP 架构的 OLAP 数据库，通常都是通过提高并发，来处理大量数据的。</p>\n<p>本质上，Doris 的数据存储在类似 SSTable（Sorted String Table）的数据结构中。该结构是一种有序的数据结构，可以按照指定的列进行排序存储。在这种数据结构上，以排序列作为条件进行查找，会非常的高效。</p>\n<p>在 Aggregate、Unique 和 Duplicate 三种数据模型中。底层的数据存储，是按照各自建表语句中，AGGREGATE KEY、UNIQUE KEY 和 DUPLICATE KEY 中指定的列进行排序存储的。</p>\n<p>而前缀索引，即在排序的基础上，实现的一种根据给定前缀列，快速查询数据的索引方式。</p>\n<h2 id=\"示例\"><a href=\"#示例\" class=\"headerlink\" title=\"示例\"></a>示例</h2><p>我们将一行数据的前 <strong>36 个字节</strong> 作为这行数据的前缀索引。当遇到 VARCHAR 类型时，前缀索引会直接截断。我们举例说明：</p>\n<ol>\n<li><p>以下表结构的前缀索引为 user_id(8 Bytes) + age(4 Bytes) + message(prefix 20 Bytes)。</p>\n<table>\n<thead>\n<tr>\n<th>ColumnName</th>\n<th>Type</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>user_id</td>\n<td>BIGINT</td>\n</tr>\n<tr>\n<td>age</td>\n<td>INT</td>\n</tr>\n<tr>\n<td>message</td>\n<td>VARCHAR(100)</td>\n</tr>\n<tr>\n<td>max_dwell_time</td>\n<td>DATETIME</td>\n</tr>\n<tr>\n<td>min_dwell_time</td>\n<td>DATETIME</td>\n</tr>\n</tbody></table>\n</li>\n<li><p>以下表结构的前缀索引为 user_name(20 Bytes)。即使没有达到 36 个字节，因为遇到 VARCHAR，所以直接截断，不再往后继续。</p>\n<table>\n<thead>\n<tr>\n<th>ColumnName</th>\n<th>Type</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>user_name</td>\n<td>VARCHAR(20)</td>\n</tr>\n<tr>\n<td>age</td>\n<td>INT</td>\n</tr>\n<tr>\n<td>message</td>\n<td>VARCHAR(100)</td>\n</tr>\n<tr>\n<td>max_dwell_time</td>\n<td>DATETIME</td>\n</tr>\n<tr>\n<td>min_dwell_time</td>\n<td>DATETIME</td>\n</tr>\n</tbody></table>\n</li>\n</ol>\n<p>当我们的查询条件，是<strong>前缀索引的前缀</strong>时，可以极大的加快查询速度。比如在第一个例子中，我们执行如下查询：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">SELECT</span> <span class=\"operator\">*</span> <span class=\"keyword\">FROM</span> <span class=\"keyword\">table</span> <span class=\"keyword\">WHERE</span> user_id<span class=\"operator\">=</span><span class=\"number\">1829239</span> <span class=\"keyword\">and</span> age<span class=\"operator\">=</span><span class=\"number\">20</span>；</span><br></pre></td></tr></table></figure>\n\n<p>该查询的效率会<strong>远高于</strong>如下查询：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">SELECT</span> <span class=\"operator\">*</span> <span class=\"keyword\">FROM</span> <span class=\"keyword\">table</span> <span class=\"keyword\">WHERE</span> age<span class=\"operator\">=</span><span class=\"number\">20</span>；</span><br></pre></td></tr></table></figure>\n\n<p>所以在建表时，<strong>正确的选择列顺序，能够极大地提高查询效率</strong>。</p>\n<h2 id=\"通过ROLLUP来调整前缀索引\"><a href=\"#通过ROLLUP来调整前缀索引\" class=\"headerlink\" title=\"通过ROLLUP来调整前缀索引\"></a>通过ROLLUP来调整前缀索引</h2><p>因为建表时已经指定了列顺序，所以一个表只有一种前缀索引。这对于使用其他不能命中前缀索引的列作为条件进行的查询来说，效率上可能无法满足需求。因此，我们可以通过创建 ROLLUP 来人为的调整列顺序。详情可参考<a href=\"https://doris.apache.org/zh-CN/docs/data-table/hit-the-rollup\">ROLLUP</a>。</p>\n<h1 id=\"BloomFilter索引\"><a href=\"#BloomFilter索引\" class=\"headerlink\" title=\"BloomFilter索引\"></a>BloomFilter索引</h1><h2 id=\"Doris-BloomFilter索引及使用使用场景\"><a href=\"#Doris-BloomFilter索引及使用使用场景\" class=\"headerlink\" title=\"Doris BloomFilter索引及使用使用场景\"></a>Doris BloomFilter索引及使用使用场景</h2><p>举个例子：如果要查找一个占用100字节存储空间大小的短行，一个64KB的HFile数据块应该包含(64 * 1024)&#x2F;100 &#x3D; 655.53 &#x3D; ~700行，如果仅能在整个数据块的起始行键上建立索引，那么它是无法给你提供细粒度的索引信息的。因为要查找的行数据可能会落在该数据块的行区间上，也可能行数据没在该数据块上，也可能是表中根本就不存在该行数据，也或者是行数据在另一个HFile里，甚至在MemStore里。以上这几种情况，都会导致从磁盘读取数据块时带来额外的IO开销，也会滥用数据块的缓存，当面对一个巨大的数据集且处于高并发读时，会严重影响性能。</p>\n<p>因此，HBase提供了布隆过滤器，它允许你对存储在每个数据块的数据做一个反向测试。当某行被请求时，通过布隆过滤器先检查该行是否不在这个数据块，布隆过滤器要么确定回答该行不在，要么回答它不知道。这就是为什么我们称它是反向测试。布隆过滤器同样也可以应用到行里的单元上，当访问某列标识符时可以先使用同样的反向测试。</p>\n<p>但布隆过滤器也不是没有代价。存储这个额外的索引层次会占用额外的空间。布隆过滤器随着它们的索引对象数据增长而增长，所以行级布隆过滤器比列标识符级布隆过滤器占用空间要少。当空间不是问题时，它们可以帮助你榨干系统的性能潜力。 Doris的BloomFilter索引可以通过建表的时候指定，或者通过表的ALTER操作来完成。Bloom Filter本质上是一种位图结构，用于快速的判断一个给定的值是否在一个集合中。这种判断会产生小概率的误判。即如果返回false，则一定不在这个集合内。而如果范围true，则有可能在这个集合内。</p>\n<p>BloomFilter索引也是以Block为粒度创建的。每个Block中，指定列的值作为一个集合生成一个BloomFilter索引条目，用于在查询是快速过滤不满足条件的数据。</p>\n<p>下面我们通过实例来看看Doris怎么创建BloomFilter索引。</p>\n<h2 id=\"创建BloomFilter索引\"><a href=\"#创建BloomFilter索引\" class=\"headerlink\" title=\"创建BloomFilter索引\"></a>创建BloomFilter索引</h2><p>Doris BloomFilter索引的创建是通过在建表语句的PROPERTIES里加上”bloom_filter_columns”&#x3D;”k1,k2,k3”,这个属性，k1,k2,k3是你要创建的BloomFilter索引的Key列名称，例如下面我们对表里的saler_id,category_id创建了BloomFilter索引。</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">CREATE</span> <span class=\"keyword\">TABLE</span> IF <span class=\"keyword\">NOT</span> <span class=\"keyword\">EXISTS</span> sale_detail_bloom  (</span><br><span class=\"line\">    sale_date <span class=\"type\">date</span> <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span> COMMENT &quot;销售时间&quot;,</span><br><span class=\"line\">    customer_id <span class=\"type\">int</span> <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span> COMMENT &quot;客户编号&quot;,</span><br><span class=\"line\">    saler_id <span class=\"type\">int</span> <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span> COMMENT &quot;销售员&quot;,</span><br><span class=\"line\">    sku_id <span class=\"type\">int</span> <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span> COMMENT &quot;商品编号&quot;,</span><br><span class=\"line\">    category_id <span class=\"type\">int</span> <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span> COMMENT &quot;商品分类&quot;,</span><br><span class=\"line\">    sale_count <span class=\"type\">int</span> <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span> COMMENT &quot;销售数量&quot;,</span><br><span class=\"line\">    sale_price <span class=\"type\">DECIMAL</span>(<span class=\"number\">12</span>,<span class=\"number\">2</span>) <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span> COMMENT &quot;单价&quot;,</span><br><span class=\"line\">    sale_amt <span class=\"type\">DECIMAL</span>(<span class=\"number\">20</span>,<span class=\"number\">2</span>)  COMMENT &quot;销售总金额&quot;</span><br><span class=\"line\">)</span><br><span class=\"line\">Duplicate  KEY(sale_date, customer_id,saler_id,sku_id,category_id)</span><br><span class=\"line\"><span class=\"keyword\">PARTITION</span> <span class=\"keyword\">BY</span> <span class=\"keyword\">RANGE</span>(sale_date)</span><br><span class=\"line\">(</span><br><span class=\"line\"><span class=\"keyword\">PARTITION</span> P_202111 <span class=\"keyword\">VALUES</span> [(<span class=\"string\">&#x27;2021-11-01&#x27;</span>), (<span class=\"string\">&#x27;2021-12-01&#x27;</span>))</span><br><span class=\"line\">)</span><br><span class=\"line\">DISTRIBUTED <span class=\"keyword\">BY</span> HASH(saler_id) BUCKETS <span class=\"number\">10</span></span><br><span class=\"line\">PROPERTIES (</span><br><span class=\"line\">&quot;replication_num&quot; <span class=\"operator\">=</span> &quot;3&quot;,</span><br><span class=\"line\">&quot;bloom_filter_columns&quot;<span class=\"operator\">=</span>&quot;saler_id,category_id&quot;,</span><br><span class=\"line\">&quot;dynamic_partition.enable&quot; <span class=\"operator\">=</span> &quot;true&quot;,</span><br><span class=\"line\">&quot;dynamic_partition.time_unit&quot; <span class=\"operator\">=</span> &quot;MONTH&quot;,</span><br><span class=\"line\">&quot;dynamic_partition.time_zone&quot; <span class=\"operator\">=</span> &quot;Asia/Shanghai&quot;,</span><br><span class=\"line\">&quot;dynamic_partition.start&quot; <span class=\"operator\">=</span> &quot;-2147483648&quot;,</span><br><span class=\"line\">&quot;dynamic_partition.end&quot; <span class=\"operator\">=</span> &quot;2&quot;,</span><br><span class=\"line\">&quot;dynamic_partition.prefix&quot; <span class=\"operator\">=</span> &quot;P_&quot;,</span><br><span class=\"line\">&quot;dynamic_partition.replication_num&quot; <span class=\"operator\">=</span> &quot;3&quot;,</span><br><span class=\"line\">&quot;dynamic_partition.buckets&quot; <span class=\"operator\">=</span> &quot;3&quot;</span><br><span class=\"line\">);</span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"查看BloomFilter索引\"><a href=\"#查看BloomFilter索引\" class=\"headerlink\" title=\"查看BloomFilter索引\"></a>查看BloomFilter索引</h2><p>查看我们在表上建立的BloomFilter索引是使用:</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">SHOW</span> <span class=\"keyword\">CREATE</span> <span class=\"keyword\">TABLE</span> <span class=\"operator\">&lt;</span>table_name<span class=\"operator\">&gt;</span></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"删除BloomFilter索引\"><a href=\"#删除BloomFilter索引\" class=\"headerlink\" title=\"删除BloomFilter索引\"></a>删除BloomFilter索引</h2><p>删除索引即为将索引列从bloom_filter_columns属性中移除：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">ALTER</span> <span class=\"keyword\">TABLE</span> <span class=\"operator\">&lt;</span>db.table_name<span class=\"operator\">&gt;</span> <span class=\"keyword\">SET</span> (&quot;bloom_filter_columns&quot; <span class=\"operator\">=</span> &quot;&quot;);</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"修改BloomFilter索引\"><a href=\"#修改BloomFilter索引\" class=\"headerlink\" title=\"修改BloomFilter索引\"></a>修改BloomFilter索引</h2><p>修改索引即为修改表的bloom_filter_columns属性：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">ALTER</span> <span class=\"keyword\">TABLE</span> <span class=\"operator\">&lt;</span>db.table_name<span class=\"operator\">&gt;</span> <span class=\"keyword\">SET</span> (&quot;bloom_filter_columns&quot; <span class=\"operator\">=</span> &quot;k1,k3&quot;);</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Doris-BloomFilter使用场景\"><a href=\"#Doris-BloomFilter使用场景\" class=\"headerlink\" title=\"Doris BloomFilter使用场景\"></a><strong>Doris BloomFilter使用场景</strong></h2><p>满足以下几个条件时可以考虑对某列建立Bloom Filter 索引：</p>\n<ol>\n<li>首先BloomFilter适用于非前缀过滤.</li>\n<li>查询会根据该列高频过滤，而且查询条件大多是in和 &#x3D; 过滤.</li>\n<li>不同于Bitmap, BloomFilter适用于高基数列。比如UserID。因为如果创建在低基数的列上，比如”性别“列，则每个Block几乎都会包含所有取值，导致BloomFilter索引失去意义</li>\n</ol>\n<h2 id=\"Doris-BloomFilter使用注意事项\"><a href=\"#Doris-BloomFilter使用注意事项\" class=\"headerlink\" title=\"Doris BloomFilter使用注意事项\"></a><strong>Doris BloomFilter使用注意事项</strong></h2><ol>\n<li>不支持对Tinyint、Float、Double 类型的列建Bloom Filter索引。</li>\n<li>Bloom Filter索引只对in和 &#x3D; 过滤查询有加速效果。</li>\n<li>如果要查看某个查询是否命中了Bloom Filter索引，可以通过查询的Profile信息查看</li>\n</ol>\n<h1 id=\"Bitmap-索引\"><a href=\"#Bitmap-索引\" class=\"headerlink\" title=\"Bitmap 索引\"></a>Bitmap 索引</h1>"},{"title":"基于Doris的数据中台的实践与优化","date":"2022-09-30T07:42:16.000Z","updated":"2022-09-30T07:42:16.000Z","cover":"https://tva3.sinaimg.cn/large/0084aYsLgy1h22161jezaj30xc0f0dh1.jpg","top_img":null,"description":null,"keywords":null,"_content":"\n## 前言\n\n> 随着数据量不断膨胀，基于Oracle的ETL和BI报表可视化业务越来越慢，难以保证数据服务的SLA，为了减少整个大数据平台的复杂度，决定开始调研-'以 Apache Doris 为核心建设一站式数据中台'。\n>\n> 展望：\n>\n> 1、所有业务数据通过Flink实时导入到Doris\n>\n> 2、ETL全部在Doris中完成 \n>\n> 3、ETL后，基于Doris的ad-hoc能力，可以直接作为ADS层对外提供服务。\n\n## 遇到的问题\n\n- 由于业务非常复杂，ETL过程也非常繁琐，往往涉及数十张表的Join，这非常考验Doris的查询优化器。同时ETL SQL中常常需要开窗排序，非常容易造成内存溢出，导致ETL SQL无法完成。以应对大查询，做了以下参数方面的优化。\n\n  >SET enable_profile = true; \n  >\n  >SET query_timeout = 30000;\n  >\n  >SET enable_spilling = true;\n  >\n  >SET exec_mem_limit = 10 * 1024 * 1024 * 1024;\n  >\n  >SET parallel_fragment_exec_instance_num = 8;\n  >\n  >SET enable_cost_based_join_reorder = true;\n","source":"_posts/bigdata/Doris大查询实践与优化.md","raw":"---\ntitle: 基于Doris的数据中台的实践与优化\ntags:\n  - 'Doris'\n  - '数据中台'\ncategories:\n  - [bigdata,Doris]\ndate: 2022-09-30 15:42:16\nupdated: 2022-09-30 15:42:16\ncover:\ntop_img:\ndescription:\nkeywords:\n---\n\n## 前言\n\n> 随着数据量不断膨胀，基于Oracle的ETL和BI报表可视化业务越来越慢，难以保证数据服务的SLA，为了减少整个大数据平台的复杂度，决定开始调研-'以 Apache Doris 为核心建设一站式数据中台'。\n>\n> 展望：\n>\n> 1、所有业务数据通过Flink实时导入到Doris\n>\n> 2、ETL全部在Doris中完成 \n>\n> 3、ETL后，基于Doris的ad-hoc能力，可以直接作为ADS层对外提供服务。\n\n## 遇到的问题\n\n- 由于业务非常复杂，ETL过程也非常繁琐，往往涉及数十张表的Join，这非常考验Doris的查询优化器。同时ETL SQL中常常需要开窗排序，非常容易造成内存溢出，导致ETL SQL无法完成。以应对大查询，做了以下参数方面的优化。\n\n  >SET enable_profile = true; \n  >\n  >SET query_timeout = 30000;\n  >\n  >SET enable_spilling = true;\n  >\n  >SET exec_mem_limit = 10 * 1024 * 1024 * 1024;\n  >\n  >SET parallel_fragment_exec_instance_num = 8;\n  >\n  >SET enable_cost_based_join_reorder = true;\n","slug":"bigdata/Doris大查询实践与优化","published":1,"comments":1,"layout":"post","photos":[],"link":"","_id":"cl9y38ds9000xfwuicz9h5xkl","content":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><blockquote>\n<p>随着数据量不断膨胀，基于Oracle的ETL和BI报表可视化业务越来越慢，难以保证数据服务的SLA，为了减少整个大数据平台的复杂度，决定开始调研-‘以 Apache Doris 为核心建设一站式数据中台’。</p>\n<p>展望：</p>\n<p>1、所有业务数据通过Flink实时导入到Doris</p>\n<p>2、ETL全部在Doris中完成 </p>\n<p>3、ETL后，基于Doris的ad-hoc能力，可以直接作为ADS层对外提供服务。</p>\n</blockquote>\n<h2 id=\"遇到的问题\"><a href=\"#遇到的问题\" class=\"headerlink\" title=\"遇到的问题\"></a>遇到的问题</h2><ul>\n<li><p>由于业务非常复杂，ETL过程也非常繁琐，往往涉及数十张表的Join，这非常考验Doris的查询优化器。同时ETL SQL中常常需要开窗排序，非常容易造成内存溢出，导致ETL SQL无法完成。以应对大查询，做了以下参数方面的优化。</p>\n<blockquote>\n<p>SET enable_profile &#x3D; true; </p>\n<p>SET query_timeout &#x3D; 30000;</p>\n<p>SET enable_spilling &#x3D; true;</p>\n<p>SET exec_mem_limit &#x3D; 10 * 1024 * 1024 * 1024;</p>\n<p>SET parallel_fragment_exec_instance_num &#x3D; 8;</p>\n<p>SET enable_cost_based_join_reorder &#x3D; true;</p>\n</blockquote>\n</li>\n</ul>\n","site":{"data":{"link":[{"class_name":"友情链接","class_desc":"那些人，那些事","link_list":[{"name":"张洪Heo","link":"https://blog.zhheo.com/","avatar":"https://npm.elemecdn.com/guli-heo/img/avatar2.png","descr":"分享设计与科技生活"},{"name":"瞬間の筆記","link":"https://hikki.site","descr":"喜欢的东西就努力去追求，万一成功了呢!","avatar":"https://cdn.jsdelivr.net/gh/0000rookie/imgs/202206120315.png"}]}]}},"excerpt":"","more":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><blockquote>\n<p>随着数据量不断膨胀，基于Oracle的ETL和BI报表可视化业务越来越慢，难以保证数据服务的SLA，为了减少整个大数据平台的复杂度，决定开始调研-‘以 Apache Doris 为核心建设一站式数据中台’。</p>\n<p>展望：</p>\n<p>1、所有业务数据通过Flink实时导入到Doris</p>\n<p>2、ETL全部在Doris中完成 </p>\n<p>3、ETL后，基于Doris的ad-hoc能力，可以直接作为ADS层对外提供服务。</p>\n</blockquote>\n<h2 id=\"遇到的问题\"><a href=\"#遇到的问题\" class=\"headerlink\" title=\"遇到的问题\"></a>遇到的问题</h2><ul>\n<li><p>由于业务非常复杂，ETL过程也非常繁琐，往往涉及数十张表的Join，这非常考验Doris的查询优化器。同时ETL SQL中常常需要开窗排序，非常容易造成内存溢出，导致ETL SQL无法完成。以应对大查询，做了以下参数方面的优化。</p>\n<blockquote>\n<p>SET enable_profile &#x3D; true; </p>\n<p>SET query_timeout &#x3D; 30000;</p>\n<p>SET enable_spilling &#x3D; true;</p>\n<p>SET exec_mem_limit &#x3D; 10 * 1024 * 1024 * 1024;</p>\n<p>SET parallel_fragment_exec_instance_num &#x3D; 8;</p>\n<p>SET enable_cost_based_join_reorder &#x3D; true;</p>\n</blockquote>\n</li>\n</ul>\n"},{"title":"Flink-SQL-Client与Hive集成问题指南","top_img":null,"date":"2022-09-13T02:51:08.000Z","updated":"2022-09-13T02:52:08.000Z","cover":"https://zfh-tuchuang.oss-cn-shanghai.aliyuncs.com/img/site-backgound.jpg","description":null,"keywords":null,"_content":"\n>只需要下载对应的`flink-sql-connector-hive-3.1.2_2.12-1.14.5.jar`,放在{FLINK_HOME}/lib下面即可。\n>\n>不需要下载什么`flink-shaded-hadoop-3-uber-3.1.1.7.2.9.0-173-9.0.jar`放在{FLINK_HOME}/lib下面,现在Flink通过\n>\n>```shell\n>export HADOOP_CLASSPATH=`hadoop classpath`\n>```\n>\n>来寻找Hadoop相关的Jar包。\n>\n>\n>\n>当Flink on YARN时，还需要在{FLINK_HOME}/lib中添加以下依赖：\n>\n>```shell\n>要么是这个：\n>       flink-shaded-hadoop-2-uber-2.7.5-8.0.jar\n>\n>要么是，可以直接从hadoop/share/hadoop/mapreduce/等目录拷过来：\n>      hadoop-common-3.0.0-cdh6.3.1.jar\n>      hadoop-mapreduce-client-common-3.0.0-cdh6.3.1.jar\n>      hadoop-mapreduce-client-core-3.0.0-cdh6.3.1.jar\n>      hadoop-mapreduce-client-hs-3.0.0-cdh6.3.1.jar\n>      hadoop-mapreduce-client-jobclient-3.0.0-cdh6.3.1.jar\n>```\n>\n>\n\n## ENV\n\n- Flink ：1.14.5\n- Hadoop：3.2.3\n- Hive：3.1.2+\n\n\n\n## Error\n\n- `Caused by: java.lang.NoSuchMethodError: com.google.common.base.Preconditions.checkArgument(ZLjava/lang/String;Ljava/lang/Object;)V`\n\n  解压`flink-sql-connector-hive-3.1.2_2.12-1.14.5.jar`,直接将里面的com/google文件夹删除\n\n- 其他找不到Hadoop相关Jar包的错误，\n\n  一般都是因为\n\n  ```shell\n  export HADOOP_CLASSPATH=`hadoop classpath`\n  ```\n\n​      没有设置成功，不仅sql-client.sh要在此环境下启动，Standalone的Flink也要在此环境下启动。\n\n- 执行\n\n  ```shell\n  echo `hadoop classpath`\n  ```\n\n  后，下面这样才算成功\n\n  ```\n  /opt/module/hadoop-3.2.3/etc/hadoop:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/*:/opt/module/hadoop-3.2.3/share/hadoop/common/*:/opt/module/hadoop-3.2.3/share/hadoop/hdfs:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/*:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/*:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/lib/*:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/*:/opt/module/hadoop-3.2.3/share/hadoop/yarn:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/*:/opt/module/hadoop-3.2.3/share/hadoop/yarn/*:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/accessors-smart-2.4.7.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/asm-5.0.4.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/avro-1.7.7.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/checker-qual-2.5.2.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/commons-codec-1.11.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/commons-compress-1.21.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/commons-io-2.8.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/commons-lang3-3.7.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/commons-net-3.6.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/commons-text-1.4.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/curator-client-2.13.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/curator-framework-2.13.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/dnsjava-2.1.7.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/error_prone_annotations-2.2.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/failureaccess-1.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/gson-2.2.4.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/guava-27.0-jre.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/hadoop-annotations-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/hadoop-auth-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/httpclient-4.5.13.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/httpcore-4.4.13.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jackson-annotations-2.10.5.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jackson-core-2.10.5.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jackson-databind-2.10.5.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/javax.activation-api-1.2.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jersey-core-1.19.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jersey-json-1.19.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jersey-server-1.19.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jersey-servlet-1.19.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jettison-1.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jetty-http-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jetty-io-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jetty-security-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jetty-server-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jetty-servlet-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jetty-util-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jetty-util-ajax-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jetty-webapp-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jetty-xml-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jsch-0.1.55.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/json-smart-2.4.7.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jsr305-3.0.2.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerb-client-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerb-common-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerb-core-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerb-server-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerb-util-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerby-config-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerby-util-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/metrics-core-3.2.4.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/netty-3.10.6.Final.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/paranamer-2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/re2j-1.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/snappy-java-1.0.5.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/spotbugs-annotations-3.1.9.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/stax2-api-4.2.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/token-provider-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/zookeeper-3.4.14.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/hadoop-common-3.2.3-tests.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/hadoop-common-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/hadoop-kms-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/hadoop-nfs-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/jdiff:/opt/module/hadoop-3.2.3/share/hadoop/common/lib:/opt/module/hadoop-3.2.3/share/hadoop/common/sources:/opt/module/hadoop-3.2.3/share/hadoop/common/webapps:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/accessors-smart-2.4.7.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/asm-5.0.4.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/avro-1.7.7.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/commons-net-3.6.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/commons-text-1.4.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/error_prone_annotations-2.2.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/gson-2.2.4.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/hadoop-annotations-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/hadoop-auth-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jackson-annotations-2.10.5.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jackson-core-2.10.5.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jackson-databind-2.10.5.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/javax.activation-api-1.2.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jettison-1.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jetty-http-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jetty-io-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jetty-security-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jetty-server-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jetty-servlet-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jetty-util-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jetty-webapp-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jetty-xml-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/json-smart-2.4.7.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/netty-all-4.1.68.Final.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/okio-1.6.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/paranamer-2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/re2j-1.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/spotbugs-annotations-3.1.9.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/woodstox-core-5.3.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/zookeeper-3.4.14.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/hadoop-hdfs-3.2.3-tests.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/hadoop-hdfs-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/hadoop-hdfs-client-3.2.3-tests.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/hadoop-hdfs-client-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.3-tests.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.3-tests.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/jdiff:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/sources:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/webapps:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/lib/junit-4.13.2.jar:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.3-tests.jar:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/jdiff:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/lib:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/lib-examples:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/sources:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/fst-2.50.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/guice-4.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/jackson-jaxrs-base-2.10.5.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.10.5.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.10.5.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/jakarta.activation-api-1.2.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/jersey-client-1.19.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/objenesis-1.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/snakeyaml-1.26.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-api-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-client-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-common-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-registry-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-server-common-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-server-router-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-services-api-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-services-core-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-submarine-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib:/opt/module/hadoop-3.2.3/share/hadoop/yarn/sources:/opt/module/hadoop-3.2.3/share/hadoop/yarn/test:/opt/module/hadoop-3.2.3/share/hadoop/yarn/timelineservice:/opt/module/hadoop-3.2.3/share/hadoop/yarn/webapps:/opt/module/hadoop-3.2.3/share/hadoop/yarn/yarn-service-examples\n  ```\n\n  \n\n  而这样不算成功：\n\n  ```\n  /opt/module/hadoop-3.2.3/etc/hadoop:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/*:/opt/module/hadoop-3.2.3/share/hadoop/common/*:/opt/module/hadoop-3.2.3/share/hadoop/hdfs:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/*:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/*:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/lib/*:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/*:/opt/module/hadoop-3.2.3/share/hadoop/yarn:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/*:/opt/module/hadoop-3.2.3/share/hadoop/yarn/*\n  ```\n\n  \n\n- quit;退出sql-client时报错：\n\n  ```\n  Exception in thread \"Thread-4\" java.lang.IllegalStateException: Trying to access closed classloader. Please check if you store classloaders directly or indirectly in static fields. If the stacktrace suggests that the leak occurs in a third party library and cannot be fixed immediately, you can disable this check with the configuration 'classloader.check-leaked-classloader'.\n  ```\n\n  可以在在 flink 配置文件里 flink-conf.yaml设置`classloader.check-leaked-classloader: false`\n","source":"_posts/bigdata/Flink-SQL-Client与Hive集成问题指南.md","raw":"---\ntitle: Flink-SQL-Client与Hive集成问题指南\ntags:\n  - 'Flink'\ncategories:\n  - [bigdata,Flink]\ntop_img: \ndate: 2022-09-13 10:51:08\nupdated: 2022-09-13 10:52:08\ncover:\ndescription:\nkeywords:\n---\n\n>只需要下载对应的`flink-sql-connector-hive-3.1.2_2.12-1.14.5.jar`,放在{FLINK_HOME}/lib下面即可。\n>\n>不需要下载什么`flink-shaded-hadoop-3-uber-3.1.1.7.2.9.0-173-9.0.jar`放在{FLINK_HOME}/lib下面,现在Flink通过\n>\n>```shell\n>export HADOOP_CLASSPATH=`hadoop classpath`\n>```\n>\n>来寻找Hadoop相关的Jar包。\n>\n>\n>\n>当Flink on YARN时，还需要在{FLINK_HOME}/lib中添加以下依赖：\n>\n>```shell\n>要么是这个：\n>       flink-shaded-hadoop-2-uber-2.7.5-8.0.jar\n>\n>要么是，可以直接从hadoop/share/hadoop/mapreduce/等目录拷过来：\n>      hadoop-common-3.0.0-cdh6.3.1.jar\n>      hadoop-mapreduce-client-common-3.0.0-cdh6.3.1.jar\n>      hadoop-mapreduce-client-core-3.0.0-cdh6.3.1.jar\n>      hadoop-mapreduce-client-hs-3.0.0-cdh6.3.1.jar\n>      hadoop-mapreduce-client-jobclient-3.0.0-cdh6.3.1.jar\n>```\n>\n>\n\n## ENV\n\n- Flink ：1.14.5\n- Hadoop：3.2.3\n- Hive：3.1.2+\n\n\n\n## Error\n\n- `Caused by: java.lang.NoSuchMethodError: com.google.common.base.Preconditions.checkArgument(ZLjava/lang/String;Ljava/lang/Object;)V`\n\n  解压`flink-sql-connector-hive-3.1.2_2.12-1.14.5.jar`,直接将里面的com/google文件夹删除\n\n- 其他找不到Hadoop相关Jar包的错误，\n\n  一般都是因为\n\n  ```shell\n  export HADOOP_CLASSPATH=`hadoop classpath`\n  ```\n\n​      没有设置成功，不仅sql-client.sh要在此环境下启动，Standalone的Flink也要在此环境下启动。\n\n- 执行\n\n  ```shell\n  echo `hadoop classpath`\n  ```\n\n  后，下面这样才算成功\n\n  ```\n  /opt/module/hadoop-3.2.3/etc/hadoop:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/*:/opt/module/hadoop-3.2.3/share/hadoop/common/*:/opt/module/hadoop-3.2.3/share/hadoop/hdfs:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/*:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/*:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/lib/*:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/*:/opt/module/hadoop-3.2.3/share/hadoop/yarn:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/*:/opt/module/hadoop-3.2.3/share/hadoop/yarn/*:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/accessors-smart-2.4.7.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/asm-5.0.4.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/avro-1.7.7.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/checker-qual-2.5.2.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/commons-codec-1.11.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/commons-compress-1.21.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/commons-io-2.8.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/commons-lang3-3.7.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/commons-net-3.6.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/commons-text-1.4.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/curator-client-2.13.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/curator-framework-2.13.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/dnsjava-2.1.7.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/error_prone_annotations-2.2.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/failureaccess-1.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/gson-2.2.4.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/guava-27.0-jre.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/hadoop-annotations-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/hadoop-auth-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/httpclient-4.5.13.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/httpcore-4.4.13.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jackson-annotations-2.10.5.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jackson-core-2.10.5.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jackson-databind-2.10.5.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/javax.activation-api-1.2.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jersey-core-1.19.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jersey-json-1.19.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jersey-server-1.19.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jersey-servlet-1.19.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jettison-1.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jetty-http-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jetty-io-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jetty-security-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jetty-server-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jetty-servlet-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jetty-util-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jetty-util-ajax-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jetty-webapp-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jetty-xml-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jsch-0.1.55.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/json-smart-2.4.7.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jsr305-3.0.2.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerb-client-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerb-common-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerb-core-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerb-server-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerb-util-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerby-config-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerby-util-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/metrics-core-3.2.4.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/netty-3.10.6.Final.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/paranamer-2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/re2j-1.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/snappy-java-1.0.5.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/spotbugs-annotations-3.1.9.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/stax2-api-4.2.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/token-provider-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/zookeeper-3.4.14.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/hadoop-common-3.2.3-tests.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/hadoop-common-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/hadoop-kms-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/hadoop-nfs-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/jdiff:/opt/module/hadoop-3.2.3/share/hadoop/common/lib:/opt/module/hadoop-3.2.3/share/hadoop/common/sources:/opt/module/hadoop-3.2.3/share/hadoop/common/webapps:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/accessors-smart-2.4.7.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/asm-5.0.4.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/avro-1.7.7.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/commons-net-3.6.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/commons-text-1.4.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/error_prone_annotations-2.2.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/gson-2.2.4.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/hadoop-annotations-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/hadoop-auth-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jackson-annotations-2.10.5.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jackson-core-2.10.5.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jackson-databind-2.10.5.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/javax.activation-api-1.2.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jettison-1.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jetty-http-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jetty-io-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jetty-security-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jetty-server-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jetty-servlet-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jetty-util-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jetty-webapp-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jetty-xml-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/json-smart-2.4.7.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/netty-all-4.1.68.Final.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/okio-1.6.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/paranamer-2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/re2j-1.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/spotbugs-annotations-3.1.9.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/woodstox-core-5.3.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/zookeeper-3.4.14.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/hadoop-hdfs-3.2.3-tests.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/hadoop-hdfs-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/hadoop-hdfs-client-3.2.3-tests.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/hadoop-hdfs-client-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.3-tests.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.3-tests.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/jdiff:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/sources:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/webapps:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/lib/junit-4.13.2.jar:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.3-tests.jar:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/jdiff:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/lib:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/lib-examples:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/sources:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/fst-2.50.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/guice-4.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/jackson-jaxrs-base-2.10.5.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.10.5.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.10.5.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/jakarta.activation-api-1.2.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/jersey-client-1.19.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/objenesis-1.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/snakeyaml-1.26.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-api-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-client-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-common-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-registry-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-server-common-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-server-router-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-services-api-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-services-core-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-submarine-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib:/opt/module/hadoop-3.2.3/share/hadoop/yarn/sources:/opt/module/hadoop-3.2.3/share/hadoop/yarn/test:/opt/module/hadoop-3.2.3/share/hadoop/yarn/timelineservice:/opt/module/hadoop-3.2.3/share/hadoop/yarn/webapps:/opt/module/hadoop-3.2.3/share/hadoop/yarn/yarn-service-examples\n  ```\n\n  \n\n  而这样不算成功：\n\n  ```\n  /opt/module/hadoop-3.2.3/etc/hadoop:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/*:/opt/module/hadoop-3.2.3/share/hadoop/common/*:/opt/module/hadoop-3.2.3/share/hadoop/hdfs:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/*:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/*:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/lib/*:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/*:/opt/module/hadoop-3.2.3/share/hadoop/yarn:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/*:/opt/module/hadoop-3.2.3/share/hadoop/yarn/*\n  ```\n\n  \n\n- quit;退出sql-client时报错：\n\n  ```\n  Exception in thread \"Thread-4\" java.lang.IllegalStateException: Trying to access closed classloader. Please check if you store classloaders directly or indirectly in static fields. If the stacktrace suggests that the leak occurs in a third party library and cannot be fixed immediately, you can disable this check with the configuration 'classloader.check-leaked-classloader'.\n  ```\n\n  可以在在 flink 配置文件里 flink-conf.yaml设置`classloader.check-leaked-classloader: false`\n","slug":"bigdata/Flink-SQL-Client与Hive集成问题指南","published":1,"comments":1,"layout":"post","photos":[],"link":"","_id":"cl9y38dsa0012fwui3s268d47","content":"<blockquote>\n<p>只需要下载对应的<code>flink-sql-connector-hive-3.1.2_2.12-1.14.5.jar</code>,放在{FLINK_HOME}&#x2F;lib下面即可。</p>\n<p>不需要下载什么<code>flink-shaded-hadoop-3-uber-3.1.1.7.2.9.0-173-9.0.jar</code>放在{FLINK_HOME}&#x2F;lib下面,现在Flink通过</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\">&gt;</span><span class=\"language-bash\"><span class=\"built_in\">export</span> HADOOP_CLASSPATH=`hadoop classpath`</span></span><br></pre></td></tr></table></figure>\n\n<p>来寻找Hadoop相关的Jar包。</p>\n<p>当Flink on YARN时，还需要在{FLINK_HOME}&#x2F;lib中添加以下依赖：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\">&gt;</span><span class=\"language-bash\">要么是这个：</span></span><br><span class=\"line\">      flink-shaded-hadoop-2-uber-2.7.5-8.0.jar</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\">&gt;</span><span class=\"language-bash\">要么是，可以直接从hadoop/share/hadoop/mapreduce/等目录拷过来：</span></span><br><span class=\"line\">     hadoop-common-3.0.0-cdh6.3.1.jar</span><br><span class=\"line\">     hadoop-mapreduce-client-common-3.0.0-cdh6.3.1.jar</span><br><span class=\"line\">     hadoop-mapreduce-client-core-3.0.0-cdh6.3.1.jar</span><br><span class=\"line\">     hadoop-mapreduce-client-hs-3.0.0-cdh6.3.1.jar</span><br><span class=\"line\">     hadoop-mapreduce-client-jobclient-3.0.0-cdh6.3.1.jar</span><br></pre></td></tr></table></figure>\n\n\n</blockquote>\n<h2 id=\"ENV\"><a href=\"#ENV\" class=\"headerlink\" title=\"ENV\"></a>ENV</h2><ul>\n<li>Flink ：1.14.5</li>\n<li>Hadoop：3.2.3</li>\n<li>Hive：3.1.2+</li>\n</ul>\n<h2 id=\"Error\"><a href=\"#Error\" class=\"headerlink\" title=\"Error\"></a>Error</h2><ul>\n<li><p><code>Caused by: java.lang.NoSuchMethodError: com.google.common.base.Preconditions.checkArgument(ZLjava/lang/String;Ljava/lang/Object;)V</code></p>\n<p>解压<code>flink-sql-connector-hive-3.1.2_2.12-1.14.5.jar</code>,直接将里面的com&#x2F;google文件夹删除</p>\n</li>\n<li><p>其他找不到Hadoop相关Jar包的错误，</p>\n<p>一般都是因为</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">export HADOOP_CLASSPATH=`hadoop classpath`</span><br></pre></td></tr></table></figure></li>\n</ul>\n<p>​      没有设置成功，不仅sql-client.sh要在此环境下启动，Standalone的Flink也要在此环境下启动。</p>\n<ul>\n<li><p>执行</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">echo `hadoop classpath`</span><br></pre></td></tr></table></figure>\n\n<p>后，下面这样才算成功</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/opt/module/hadoop-3.2.3/etc/hadoop:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/*:/opt/module/hadoop-3.2.3/share/hadoop/common/*:/opt/module/hadoop-3.2.3/share/hadoop/hdfs:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/*:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/*:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/lib/*:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/*:/opt/module/hadoop-3.2.3/share/hadoop/yarn:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/*:/opt/module/hadoop-3.2.3/share/hadoop/yarn/*:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/accessors-smart-2.4.7.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/asm-5.0.4.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/avro-1.7.7.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/checker-qual-2.5.2.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/commons-codec-1.11.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/commons-compress-1.21.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/commons-io-2.8.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/commons-lang3-3.7.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/commons-net-3.6.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/commons-text-1.4.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/curator-client-2.13.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/curator-framework-2.13.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/dnsjava-2.1.7.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/error_prone_annotations-2.2.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/failureaccess-1.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/gson-2.2.4.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/guava-27.0-jre.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/hadoop-annotations-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/hadoop-auth-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/httpclient-4.5.13.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/httpcore-4.4.13.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jackson-annotations-2.10.5.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jackson-core-2.10.5.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jackson-databind-2.10.5.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/javax.activation-api-1.2.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jersey-core-1.19.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jersey-json-1.19.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jersey-server-1.19.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jersey-servlet-1.19.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jettison-1.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jetty-http-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jetty-io-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jetty-security-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jetty-server-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jetty-servlet-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jetty-util-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jetty-util-ajax-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jetty-webapp-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jetty-xml-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jsch-0.1.55.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/json-smart-2.4.7.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jsr305-3.0.2.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerb-client-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerb-common-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerb-core-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerb-server-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerb-util-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerby-config-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerby-util-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/metrics-core-3.2.4.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/netty-3.10.6.Final.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/paranamer-2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/re2j-1.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/snappy-java-1.0.5.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/spotbugs-annotations-3.1.9.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/stax2-api-4.2.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/token-provider-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/zookeeper-3.4.14.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/hadoop-common-3.2.3-tests.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/hadoop-common-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/hadoop-kms-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/hadoop-nfs-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/jdiff:/opt/module/hadoop-3.2.3/share/hadoop/common/lib:/opt/module/hadoop-3.2.3/share/hadoop/common/sources:/opt/module/hadoop-3.2.3/share/hadoop/common/webapps:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/accessors-smart-2.4.7.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/asm-5.0.4.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/avro-1.7.7.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/commons-net-3.6.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/commons-text-1.4.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/error_prone_annotations-2.2.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/gson-2.2.4.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/hadoop-annotations-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/hadoop-auth-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jackson-annotations-2.10.5.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jackson-core-2.10.5.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jackson-databind-2.10.5.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/javax.activation-api-1.2.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jettison-1.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jetty-http-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jetty-io-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jetty-security-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jetty-server-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jetty-servlet-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jetty-util-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jetty-webapp-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jetty-xml-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/json-smart-2.4.7.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/netty-all-4.1.68.Final.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/okio-1.6.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/paranamer-2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/re2j-1.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/spotbugs-annotations-3.1.9.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/woodstox-core-5.3.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/zookeeper-3.4.14.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/hadoop-hdfs-3.2.3-tests.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/hadoop-hdfs-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/hadoop-hdfs-client-3.2.3-tests.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/hadoop-hdfs-client-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.3-tests.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.3-tests.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/jdiff:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/sources:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/webapps:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/lib/junit-4.13.2.jar:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.3-tests.jar:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/jdiff:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/lib:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/lib-examples:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/sources:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/fst-2.50.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/guice-4.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/jackson-jaxrs-base-2.10.5.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.10.5.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.10.5.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/jakarta.activation-api-1.2.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/jersey-client-1.19.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/objenesis-1.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/snakeyaml-1.26.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-api-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-client-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-common-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-registry-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-server-common-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-server-router-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-services-api-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-services-core-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-submarine-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib:/opt/module/hadoop-3.2.3/share/hadoop/yarn/sources:/opt/module/hadoop-3.2.3/share/hadoop/yarn/test:/opt/module/hadoop-3.2.3/share/hadoop/yarn/timelineservice:/opt/module/hadoop-3.2.3/share/hadoop/yarn/webapps:/opt/module/hadoop-3.2.3/share/hadoop/yarn/yarn-service-examples</span><br></pre></td></tr></table></figure>\n\n\n\n<p>而这样不算成功：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/opt/module/hadoop-3.2.3/etc/hadoop:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/*:/opt/module/hadoop-3.2.3/share/hadoop/common/*:/opt/module/hadoop-3.2.3/share/hadoop/hdfs:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/*:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/*:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/lib/*:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/*:/opt/module/hadoop-3.2.3/share/hadoop/yarn:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/*:/opt/module/hadoop-3.2.3/share/hadoop/yarn/*</span><br></pre></td></tr></table></figure>\n\n\n</li>\n<li><p>quit;退出sql-client时报错：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Exception in thread &quot;Thread-4&quot; java.lang.IllegalStateException: Trying to access closed classloader. Please check if you store classloaders directly or indirectly in static fields. If the stacktrace suggests that the leak occurs in a third party library and cannot be fixed immediately, you can disable this check with the configuration &#x27;classloader.check-leaked-classloader&#x27;.</span><br></pre></td></tr></table></figure>\n\n<p>可以在在 flink 配置文件里 flink-conf.yaml设置<code>classloader.check-leaked-classloader: false</code></p>\n</li>\n</ul>\n","site":{"data":{"link":[{"class_name":"友情链接","class_desc":"那些人，那些事","link_list":[{"name":"张洪Heo","link":"https://blog.zhheo.com/","avatar":"https://npm.elemecdn.com/guli-heo/img/avatar2.png","descr":"分享设计与科技生活"},{"name":"瞬間の筆記","link":"https://hikki.site","descr":"喜欢的东西就努力去追求，万一成功了呢!","avatar":"https://cdn.jsdelivr.net/gh/0000rookie/imgs/202206120315.png"}]}]}},"excerpt":"","more":"<blockquote>\n<p>只需要下载对应的<code>flink-sql-connector-hive-3.1.2_2.12-1.14.5.jar</code>,放在{FLINK_HOME}&#x2F;lib下面即可。</p>\n<p>不需要下载什么<code>flink-shaded-hadoop-3-uber-3.1.1.7.2.9.0-173-9.0.jar</code>放在{FLINK_HOME}&#x2F;lib下面,现在Flink通过</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\">&gt;</span><span class=\"language-bash\"><span class=\"built_in\">export</span> HADOOP_CLASSPATH=`hadoop classpath`</span></span><br></pre></td></tr></table></figure>\n\n<p>来寻找Hadoop相关的Jar包。</p>\n<p>当Flink on YARN时，还需要在{FLINK_HOME}&#x2F;lib中添加以下依赖：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\">&gt;</span><span class=\"language-bash\">要么是这个：</span></span><br><span class=\"line\">      flink-shaded-hadoop-2-uber-2.7.5-8.0.jar</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\">&gt;</span><span class=\"language-bash\">要么是，可以直接从hadoop/share/hadoop/mapreduce/等目录拷过来：</span></span><br><span class=\"line\">     hadoop-common-3.0.0-cdh6.3.1.jar</span><br><span class=\"line\">     hadoop-mapreduce-client-common-3.0.0-cdh6.3.1.jar</span><br><span class=\"line\">     hadoop-mapreduce-client-core-3.0.0-cdh6.3.1.jar</span><br><span class=\"line\">     hadoop-mapreduce-client-hs-3.0.0-cdh6.3.1.jar</span><br><span class=\"line\">     hadoop-mapreduce-client-jobclient-3.0.0-cdh6.3.1.jar</span><br></pre></td></tr></table></figure>\n\n\n</blockquote>\n<h2 id=\"ENV\"><a href=\"#ENV\" class=\"headerlink\" title=\"ENV\"></a>ENV</h2><ul>\n<li>Flink ：1.14.5</li>\n<li>Hadoop：3.2.3</li>\n<li>Hive：3.1.2+</li>\n</ul>\n<h2 id=\"Error\"><a href=\"#Error\" class=\"headerlink\" title=\"Error\"></a>Error</h2><ul>\n<li><p><code>Caused by: java.lang.NoSuchMethodError: com.google.common.base.Preconditions.checkArgument(ZLjava/lang/String;Ljava/lang/Object;)V</code></p>\n<p>解压<code>flink-sql-connector-hive-3.1.2_2.12-1.14.5.jar</code>,直接将里面的com&#x2F;google文件夹删除</p>\n</li>\n<li><p>其他找不到Hadoop相关Jar包的错误，</p>\n<p>一般都是因为</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">export HADOOP_CLASSPATH=`hadoop classpath`</span><br></pre></td></tr></table></figure></li>\n</ul>\n<p>​      没有设置成功，不仅sql-client.sh要在此环境下启动，Standalone的Flink也要在此环境下启动。</p>\n<ul>\n<li><p>执行</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">echo `hadoop classpath`</span><br></pre></td></tr></table></figure>\n\n<p>后，下面这样才算成功</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/opt/module/hadoop-3.2.3/etc/hadoop:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/*:/opt/module/hadoop-3.2.3/share/hadoop/common/*:/opt/module/hadoop-3.2.3/share/hadoop/hdfs:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/*:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/*:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/lib/*:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/*:/opt/module/hadoop-3.2.3/share/hadoop/yarn:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/*:/opt/module/hadoop-3.2.3/share/hadoop/yarn/*:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/accessors-smart-2.4.7.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/asm-5.0.4.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/avro-1.7.7.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/checker-qual-2.5.2.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/commons-codec-1.11.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/commons-compress-1.21.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/commons-io-2.8.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/commons-lang3-3.7.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/commons-net-3.6.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/commons-text-1.4.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/curator-client-2.13.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/curator-framework-2.13.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/dnsjava-2.1.7.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/error_prone_annotations-2.2.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/failureaccess-1.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/gson-2.2.4.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/guava-27.0-jre.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/hadoop-annotations-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/hadoop-auth-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/httpclient-4.5.13.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/httpcore-4.4.13.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jackson-annotations-2.10.5.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jackson-core-2.10.5.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jackson-databind-2.10.5.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/javax.activation-api-1.2.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jersey-core-1.19.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jersey-json-1.19.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jersey-server-1.19.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jersey-servlet-1.19.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jettison-1.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jetty-http-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jetty-io-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jetty-security-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jetty-server-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jetty-servlet-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jetty-util-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jetty-util-ajax-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jetty-webapp-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jetty-xml-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jsch-0.1.55.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/json-smart-2.4.7.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jsr305-3.0.2.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerb-client-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerb-common-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerb-core-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerb-server-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerb-util-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerby-config-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerby-util-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/metrics-core-3.2.4.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/netty-3.10.6.Final.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/paranamer-2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/re2j-1.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/snappy-java-1.0.5.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/spotbugs-annotations-3.1.9.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/stax2-api-4.2.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/token-provider-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/zookeeper-3.4.14.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/hadoop-common-3.2.3-tests.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/hadoop-common-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/hadoop-kms-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/hadoop-nfs-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/common/jdiff:/opt/module/hadoop-3.2.3/share/hadoop/common/lib:/opt/module/hadoop-3.2.3/share/hadoop/common/sources:/opt/module/hadoop-3.2.3/share/hadoop/common/webapps:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/accessors-smart-2.4.7.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/asm-5.0.4.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/avro-1.7.7.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/commons-net-3.6.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/commons-text-1.4.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/error_prone_annotations-2.2.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/gson-2.2.4.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/hadoop-annotations-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/hadoop-auth-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jackson-annotations-2.10.5.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jackson-core-2.10.5.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jackson-databind-2.10.5.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/javax.activation-api-1.2.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jettison-1.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jetty-http-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jetty-io-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jetty-security-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jetty-server-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jetty-servlet-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jetty-util-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jetty-webapp-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jetty-xml-9.4.40.v20210413.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/json-smart-2.4.7.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/netty-all-4.1.68.Final.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/okio-1.6.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/paranamer-2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/re2j-1.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/spotbugs-annotations-3.1.9.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/woodstox-core-5.3.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/zookeeper-3.4.14.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/hadoop-hdfs-3.2.3-tests.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/hadoop-hdfs-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/hadoop-hdfs-client-3.2.3-tests.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/hadoop-hdfs-client-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.3-tests.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.3-tests.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/jdiff:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/sources:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/webapps:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/lib/junit-4.13.2.jar:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.3-tests.jar:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/jdiff:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/lib:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/lib-examples:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/sources:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/fst-2.50.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/guice-4.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/jackson-jaxrs-base-2.10.5.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.10.5.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.10.5.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/jakarta.activation-api-1.2.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/jersey-client-1.19.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/objenesis-1.0.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/snakeyaml-1.26.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-api-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-client-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-common-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-registry-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-server-common-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-server-router-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-services-api-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-services-core-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/hadoop-yarn-submarine-3.2.3.jar:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib:/opt/module/hadoop-3.2.3/share/hadoop/yarn/sources:/opt/module/hadoop-3.2.3/share/hadoop/yarn/test:/opt/module/hadoop-3.2.3/share/hadoop/yarn/timelineservice:/opt/module/hadoop-3.2.3/share/hadoop/yarn/webapps:/opt/module/hadoop-3.2.3/share/hadoop/yarn/yarn-service-examples</span><br></pre></td></tr></table></figure>\n\n\n\n<p>而这样不算成功：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/opt/module/hadoop-3.2.3/etc/hadoop:/opt/module/hadoop-3.2.3/share/hadoop/common/lib/*:/opt/module/hadoop-3.2.3/share/hadoop/common/*:/opt/module/hadoop-3.2.3/share/hadoop/hdfs:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/lib/*:/opt/module/hadoop-3.2.3/share/hadoop/hdfs/*:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/lib/*:/opt/module/hadoop-3.2.3/share/hadoop/mapreduce/*:/opt/module/hadoop-3.2.3/share/hadoop/yarn:/opt/module/hadoop-3.2.3/share/hadoop/yarn/lib/*:/opt/module/hadoop-3.2.3/share/hadoop/yarn/*</span><br></pre></td></tr></table></figure>\n\n\n</li>\n<li><p>quit;退出sql-client时报错：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Exception in thread &quot;Thread-4&quot; java.lang.IllegalStateException: Trying to access closed classloader. Please check if you store classloaders directly or indirectly in static fields. If the stacktrace suggests that the leak occurs in a third party library and cannot be fixed immediately, you can disable this check with the configuration &#x27;classloader.check-leaked-classloader&#x27;.</span><br></pre></td></tr></table></figure>\n\n<p>可以在在 flink 配置文件里 flink-conf.yaml设置<code>classloader.check-leaked-classloader: false</code></p>\n</li>\n</ul>\n"},{"title":"Flink调优","top_img":"/img/bg/banner.gif","date":"2022-08-08T12:23:04.000Z","updated":"2022-08-08T12:23:04.000Z","cover":"https://tvax4.sinaimg.cn/large/0084aYsLgy1h3jum72m7kj31220e6jsc.jpg","description":null,"keywords":null,"_content":"\n# 内存设置（1CPU配置4G内存）\n\n> bin/flink run \\\n>\n> -t yarn-per-job \\\n>\n> -d \\\n>\n> -p 5 \\ 指定并行度\n>\n> -Dyarn.application.queue=test \\ 指定yarn队列\n>\n> -Djobmanager.memory.process.size=2048mb \\ JM2~4G足够\n>\n> -Dtaskmanager.memory.process.size=6144mb \\ 单个TM2~8G足够\n>\n> -Dtaskmanager.numberOfTaskSlots=2 \\ **与容器核数1core：1slot或1core：2slot**\n>\n> -c com.atguigu.app.dwd.LogBaseApp \\\n>\n> /opt/module/gmall-flink/gmall-realtime-1.0-SNAPSHOT-jar-with-dependencies.jar\n\nFlink是实时流处理，关键在于资源情况能不能抗住高峰时期每秒的数据量，通常用QPS/TPS来描述数据情况。\n\n##  TaskManager 内存模型  \n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1654665961981-86c260ab-5310-4674-ac61-6a1d1f738f18.png)\n\n### 1、内存模型详解\n\n#### JVM 特定内存：JVM 本身使用的内存，包含 JVM 的 metaspace 和 over-head\n\n1）JVMmetaspace：JVM 元空间\n\ntaskmanager.memory.jvm-metaspace.size，默认 256mb\n\n\n\n2）JVMover-head执行开销：JVM执行时自身所需要的内容，包括线程堆栈、IO、编译缓存等所使用的内存。\n\ntaskmanager.memory.jvm-overhead.fraction，默认 0.1\n\ntaskmanager.memory.jvm-overhead.min，默认 192mb\n\ntaskmanager.memory.jvm-overhead.max，默认 1gb\n\n\n\n**总进程内存\\*fraction，如果小于配置的 min（或大于配置的 max）大小，则使用 min/max**\n\n**大小**\n\n\n\n#### 框架内存：Flink 框架，即 TaskManager 本身所占用的内存，不计入 Slot 的资源中。\n\n堆内：taskmanager.memory.framework.heap.size，默认 128MB\n\n堆外：taskmanager.memory.framework.off-heap.size，默认 128MB\n\n#### Task内存：Task执行用户代码时所使用的内存\n\n堆内：taskmanager.memory.task.heap.size，默认 none，由 Flink 内存扣除掉其他部分的内存得到。\n\n堆外：taskmanager.memory.task.off-heap.size，默认 0，表示不使用堆外内存\n\n#### 网络内存：网络数据交换所使用的堆外内存大小，如网络数据交换缓冲区\n\n**堆外：**\n\ntaskmanager.memory.network.fraction，默认 0.1\n\ntaskmanager.memory.network.min，默认 64mb\n\ntaskmanager.memory.network.max，默认 1gb\n\n**Flink 内存\\*fraction，如果小于配置的 min（或大于配置的 max）大小，则使用 min/max大小**\n\n  \n\n#### 托管内存：用于 RocksDBStateBackend 的本地内存和批的排序、哈希表、缓存中间结果。\n\n堆外：taskmanager.memory.managed.fraction，默认 0.4\n\ntaskmanager.memory.managed.size，默认 none\n\n**如果 size 没指定，则等于 Flink 内存\\*fraction**\n\n## 2、案例分析  \n\n基于Yarn模式，一般参数指定的是总进程内存，taskmanager.memory.process.size，比如指定为 4G，每一块内存得到大小如下：\n\n（1）计算 Flink 内存\n\nJVM 元空间 256m\n\nJVM 执行开销： 4g*0.1=409.6m，在[192m,1g]之间，最终结果 409.6m\n\nFlink 内存=4g-256m-409.6m=3430.4m\n\n（2）网络内存=3430.4m*0.1=343.04m，在[64m,1g]之间，最终结果 343.04m\n\n（3）托管内存=3430.4m*0.4=1372.16m\n\n（4）框架内存，堆内和堆外都是 128m\n\n（5）Task堆内内存=3430.4m-128m-128m-343.04m-1372.16m=1459.2m\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1654667261844-9b48b348-1bcb-4ca8-b556-f63a3680cf83.png)\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1654667279269-d43c4812-9561-433a-83fe-a8d70b5fb5b9.png)\n\n### 所以进程内存给多大，每一部分内存需不需要调整，可以看内存的使用率来调整。\n\n## 合理利用 cpu 资源\n\nYarn 的**容量调度器**默认情况下是使用“DefaultResourceCalculator”分配策略，只根据内存调度资源，所以在 Yarn 的资源管理页面上看到每个容器的 vcore 个数还是 1。\n\n可以修改策略为 DominantResourceCalculator，该资源计算器在计算资源的时候会综合考虑 cpu 和内存的情况。在capacity-scheduler.xml 中修改属性:\n\n```xml\n<property>\n  <name>yarn.scheduler.capacity.resource-calculator</name>\n  <!-- <value>org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator</value> -->\n  <value>org.apache.hadoop.yarn.util.resource.DominantResourceCalculator</value>\n</property>\n```\n\n### 1.1.1    使用DefaultResourceCalculator 策略\n\n```shell\nbin/flink run \\\n-t yarn-per-job \\\n-d \\\n-p 5 \\\n-Drest.flamegraph.enabled=true \\\n-Dyarn.application.queue=test \\\n-Djobmanager.memory.process.size=1024mb \\\n-Dtaskmanager.memory.process.size=4096mb \\\n-Dtaskmanager.numberOfTaskSlots=2 \\\n-c com.atguigu.flink.tuning.UvDemo \\\n/opt/module/flink-1.13.1/myjar/flink-tuning-1.0-SNAPSHOT.jar\n```\n\n可以看到一个容器只有一个 vcore：\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1654668251950-033e4bc0-4b65-4fe8-b309-45a29956922b.png)\n\n### 1.1.2    使用DominantResourceCalculator 策略\n\n修改后 yarn 配置后，分发配置并重启 yarn，再次提交 flink 作业：\n\n> bin/flinkrun\\\n>\n> -tyarn-per-job\\\n>\n> -d\\\n>\n> -p5\\\n>\n> -Drest.flamegraph.enabled=true\\\n>\n> -Dyarn.application.queue=test\\\n>\n> -Djobmanager.memory.process.size=1024mb \\\n>\n> -Dtaskmanager.memory.process.size=4096mb\\\n>\n> -Dtaskmanager.numberOfTaskSlots=2\\\n>\n> -ccom.atguigu.flink.tuning.UvDemo\\\n>\n> /opt/module/flink-1.13.1/myjar/flink-tuning-1.0-SNAPSHOT.jar\n\n看到容器的 vcore 数变了:\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1654668344371-82744e2d-89b2-4fab-8a09-f77475df1088.png)\n\nJobManager1 个，占用 1 个容器，vcore=1\n\nTaskManager3 个，占用 3 个容器，每个容器 vcore=2，总 vcore=2*3=6，因为默认单个容器的 vcore 数=单 TM 的slot 数\n\n### 1.1.3    使用 DominantResourceCalculator 策略并指定容器**vcore 数**\n\n指定yarn 容器的 vcore 数，提交：\n\n> bin/flinkrun\\\n>\n> -tyarn-per-job\\\n>\n> -d\\\n>\n> -p5\\\n>\n> -Drest.flamegraph.enabled=true\\\n>\n> -Dyarn.application.queue=test\\\n>\n> -Dyarn.containers.vcores=3\\\n>\n>  -Djobmanager.memory.process.size=1024mb \\ -Dtaskmanager.memory.process.size=4096mb \\ -Dtaskmanager.numberOfTaskSlots=2 \\ -c com.atguigu.flink.tuning.UvDemo \\ /opt/module/flink-1.13.1/myjar/flink-tuning-1.0-SNAPSHOT.jar  \n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1654668509233-7292aa6f-0e54-4799-ba38-ab72659ef824.png)\n\nJobManager1 个，占用 1 个容器，vcore=1\n\nTaskManager3 个，占用 3 个容器，每个容器vcore =3，总 vcore=3*3=9\n\n# RocksDB大状态调优\n\nRocksDB 是基于 LSM Tree 实现的（类似HBase），写数据都是先缓存到内存中，所以RocksDB 的写请求效率比较高。RocksDB 使用内存结合磁盘的方式来存储数据，每次获取数据时，先从内存中 blockcache 中查找，如果内存中没有再去磁盘中查询。优化后差不多单并行度 TPS 5000 record/s。**使用RocksDB 时，状态大小仅受可用磁盘空间量的限制，性能瓶颈主要在于 RocksDB对磁盘的读请求，每次读写操作都必须对数据进行反序列化或者序列化。**所以当处理性能不够时，仅需要横向扩展并行度即可提高整个Job 的吞吐量。\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1654669015363-a35261ab-d4ff-4068-a013-eecfe78a5c7d.png)\n\n\n\n从 Flink1.10 开始，Flink 默认将 RocksDB 的内存大小配置为每个 taskslot 的托管内存。调试内存性能的问题主要是通过调整配置项 taskmanager.memory.managed.size或者 taskmanager.memory.managed.fraction以增加 Flink 的托管内存(即堆外的托管内存)。进一步可以调整一些参数进行高级性能调优，这些参数也可以在应用程序中通过RocksDBStateBackend.setRocksDBOptions(RocksDBOptionsFactory)指定。下面介绍\n\n提高资源利用率的几个重要配置：\n\n### 2.1.1   开启State访问性能监控\n\nFlink 1.13 中引入了 State 访问的性能监控，即 latency trackig state。此功能不局限于 StateBackend 的类型，自定义实现的 StateBackend 也可以复用此功能。\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1654670053632-0e169f44-1340-4202-ab6a-bd9a6173a14a.png)\n\nState访问性能监控会产生一定的性能影响，所以，默认每 100次做一次取样(sample)，对不同的 StateBackend 性能损失影响不同：\n\n- 对于 RocksDBStateBackend，性能损失大概在 1% 左右\n- 对于 HeapStateBackend，性能损失最多可达 10%\n\n```yaml\nstate.backend.latency-track.keyed-state-enabled：true #启用访问状态的性能监控 \nstate.backend.latency-track.sample-interval: 100 #采样间隔 \nstate.backend.latency-track.history-size: 128 #保留的采样数据个数，越大越精确 \nstate.backend.latency-track.state-name-as-variable: true #将状态名作为变量  \n```\n\n正常开启第一个参数即可。\n\n> bin/flink run \\\n>\n> -t yarn-per-job \\\n>\n> -d \\\n>\n> -p 5 \\\n>\n> -Drest.flamegraph.enabled=true \\\n>\n> -Dyarn.application.queue=test \\\n>\n> -Djobmanager.memory.process.size=1024mb \\\n>\n> -Dtaskmanager.memory.process.size=4096mb \\\n>\n> -Dtaskmanager.numberOfTaskSlots=2 \\\n>\n>  -Dstate.backend.latency-track.keyed-state-enabled=true \\ \n>\n> -c com.atguigu.flink.tuning.RocksdbTuning \\ /opt/module/flink-1.13.1/myjar/flink-tuning-1.0-SNAPSHOT.jar  \n\n### 2.1.2    开启增量检查点和本地恢复\n\n1）开启增量检查点\n\nRocksDB 是目前唯一可用于支持有状态流处理应用程序增量检查点的状态后端，可以修改参数开启增量检查点：\n\nstate.backend.incremental: true #默认 false，改为 true。 \n\n或代码中指定 new EmbeddedRocksDBStateBackend(true)  \n\n2）开启本地恢复\n\n当 Flink任务失败时，可以基于本地的状态信息进行恢复任务，可能不需要从 hdfs拉取数据。本地恢复目前仅涵盖键控类型的状态后端（RocksDB），MemoryStateBackend不支持本地恢复并忽略此选项。\n\nstate.backend.local-recovery:true\n\n### 2.1.3    调整预定义选项\n\nFlink针对不同的设置为 RocksDB提供了一些预定义的选项集合,其中包含了后续提到的一些参数，如果调整预定义选项后还达不到预期，再去调整后面的 block、writebuffer等参数。\n\n当 前 支 持 的 预 定 义 选 项 有   DEFAULT 、 SPINNING_DISK_OPTIMIZED 、\n\nSPINNING_DISK_OPTIMIZED_HIGH_MEM 或FLASH_SSD_OPTIMIZED。有条件上 SSD\n\n的，可以指定为 FLASH_SSD_OPTIMIZED\n\n state.backend.rocksdb.predefined-options： SPINNING_DISK_OPTIMIZED_HIGH_MEM #设置为机械硬盘+内存模式  \n\n### 2.1.4    增大 block 缓存\n\n整个 RocksDB 共享一个 blockcache，读数据时内存的 cache 大小，该参数越大读\n\n数据时缓存命中率越高，默认大小为8MB，建议设置到64~256MB。\n\nstate.backend.rocksdb.block.cache-size:64m     #默认8m  \n\n### 2.1.5    增大writebuffer 和 level 阈值大小\n\nRocksDB 中，每个 State 使用一个 ColumnFamily，每个 ColumnFamily 使用独占的 writebuffer，默认 64MB，建议调大。\n\n调整这个参数通常要适当增加 L1层的大小阈值 max-size-level-base，默认 256m。\n\n该值太小会造成能存放的 SST 文件过少，层级变多造成查找困难，太大会造成文件过多，合并困难。建议设为 target_file_size_base（默认 64MB） 的倍数，且不能太小，例如 5~10倍，即 320~640MB。\n\nstate.backend.rocksdb.writebuffer.size: 128m\n\nstate.backend.rocksdb.compaction.level.max-size-level-base:320m   \n\n### 2.1.6    增大write buffer 数量\n\n每个 ColumnFamily对应的 writebuffer 最大数量，这实际上是内存中“只读内存表“的最大数量，默认值是 2。对于机械磁盘来说，如果内存足够大，可以调大到 5左右\n\nstate.backend.rocksdb.writebuffer.count:5                                                                     \n\n### 2.1.7    增大后台线程数和writebuffer 合并数\n\n1）增大线程数\n\n用于后台 flush和合并 sst文件的线程数，默认为 1，建议调大，机械硬盘用户可以改为 4等更大的值\n\nstate.backend.rocksdb.thread.num: 4                                                                             \n\n2）增大writebuffer 最小合并数\n\n将数据从 writebuffer 中 flush 到磁盘时，需要合并的 writebuffer 最小数量，默认\n\n值为 1，可以调成 3。\n\nstate.backend.rocksdb.writebuffer.number-to-merge:3                                             \n\n### 2.1.8    开启分区索引功能\n\nFlink1.13 中对 RocksDB 增加了分区索引功能，复用了 RocksDB 的partitionedIndex&filter 功能，简单来说就是对 RocksDB 的 partitionedIndex 做了多级索引。也就是将内存中的最上层常驻，下层根据需要再 load回来，这样就大大降低了数据 Swap竞争。线上测试中，相对于**内存比较小**的场景中，性能提升 10 倍左右。如果在内存管控下 Rocksdb 性能不如预期的话，这也能成为一个性能优化点。\n\nstate.backend.rocksdb.memory.partitioned-index-filters:true   #默认false                \n\n\n\n**2.1.9**    **参数设定案例**\n\n```sh\nbin/flinkrun\\\n-tyarn-per-job\\\n-d\\\n-p5\\\n-Drest.flamegraph.enabled=true\\\n-Dyarn.application.queue=test\\\n-Djobmanager.memory.process.size=1024mb \\\n-Dtaskmanager.memory.process.size=4096mb\\\n-Dtaskmanager.numberOfTaskSlots=2\\\n-Dstate.backend.incremental=true\\\n-Dstate.backend.local-recovery=true\\\n-Dstate.backend.rocksdb.predefined-options=SPINNING_DISK_OPTIMIZED_HIGH_MEM\\\n-Dstate.backend.rocksdb.block.cache-size=64m\\\n-Dstate.backend.rocksdb.writebuffer.size=128m\\\n-Dstate.backend.rocksdb.compaction.level.max-size-level-base=320m\\\n-Dstate.backend.rocksdb.writebuffer.count=5 \\\n-Dstate.backend.rocksdb.thread.num=4\\\n-Dstate.backend.rocksdb.writebuffer.number-to-merge=3\\\n-Dstate.backend.rocksdb.memory.partitioned-index-filters=true\\\n-Dstate.backend.latency-track.keyed-state-enabled=true\\\n-ccom.atguigu.flink.tuning.RocksdbTuning\\\n/opt/module/flink-1.13.1/myjar/flink-tuning-1.0-SNAPSHOT.jar\n```\n\n\n\n### 设置本地 RocksDB 多目录\n\n在flink-conf.yaml 中配置：\n\n```plain\nstate.backend.rocksdb.localdir: /data1/flink/rocksdb,/data2/flink/rocksdb,/data3/flink/rocksdb\n```\n\n\n\n注意：不要配置单块磁盘的多个目录，务必将目录配置到多块不同的磁盘上，让多块磁盘来分担压力。**当设置多个 RocksDB 本地磁盘目录时，Flink 会****随机选择****要使用的目录，所以就可能存在三个并行度共用同一目录的情况。**如果服务器磁盘数较多，一般不会出现该情况，但是如果任务重启后吞吐量较低，可以检查是否发生了多个并行度共用同一块磁盘的情况。\n\n**当一个 TaskManager 包含 3 个 slot 时，那么单个服务器上的三个并行度都对磁盘造成频繁读写，从而导致三个并行度的之间相互争抢同一个磁盘 io，这样务必导致三个并行度的吞吐量都会下降。设置多目录实现三个并行度使用不同的硬盘从而减少资源竞争。**\n\n如下所示是测试过程中磁盘的 IO 使用率，可以看出三个大状态算子的并行度分别对应了三块磁盘，这三块磁盘的 IO 平均使用率都保持在 45% 左右，IO 最高使用率几乎都是 100%，而其他磁盘的 IO 平均使用率相对低很多。**由此可见使用 RocksDB 做为状态后端且有大状态的频繁读取时， 对磁盘IO性能消耗确实比较大。**\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1654662632337-7fe1e6c6-5fe2-412e-82e8-77f3c81458b7.png)\n\n如下图所示，其中两个并行度共用了 sdb 磁盘，一个并行度使用 sdj磁盘。可以看到 sdb 磁盘的 IO 使用率已经达到了 91.6%，就会导致 sdb 磁盘对应的两个并行度吞吐量大大降低，从而使得整个 Flink 任务吞吐量降低。**如果每个服务器上有一两块 SSD，强烈建议将 RocksDB 的本地磁盘目录配置到 SSD 的目录下**，**从 HDD 改为 SSD 对于性能的提升可能比配置 10 个优化参数更有效。**\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1654662673431-6575b710-490c-49c4-bec7-f4b7964b3fc7.png)\n\n- **state.backend.incremental：**开启增量检查点，默认false，改为true。\n- **state.backend.rocksdb.predefined-options：**SPINNING_DISK_OPTIMIZED_HIGH_MEM设置为机械硬盘+内存模式，有条件上SSD，指定为FLASH_SSD_OPTIMIZED\n- **state.backend.rocksdb.block.cache-size**: 整个 RocksDB 共享一个 block cache，读数据时内存的 cache 大小，该参数越大读数据时缓存命中率越高，默认大小为 8 MB，建议设置到 64 ~ 256 MB。\n- **state.backend.rocksdb.thread.num**: 用于后台 flush 和合并 sst 文件的线程数，默认为 1，建议调大，机械硬盘用户可以改为 4 等更大的值。\n- **state.backend.rocksdb.writebuffer.size**: RocksDB 中，每个 State 使用一个 Column Family，每个 Column Family 使用独占的 write buffer，建议调大，例如：32M\n- **state.backend.rocksdb.writebuffer.count**: 每个 Column Family 对应的 writebuffer 数目，默认值是 2，对于机械磁盘来说，如果内存⾜够大，可以调大到 5 左右\n- **state.backend.rocksdb.writebuffer.number-to-merge**: 将数据从 writebuffer 中 flush 到磁盘时，需要合并的 writebuffer 数量，默认值为 1，可以调成3。\n- **state.backend.local-recovery**: 设置本地恢复，当 Flink 任务失败时，可以基于本地的状态信息进行恢复任务，可能不需要从 hdfs 拉取数据\n\n## Checkpoint设置\n\n一般我们的 Checkpoint 时间间隔可以设置为分钟级别（1~5分钟），例如 1 分钟、3 分钟，对于状态很大的任务每次 Checkpoint 访问 HDFS 比较耗时，可以设置为 5~10 分钟一次Checkpoint，并且调大两次 Checkpoint 之间的暂停间隔，例如设置两次Checkpoint 之间至少暂停 4或8 分钟。\n\n同时，也需要考虑时效性的要求,需要在时效性和性能之间做一个平衡，如果时效性要求高，结合 end- to-end 时长，设置秒级或毫秒级。\n\n如果 Checkpoint 语义配置为 EXACTLY_ONCE，那么在 Checkpoint 过程中还会存在 barrier 对齐的过程，可以通过 Flink Web UI 的 Checkpoint 选项卡来查看 Checkpoint 过程中各阶段的耗时情况，从而确定到底是哪个阶段导致 Checkpoint 时间过长然后针对性的解决问题。\n\nRocksDB相关参数在1.3中已说明，可以在flink-conf.yaml指定，也可以在Job的代码中调用API单独指定，这里不再列出。\n\n```scala\n// 使⽤ RocksDBStateBackend 做为状态后端，并开启增量 Checkpoint\nRocksDBStateBackend rocksDBStateBackend = new RocksDBStateBackend(\"hdfs://hadoop102:8020/flink/checkpoints\", true);\nenv.setStateBackend(rocksDBStateBackend);\n\n// 开启Checkpoint，间隔为 3 分钟\nenv.enableCheckpointing(TimeUnit.MINUTES.toMillis(3));\n// 配置 Checkpoint\nCheckpointConfig checkpointConf = env.getCheckpointConfig();\ncheckpointConf.setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE)\n// 最小间隔 4分钟\ncheckpointConf.setMinPauseBetweenCheckpoints(TimeUnit.MINUTES.toMillis(4))\n// 超时时间 10分钟\ncheckpointConf.setCheckpointTimeout(TimeUnit.MINUTES.toMillis(10));\n// 保存checkpoint\ncheckpointConf.enableExternalizedCheckpoints(\nCheckpointConfig.ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION);\n```\n\n# 反压处理\n\n## 3.1 概述\n\nFlink 网络流控及反压的介绍：\n\nhttps://flink-learning.org.cn/article/detail/138316d1556f8f9d34e517d04d670626\n\n### 3.1.1    反压的理解\n\n简单来说，Flink 拓扑中每个节点（Task）间的数据都以阻塞队列的方式传输，下游来不及消费导致队列被占满后，上游的生产也会被阻塞，最终导致数据源的摄入被阻塞。\n\n反压（BackPressure）通常产生于这样的场景：短时间的负载高峰导致系统接收数据的速率远高于它处理数据的速率。许多日常问题都会导致反压，例如，垃圾回收停顿可能会导致流入的数据快速堆积，或遇到大促、秒杀活动导致流量陡增。\n\n### 3.1.2    反压的危害\n\n反压如果不能得到正确的处理，可能会影响到 checkpoint时长和 state大小，甚至可能会导致资源耗尽甚至系统崩溃。\n\n- 1）影响 checkpoint 时长：barrier 不会越过普通数据，数据处理被阻塞也会导致checkpointbarrier 流经整个数据管道的时长变长，导致 checkpoint 总体时间（End toEndDuration）变长。\n- 2）影响 state 大小：barrier 对齐时，接受到较快的输入管道的 barrier 后，它后面数据会被缓存起来但不处理，直到较慢的输入管道的 barrier 也到达，这些被缓存的数据会被放到 state 里面，导致 checkpoint 变大。\n\n这两个影响对于生产环境的作业来说是十分危险的，因为 checkpoint 是保证数据一致性的关键，checkpoint 时间变长有可能导致 checkpoint**超时失败**，而 state 大小同样可能拖慢 checkpoint 甚至导致 **OOM**（使用 Heap-basedStateBackend）或者物理内存使用**超出容器资源**（使用 RocksDBStateBackend）的稳定性问题。\n\n**因此，我们在生产中要尽量避免出现反压的情况。**\n\n## 3.2 定位反压节点\n\n解决反压首先要做的是定位到造成反压的节点，排查的时候，先把operatorchain 禁用，方便定位到具体算子。\n\n\n\n提交UvDemo:\n\n> bin/flinkrun\\\n>\n> -tyarn-per-job\\\n>\n> -d\\\n>\n> -p5 \\\n>\n> -Drest.flamegraph.enabled=true\\\n>\n> -Dyarn.application.queue=test\\\n>\n> -Djobmanager.memory.process.size=1024mb \\\n>\n> -Dtaskmanager.memory.process.size=2048mb\\\n>\n> -Dtaskmanager.numberOfTaskSlots=2\\\n>\n> -ccom.atguigu.flink.tuning.UvDemo \\\n>\n> /opt/module/flink-1.13.1/myjar/flink-tuning-1.0-SNAPSHOT.jar\n\n### 3.2.1    利用 FlinkWebUI 定位\n\nFlinkWebUI 的反压监控提供了 SubTask 级别的反压监控，1.13 版本以前是通过周期性对  Task  线程的栈信息采样，得到线程被阻塞在请求  Buffer（意味着被下游队列阻塞）\n\n的频率来判断该节点是否处于反压状态。默认配置下，这个频率在 0.1以下则为 OK，0.1\n\n至 0.5为 LOW，而超过 0.5则为 HIGH。\n\nFlink1.13 优化了反压检测的逻辑（使用基于任务 Mailbox计时，而不在再于堆栈采样），并且重新实现了作业图的 UI展示：Flink现在在 UI 上通过颜色和数值来展示繁忙和反压的程度。\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1654674284140-b680f841-3ad4-4250-87fd-8c331333f1f5.png)\n\n1）通过WebUI看到 Map算子处于反压：\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1654674446026-5ec8c33c-cadc-44c9-9d00-b644899f52d6.png)\n\n3）分析瓶颈算子\n\n如果处于反压状态，那么有两种可能性：\n\n（1）  该节点的发送速率跟不上它的产生数据速率。这一般会发生在一条输入多条输出的 Operator（比如 flatmap）。这种情况，该节点是反压的根源节点，它是从 SourceTask到 Sink Task 的第一个出现反压的节点。**（很少出现，表现为：反压算子一进多出，后面的算子处理速度慢，从这个反压算子开始，后面的算子都反压了。图示，绿色为反压节点：**\n\n**（OK-> OK->** **反** **->反 -> 反 ）**\n\n**一进多出，输入缓存区使用率可能高也可能低，输出缓存区使用率高**\n\n（2）  下游的节点接受速率较慢，通过反压机制限制了该节点的发送速率。这种情况，需要继续排查下游节点，一直找到第一个为OK的一般就是根源节点。**（表现为：这个反压算子处理速度慢，阻塞了前面的算子，导致前面的算子反压了，其后面的算子表现为不反压。图示，绿色为反压节点：**\n\n​      **（反 -> 反 ->** **OK**-> OK-> OK）\n\n**输入缓存区使用率高，输出缓存区使用率低**\n\n总体来看，如果我们找到第一个出现反压的节点，反压根源要么是就这个节点，要么是它紧接着的下游节点。\n\n通常来讲，第二种情况更常见。如果无法确定，还需要结合 Metrics进一步判断。\n\n### 3.2.2    利用 Metrics 定位\n\n监控反压时会用到的 Metrics 主要和 Channel 接受端的 Buffer 使用率有关，最为\n\n有用的是以下几个 Metrics:\n\n| **Metris**                        | **描述**                        |\n| --------------------------------- | ------------------------------- |\n| outPoolUsage                      | 发送端 Buffer 的使用率          |\n| inPoolUsage                       | 接收端 Buffer 的使用率          |\n| floatingBuffersUsage（1.9 以上）  | 接收端 FloatingBuffer 的使用率  |\n| exclusiveBuffersUsage（1.9 以上） | 接收端 ExclusiveBuffer 的使用率 |\n\n其中 inPoolUsage = floatingBuffersUsage + exclusiveBuffersUsage。\n\n#### 1）根据指标分析反压\n\n分析反压的大致思路是：如果一个 Subtask 的发送端 Buffer占用率很高，则表明它被下游反压限速了；如果一个 Subtask 的接受端 Buffer 占用很高，则表明它将反压传导至上游。反压情况可以根据以下表格进行对号入座(1.9 以上):\n\n|                                            | **outPoolUsage** **低**                                      | **outPoolUsage** **高**                    |\n| ------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------ |\n| **inPoolUsage** **低**                     | 正常                                                         | 被下游反压，处于临时情况（还没传递到上游） |\n| 可能是反压的根源，一条输入多条输出的场景   |                                                              |                                            |\n| **inPoolUsage** **高**                     | 如果上游所有 outPoolUsage 都是低，有可能最终可能导致反压（还没传递到上游） | 被下游反压                                 |\n| 如果上游的 outPoolUsage 是高，则为反压根源 |                                                              |                                            |\n\n#### 2）可以进一步分析数据传输\n\nFlink1.9 及以上版本，还可以根据 floatingBuffersUsage/exclusiveBuffersUsage 以及其上游 Task 的 outPoolUsage 来进行进一步的分析一个 Subtask 和其上游Subtask 的数据传输。\n\n在流量较大时，Channel  的  ExclusiveBuffer  可能会被写满，此时  Flink  会向  BufferPool 申请剩余的 FloatingBuffer。这些 **FloatingBuffer 属于备用 Buffer。**\n\n\n\n|                                                              | **exclusiveBuffersUsage** **低**        | **exclusiveBuffersUsage** **高**                  |\n| ------------------------------------------------------------ | --------------------------------------- | ------------------------------------------------- |\n| **floatingBuffersUsage** **低**所有上游**outPoolUsage** **低** | 正常                                    |                                                   |\n| **floatingBuffersUsage** **低**上游某个**outPoolUsage** **高** | 潜在的网络瓶颈                          |                                                   |\n| **floatingBuffersUsage**高所有上游**outPoolUsage** **低**    | 最终对部分inputChannel 反压（正在传递） | 最终对大多数或所有   inputChannel反压（正在传递） |\n| **floatingBuffersUsage**高上游某个**outPoolUsage** **高**    | 只对部分 inputChannel 反压              | 对大多数或所有 inputChannel 反压                  |\n\n总结：\n\n- 1）floatingBuffersUsage 为高，则表明反压正在传导至上游\n- 2）同时 exclusiveBuffersUsage 为低，则表明可能有倾斜\n\n\n\n比如，floatingBuffersUsage 高、exclusiveBuffersUsage 低为有倾斜，因为少数\n\nchannel 占用了大部分的 FloatingBuffer。\n\n## 3.3 反压的原因及处理\n\n注意：反压可能是暂时的，可能是由于负载高峰、CheckPoint 或作业重启引起的数据积压而导致反压。如果反压是暂时的，应该忽略它。另外，请记住，断断续续的反压会影响我们分析和解决问题。\n\n定位到反压节点后，分析造成原因的办法主要是观察 TaskThread。按照下面的顺序，一步一步去排查。\n\n### 3.3.1    查看是否数据倾斜\n\n**在实践中，很多情况下的反压是由于数据倾斜造成的，这点我们可以通过 Web UI各**\n\n**个 SubTask 的 RecordsSent 和 RecordReceived 来确认，另外 Checkpointdetail里不同 SubTask 的 Statesize 也是一个分析数据倾斜的有用指标。**\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1654675365111-f2598a4c-7ae6-4c6b-852b-a2c31b53623e.png)\n\n（关于数据倾斜的详细解决方案，会在下一章节详细讨论）\n\n### 3.3.2    使用火焰图分析\n\n如果不是数据倾斜，最常见的问题可能是用户代码的执行效率问题（频繁被阻塞或者性能问题），需要找到瓶颈算子中的哪部分计算逻辑消耗巨大。\n\n最有用的办法就是对 TaskManager 进行 CPUprofile，从中我们可以分析到 TaskThread 是否跑满一个 CPU 核：如果是的话要分析 CPU 主要花费在哪些函数里面；如果不是的话要看 TaskThread 阻塞在哪里，可能是用户函数本身有些同步的调用，可能是checkpoint 或者 GC 等系统活动导致的暂时系统暂停。\n\n#### 1）开启火焰图功能\n\nFlink1.13直接在 WebUI提供 JVM的 CPU 火焰图，这将大大简化性能瓶颈的分析，默认是不开启的，需要修改参数：\n\nrest.flamegraph.enabled:true#默认false                                                                          \n\n\n\n也可以在提交时指定：\n\n> bin/flinkrun\\\n>\n> -tyarn-per-job\\\n>\n> -d\\\n>\n> -p5 \\\n>\n> -Drest.flamegraph.enabled=true\\\n>\n> -Dyarn.application.queue=test\\\n>\n> -Drest.flamegraph.enabled=true\\\n>\n> -Djobmanager.memory.process.size=1024mb \\\n>\n> -Dtaskmanager.memory.process.size=2048mb\\\n>\n> -Dtaskmanager.numberOfTaskSlots=2\\\n>\n> -ccom.atguigu.flink.tuning.UvDemo \\\n>\n> /opt/module/flink-1.13.1/myjar/flink-tuning-1.0-SNAPSHOT.jar\n\n#### 2）WebUI 查看火焰图\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1654675647317-7df4c4eb-e01f-4637-9d0e-a9980331f2c2.png)\n\n火焰图是通过对堆栈跟踪进行多次采样来构建的。每个方法调用都由一个条形表示，其中条形的长度与其在样本中出现的次数成正比。\n\n- On-CPU: 处于 [RUNNABLE, NEW]状态的线程\n- Off-CPU: 处于 [TIMED_WAITING, WAITING, BLOCKED]的线程，用于查看在样本中发现的阻塞调用。\n\n#### 3）分析火焰图\n\n颜色没有特殊含义，具体查看：\n\n- 纵向是调用链，从下往上，顶部就是正在执行的函数\n- 横向是样本出现次数，可以理解为执行时长。\n\n**看顶层的哪个函数占据的宽度最大。只要有\"平顶\"（plateaus），就表示该函数可能存在性能问题。**\n\n如果是 Flink1.13 以前的版本，可以手动做火焰图：\n\n如何生成火焰图：http://www.54tianzhisheng.cn/2020/10/05/flink-jvm-profiler/\n\n### 3.3.3    分析GC 情况\n\nTaskManager 的内存以及 GC 问题也可能会导致反压，包括 TaskManagerJVM 各区内存不合理导致的频繁 FullGC 甚至失联。通常建议使用默认的 G1 垃圾回收器。\n\n可以通过打印 GC 日志（-XX:+PrintGCDetails），使用 GC 分析器（GCViewer 工具）来验证是否处于这种情况。\n\n\n\n- 在 Flink 提交脚本中,设置 JVM 参数，打印 GC 日志：\n\n> bin/flinkrun\\\n>\n> -tyarn-per-job\\\n>\n> -d\\\n>\n> -p5 \\\n>\n> -Drest.flamegraph.enabled=true\\\n>\n> -Denv.java.opts=\"-XX:+PrintGCDetails-XX:+PrintGCDateStamps\"\\\n>\n> -Dyarn.application.queue=test\\\n>\n> -Djobmanager.memory.process.size=1024mb \\\n>\n> -Dtaskmanager.memory.process.size=2048mb\\\n>\n> -Dtaskmanager.numberOfTaskSlots=2\\\n>\n> -ccom.atguigu.flink.tuning.UvDemo \\\n>\n> /opt/module/flink-1.13.1/myjar/flink-tuning-1.0-SNAPSHOT.jar\n\n\n\n- 下载 GC 日志的方式：\n\n因为是 onyarn 模式，运行的节点一个一个找比较麻烦。可以打开 WebUI，选择JobManager 或者 TaskManager，点击 Stdout，即可看到 GC 日志，点击下载按钮即可将 GC日志通过 HTTP的方式下载下来。\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1654679097595-18b82b7c-8bd5-4d21-b720-44c795ce377a.png)\n\n- 分析 GC 日志：\n\n通过 GC 日志分析出单个 FlinkTaskmanager 堆总大小、年轻代、老年代分配的内存空间、FullGC 后老年代剩余大小等，相关指标定义可以去 Github 具体查看。\n\nGCViewer 地址：https://github.com/chewiebug/GCViewer\n\nLinux 下分析：\n\njava -jargcviewer_1.3.4.jargc.log                                                                                    \n\nWindows 下分析：\n\n直接双击gcviewer_1.3.4.jar，打开GUI界面，选择gc的log打开         \n\n​                      \n\n扩展：最重要的指标是FullGC 后，老年代剩余大小这个指标，按照《Java 性能优化权威指南》这本书 Java 堆大小计算法则，设 FullGC 后老年代剩余大小空间为 M，那么堆的大小建议 3~4 倍 M，新生代为 1~1.5 倍 M，老年代应为 2~3 倍 M。\n\n### 3.3.4    外部组件交互\n\n如果发现我们的 Source端数据读取性能比较低或者 Sink端写入性能较差，需要检查第三方组件是否遇到瓶颈，还有就是做维表join时的性能问题。\n\n例如：\n\nKafka集群是否需要扩容，Kafka 连接器是否并行度较低\n\nHBase的 rowkey 是否遇到热点问题，是否请求处理不过来\n\nClickHouse并发能力较弱，是否达到瓶颈\n\n……\n\n关于第三方组件的性能问题，需要结合具体的组件来分析，最常用的思路：\n\n- 1）异步 io+热缓存来优化读写性能\n- 2）先攒批再读写维表join参考：\n\nhttps://flink-learning.org.cn/article/detail/b8df32fbc6542257a5b449114e137cc3\n\nhttps://www.jianshu.com/p/a62fa483ff54\n\n\n\n# 四、数据倾斜\n\n## 4.1  判断是否存在数据倾斜\n\n相同 Task 的多个 Subtask 中， 个别 Subtask 接收到的数据量明显大于其他Subtask 接收到的数据量，通过 FlinkWebUI 可以精确地看到每个 Subtask 处理了多少数据，即可判断出 Flink 任务是否存在数据倾斜。通常，数据倾斜也会引起反压。\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1654692839400-88f4eb2d-9389-4011-a676-2f6da336cb39.png)\n\n另外， 有时 Checkpointdetail 里不同 SubTask 的 Statesize 也是一个分析数据倾斜的有用指标。\n\n## 4.2 数据倾斜的解决\n\n### 4.2.1    keyBy 后的聚合操作存在数据倾斜\n\n#### 1）为什么不能直接用二次聚合来处理（没有卵用）\n\nFlink是实时流处理，如果keyby之后的聚合操作存在数据倾斜，且没有开窗口（没攒批）的情况下，简单的认为使用两阶段聚合，是不能解决问题的。因为这个时候Flink是来一条处理一条，且向下游发送一条结果，对于原来 keyby的维度（第二阶段聚合）来讲，数据量并没有减少，且结果重复计算（非 FlinkSQL，未使用回撤流），如下图所示：\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1654692995562-f3b6caac-04e3-45ac-87bc-92286cb10e2b.png)\n\n#### 2）使用 LocalKeyBy 的思想\n\n在 keyBy 上游算子数据发送之前，首先在上游算子的本地对数据进行聚合后，再发送到下游，使下游接收到的数据量大大减少，从而使得 keyBy 之后的聚合操作不再是任务的瓶颈。类似 MapReduce中 Combiner的思想，但是这要求聚合操作必须是多条数据或者一批数据才能聚合，单条数据没有办法通过聚合来减少数据量。从 FlinkLocalKeyBy实现原理来讲，必然会存在一个积攒批次的过程，在上游算子中必须攒够一定的数据量，对这些数据聚合后再发送到下游。\n\n#### 实现方式：\n\n- DataStreamAPI 需要自己写代码实现\n- SQL 可以指定参数，开启miniBatch 和 LocalGlobal 功能（推荐，后续介绍）\n\n### 4.1.1    keyBy之前发生数据倾斜\n\n如果 keyBy 之前就存在数据倾斜，上游算子的某些实例可能处理的数据较多，某些实例可能处理的数据较少，产生该情况可能是因为数据源的数据本身就不均匀，例如由于某些原因 Kafka 的 topic 中某些 partition 的数据量较大，某些 partition 的数据量较少。\n\n对于不存在 keyBy 的 Flink 任务也会出现该情况。\n\n这种情况，需要让 Flink 任务强制进行shuffle。使用 shuffle、rebalance 或 rescale\n\n算子即可将数据均匀分配，从而解决数据倾斜的问题。\n\n### 4.1.2    keyBy 后的窗口聚合操作存在数据倾斜\n\n因为使用了窗口，变成了有界数据（攒批）的处理，窗口默认是触发时才会输出一条结果发往下游，所以可以使用两阶段聚合的方式：\n\n#### 1）实现思路：\n\n- 第一阶段聚合：key拼接随机数前缀或后缀，进行 keyby、开窗、聚合\n\n**注意：聚合完不再是 WindowedStream，要获取 WindowEnd 作为窗口标记作为第二阶段分组依据，避免不同窗口的结果聚合到一起）**\n\n- 第二阶段聚合：按照原来的 key 及windowEnd 作keyby、聚合\n\nSQL写法参考：https://zhuanlan.zhihu.com/p/197299746\n","source":"_posts/bigdata/Flink调优.md","raw":"---\ntitle: Flink调优\ntags:\n  - 'Flink'\n  - '调优'\ncategories:\n  - [bigdata,Flink]\ntop_img: '/img/bg/banner.gif'\ndate: 2022-08-08 20:23:04\nupdated: 2022-08-08 20:23:04\ncover:\ndescription:\nkeywords:\n---\n\n# 内存设置（1CPU配置4G内存）\n\n> bin/flink run \\\n>\n> -t yarn-per-job \\\n>\n> -d \\\n>\n> -p 5 \\ 指定并行度\n>\n> -Dyarn.application.queue=test \\ 指定yarn队列\n>\n> -Djobmanager.memory.process.size=2048mb \\ JM2~4G足够\n>\n> -Dtaskmanager.memory.process.size=6144mb \\ 单个TM2~8G足够\n>\n> -Dtaskmanager.numberOfTaskSlots=2 \\ **与容器核数1core：1slot或1core：2slot**\n>\n> -c com.atguigu.app.dwd.LogBaseApp \\\n>\n> /opt/module/gmall-flink/gmall-realtime-1.0-SNAPSHOT-jar-with-dependencies.jar\n\nFlink是实时流处理，关键在于资源情况能不能抗住高峰时期每秒的数据量，通常用QPS/TPS来描述数据情况。\n\n##  TaskManager 内存模型  \n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1654665961981-86c260ab-5310-4674-ac61-6a1d1f738f18.png)\n\n### 1、内存模型详解\n\n#### JVM 特定内存：JVM 本身使用的内存，包含 JVM 的 metaspace 和 over-head\n\n1）JVMmetaspace：JVM 元空间\n\ntaskmanager.memory.jvm-metaspace.size，默认 256mb\n\n\n\n2）JVMover-head执行开销：JVM执行时自身所需要的内容，包括线程堆栈、IO、编译缓存等所使用的内存。\n\ntaskmanager.memory.jvm-overhead.fraction，默认 0.1\n\ntaskmanager.memory.jvm-overhead.min，默认 192mb\n\ntaskmanager.memory.jvm-overhead.max，默认 1gb\n\n\n\n**总进程内存\\*fraction，如果小于配置的 min（或大于配置的 max）大小，则使用 min/max**\n\n**大小**\n\n\n\n#### 框架内存：Flink 框架，即 TaskManager 本身所占用的内存，不计入 Slot 的资源中。\n\n堆内：taskmanager.memory.framework.heap.size，默认 128MB\n\n堆外：taskmanager.memory.framework.off-heap.size，默认 128MB\n\n#### Task内存：Task执行用户代码时所使用的内存\n\n堆内：taskmanager.memory.task.heap.size，默认 none，由 Flink 内存扣除掉其他部分的内存得到。\n\n堆外：taskmanager.memory.task.off-heap.size，默认 0，表示不使用堆外内存\n\n#### 网络内存：网络数据交换所使用的堆外内存大小，如网络数据交换缓冲区\n\n**堆外：**\n\ntaskmanager.memory.network.fraction，默认 0.1\n\ntaskmanager.memory.network.min，默认 64mb\n\ntaskmanager.memory.network.max，默认 1gb\n\n**Flink 内存\\*fraction，如果小于配置的 min（或大于配置的 max）大小，则使用 min/max大小**\n\n  \n\n#### 托管内存：用于 RocksDBStateBackend 的本地内存和批的排序、哈希表、缓存中间结果。\n\n堆外：taskmanager.memory.managed.fraction，默认 0.4\n\ntaskmanager.memory.managed.size，默认 none\n\n**如果 size 没指定，则等于 Flink 内存\\*fraction**\n\n## 2、案例分析  \n\n基于Yarn模式，一般参数指定的是总进程内存，taskmanager.memory.process.size，比如指定为 4G，每一块内存得到大小如下：\n\n（1）计算 Flink 内存\n\nJVM 元空间 256m\n\nJVM 执行开销： 4g*0.1=409.6m，在[192m,1g]之间，最终结果 409.6m\n\nFlink 内存=4g-256m-409.6m=3430.4m\n\n（2）网络内存=3430.4m*0.1=343.04m，在[64m,1g]之间，最终结果 343.04m\n\n（3）托管内存=3430.4m*0.4=1372.16m\n\n（4）框架内存，堆内和堆外都是 128m\n\n（5）Task堆内内存=3430.4m-128m-128m-343.04m-1372.16m=1459.2m\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1654667261844-9b48b348-1bcb-4ca8-b556-f63a3680cf83.png)\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1654667279269-d43c4812-9561-433a-83fe-a8d70b5fb5b9.png)\n\n### 所以进程内存给多大，每一部分内存需不需要调整，可以看内存的使用率来调整。\n\n## 合理利用 cpu 资源\n\nYarn 的**容量调度器**默认情况下是使用“DefaultResourceCalculator”分配策略，只根据内存调度资源，所以在 Yarn 的资源管理页面上看到每个容器的 vcore 个数还是 1。\n\n可以修改策略为 DominantResourceCalculator，该资源计算器在计算资源的时候会综合考虑 cpu 和内存的情况。在capacity-scheduler.xml 中修改属性:\n\n```xml\n<property>\n  <name>yarn.scheduler.capacity.resource-calculator</name>\n  <!-- <value>org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator</value> -->\n  <value>org.apache.hadoop.yarn.util.resource.DominantResourceCalculator</value>\n</property>\n```\n\n### 1.1.1    使用DefaultResourceCalculator 策略\n\n```shell\nbin/flink run \\\n-t yarn-per-job \\\n-d \\\n-p 5 \\\n-Drest.flamegraph.enabled=true \\\n-Dyarn.application.queue=test \\\n-Djobmanager.memory.process.size=1024mb \\\n-Dtaskmanager.memory.process.size=4096mb \\\n-Dtaskmanager.numberOfTaskSlots=2 \\\n-c com.atguigu.flink.tuning.UvDemo \\\n/opt/module/flink-1.13.1/myjar/flink-tuning-1.0-SNAPSHOT.jar\n```\n\n可以看到一个容器只有一个 vcore：\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1654668251950-033e4bc0-4b65-4fe8-b309-45a29956922b.png)\n\n### 1.1.2    使用DominantResourceCalculator 策略\n\n修改后 yarn 配置后，分发配置并重启 yarn，再次提交 flink 作业：\n\n> bin/flinkrun\\\n>\n> -tyarn-per-job\\\n>\n> -d\\\n>\n> -p5\\\n>\n> -Drest.flamegraph.enabled=true\\\n>\n> -Dyarn.application.queue=test\\\n>\n> -Djobmanager.memory.process.size=1024mb \\\n>\n> -Dtaskmanager.memory.process.size=4096mb\\\n>\n> -Dtaskmanager.numberOfTaskSlots=2\\\n>\n> -ccom.atguigu.flink.tuning.UvDemo\\\n>\n> /opt/module/flink-1.13.1/myjar/flink-tuning-1.0-SNAPSHOT.jar\n\n看到容器的 vcore 数变了:\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1654668344371-82744e2d-89b2-4fab-8a09-f77475df1088.png)\n\nJobManager1 个，占用 1 个容器，vcore=1\n\nTaskManager3 个，占用 3 个容器，每个容器 vcore=2，总 vcore=2*3=6，因为默认单个容器的 vcore 数=单 TM 的slot 数\n\n### 1.1.3    使用 DominantResourceCalculator 策略并指定容器**vcore 数**\n\n指定yarn 容器的 vcore 数，提交：\n\n> bin/flinkrun\\\n>\n> -tyarn-per-job\\\n>\n> -d\\\n>\n> -p5\\\n>\n> -Drest.flamegraph.enabled=true\\\n>\n> -Dyarn.application.queue=test\\\n>\n> -Dyarn.containers.vcores=3\\\n>\n>  -Djobmanager.memory.process.size=1024mb \\ -Dtaskmanager.memory.process.size=4096mb \\ -Dtaskmanager.numberOfTaskSlots=2 \\ -c com.atguigu.flink.tuning.UvDemo \\ /opt/module/flink-1.13.1/myjar/flink-tuning-1.0-SNAPSHOT.jar  \n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1654668509233-7292aa6f-0e54-4799-ba38-ab72659ef824.png)\n\nJobManager1 个，占用 1 个容器，vcore=1\n\nTaskManager3 个，占用 3 个容器，每个容器vcore =3，总 vcore=3*3=9\n\n# RocksDB大状态调优\n\nRocksDB 是基于 LSM Tree 实现的（类似HBase），写数据都是先缓存到内存中，所以RocksDB 的写请求效率比较高。RocksDB 使用内存结合磁盘的方式来存储数据，每次获取数据时，先从内存中 blockcache 中查找，如果内存中没有再去磁盘中查询。优化后差不多单并行度 TPS 5000 record/s。**使用RocksDB 时，状态大小仅受可用磁盘空间量的限制，性能瓶颈主要在于 RocksDB对磁盘的读请求，每次读写操作都必须对数据进行反序列化或者序列化。**所以当处理性能不够时，仅需要横向扩展并行度即可提高整个Job 的吞吐量。\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1654669015363-a35261ab-d4ff-4068-a013-eecfe78a5c7d.png)\n\n\n\n从 Flink1.10 开始，Flink 默认将 RocksDB 的内存大小配置为每个 taskslot 的托管内存。调试内存性能的问题主要是通过调整配置项 taskmanager.memory.managed.size或者 taskmanager.memory.managed.fraction以增加 Flink 的托管内存(即堆外的托管内存)。进一步可以调整一些参数进行高级性能调优，这些参数也可以在应用程序中通过RocksDBStateBackend.setRocksDBOptions(RocksDBOptionsFactory)指定。下面介绍\n\n提高资源利用率的几个重要配置：\n\n### 2.1.1   开启State访问性能监控\n\nFlink 1.13 中引入了 State 访问的性能监控，即 latency trackig state。此功能不局限于 StateBackend 的类型，自定义实现的 StateBackend 也可以复用此功能。\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1654670053632-0e169f44-1340-4202-ab6a-bd9a6173a14a.png)\n\nState访问性能监控会产生一定的性能影响，所以，默认每 100次做一次取样(sample)，对不同的 StateBackend 性能损失影响不同：\n\n- 对于 RocksDBStateBackend，性能损失大概在 1% 左右\n- 对于 HeapStateBackend，性能损失最多可达 10%\n\n```yaml\nstate.backend.latency-track.keyed-state-enabled：true #启用访问状态的性能监控 \nstate.backend.latency-track.sample-interval: 100 #采样间隔 \nstate.backend.latency-track.history-size: 128 #保留的采样数据个数，越大越精确 \nstate.backend.latency-track.state-name-as-variable: true #将状态名作为变量  \n```\n\n正常开启第一个参数即可。\n\n> bin/flink run \\\n>\n> -t yarn-per-job \\\n>\n> -d \\\n>\n> -p 5 \\\n>\n> -Drest.flamegraph.enabled=true \\\n>\n> -Dyarn.application.queue=test \\\n>\n> -Djobmanager.memory.process.size=1024mb \\\n>\n> -Dtaskmanager.memory.process.size=4096mb \\\n>\n> -Dtaskmanager.numberOfTaskSlots=2 \\\n>\n>  -Dstate.backend.latency-track.keyed-state-enabled=true \\ \n>\n> -c com.atguigu.flink.tuning.RocksdbTuning \\ /opt/module/flink-1.13.1/myjar/flink-tuning-1.0-SNAPSHOT.jar  \n\n### 2.1.2    开启增量检查点和本地恢复\n\n1）开启增量检查点\n\nRocksDB 是目前唯一可用于支持有状态流处理应用程序增量检查点的状态后端，可以修改参数开启增量检查点：\n\nstate.backend.incremental: true #默认 false，改为 true。 \n\n或代码中指定 new EmbeddedRocksDBStateBackend(true)  \n\n2）开启本地恢复\n\n当 Flink任务失败时，可以基于本地的状态信息进行恢复任务，可能不需要从 hdfs拉取数据。本地恢复目前仅涵盖键控类型的状态后端（RocksDB），MemoryStateBackend不支持本地恢复并忽略此选项。\n\nstate.backend.local-recovery:true\n\n### 2.1.3    调整预定义选项\n\nFlink针对不同的设置为 RocksDB提供了一些预定义的选项集合,其中包含了后续提到的一些参数，如果调整预定义选项后还达不到预期，再去调整后面的 block、writebuffer等参数。\n\n当 前 支 持 的 预 定 义 选 项 有   DEFAULT 、 SPINNING_DISK_OPTIMIZED 、\n\nSPINNING_DISK_OPTIMIZED_HIGH_MEM 或FLASH_SSD_OPTIMIZED。有条件上 SSD\n\n的，可以指定为 FLASH_SSD_OPTIMIZED\n\n state.backend.rocksdb.predefined-options： SPINNING_DISK_OPTIMIZED_HIGH_MEM #设置为机械硬盘+内存模式  \n\n### 2.1.4    增大 block 缓存\n\n整个 RocksDB 共享一个 blockcache，读数据时内存的 cache 大小，该参数越大读\n\n数据时缓存命中率越高，默认大小为8MB，建议设置到64~256MB。\n\nstate.backend.rocksdb.block.cache-size:64m     #默认8m  \n\n### 2.1.5    增大writebuffer 和 level 阈值大小\n\nRocksDB 中，每个 State 使用一个 ColumnFamily，每个 ColumnFamily 使用独占的 writebuffer，默认 64MB，建议调大。\n\n调整这个参数通常要适当增加 L1层的大小阈值 max-size-level-base，默认 256m。\n\n该值太小会造成能存放的 SST 文件过少，层级变多造成查找困难，太大会造成文件过多，合并困难。建议设为 target_file_size_base（默认 64MB） 的倍数，且不能太小，例如 5~10倍，即 320~640MB。\n\nstate.backend.rocksdb.writebuffer.size: 128m\n\nstate.backend.rocksdb.compaction.level.max-size-level-base:320m   \n\n### 2.1.6    增大write buffer 数量\n\n每个 ColumnFamily对应的 writebuffer 最大数量，这实际上是内存中“只读内存表“的最大数量，默认值是 2。对于机械磁盘来说，如果内存足够大，可以调大到 5左右\n\nstate.backend.rocksdb.writebuffer.count:5                                                                     \n\n### 2.1.7    增大后台线程数和writebuffer 合并数\n\n1）增大线程数\n\n用于后台 flush和合并 sst文件的线程数，默认为 1，建议调大，机械硬盘用户可以改为 4等更大的值\n\nstate.backend.rocksdb.thread.num: 4                                                                             \n\n2）增大writebuffer 最小合并数\n\n将数据从 writebuffer 中 flush 到磁盘时，需要合并的 writebuffer 最小数量，默认\n\n值为 1，可以调成 3。\n\nstate.backend.rocksdb.writebuffer.number-to-merge:3                                             \n\n### 2.1.8    开启分区索引功能\n\nFlink1.13 中对 RocksDB 增加了分区索引功能，复用了 RocksDB 的partitionedIndex&filter 功能，简单来说就是对 RocksDB 的 partitionedIndex 做了多级索引。也就是将内存中的最上层常驻，下层根据需要再 load回来，这样就大大降低了数据 Swap竞争。线上测试中，相对于**内存比较小**的场景中，性能提升 10 倍左右。如果在内存管控下 Rocksdb 性能不如预期的话，这也能成为一个性能优化点。\n\nstate.backend.rocksdb.memory.partitioned-index-filters:true   #默认false                \n\n\n\n**2.1.9**    **参数设定案例**\n\n```sh\nbin/flinkrun\\\n-tyarn-per-job\\\n-d\\\n-p5\\\n-Drest.flamegraph.enabled=true\\\n-Dyarn.application.queue=test\\\n-Djobmanager.memory.process.size=1024mb \\\n-Dtaskmanager.memory.process.size=4096mb\\\n-Dtaskmanager.numberOfTaskSlots=2\\\n-Dstate.backend.incremental=true\\\n-Dstate.backend.local-recovery=true\\\n-Dstate.backend.rocksdb.predefined-options=SPINNING_DISK_OPTIMIZED_HIGH_MEM\\\n-Dstate.backend.rocksdb.block.cache-size=64m\\\n-Dstate.backend.rocksdb.writebuffer.size=128m\\\n-Dstate.backend.rocksdb.compaction.level.max-size-level-base=320m\\\n-Dstate.backend.rocksdb.writebuffer.count=5 \\\n-Dstate.backend.rocksdb.thread.num=4\\\n-Dstate.backend.rocksdb.writebuffer.number-to-merge=3\\\n-Dstate.backend.rocksdb.memory.partitioned-index-filters=true\\\n-Dstate.backend.latency-track.keyed-state-enabled=true\\\n-ccom.atguigu.flink.tuning.RocksdbTuning\\\n/opt/module/flink-1.13.1/myjar/flink-tuning-1.0-SNAPSHOT.jar\n```\n\n\n\n### 设置本地 RocksDB 多目录\n\n在flink-conf.yaml 中配置：\n\n```plain\nstate.backend.rocksdb.localdir: /data1/flink/rocksdb,/data2/flink/rocksdb,/data3/flink/rocksdb\n```\n\n\n\n注意：不要配置单块磁盘的多个目录，务必将目录配置到多块不同的磁盘上，让多块磁盘来分担压力。**当设置多个 RocksDB 本地磁盘目录时，Flink 会****随机选择****要使用的目录，所以就可能存在三个并行度共用同一目录的情况。**如果服务器磁盘数较多，一般不会出现该情况，但是如果任务重启后吞吐量较低，可以检查是否发生了多个并行度共用同一块磁盘的情况。\n\n**当一个 TaskManager 包含 3 个 slot 时，那么单个服务器上的三个并行度都对磁盘造成频繁读写，从而导致三个并行度的之间相互争抢同一个磁盘 io，这样务必导致三个并行度的吞吐量都会下降。设置多目录实现三个并行度使用不同的硬盘从而减少资源竞争。**\n\n如下所示是测试过程中磁盘的 IO 使用率，可以看出三个大状态算子的并行度分别对应了三块磁盘，这三块磁盘的 IO 平均使用率都保持在 45% 左右，IO 最高使用率几乎都是 100%，而其他磁盘的 IO 平均使用率相对低很多。**由此可见使用 RocksDB 做为状态后端且有大状态的频繁读取时， 对磁盘IO性能消耗确实比较大。**\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1654662632337-7fe1e6c6-5fe2-412e-82e8-77f3c81458b7.png)\n\n如下图所示，其中两个并行度共用了 sdb 磁盘，一个并行度使用 sdj磁盘。可以看到 sdb 磁盘的 IO 使用率已经达到了 91.6%，就会导致 sdb 磁盘对应的两个并行度吞吐量大大降低，从而使得整个 Flink 任务吞吐量降低。**如果每个服务器上有一两块 SSD，强烈建议将 RocksDB 的本地磁盘目录配置到 SSD 的目录下**，**从 HDD 改为 SSD 对于性能的提升可能比配置 10 个优化参数更有效。**\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1654662673431-6575b710-490c-49c4-bec7-f4b7964b3fc7.png)\n\n- **state.backend.incremental：**开启增量检查点，默认false，改为true。\n- **state.backend.rocksdb.predefined-options：**SPINNING_DISK_OPTIMIZED_HIGH_MEM设置为机械硬盘+内存模式，有条件上SSD，指定为FLASH_SSD_OPTIMIZED\n- **state.backend.rocksdb.block.cache-size**: 整个 RocksDB 共享一个 block cache，读数据时内存的 cache 大小，该参数越大读数据时缓存命中率越高，默认大小为 8 MB，建议设置到 64 ~ 256 MB。\n- **state.backend.rocksdb.thread.num**: 用于后台 flush 和合并 sst 文件的线程数，默认为 1，建议调大，机械硬盘用户可以改为 4 等更大的值。\n- **state.backend.rocksdb.writebuffer.size**: RocksDB 中，每个 State 使用一个 Column Family，每个 Column Family 使用独占的 write buffer，建议调大，例如：32M\n- **state.backend.rocksdb.writebuffer.count**: 每个 Column Family 对应的 writebuffer 数目，默认值是 2，对于机械磁盘来说，如果内存⾜够大，可以调大到 5 左右\n- **state.backend.rocksdb.writebuffer.number-to-merge**: 将数据从 writebuffer 中 flush 到磁盘时，需要合并的 writebuffer 数量，默认值为 1，可以调成3。\n- **state.backend.local-recovery**: 设置本地恢复，当 Flink 任务失败时，可以基于本地的状态信息进行恢复任务，可能不需要从 hdfs 拉取数据\n\n## Checkpoint设置\n\n一般我们的 Checkpoint 时间间隔可以设置为分钟级别（1~5分钟），例如 1 分钟、3 分钟，对于状态很大的任务每次 Checkpoint 访问 HDFS 比较耗时，可以设置为 5~10 分钟一次Checkpoint，并且调大两次 Checkpoint 之间的暂停间隔，例如设置两次Checkpoint 之间至少暂停 4或8 分钟。\n\n同时，也需要考虑时效性的要求,需要在时效性和性能之间做一个平衡，如果时效性要求高，结合 end- to-end 时长，设置秒级或毫秒级。\n\n如果 Checkpoint 语义配置为 EXACTLY_ONCE，那么在 Checkpoint 过程中还会存在 barrier 对齐的过程，可以通过 Flink Web UI 的 Checkpoint 选项卡来查看 Checkpoint 过程中各阶段的耗时情况，从而确定到底是哪个阶段导致 Checkpoint 时间过长然后针对性的解决问题。\n\nRocksDB相关参数在1.3中已说明，可以在flink-conf.yaml指定，也可以在Job的代码中调用API单独指定，这里不再列出。\n\n```scala\n// 使⽤ RocksDBStateBackend 做为状态后端，并开启增量 Checkpoint\nRocksDBStateBackend rocksDBStateBackend = new RocksDBStateBackend(\"hdfs://hadoop102:8020/flink/checkpoints\", true);\nenv.setStateBackend(rocksDBStateBackend);\n\n// 开启Checkpoint，间隔为 3 分钟\nenv.enableCheckpointing(TimeUnit.MINUTES.toMillis(3));\n// 配置 Checkpoint\nCheckpointConfig checkpointConf = env.getCheckpointConfig();\ncheckpointConf.setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE)\n// 最小间隔 4分钟\ncheckpointConf.setMinPauseBetweenCheckpoints(TimeUnit.MINUTES.toMillis(4))\n// 超时时间 10分钟\ncheckpointConf.setCheckpointTimeout(TimeUnit.MINUTES.toMillis(10));\n// 保存checkpoint\ncheckpointConf.enableExternalizedCheckpoints(\nCheckpointConfig.ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION);\n```\n\n# 反压处理\n\n## 3.1 概述\n\nFlink 网络流控及反压的介绍：\n\nhttps://flink-learning.org.cn/article/detail/138316d1556f8f9d34e517d04d670626\n\n### 3.1.1    反压的理解\n\n简单来说，Flink 拓扑中每个节点（Task）间的数据都以阻塞队列的方式传输，下游来不及消费导致队列被占满后，上游的生产也会被阻塞，最终导致数据源的摄入被阻塞。\n\n反压（BackPressure）通常产生于这样的场景：短时间的负载高峰导致系统接收数据的速率远高于它处理数据的速率。许多日常问题都会导致反压，例如，垃圾回收停顿可能会导致流入的数据快速堆积，或遇到大促、秒杀活动导致流量陡增。\n\n### 3.1.2    反压的危害\n\n反压如果不能得到正确的处理，可能会影响到 checkpoint时长和 state大小，甚至可能会导致资源耗尽甚至系统崩溃。\n\n- 1）影响 checkpoint 时长：barrier 不会越过普通数据，数据处理被阻塞也会导致checkpointbarrier 流经整个数据管道的时长变长，导致 checkpoint 总体时间（End toEndDuration）变长。\n- 2）影响 state 大小：barrier 对齐时，接受到较快的输入管道的 barrier 后，它后面数据会被缓存起来但不处理，直到较慢的输入管道的 barrier 也到达，这些被缓存的数据会被放到 state 里面，导致 checkpoint 变大。\n\n这两个影响对于生产环境的作业来说是十分危险的，因为 checkpoint 是保证数据一致性的关键，checkpoint 时间变长有可能导致 checkpoint**超时失败**，而 state 大小同样可能拖慢 checkpoint 甚至导致 **OOM**（使用 Heap-basedStateBackend）或者物理内存使用**超出容器资源**（使用 RocksDBStateBackend）的稳定性问题。\n\n**因此，我们在生产中要尽量避免出现反压的情况。**\n\n## 3.2 定位反压节点\n\n解决反压首先要做的是定位到造成反压的节点，排查的时候，先把operatorchain 禁用，方便定位到具体算子。\n\n\n\n提交UvDemo:\n\n> bin/flinkrun\\\n>\n> -tyarn-per-job\\\n>\n> -d\\\n>\n> -p5 \\\n>\n> -Drest.flamegraph.enabled=true\\\n>\n> -Dyarn.application.queue=test\\\n>\n> -Djobmanager.memory.process.size=1024mb \\\n>\n> -Dtaskmanager.memory.process.size=2048mb\\\n>\n> -Dtaskmanager.numberOfTaskSlots=2\\\n>\n> -ccom.atguigu.flink.tuning.UvDemo \\\n>\n> /opt/module/flink-1.13.1/myjar/flink-tuning-1.0-SNAPSHOT.jar\n\n### 3.2.1    利用 FlinkWebUI 定位\n\nFlinkWebUI 的反压监控提供了 SubTask 级别的反压监控，1.13 版本以前是通过周期性对  Task  线程的栈信息采样，得到线程被阻塞在请求  Buffer（意味着被下游队列阻塞）\n\n的频率来判断该节点是否处于反压状态。默认配置下，这个频率在 0.1以下则为 OK，0.1\n\n至 0.5为 LOW，而超过 0.5则为 HIGH。\n\nFlink1.13 优化了反压检测的逻辑（使用基于任务 Mailbox计时，而不在再于堆栈采样），并且重新实现了作业图的 UI展示：Flink现在在 UI 上通过颜色和数值来展示繁忙和反压的程度。\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1654674284140-b680f841-3ad4-4250-87fd-8c331333f1f5.png)\n\n1）通过WebUI看到 Map算子处于反压：\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1654674446026-5ec8c33c-cadc-44c9-9d00-b644899f52d6.png)\n\n3）分析瓶颈算子\n\n如果处于反压状态，那么有两种可能性：\n\n（1）  该节点的发送速率跟不上它的产生数据速率。这一般会发生在一条输入多条输出的 Operator（比如 flatmap）。这种情况，该节点是反压的根源节点，它是从 SourceTask到 Sink Task 的第一个出现反压的节点。**（很少出现，表现为：反压算子一进多出，后面的算子处理速度慢，从这个反压算子开始，后面的算子都反压了。图示，绿色为反压节点：**\n\n**（OK-> OK->** **反** **->反 -> 反 ）**\n\n**一进多出，输入缓存区使用率可能高也可能低，输出缓存区使用率高**\n\n（2）  下游的节点接受速率较慢，通过反压机制限制了该节点的发送速率。这种情况，需要继续排查下游节点，一直找到第一个为OK的一般就是根源节点。**（表现为：这个反压算子处理速度慢，阻塞了前面的算子，导致前面的算子反压了，其后面的算子表现为不反压。图示，绿色为反压节点：**\n\n​      **（反 -> 反 ->** **OK**-> OK-> OK）\n\n**输入缓存区使用率高，输出缓存区使用率低**\n\n总体来看，如果我们找到第一个出现反压的节点，反压根源要么是就这个节点，要么是它紧接着的下游节点。\n\n通常来讲，第二种情况更常见。如果无法确定，还需要结合 Metrics进一步判断。\n\n### 3.2.2    利用 Metrics 定位\n\n监控反压时会用到的 Metrics 主要和 Channel 接受端的 Buffer 使用率有关，最为\n\n有用的是以下几个 Metrics:\n\n| **Metris**                        | **描述**                        |\n| --------------------------------- | ------------------------------- |\n| outPoolUsage                      | 发送端 Buffer 的使用率          |\n| inPoolUsage                       | 接收端 Buffer 的使用率          |\n| floatingBuffersUsage（1.9 以上）  | 接收端 FloatingBuffer 的使用率  |\n| exclusiveBuffersUsage（1.9 以上） | 接收端 ExclusiveBuffer 的使用率 |\n\n其中 inPoolUsage = floatingBuffersUsage + exclusiveBuffersUsage。\n\n#### 1）根据指标分析反压\n\n分析反压的大致思路是：如果一个 Subtask 的发送端 Buffer占用率很高，则表明它被下游反压限速了；如果一个 Subtask 的接受端 Buffer 占用很高，则表明它将反压传导至上游。反压情况可以根据以下表格进行对号入座(1.9 以上):\n\n|                                            | **outPoolUsage** **低**                                      | **outPoolUsage** **高**                    |\n| ------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------ |\n| **inPoolUsage** **低**                     | 正常                                                         | 被下游反压，处于临时情况（还没传递到上游） |\n| 可能是反压的根源，一条输入多条输出的场景   |                                                              |                                            |\n| **inPoolUsage** **高**                     | 如果上游所有 outPoolUsage 都是低，有可能最终可能导致反压（还没传递到上游） | 被下游反压                                 |\n| 如果上游的 outPoolUsage 是高，则为反压根源 |                                                              |                                            |\n\n#### 2）可以进一步分析数据传输\n\nFlink1.9 及以上版本，还可以根据 floatingBuffersUsage/exclusiveBuffersUsage 以及其上游 Task 的 outPoolUsage 来进行进一步的分析一个 Subtask 和其上游Subtask 的数据传输。\n\n在流量较大时，Channel  的  ExclusiveBuffer  可能会被写满，此时  Flink  会向  BufferPool 申请剩余的 FloatingBuffer。这些 **FloatingBuffer 属于备用 Buffer。**\n\n\n\n|                                                              | **exclusiveBuffersUsage** **低**        | **exclusiveBuffersUsage** **高**                  |\n| ------------------------------------------------------------ | --------------------------------------- | ------------------------------------------------- |\n| **floatingBuffersUsage** **低**所有上游**outPoolUsage** **低** | 正常                                    |                                                   |\n| **floatingBuffersUsage** **低**上游某个**outPoolUsage** **高** | 潜在的网络瓶颈                          |                                                   |\n| **floatingBuffersUsage**高所有上游**outPoolUsage** **低**    | 最终对部分inputChannel 反压（正在传递） | 最终对大多数或所有   inputChannel反压（正在传递） |\n| **floatingBuffersUsage**高上游某个**outPoolUsage** **高**    | 只对部分 inputChannel 反压              | 对大多数或所有 inputChannel 反压                  |\n\n总结：\n\n- 1）floatingBuffersUsage 为高，则表明反压正在传导至上游\n- 2）同时 exclusiveBuffersUsage 为低，则表明可能有倾斜\n\n\n\n比如，floatingBuffersUsage 高、exclusiveBuffersUsage 低为有倾斜，因为少数\n\nchannel 占用了大部分的 FloatingBuffer。\n\n## 3.3 反压的原因及处理\n\n注意：反压可能是暂时的，可能是由于负载高峰、CheckPoint 或作业重启引起的数据积压而导致反压。如果反压是暂时的，应该忽略它。另外，请记住，断断续续的反压会影响我们分析和解决问题。\n\n定位到反压节点后，分析造成原因的办法主要是观察 TaskThread。按照下面的顺序，一步一步去排查。\n\n### 3.3.1    查看是否数据倾斜\n\n**在实践中，很多情况下的反压是由于数据倾斜造成的，这点我们可以通过 Web UI各**\n\n**个 SubTask 的 RecordsSent 和 RecordReceived 来确认，另外 Checkpointdetail里不同 SubTask 的 Statesize 也是一个分析数据倾斜的有用指标。**\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1654675365111-f2598a4c-7ae6-4c6b-852b-a2c31b53623e.png)\n\n（关于数据倾斜的详细解决方案，会在下一章节详细讨论）\n\n### 3.3.2    使用火焰图分析\n\n如果不是数据倾斜，最常见的问题可能是用户代码的执行效率问题（频繁被阻塞或者性能问题），需要找到瓶颈算子中的哪部分计算逻辑消耗巨大。\n\n最有用的办法就是对 TaskManager 进行 CPUprofile，从中我们可以分析到 TaskThread 是否跑满一个 CPU 核：如果是的话要分析 CPU 主要花费在哪些函数里面；如果不是的话要看 TaskThread 阻塞在哪里，可能是用户函数本身有些同步的调用，可能是checkpoint 或者 GC 等系统活动导致的暂时系统暂停。\n\n#### 1）开启火焰图功能\n\nFlink1.13直接在 WebUI提供 JVM的 CPU 火焰图，这将大大简化性能瓶颈的分析，默认是不开启的，需要修改参数：\n\nrest.flamegraph.enabled:true#默认false                                                                          \n\n\n\n也可以在提交时指定：\n\n> bin/flinkrun\\\n>\n> -tyarn-per-job\\\n>\n> -d\\\n>\n> -p5 \\\n>\n> -Drest.flamegraph.enabled=true\\\n>\n> -Dyarn.application.queue=test\\\n>\n> -Drest.flamegraph.enabled=true\\\n>\n> -Djobmanager.memory.process.size=1024mb \\\n>\n> -Dtaskmanager.memory.process.size=2048mb\\\n>\n> -Dtaskmanager.numberOfTaskSlots=2\\\n>\n> -ccom.atguigu.flink.tuning.UvDemo \\\n>\n> /opt/module/flink-1.13.1/myjar/flink-tuning-1.0-SNAPSHOT.jar\n\n#### 2）WebUI 查看火焰图\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1654675647317-7df4c4eb-e01f-4637-9d0e-a9980331f2c2.png)\n\n火焰图是通过对堆栈跟踪进行多次采样来构建的。每个方法调用都由一个条形表示，其中条形的长度与其在样本中出现的次数成正比。\n\n- On-CPU: 处于 [RUNNABLE, NEW]状态的线程\n- Off-CPU: 处于 [TIMED_WAITING, WAITING, BLOCKED]的线程，用于查看在样本中发现的阻塞调用。\n\n#### 3）分析火焰图\n\n颜色没有特殊含义，具体查看：\n\n- 纵向是调用链，从下往上，顶部就是正在执行的函数\n- 横向是样本出现次数，可以理解为执行时长。\n\n**看顶层的哪个函数占据的宽度最大。只要有\"平顶\"（plateaus），就表示该函数可能存在性能问题。**\n\n如果是 Flink1.13 以前的版本，可以手动做火焰图：\n\n如何生成火焰图：http://www.54tianzhisheng.cn/2020/10/05/flink-jvm-profiler/\n\n### 3.3.3    分析GC 情况\n\nTaskManager 的内存以及 GC 问题也可能会导致反压，包括 TaskManagerJVM 各区内存不合理导致的频繁 FullGC 甚至失联。通常建议使用默认的 G1 垃圾回收器。\n\n可以通过打印 GC 日志（-XX:+PrintGCDetails），使用 GC 分析器（GCViewer 工具）来验证是否处于这种情况。\n\n\n\n- 在 Flink 提交脚本中,设置 JVM 参数，打印 GC 日志：\n\n> bin/flinkrun\\\n>\n> -tyarn-per-job\\\n>\n> -d\\\n>\n> -p5 \\\n>\n> -Drest.flamegraph.enabled=true\\\n>\n> -Denv.java.opts=\"-XX:+PrintGCDetails-XX:+PrintGCDateStamps\"\\\n>\n> -Dyarn.application.queue=test\\\n>\n> -Djobmanager.memory.process.size=1024mb \\\n>\n> -Dtaskmanager.memory.process.size=2048mb\\\n>\n> -Dtaskmanager.numberOfTaskSlots=2\\\n>\n> -ccom.atguigu.flink.tuning.UvDemo \\\n>\n> /opt/module/flink-1.13.1/myjar/flink-tuning-1.0-SNAPSHOT.jar\n\n\n\n- 下载 GC 日志的方式：\n\n因为是 onyarn 模式，运行的节点一个一个找比较麻烦。可以打开 WebUI，选择JobManager 或者 TaskManager，点击 Stdout，即可看到 GC 日志，点击下载按钮即可将 GC日志通过 HTTP的方式下载下来。\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1654679097595-18b82b7c-8bd5-4d21-b720-44c795ce377a.png)\n\n- 分析 GC 日志：\n\n通过 GC 日志分析出单个 FlinkTaskmanager 堆总大小、年轻代、老年代分配的内存空间、FullGC 后老年代剩余大小等，相关指标定义可以去 Github 具体查看。\n\nGCViewer 地址：https://github.com/chewiebug/GCViewer\n\nLinux 下分析：\n\njava -jargcviewer_1.3.4.jargc.log                                                                                    \n\nWindows 下分析：\n\n直接双击gcviewer_1.3.4.jar，打开GUI界面，选择gc的log打开         \n\n​                      \n\n扩展：最重要的指标是FullGC 后，老年代剩余大小这个指标，按照《Java 性能优化权威指南》这本书 Java 堆大小计算法则，设 FullGC 后老年代剩余大小空间为 M，那么堆的大小建议 3~4 倍 M，新生代为 1~1.5 倍 M，老年代应为 2~3 倍 M。\n\n### 3.3.4    外部组件交互\n\n如果发现我们的 Source端数据读取性能比较低或者 Sink端写入性能较差，需要检查第三方组件是否遇到瓶颈，还有就是做维表join时的性能问题。\n\n例如：\n\nKafka集群是否需要扩容，Kafka 连接器是否并行度较低\n\nHBase的 rowkey 是否遇到热点问题，是否请求处理不过来\n\nClickHouse并发能力较弱，是否达到瓶颈\n\n……\n\n关于第三方组件的性能问题，需要结合具体的组件来分析，最常用的思路：\n\n- 1）异步 io+热缓存来优化读写性能\n- 2）先攒批再读写维表join参考：\n\nhttps://flink-learning.org.cn/article/detail/b8df32fbc6542257a5b449114e137cc3\n\nhttps://www.jianshu.com/p/a62fa483ff54\n\n\n\n# 四、数据倾斜\n\n## 4.1  判断是否存在数据倾斜\n\n相同 Task 的多个 Subtask 中， 个别 Subtask 接收到的数据量明显大于其他Subtask 接收到的数据量，通过 FlinkWebUI 可以精确地看到每个 Subtask 处理了多少数据，即可判断出 Flink 任务是否存在数据倾斜。通常，数据倾斜也会引起反压。\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1654692839400-88f4eb2d-9389-4011-a676-2f6da336cb39.png)\n\n另外， 有时 Checkpointdetail 里不同 SubTask 的 Statesize 也是一个分析数据倾斜的有用指标。\n\n## 4.2 数据倾斜的解决\n\n### 4.2.1    keyBy 后的聚合操作存在数据倾斜\n\n#### 1）为什么不能直接用二次聚合来处理（没有卵用）\n\nFlink是实时流处理，如果keyby之后的聚合操作存在数据倾斜，且没有开窗口（没攒批）的情况下，简单的认为使用两阶段聚合，是不能解决问题的。因为这个时候Flink是来一条处理一条，且向下游发送一条结果，对于原来 keyby的维度（第二阶段聚合）来讲，数据量并没有减少，且结果重复计算（非 FlinkSQL，未使用回撤流），如下图所示：\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1654692995562-f3b6caac-04e3-45ac-87bc-92286cb10e2b.png)\n\n#### 2）使用 LocalKeyBy 的思想\n\n在 keyBy 上游算子数据发送之前，首先在上游算子的本地对数据进行聚合后，再发送到下游，使下游接收到的数据量大大减少，从而使得 keyBy 之后的聚合操作不再是任务的瓶颈。类似 MapReduce中 Combiner的思想，但是这要求聚合操作必须是多条数据或者一批数据才能聚合，单条数据没有办法通过聚合来减少数据量。从 FlinkLocalKeyBy实现原理来讲，必然会存在一个积攒批次的过程，在上游算子中必须攒够一定的数据量，对这些数据聚合后再发送到下游。\n\n#### 实现方式：\n\n- DataStreamAPI 需要自己写代码实现\n- SQL 可以指定参数，开启miniBatch 和 LocalGlobal 功能（推荐，后续介绍）\n\n### 4.1.1    keyBy之前发生数据倾斜\n\n如果 keyBy 之前就存在数据倾斜，上游算子的某些实例可能处理的数据较多，某些实例可能处理的数据较少，产生该情况可能是因为数据源的数据本身就不均匀，例如由于某些原因 Kafka 的 topic 中某些 partition 的数据量较大，某些 partition 的数据量较少。\n\n对于不存在 keyBy 的 Flink 任务也会出现该情况。\n\n这种情况，需要让 Flink 任务强制进行shuffle。使用 shuffle、rebalance 或 rescale\n\n算子即可将数据均匀分配，从而解决数据倾斜的问题。\n\n### 4.1.2    keyBy 后的窗口聚合操作存在数据倾斜\n\n因为使用了窗口，变成了有界数据（攒批）的处理，窗口默认是触发时才会输出一条结果发往下游，所以可以使用两阶段聚合的方式：\n\n#### 1）实现思路：\n\n- 第一阶段聚合：key拼接随机数前缀或后缀，进行 keyby、开窗、聚合\n\n**注意：聚合完不再是 WindowedStream，要获取 WindowEnd 作为窗口标记作为第二阶段分组依据，避免不同窗口的结果聚合到一起）**\n\n- 第二阶段聚合：按照原来的 key 及windowEnd 作keyby、聚合\n\nSQL写法参考：https://zhuanlan.zhihu.com/p/197299746\n","slug":"bigdata/Flink调优","published":1,"comments":1,"layout":"post","photos":[],"link":"","_id":"cl9y38dsb0015fwui6j6wap6g","content":"<h1 id=\"内存设置（1CPU配置4G内存）\"><a href=\"#内存设置（1CPU配置4G内存）\" class=\"headerlink\" title=\"内存设置（1CPU配置4G内存）\"></a>内存设置（1CPU配置4G内存）</h1><blockquote>\n<p>bin&#x2F;flink run \\</p>\n<p>-t yarn-per-job \\</p>\n<p>-d \\</p>\n<p>-p 5 \\ 指定并行度</p>\n<p>-Dyarn.application.queue&#x3D;test \\ 指定yarn队列</p>\n<p>-Djobmanager.memory.process.size&#x3D;2048mb \\ JM2~4G足够</p>\n<p>-Dtaskmanager.memory.process.size&#x3D;6144mb \\ 单个TM2~8G足够</p>\n<p>-Dtaskmanager.numberOfTaskSlots&#x3D;2 \\ <strong>与容器核数1core：1slot或1core：2slot</strong></p>\n<p>-c com.atguigu.app.dwd.LogBaseApp \\</p>\n<p>&#x2F;opt&#x2F;module&#x2F;gmall-flink&#x2F;gmall-realtime-1.0-SNAPSHOT-jar-with-dependencies.jar</p>\n</blockquote>\n<p>Flink是实时流处理，关键在于资源情况能不能抗住高峰时期每秒的数据量，通常用QPS&#x2F;TPS来描述数据情况。</p>\n<h2 id=\"TaskManager-内存模型\"><a href=\"#TaskManager-内存模型\" class=\"headerlink\" title=\"TaskManager 内存模型\"></a>TaskManager 内存模型</h2><p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1654665961981-86c260ab-5310-4674-ac61-6a1d1f738f18.png\" alt=\"img\"></p>\n<h3 id=\"1、内存模型详解\"><a href=\"#1、内存模型详解\" class=\"headerlink\" title=\"1、内存模型详解\"></a>1、内存模型详解</h3><h4 id=\"JVM-特定内存：JVM-本身使用的内存，包含-JVM-的-metaspace-和-over-head\"><a href=\"#JVM-特定内存：JVM-本身使用的内存，包含-JVM-的-metaspace-和-over-head\" class=\"headerlink\" title=\"JVM 特定内存：JVM 本身使用的内存，包含 JVM 的 metaspace 和 over-head\"></a>JVM 特定内存：JVM 本身使用的内存，包含 JVM 的 metaspace 和 over-head</h4><p>1）JVMmetaspace：JVM 元空间</p>\n<p>taskmanager.memory.jvm-metaspace.size，默认 256mb</p>\n<p>2）JVMover-head执行开销：JVM执行时自身所需要的内容，包括线程堆栈、IO、编译缓存等所使用的内存。</p>\n<p>taskmanager.memory.jvm-overhead.fraction，默认 0.1</p>\n<p>taskmanager.memory.jvm-overhead.min，默认 192mb</p>\n<p>taskmanager.memory.jvm-overhead.max，默认 1gb</p>\n<p><strong>总进程内存*fraction，如果小于配置的 min（或大于配置的 max）大小，则使用 min&#x2F;max</strong></p>\n<p><strong>大小</strong></p>\n<h4 id=\"框架内存：Flink-框架，即-TaskManager-本身所占用的内存，不计入-Slot-的资源中。\"><a href=\"#框架内存：Flink-框架，即-TaskManager-本身所占用的内存，不计入-Slot-的资源中。\" class=\"headerlink\" title=\"框架内存：Flink 框架，即 TaskManager 本身所占用的内存，不计入 Slot 的资源中。\"></a>框架内存：Flink 框架，即 TaskManager 本身所占用的内存，不计入 Slot 的资源中。</h4><p>堆内：taskmanager.memory.framework.heap.size，默认 128MB</p>\n<p>堆外：taskmanager.memory.framework.off-heap.size，默认 128MB</p>\n<h4 id=\"Task内存：Task执行用户代码时所使用的内存\"><a href=\"#Task内存：Task执行用户代码时所使用的内存\" class=\"headerlink\" title=\"Task内存：Task执行用户代码时所使用的内存\"></a>Task内存：Task执行用户代码时所使用的内存</h4><p>堆内：taskmanager.memory.task.heap.size，默认 none，由 Flink 内存扣除掉其他部分的内存得到。</p>\n<p>堆外：taskmanager.memory.task.off-heap.size，默认 0，表示不使用堆外内存</p>\n<h4 id=\"网络内存：网络数据交换所使用的堆外内存大小，如网络数据交换缓冲区\"><a href=\"#网络内存：网络数据交换所使用的堆外内存大小，如网络数据交换缓冲区\" class=\"headerlink\" title=\"网络内存：网络数据交换所使用的堆外内存大小，如网络数据交换缓冲区\"></a>网络内存：网络数据交换所使用的堆外内存大小，如网络数据交换缓冲区</h4><p><strong>堆外：</strong></p>\n<p>taskmanager.memory.network.fraction，默认 0.1</p>\n<p>taskmanager.memory.network.min，默认 64mb</p>\n<p>taskmanager.memory.network.max，默认 1gb</p>\n<p><strong>Flink 内存*fraction，如果小于配置的 min（或大于配置的 max）大小，则使用 min&#x2F;max大小</strong></p>\n<h4 id=\"托管内存：用于-RocksDBStateBackend-的本地内存和批的排序、哈希表、缓存中间结果。\"><a href=\"#托管内存：用于-RocksDBStateBackend-的本地内存和批的排序、哈希表、缓存中间结果。\" class=\"headerlink\" title=\"托管内存：用于 RocksDBStateBackend 的本地内存和批的排序、哈希表、缓存中间结果。\"></a>托管内存：用于 RocksDBStateBackend 的本地内存和批的排序、哈希表、缓存中间结果。</h4><p>堆外：taskmanager.memory.managed.fraction，默认 0.4</p>\n<p>taskmanager.memory.managed.size，默认 none</p>\n<p><strong>如果 size 没指定，则等于 Flink 内存*fraction</strong></p>\n<h2 id=\"2、案例分析\"><a href=\"#2、案例分析\" class=\"headerlink\" title=\"2、案例分析\"></a>2、案例分析</h2><p>基于Yarn模式，一般参数指定的是总进程内存，taskmanager.memory.process.size，比如指定为 4G，每一块内存得到大小如下：</p>\n<p>（1）计算 Flink 内存</p>\n<p>JVM 元空间 256m</p>\n<p>JVM 执行开销： 4g*0.1&#x3D;409.6m，在[192m,1g]之间，最终结果 409.6m</p>\n<p>Flink 内存&#x3D;4g-256m-409.6m&#x3D;3430.4m</p>\n<p>（2）网络内存&#x3D;3430.4m*0.1&#x3D;343.04m，在[64m,1g]之间，最终结果 343.04m</p>\n<p>（3）托管内存&#x3D;3430.4m*0.4&#x3D;1372.16m</p>\n<p>（4）框架内存，堆内和堆外都是 128m</p>\n<p>（5）Task堆内内存&#x3D;3430.4m-128m-128m-343.04m-1372.16m&#x3D;1459.2m</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1654667261844-9b48b348-1bcb-4ca8-b556-f63a3680cf83.png\" alt=\"img\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1654667279269-d43c4812-9561-433a-83fe-a8d70b5fb5b9.png\" alt=\"img\"></p>\n<h3 id=\"所以进程内存给多大，每一部分内存需不需要调整，可以看内存的使用率来调整。\"><a href=\"#所以进程内存给多大，每一部分内存需不需要调整，可以看内存的使用率来调整。\" class=\"headerlink\" title=\"所以进程内存给多大，每一部分内存需不需要调整，可以看内存的使用率来调整。\"></a>所以进程内存给多大，每一部分内存需不需要调整，可以看内存的使用率来调整。</h3><h2 id=\"合理利用-cpu-资源\"><a href=\"#合理利用-cpu-资源\" class=\"headerlink\" title=\"合理利用 cpu 资源\"></a>合理利用 cpu 资源</h2><p>Yarn 的<strong>容量调度器</strong>默认情况下是使用“DefaultResourceCalculator”分配策略，只根据内存调度资源，所以在 Yarn 的资源管理页面上看到每个容器的 vcore 个数还是 1。</p>\n<p>可以修改策略为 DominantResourceCalculator，该资源计算器在计算资源的时候会综合考虑 cpu 和内存的情况。在capacity-scheduler.xml 中修改属性:</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>yarn.scheduler.capacity.resource-calculator<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">  <span class=\"comment\">&lt;!-- &lt;value&gt;org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator&lt;/value&gt; --&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>org.apache.hadoop.yarn.util.resource.DominantResourceCalculator<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n\n<h3 id=\"1-1-1-使用DefaultResourceCalculator-策略\"><a href=\"#1-1-1-使用DefaultResourceCalculator-策略\" class=\"headerlink\" title=\"1.1.1    使用DefaultResourceCalculator 策略\"></a>1.1.1    使用DefaultResourceCalculator 策略</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/flink run \\</span><br><span class=\"line\">-t yarn-per-job \\</span><br><span class=\"line\">-d \\</span><br><span class=\"line\">-p 5 \\</span><br><span class=\"line\">-Drest.flamegraph.enabled=true \\</span><br><span class=\"line\">-Dyarn.application.queue=test \\</span><br><span class=\"line\">-Djobmanager.memory.process.size=1024mb \\</span><br><span class=\"line\">-Dtaskmanager.memory.process.size=4096mb \\</span><br><span class=\"line\">-Dtaskmanager.numberOfTaskSlots=2 \\</span><br><span class=\"line\">-c com.atguigu.flink.tuning.UvDemo \\</span><br><span class=\"line\">/opt/module/flink-1.13.1/myjar/flink-tuning-1.0-SNAPSHOT.jar</span><br></pre></td></tr></table></figure>\n\n<p>可以看到一个容器只有一个 vcore：</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1654668251950-033e4bc0-4b65-4fe8-b309-45a29956922b.png\" alt=\"img\"></p>\n<h3 id=\"1-1-2-使用DominantResourceCalculator-策略\"><a href=\"#1-1-2-使用DominantResourceCalculator-策略\" class=\"headerlink\" title=\"1.1.2    使用DominantResourceCalculator 策略\"></a>1.1.2    使用DominantResourceCalculator 策略</h3><p>修改后 yarn 配置后，分发配置并重启 yarn，再次提交 flink 作业：</p>\n<blockquote>\n<p>bin&#x2F;flinkrun\\</p>\n<p>-tyarn-per-job\\</p>\n<p>-d\\</p>\n<p>-p5\\</p>\n<p>-Drest.flamegraph.enabled&#x3D;true\\</p>\n<p>-Dyarn.application.queue&#x3D;test\\</p>\n<p>-Djobmanager.memory.process.size&#x3D;1024mb \\</p>\n<p>-Dtaskmanager.memory.process.size&#x3D;4096mb\\</p>\n<p>-Dtaskmanager.numberOfTaskSlots&#x3D;2\\</p>\n<p>-ccom.atguigu.flink.tuning.UvDemo\\</p>\n<p>&#x2F;opt&#x2F;module&#x2F;flink-1.13.1&#x2F;myjar&#x2F;flink-tuning-1.0-SNAPSHOT.jar</p>\n</blockquote>\n<p>看到容器的 vcore 数变了:</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1654668344371-82744e2d-89b2-4fab-8a09-f77475df1088.png\" alt=\"img\"></p>\n<p>JobManager1 个，占用 1 个容器，vcore&#x3D;1</p>\n<p>TaskManager3 个，占用 3 个容器，每个容器 vcore&#x3D;2，总 vcore&#x3D;2*3&#x3D;6，因为默认单个容器的 vcore 数&#x3D;单 TM 的slot 数</p>\n<h3 id=\"1-1-3-使用-DominantResourceCalculator-策略并指定容器vcore-数\"><a href=\"#1-1-3-使用-DominantResourceCalculator-策略并指定容器vcore-数\" class=\"headerlink\" title=\"1.1.3    使用 DominantResourceCalculator 策略并指定容器vcore 数\"></a>1.1.3    使用 DominantResourceCalculator 策略并指定容器<strong>vcore 数</strong></h3><p>指定yarn 容器的 vcore 数，提交：</p>\n<blockquote>\n<p>bin&#x2F;flinkrun\\</p>\n<p>-tyarn-per-job\\</p>\n<p>-d\\</p>\n<p>-p5\\</p>\n<p>-Drest.flamegraph.enabled&#x3D;true\\</p>\n<p>-Dyarn.application.queue&#x3D;test\\</p>\n<p>-Dyarn.containers.vcores&#x3D;3\\</p>\n<p> -Djobmanager.memory.process.size&#x3D;1024mb \\ -Dtaskmanager.memory.process.size&#x3D;4096mb \\ -Dtaskmanager.numberOfTaskSlots&#x3D;2 \\ -c com.atguigu.flink.tuning.UvDemo \\ &#x2F;opt&#x2F;module&#x2F;flink-1.13.1&#x2F;myjar&#x2F;flink-tuning-1.0-SNAPSHOT.jar  </p>\n</blockquote>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1654668509233-7292aa6f-0e54-4799-ba38-ab72659ef824.png\" alt=\"img\"></p>\n<p>JobManager1 个，占用 1 个容器，vcore&#x3D;1</p>\n<p>TaskManager3 个，占用 3 个容器，每个容器vcore &#x3D;3，总 vcore&#x3D;3*3&#x3D;9</p>\n<h1 id=\"RocksDB大状态调优\"><a href=\"#RocksDB大状态调优\" class=\"headerlink\" title=\"RocksDB大状态调优\"></a>RocksDB大状态调优</h1><p>RocksDB 是基于 LSM Tree 实现的（类似HBase），写数据都是先缓存到内存中，所以RocksDB 的写请求效率比较高。RocksDB 使用内存结合磁盘的方式来存储数据，每次获取数据时，先从内存中 blockcache 中查找，如果内存中没有再去磁盘中查询。优化后差不多单并行度 TPS 5000 record&#x2F;s。<strong>使用RocksDB 时，状态大小仅受可用磁盘空间量的限制，性能瓶颈主要在于 RocksDB对磁盘的读请求，每次读写操作都必须对数据进行反序列化或者序列化。</strong>所以当处理性能不够时，仅需要横向扩展并行度即可提高整个Job 的吞吐量。</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1654669015363-a35261ab-d4ff-4068-a013-eecfe78a5c7d.png\" alt=\"img\"></p>\n<p>从 Flink1.10 开始，Flink 默认将 RocksDB 的内存大小配置为每个 taskslot 的托管内存。调试内存性能的问题主要是通过调整配置项 taskmanager.memory.managed.size或者 taskmanager.memory.managed.fraction以增加 Flink 的托管内存(即堆外的托管内存)。进一步可以调整一些参数进行高级性能调优，这些参数也可以在应用程序中通过RocksDBStateBackend.setRocksDBOptions(RocksDBOptionsFactory)指定。下面介绍</p>\n<p>提高资源利用率的几个重要配置：</p>\n<h3 id=\"2-1-1-开启State访问性能监控\"><a href=\"#2-1-1-开启State访问性能监控\" class=\"headerlink\" title=\"2.1.1   开启State访问性能监控\"></a>2.1.1   开启State访问性能监控</h3><p>Flink 1.13 中引入了 State 访问的性能监控，即 latency trackig state。此功能不局限于 StateBackend 的类型，自定义实现的 StateBackend 也可以复用此功能。</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1654670053632-0e169f44-1340-4202-ab6a-bd9a6173a14a.png\" alt=\"img\"></p>\n<p>State访问性能监控会产生一定的性能影响，所以，默认每 100次做一次取样(sample)，对不同的 StateBackend 性能损失影响不同：</p>\n<ul>\n<li>对于 RocksDBStateBackend，性能损失大概在 1% 左右</li>\n<li>对于 HeapStateBackend，性能损失最多可达 10%</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">state.backend.latency-track.keyed-state-enabled：true</span> <span class=\"comment\">#启用访问状态的性能监控 </span></span><br><span class=\"line\"><span class=\"attr\">state.backend.latency-track.sample-interval:</span> <span class=\"number\">100</span> <span class=\"comment\">#采样间隔 </span></span><br><span class=\"line\"><span class=\"attr\">state.backend.latency-track.history-size:</span> <span class=\"number\">128</span> <span class=\"comment\">#保留的采样数据个数，越大越精确 </span></span><br><span class=\"line\"><span class=\"attr\">state.backend.latency-track.state-name-as-variable:</span> <span class=\"literal\">true</span> <span class=\"comment\">#将状态名作为变量  </span></span><br></pre></td></tr></table></figure>\n\n<p>正常开启第一个参数即可。</p>\n<blockquote>\n<p>bin&#x2F;flink run \\</p>\n<p>-t yarn-per-job \\</p>\n<p>-d \\</p>\n<p>-p 5 \\</p>\n<p>-Drest.flamegraph.enabled&#x3D;true \\</p>\n<p>-Dyarn.application.queue&#x3D;test \\</p>\n<p>-Djobmanager.memory.process.size&#x3D;1024mb \\</p>\n<p>-Dtaskmanager.memory.process.size&#x3D;4096mb \\</p>\n<p>-Dtaskmanager.numberOfTaskSlots&#x3D;2 \\</p>\n<p> -Dstate.backend.latency-track.keyed-state-enabled&#x3D;true \\ </p>\n<p>-c com.atguigu.flink.tuning.RocksdbTuning \\ &#x2F;opt&#x2F;module&#x2F;flink-1.13.1&#x2F;myjar&#x2F;flink-tuning-1.0-SNAPSHOT.jar  </p>\n</blockquote>\n<h3 id=\"2-1-2-开启增量检查点和本地恢复\"><a href=\"#2-1-2-开启增量检查点和本地恢复\" class=\"headerlink\" title=\"2.1.2    开启增量检查点和本地恢复\"></a>2.1.2    开启增量检查点和本地恢复</h3><p>1）开启增量检查点</p>\n<p>RocksDB 是目前唯一可用于支持有状态流处理应用程序增量检查点的状态后端，可以修改参数开启增量检查点：</p>\n<p>state.backend.incremental: true #默认 false，改为 true。 </p>\n<p>或代码中指定 new EmbeddedRocksDBStateBackend(true)  </p>\n<p>2）开启本地恢复</p>\n<p>当 Flink任务失败时，可以基于本地的状态信息进行恢复任务，可能不需要从 hdfs拉取数据。本地恢复目前仅涵盖键控类型的状态后端（RocksDB），MemoryStateBackend不支持本地恢复并忽略此选项。</p>\n<p>state.backend.local-recovery:true</p>\n<h3 id=\"2-1-3-调整预定义选项\"><a href=\"#2-1-3-调整预定义选项\" class=\"headerlink\" title=\"2.1.3    调整预定义选项\"></a>2.1.3    调整预定义选项</h3><p>Flink针对不同的设置为 RocksDB提供了一些预定义的选项集合,其中包含了后续提到的一些参数，如果调整预定义选项后还达不到预期，再去调整后面的 block、writebuffer等参数。</p>\n<p>当 前 支 持 的 预 定 义 选 项 有   DEFAULT 、 SPINNING_DISK_OPTIMIZED 、</p>\n<p>SPINNING_DISK_OPTIMIZED_HIGH_MEM 或FLASH_SSD_OPTIMIZED。有条件上 SSD</p>\n<p>的，可以指定为 FLASH_SSD_OPTIMIZED</p>\n<p> state.backend.rocksdb.predefined-options： SPINNING_DISK_OPTIMIZED_HIGH_MEM #设置为机械硬盘+内存模式  </p>\n<h3 id=\"2-1-4-增大-block-缓存\"><a href=\"#2-1-4-增大-block-缓存\" class=\"headerlink\" title=\"2.1.4    增大 block 缓存\"></a>2.1.4    增大 block 缓存</h3><p>整个 RocksDB 共享一个 blockcache，读数据时内存的 cache 大小，该参数越大读</p>\n<p>数据时缓存命中率越高，默认大小为8MB，建议设置到64~256MB。</p>\n<p>state.backend.rocksdb.block.cache-size:64m     #默认8m  </p>\n<h3 id=\"2-1-5-增大writebuffer-和-level-阈值大小\"><a href=\"#2-1-5-增大writebuffer-和-level-阈值大小\" class=\"headerlink\" title=\"2.1.5    增大writebuffer 和 level 阈值大小\"></a>2.1.5    增大writebuffer 和 level 阈值大小</h3><p>RocksDB 中，每个 State 使用一个 ColumnFamily，每个 ColumnFamily 使用独占的 writebuffer，默认 64MB，建议调大。</p>\n<p>调整这个参数通常要适当增加 L1层的大小阈值 max-size-level-base，默认 256m。</p>\n<p>该值太小会造成能存放的 SST 文件过少，层级变多造成查找困难，太大会造成文件过多，合并困难。建议设为 target_file_size_base（默认 64MB） 的倍数，且不能太小，例如 5<del>10倍，即 320</del>640MB。</p>\n<p>state.backend.rocksdb.writebuffer.size: 128m</p>\n<p>state.backend.rocksdb.compaction.level.max-size-level-base:320m   </p>\n<h3 id=\"2-1-6-增大write-buffer-数量\"><a href=\"#2-1-6-增大write-buffer-数量\" class=\"headerlink\" title=\"2.1.6    增大write buffer 数量\"></a>2.1.6    增大write buffer 数量</h3><p>每个 ColumnFamily对应的 writebuffer 最大数量，这实际上是内存中“只读内存表“的最大数量，默认值是 2。对于机械磁盘来说，如果内存足够大，可以调大到 5左右</p>\n<p>state.backend.rocksdb.writebuffer.count:5                                                                     </p>\n<h3 id=\"2-1-7-增大后台线程数和writebuffer-合并数\"><a href=\"#2-1-7-增大后台线程数和writebuffer-合并数\" class=\"headerlink\" title=\"2.1.7    增大后台线程数和writebuffer 合并数\"></a>2.1.7    增大后台线程数和writebuffer 合并数</h3><p>1）增大线程数</p>\n<p>用于后台 flush和合并 sst文件的线程数，默认为 1，建议调大，机械硬盘用户可以改为 4等更大的值</p>\n<p>state.backend.rocksdb.thread.num: 4                                                                             </p>\n<p>2）增大writebuffer 最小合并数</p>\n<p>将数据从 writebuffer 中 flush 到磁盘时，需要合并的 writebuffer 最小数量，默认</p>\n<p>值为 1，可以调成 3。</p>\n<p>state.backend.rocksdb.writebuffer.number-to-merge:3                                             </p>\n<h3 id=\"2-1-8-开启分区索引功能\"><a href=\"#2-1-8-开启分区索引功能\" class=\"headerlink\" title=\"2.1.8    开启分区索引功能\"></a>2.1.8    开启分区索引功能</h3><p>Flink1.13 中对 RocksDB 增加了分区索引功能，复用了 RocksDB 的partitionedIndex&amp;filter 功能，简单来说就是对 RocksDB 的 partitionedIndex 做了多级索引。也就是将内存中的最上层常驻，下层根据需要再 load回来，这样就大大降低了数据 Swap竞争。线上测试中，相对于<strong>内存比较小</strong>的场景中，性能提升 10 倍左右。如果在内存管控下 Rocksdb 性能不如预期的话，这也能成为一个性能优化点。</p>\n<p>state.backend.rocksdb.memory.partitioned-index-filters:true   #默认false                </p>\n<p><strong>2.1.9</strong>    <strong>参数设定案例</strong></p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/flinkrun\\</span><br><span class=\"line\">-tyarn-per-job\\</span><br><span class=\"line\">-d\\</span><br><span class=\"line\">-p5\\</span><br><span class=\"line\">-Drest.flamegraph.enabled=<span class=\"literal\">true</span>\\</span><br><span class=\"line\">-Dyarn.application.queue=<span class=\"built_in\">test</span>\\</span><br><span class=\"line\">-Djobmanager.memory.process.size=1024mb \\</span><br><span class=\"line\">-Dtaskmanager.memory.process.size=4096mb\\</span><br><span class=\"line\">-Dtaskmanager.numberOfTaskSlots=2\\</span><br><span class=\"line\">-Dstate.backend.incremental=<span class=\"literal\">true</span>\\</span><br><span class=\"line\">-Dstate.backend.local-recovery=<span class=\"literal\">true</span>\\</span><br><span class=\"line\">-Dstate.backend.rocksdb.predefined-options=SPINNING_DISK_OPTIMIZED_HIGH_MEM\\</span><br><span class=\"line\">-Dstate.backend.rocksdb.block.cache-size=64m\\</span><br><span class=\"line\">-Dstate.backend.rocksdb.writebuffer.size=128m\\</span><br><span class=\"line\">-Dstate.backend.rocksdb.compaction.level.max-size-level-base=320m\\</span><br><span class=\"line\">-Dstate.backend.rocksdb.writebuffer.count=5 \\</span><br><span class=\"line\">-Dstate.backend.rocksdb.thread.num=4\\</span><br><span class=\"line\">-Dstate.backend.rocksdb.writebuffer.number-to-merge=3\\</span><br><span class=\"line\">-Dstate.backend.rocksdb.memory.partitioned-index-filters=<span class=\"literal\">true</span>\\</span><br><span class=\"line\">-Dstate.backend.latency-track.keyed-state-enabled=<span class=\"literal\">true</span>\\</span><br><span class=\"line\">-ccom.atguigu.flink.tuning.RocksdbTuning\\</span><br><span class=\"line\">/opt/module/flink-1.13.1/myjar/flink-tuning-1.0-SNAPSHOT.jar</span><br></pre></td></tr></table></figure>\n\n\n\n<h3 id=\"设置本地-RocksDB-多目录\"><a href=\"#设置本地-RocksDB-多目录\" class=\"headerlink\" title=\"设置本地 RocksDB 多目录\"></a>设置本地 RocksDB 多目录</h3><p>在flink-conf.yaml 中配置：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">state.backend.rocksdb.localdir: /data1/flink/rocksdb,/data2/flink/rocksdb,/data3/flink/rocksdb</span><br></pre></td></tr></table></figure>\n\n\n\n<p>注意：不要配置单块磁盘的多个目录，务必将目录配置到多块不同的磁盘上，让多块磁盘来分担压力。<strong>当设置多个 RocksDB 本地磁盘目录时，Flink 会<strong><strong>随机选择</strong></strong>要使用的目录，所以就可能存在三个并行度共用同一目录的情况。</strong>如果服务器磁盘数较多，一般不会出现该情况，但是如果任务重启后吞吐量较低，可以检查是否发生了多个并行度共用同一块磁盘的情况。</p>\n<p><strong>当一个 TaskManager 包含 3 个 slot 时，那么单个服务器上的三个并行度都对磁盘造成频繁读写，从而导致三个并行度的之间相互争抢同一个磁盘 io，这样务必导致三个并行度的吞吐量都会下降。设置多目录实现三个并行度使用不同的硬盘从而减少资源竞争。</strong></p>\n<p>如下所示是测试过程中磁盘的 IO 使用率，可以看出三个大状态算子的并行度分别对应了三块磁盘，这三块磁盘的 IO 平均使用率都保持在 45% 左右，IO 最高使用率几乎都是 100%，而其他磁盘的 IO 平均使用率相对低很多。<strong>由此可见使用 RocksDB 做为状态后端且有大状态的频繁读取时， 对磁盘IO性能消耗确实比较大。</strong></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1654662632337-7fe1e6c6-5fe2-412e-82e8-77f3c81458b7.png\" alt=\"img\"></p>\n<p>如下图所示，其中两个并行度共用了 sdb 磁盘，一个并行度使用 sdj磁盘。可以看到 sdb 磁盘的 IO 使用率已经达到了 91.6%，就会导致 sdb 磁盘对应的两个并行度吞吐量大大降低，从而使得整个 Flink 任务吞吐量降低。<strong>如果每个服务器上有一两块 SSD，强烈建议将 RocksDB 的本地磁盘目录配置到 SSD 的目录下</strong>，<strong>从 HDD 改为 SSD 对于性能的提升可能比配置 10 个优化参数更有效。</strong></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1654662673431-6575b710-490c-49c4-bec7-f4b7964b3fc7.png\" alt=\"img\"></p>\n<ul>\n<li><strong>state.backend.incremental：</strong>开启增量检查点，默认false，改为true。</li>\n<li><strong>state.backend.rocksdb.predefined-options：</strong>SPINNING_DISK_OPTIMIZED_HIGH_MEM设置为机械硬盘+内存模式，有条件上SSD，指定为FLASH_SSD_OPTIMIZED</li>\n<li><strong>state.backend.rocksdb.block.cache-size</strong>: 整个 RocksDB 共享一个 block cache，读数据时内存的 cache 大小，该参数越大读数据时缓存命中率越高，默认大小为 8 MB，建议设置到 64 ~ 256 MB。</li>\n<li><strong>state.backend.rocksdb.thread.num</strong>: 用于后台 flush 和合并 sst 文件的线程数，默认为 1，建议调大，机械硬盘用户可以改为 4 等更大的值。</li>\n<li><strong>state.backend.rocksdb.writebuffer.size</strong>: RocksDB 中，每个 State 使用一个 Column Family，每个 Column Family 使用独占的 write buffer，建议调大，例如：32M</li>\n<li><strong>state.backend.rocksdb.writebuffer.count</strong>: 每个 Column Family 对应的 writebuffer 数目，默认值是 2，对于机械磁盘来说，如果内存⾜够大，可以调大到 5 左右</li>\n<li><strong>state.backend.rocksdb.writebuffer.number-to-merge</strong>: 将数据从 writebuffer 中 flush 到磁盘时，需要合并的 writebuffer 数量，默认值为 1，可以调成3。</li>\n<li><strong>state.backend.local-recovery</strong>: 设置本地恢复，当 Flink 任务失败时，可以基于本地的状态信息进行恢复任务，可能不需要从 hdfs 拉取数据</li>\n</ul>\n<h2 id=\"Checkpoint设置\"><a href=\"#Checkpoint设置\" class=\"headerlink\" title=\"Checkpoint设置\"></a>Checkpoint设置</h2><p>一般我们的 Checkpoint 时间间隔可以设置为分钟级别（1<del>5分钟），例如 1 分钟、3 分钟，对于状态很大的任务每次 Checkpoint 访问 HDFS 比较耗时，可以设置为 5</del>10 分钟一次Checkpoint，并且调大两次 Checkpoint 之间的暂停间隔，例如设置两次Checkpoint 之间至少暂停 4或8 分钟。</p>\n<p>同时，也需要考虑时效性的要求,需要在时效性和性能之间做一个平衡，如果时效性要求高，结合 end- to-end 时长，设置秒级或毫秒级。</p>\n<p>如果 Checkpoint 语义配置为 EXACTLY_ONCE，那么在 Checkpoint 过程中还会存在 barrier 对齐的过程，可以通过 Flink Web UI 的 Checkpoint 选项卡来查看 Checkpoint 过程中各阶段的耗时情况，从而确定到底是哪个阶段导致 Checkpoint 时间过长然后针对性的解决问题。</p>\n<p>RocksDB相关参数在1.3中已说明，可以在flink-conf.yaml指定，也可以在Job的代码中调用API单独指定，这里不再列出。</p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 使⽤ RocksDBStateBackend 做为状态后端，并开启增量 Checkpoint</span></span><br><span class=\"line\"><span class=\"type\">RocksDBStateBackend</span> rocksDBStateBackend = <span class=\"keyword\">new</span> <span class=\"type\">RocksDBStateBackend</span>(<span class=\"string\">&quot;hdfs://hadoop102:8020/flink/checkpoints&quot;</span>, <span class=\"literal\">true</span>);</span><br><span class=\"line\">env.setStateBackend(rocksDBStateBackend);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 开启Checkpoint，间隔为 3 分钟</span></span><br><span class=\"line\">env.enableCheckpointing(<span class=\"type\">TimeUnit</span>.<span class=\"type\">MINUTES</span>.toMillis(<span class=\"number\">3</span>));</span><br><span class=\"line\"><span class=\"comment\">// 配置 Checkpoint</span></span><br><span class=\"line\"><span class=\"type\">CheckpointConfig</span> checkpointConf = env.getCheckpointConfig();</span><br><span class=\"line\">checkpointConf.setCheckpointingMode(<span class=\"type\">CheckpointingMode</span>.<span class=\"type\">EXACTLY_ONCE</span>)</span><br><span class=\"line\"><span class=\"comment\">// 最小间隔 4分钟</span></span><br><span class=\"line\">checkpointConf.setMinPauseBetweenCheckpoints(<span class=\"type\">TimeUnit</span>.<span class=\"type\">MINUTES</span>.toMillis(<span class=\"number\">4</span>))</span><br><span class=\"line\"><span class=\"comment\">// 超时时间 10分钟</span></span><br><span class=\"line\">checkpointConf.setCheckpointTimeout(<span class=\"type\">TimeUnit</span>.<span class=\"type\">MINUTES</span>.toMillis(<span class=\"number\">10</span>));</span><br><span class=\"line\"><span class=\"comment\">// 保存checkpoint</span></span><br><span class=\"line\">checkpointConf.enableExternalizedCheckpoints(</span><br><span class=\"line\"><span class=\"type\">CheckpointConfig</span>.<span class=\"type\">ExternalizedCheckpointCleanup</span>.<span class=\"type\">RETAIN_ON_CANCELLATION</span>);</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"反压处理\"><a href=\"#反压处理\" class=\"headerlink\" title=\"反压处理\"></a>反压处理</h1><h2 id=\"3-1-概述\"><a href=\"#3-1-概述\" class=\"headerlink\" title=\"3.1 概述\"></a>3.1 概述</h2><p>Flink 网络流控及反压的介绍：</p>\n<p><a href=\"https://flink-learning.org.cn/article/detail/138316d1556f8f9d34e517d04d670626\">https://flink-learning.org.cn/article/detail/138316d1556f8f9d34e517d04d670626</a></p>\n<h3 id=\"3-1-1-反压的理解\"><a href=\"#3-1-1-反压的理解\" class=\"headerlink\" title=\"3.1.1    反压的理解\"></a>3.1.1    反压的理解</h3><p>简单来说，Flink 拓扑中每个节点（Task）间的数据都以阻塞队列的方式传输，下游来不及消费导致队列被占满后，上游的生产也会被阻塞，最终导致数据源的摄入被阻塞。</p>\n<p>反压（BackPressure）通常产生于这样的场景：短时间的负载高峰导致系统接收数据的速率远高于它处理数据的速率。许多日常问题都会导致反压，例如，垃圾回收停顿可能会导致流入的数据快速堆积，或遇到大促、秒杀活动导致流量陡增。</p>\n<h3 id=\"3-1-2-反压的危害\"><a href=\"#3-1-2-反压的危害\" class=\"headerlink\" title=\"3.1.2    反压的危害\"></a>3.1.2    反压的危害</h3><p>反压如果不能得到正确的处理，可能会影响到 checkpoint时长和 state大小，甚至可能会导致资源耗尽甚至系统崩溃。</p>\n<ul>\n<li>1）影响 checkpoint 时长：barrier 不会越过普通数据，数据处理被阻塞也会导致checkpointbarrier 流经整个数据管道的时长变长，导致 checkpoint 总体时间（End toEndDuration）变长。</li>\n<li>2）影响 state 大小：barrier 对齐时，接受到较快的输入管道的 barrier 后，它后面数据会被缓存起来但不处理，直到较慢的输入管道的 barrier 也到达，这些被缓存的数据会被放到 state 里面，导致 checkpoint 变大。</li>\n</ul>\n<p>这两个影响对于生产环境的作业来说是十分危险的，因为 checkpoint 是保证数据一致性的关键，checkpoint 时间变长有可能导致 checkpoint<strong>超时失败</strong>，而 state 大小同样可能拖慢 checkpoint 甚至导致 <strong>OOM</strong>（使用 Heap-basedStateBackend）或者物理内存使用<strong>超出容器资源</strong>（使用 RocksDBStateBackend）的稳定性问题。</p>\n<p><strong>因此，我们在生产中要尽量避免出现反压的情况。</strong></p>\n<h2 id=\"3-2-定位反压节点\"><a href=\"#3-2-定位反压节点\" class=\"headerlink\" title=\"3.2 定位反压节点\"></a>3.2 定位反压节点</h2><p>解决反压首先要做的是定位到造成反压的节点，排查的时候，先把operatorchain 禁用，方便定位到具体算子。</p>\n<p>提交UvDemo:</p>\n<blockquote>\n<p>bin&#x2F;flinkrun\\</p>\n<p>-tyarn-per-job\\</p>\n<p>-d\\</p>\n<p>-p5 \\</p>\n<p>-Drest.flamegraph.enabled&#x3D;true\\</p>\n<p>-Dyarn.application.queue&#x3D;test\\</p>\n<p>-Djobmanager.memory.process.size&#x3D;1024mb \\</p>\n<p>-Dtaskmanager.memory.process.size&#x3D;2048mb\\</p>\n<p>-Dtaskmanager.numberOfTaskSlots&#x3D;2\\</p>\n<p>-ccom.atguigu.flink.tuning.UvDemo \\</p>\n<p>&#x2F;opt&#x2F;module&#x2F;flink-1.13.1&#x2F;myjar&#x2F;flink-tuning-1.0-SNAPSHOT.jar</p>\n</blockquote>\n<h3 id=\"3-2-1-利用-FlinkWebUI-定位\"><a href=\"#3-2-1-利用-FlinkWebUI-定位\" class=\"headerlink\" title=\"3.2.1    利用 FlinkWebUI 定位\"></a>3.2.1    利用 FlinkWebUI 定位</h3><p>FlinkWebUI 的反压监控提供了 SubTask 级别的反压监控，1.13 版本以前是通过周期性对  Task  线程的栈信息采样，得到线程被阻塞在请求  Buffer（意味着被下游队列阻塞）</p>\n<p>的频率来判断该节点是否处于反压状态。默认配置下，这个频率在 0.1以下则为 OK，0.1</p>\n<p>至 0.5为 LOW，而超过 0.5则为 HIGH。</p>\n<p>Flink1.13 优化了反压检测的逻辑（使用基于任务 Mailbox计时，而不在再于堆栈采样），并且重新实现了作业图的 UI展示：Flink现在在 UI 上通过颜色和数值来展示繁忙和反压的程度。</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1654674284140-b680f841-3ad4-4250-87fd-8c331333f1f5.png\" alt=\"img\"></p>\n<p>1）通过WebUI看到 Map算子处于反压：</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1654674446026-5ec8c33c-cadc-44c9-9d00-b644899f52d6.png\" alt=\"img\"></p>\n<p>3）分析瓶颈算子</p>\n<p>如果处于反压状态，那么有两种可能性：</p>\n<p>（1）  该节点的发送速率跟不上它的产生数据速率。这一般会发生在一条输入多条输出的 Operator（比如 flatmap）。这种情况，该节点是反压的根源节点，它是从 SourceTask到 Sink Task 的第一个出现反压的节点。<strong>（很少出现，表现为：反压算子一进多出，后面的算子处理速度慢，从这个反压算子开始，后面的算子都反压了。图示，绿色为反压节点：</strong></p>\n<p><strong>（OK-&gt; OK-&gt;</strong> <strong>反</strong> <strong>-&gt;反 -&gt; 反 ）</strong></p>\n<p><strong>一进多出，输入缓存区使用率可能高也可能低，输出缓存区使用率高</strong></p>\n<p>（2）  下游的节点接受速率较慢，通过反压机制限制了该节点的发送速率。这种情况，需要继续排查下游节点，一直找到第一个为OK的一般就是根源节点。<strong>（表现为：这个反压算子处理速度慢，阻塞了前面的算子，导致前面的算子反压了，其后面的算子表现为不反压。图示，绿色为反压节点：</strong></p>\n<p>​      <strong>（反 -&gt; 反 -&gt;</strong> <strong>OK</strong>-&gt; OK-&gt; OK）</p>\n<p><strong>输入缓存区使用率高，输出缓存区使用率低</strong></p>\n<p>总体来看，如果我们找到第一个出现反压的节点，反压根源要么是就这个节点，要么是它紧接着的下游节点。</p>\n<p>通常来讲，第二种情况更常见。如果无法确定，还需要结合 Metrics进一步判断。</p>\n<h3 id=\"3-2-2-利用-Metrics-定位\"><a href=\"#3-2-2-利用-Metrics-定位\" class=\"headerlink\" title=\"3.2.2    利用 Metrics 定位\"></a>3.2.2    利用 Metrics 定位</h3><p>监控反压时会用到的 Metrics 主要和 Channel 接受端的 Buffer 使用率有关，最为</p>\n<p>有用的是以下几个 Metrics:</p>\n<table>\n<thead>\n<tr>\n<th><strong>Metris</strong></th>\n<th><strong>描述</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>outPoolUsage</td>\n<td>发送端 Buffer 的使用率</td>\n</tr>\n<tr>\n<td>inPoolUsage</td>\n<td>接收端 Buffer 的使用率</td>\n</tr>\n<tr>\n<td>floatingBuffersUsage（1.9 以上）</td>\n<td>接收端 FloatingBuffer 的使用率</td>\n</tr>\n<tr>\n<td>exclusiveBuffersUsage（1.9 以上）</td>\n<td>接收端 ExclusiveBuffer 的使用率</td>\n</tr>\n</tbody></table>\n<p>其中 inPoolUsage &#x3D; floatingBuffersUsage + exclusiveBuffersUsage。</p>\n<h4 id=\"1）根据指标分析反压\"><a href=\"#1）根据指标分析反压\" class=\"headerlink\" title=\"1）根据指标分析反压\"></a>1）根据指标分析反压</h4><p>分析反压的大致思路是：如果一个 Subtask 的发送端 Buffer占用率很高，则表明它被下游反压限速了；如果一个 Subtask 的接受端 Buffer 占用很高，则表明它将反压传导至上游。反压情况可以根据以下表格进行对号入座(1.9 以上):</p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th><strong>outPoolUsage</strong> <strong>低</strong></th>\n<th><strong>outPoolUsage</strong> <strong>高</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>inPoolUsage</strong> <strong>低</strong></td>\n<td>正常</td>\n<td>被下游反压，处于临时情况（还没传递到上游）</td>\n</tr>\n<tr>\n<td>可能是反压的根源，一条输入多条输出的场景</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td><strong>inPoolUsage</strong> <strong>高</strong></td>\n<td>如果上游所有 outPoolUsage 都是低，有可能最终可能导致反压（还没传递到上游）</td>\n<td>被下游反压</td>\n</tr>\n<tr>\n<td>如果上游的 outPoolUsage 是高，则为反压根源</td>\n<td></td>\n<td></td>\n</tr>\n</tbody></table>\n<h4 id=\"2）可以进一步分析数据传输\"><a href=\"#2）可以进一步分析数据传输\" class=\"headerlink\" title=\"2）可以进一步分析数据传输\"></a>2）可以进一步分析数据传输</h4><p>Flink1.9 及以上版本，还可以根据 floatingBuffersUsage&#x2F;exclusiveBuffersUsage 以及其上游 Task 的 outPoolUsage 来进行进一步的分析一个 Subtask 和其上游Subtask 的数据传输。</p>\n<p>在流量较大时，Channel  的  ExclusiveBuffer  可能会被写满，此时  Flink  会向  BufferPool 申请剩余的 FloatingBuffer。这些 <strong>FloatingBuffer 属于备用 Buffer。</strong></p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th><strong>exclusiveBuffersUsage</strong> <strong>低</strong></th>\n<th><strong>exclusiveBuffersUsage</strong> <strong>高</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>floatingBuffersUsage</strong> <strong>低</strong>所有上游<strong>outPoolUsage</strong> <strong>低</strong></td>\n<td>正常</td>\n<td></td>\n</tr>\n<tr>\n<td><strong>floatingBuffersUsage</strong> <strong>低</strong>上游某个<strong>outPoolUsage</strong> <strong>高</strong></td>\n<td>潜在的网络瓶颈</td>\n<td></td>\n</tr>\n<tr>\n<td><strong>floatingBuffersUsage</strong>高所有上游<strong>outPoolUsage</strong> <strong>低</strong></td>\n<td>最终对部分inputChannel 反压（正在传递）</td>\n<td>最终对大多数或所有   inputChannel反压（正在传递）</td>\n</tr>\n<tr>\n<td><strong>floatingBuffersUsage</strong>高上游某个<strong>outPoolUsage</strong> <strong>高</strong></td>\n<td>只对部分 inputChannel 反压</td>\n<td>对大多数或所有 inputChannel 反压</td>\n</tr>\n</tbody></table>\n<p>总结：</p>\n<ul>\n<li>1）floatingBuffersUsage 为高，则表明反压正在传导至上游</li>\n<li>2）同时 exclusiveBuffersUsage 为低，则表明可能有倾斜</li>\n</ul>\n<p>比如，floatingBuffersUsage 高、exclusiveBuffersUsage 低为有倾斜，因为少数</p>\n<p>channel 占用了大部分的 FloatingBuffer。</p>\n<h2 id=\"3-3-反压的原因及处理\"><a href=\"#3-3-反压的原因及处理\" class=\"headerlink\" title=\"3.3 反压的原因及处理\"></a>3.3 反压的原因及处理</h2><p>注意：反压可能是暂时的，可能是由于负载高峰、CheckPoint 或作业重启引起的数据积压而导致反压。如果反压是暂时的，应该忽略它。另外，请记住，断断续续的反压会影响我们分析和解决问题。</p>\n<p>定位到反压节点后，分析造成原因的办法主要是观察 TaskThread。按照下面的顺序，一步一步去排查。</p>\n<h3 id=\"3-3-1-查看是否数据倾斜\"><a href=\"#3-3-1-查看是否数据倾斜\" class=\"headerlink\" title=\"3.3.1    查看是否数据倾斜\"></a>3.3.1    查看是否数据倾斜</h3><p><strong>在实践中，很多情况下的反压是由于数据倾斜造成的，这点我们可以通过 Web UI各</strong></p>\n<p><strong>个 SubTask 的 RecordsSent 和 RecordReceived 来确认，另外 Checkpointdetail里不同 SubTask 的 Statesize 也是一个分析数据倾斜的有用指标。</strong></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1654675365111-f2598a4c-7ae6-4c6b-852b-a2c31b53623e.png\" alt=\"img\"></p>\n<p>（关于数据倾斜的详细解决方案，会在下一章节详细讨论）</p>\n<h3 id=\"3-3-2-使用火焰图分析\"><a href=\"#3-3-2-使用火焰图分析\" class=\"headerlink\" title=\"3.3.2    使用火焰图分析\"></a>3.3.2    使用火焰图分析</h3><p>如果不是数据倾斜，最常见的问题可能是用户代码的执行效率问题（频繁被阻塞或者性能问题），需要找到瓶颈算子中的哪部分计算逻辑消耗巨大。</p>\n<p>最有用的办法就是对 TaskManager 进行 CPUprofile，从中我们可以分析到 TaskThread 是否跑满一个 CPU 核：如果是的话要分析 CPU 主要花费在哪些函数里面；如果不是的话要看 TaskThread 阻塞在哪里，可能是用户函数本身有些同步的调用，可能是checkpoint 或者 GC 等系统活动导致的暂时系统暂停。</p>\n<h4 id=\"1）开启火焰图功能\"><a href=\"#1）开启火焰图功能\" class=\"headerlink\" title=\"1）开启火焰图功能\"></a>1）开启火焰图功能</h4><p>Flink1.13直接在 WebUI提供 JVM的 CPU 火焰图，这将大大简化性能瓶颈的分析，默认是不开启的，需要修改参数：</p>\n<p>rest.flamegraph.enabled:true#默认false                                                                          </p>\n<p>也可以在提交时指定：</p>\n<blockquote>\n<p>bin&#x2F;flinkrun\\</p>\n<p>-tyarn-per-job\\</p>\n<p>-d\\</p>\n<p>-p5 \\</p>\n<p>-Drest.flamegraph.enabled&#x3D;true\\</p>\n<p>-Dyarn.application.queue&#x3D;test\\</p>\n<p>-Drest.flamegraph.enabled&#x3D;true\\</p>\n<p>-Djobmanager.memory.process.size&#x3D;1024mb \\</p>\n<p>-Dtaskmanager.memory.process.size&#x3D;2048mb\\</p>\n<p>-Dtaskmanager.numberOfTaskSlots&#x3D;2\\</p>\n<p>-ccom.atguigu.flink.tuning.UvDemo \\</p>\n<p>&#x2F;opt&#x2F;module&#x2F;flink-1.13.1&#x2F;myjar&#x2F;flink-tuning-1.0-SNAPSHOT.jar</p>\n</blockquote>\n<h4 id=\"2）WebUI-查看火焰图\"><a href=\"#2）WebUI-查看火焰图\" class=\"headerlink\" title=\"2）WebUI 查看火焰图\"></a>2）WebUI 查看火焰图</h4><p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1654675647317-7df4c4eb-e01f-4637-9d0e-a9980331f2c2.png\" alt=\"img\"></p>\n<p>火焰图是通过对堆栈跟踪进行多次采样来构建的。每个方法调用都由一个条形表示，其中条形的长度与其在样本中出现的次数成正比。</p>\n<ul>\n<li>On-CPU: 处于 [RUNNABLE, NEW]状态的线程</li>\n<li>Off-CPU: 处于 [TIMED_WAITING, WAITING, BLOCKED]的线程，用于查看在样本中发现的阻塞调用。</li>\n</ul>\n<h4 id=\"3）分析火焰图\"><a href=\"#3）分析火焰图\" class=\"headerlink\" title=\"3）分析火焰图\"></a>3）分析火焰图</h4><p>颜色没有特殊含义，具体查看：</p>\n<ul>\n<li>纵向是调用链，从下往上，顶部就是正在执行的函数</li>\n<li>横向是样本出现次数，可以理解为执行时长。</li>\n</ul>\n<p><strong>看顶层的哪个函数占据的宽度最大。只要有”平顶”（plateaus），就表示该函数可能存在性能问题。</strong></p>\n<p>如果是 Flink1.13 以前的版本，可以手动做火焰图：</p>\n<p>如何生成火焰图：<a href=\"http://www.54tianzhisheng.cn/2020/10/05/flink-jvm-profiler/\">http://www.54tianzhisheng.cn/2020/10/05/flink-jvm-profiler/</a></p>\n<h3 id=\"3-3-3-分析GC-情况\"><a href=\"#3-3-3-分析GC-情况\" class=\"headerlink\" title=\"3.3.3    分析GC 情况\"></a>3.3.3    分析GC 情况</h3><p>TaskManager 的内存以及 GC 问题也可能会导致反压，包括 TaskManagerJVM 各区内存不合理导致的频繁 FullGC 甚至失联。通常建议使用默认的 G1 垃圾回收器。</p>\n<p>可以通过打印 GC 日志（-XX:+PrintGCDetails），使用 GC 分析器（GCViewer 工具）来验证是否处于这种情况。</p>\n<ul>\n<li>在 Flink 提交脚本中,设置 JVM 参数，打印 GC 日志：</li>\n</ul>\n<blockquote>\n<p>bin&#x2F;flinkrun\\</p>\n<p>-tyarn-per-job\\</p>\n<p>-d\\</p>\n<p>-p5 \\</p>\n<p>-Drest.flamegraph.enabled&#x3D;true\\</p>\n<p>-Denv.java.opts&#x3D;”-XX:+PrintGCDetails-XX:+PrintGCDateStamps”\\</p>\n<p>-Dyarn.application.queue&#x3D;test\\</p>\n<p>-Djobmanager.memory.process.size&#x3D;1024mb \\</p>\n<p>-Dtaskmanager.memory.process.size&#x3D;2048mb\\</p>\n<p>-Dtaskmanager.numberOfTaskSlots&#x3D;2\\</p>\n<p>-ccom.atguigu.flink.tuning.UvDemo \\</p>\n<p>&#x2F;opt&#x2F;module&#x2F;flink-1.13.1&#x2F;myjar&#x2F;flink-tuning-1.0-SNAPSHOT.jar</p>\n</blockquote>\n<ul>\n<li>下载 GC 日志的方式：</li>\n</ul>\n<p>因为是 onyarn 模式，运行的节点一个一个找比较麻烦。可以打开 WebUI，选择JobManager 或者 TaskManager，点击 Stdout，即可看到 GC 日志，点击下载按钮即可将 GC日志通过 HTTP的方式下载下来。</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1654679097595-18b82b7c-8bd5-4d21-b720-44c795ce377a.png\" alt=\"img\"></p>\n<ul>\n<li>分析 GC 日志：</li>\n</ul>\n<p>通过 GC 日志分析出单个 FlinkTaskmanager 堆总大小、年轻代、老年代分配的内存空间、FullGC 后老年代剩余大小等，相关指标定义可以去 Github 具体查看。</p>\n<p>GCViewer 地址：<a href=\"https://github.com/chewiebug/GCViewer\">https://github.com/chewiebug/GCViewer</a></p>\n<p>Linux 下分析：</p>\n<p>java -jargcviewer_1.3.4.jargc.log                                                                                    </p>\n<p>Windows 下分析：</p>\n<p>直接双击gcviewer_1.3.4.jar，打开GUI界面，选择gc的log打开         </p>\n<p>​                      </p>\n<p>扩展：最重要的指标是FullGC 后，老年代剩余大小这个指标，按照《Java 性能优化权威指南》这本书 Java 堆大小计算法则，设 FullGC 后老年代剩余大小空间为 M，那么堆的大小建议 3<del>4 倍 M，新生代为 1</del>1.5 倍 M，老年代应为 2~3 倍 M。</p>\n<h3 id=\"3-3-4-外部组件交互\"><a href=\"#3-3-4-外部组件交互\" class=\"headerlink\" title=\"3.3.4    外部组件交互\"></a>3.3.4    外部组件交互</h3><p>如果发现我们的 Source端数据读取性能比较低或者 Sink端写入性能较差，需要检查第三方组件是否遇到瓶颈，还有就是做维表join时的性能问题。</p>\n<p>例如：</p>\n<p>Kafka集群是否需要扩容，Kafka 连接器是否并行度较低</p>\n<p>HBase的 rowkey 是否遇到热点问题，是否请求处理不过来</p>\n<p>ClickHouse并发能力较弱，是否达到瓶颈</p>\n<p>……</p>\n<p>关于第三方组件的性能问题，需要结合具体的组件来分析，最常用的思路：</p>\n<ul>\n<li>1）异步 io+热缓存来优化读写性能</li>\n<li>2）先攒批再读写维表join参考：</li>\n</ul>\n<p><a href=\"https://flink-learning.org.cn/article/detail/b8df32fbc6542257a5b449114e137cc3\">https://flink-learning.org.cn/article/detail/b8df32fbc6542257a5b449114e137cc3</a></p>\n<p><a href=\"https://www.jianshu.com/p/a62fa483ff54\">https://www.jianshu.com/p/a62fa483ff54</a></p>\n<h1 id=\"四、数据倾斜\"><a href=\"#四、数据倾斜\" class=\"headerlink\" title=\"四、数据倾斜\"></a>四、数据倾斜</h1><h2 id=\"4-1-判断是否存在数据倾斜\"><a href=\"#4-1-判断是否存在数据倾斜\" class=\"headerlink\" title=\"4.1  判断是否存在数据倾斜\"></a>4.1  判断是否存在数据倾斜</h2><p>相同 Task 的多个 Subtask 中， 个别 Subtask 接收到的数据量明显大于其他Subtask 接收到的数据量，通过 FlinkWebUI 可以精确地看到每个 Subtask 处理了多少数据，即可判断出 Flink 任务是否存在数据倾斜。通常，数据倾斜也会引起反压。</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1654692839400-88f4eb2d-9389-4011-a676-2f6da336cb39.png\" alt=\"img\"></p>\n<p>另外， 有时 Checkpointdetail 里不同 SubTask 的 Statesize 也是一个分析数据倾斜的有用指标。</p>\n<h2 id=\"4-2-数据倾斜的解决\"><a href=\"#4-2-数据倾斜的解决\" class=\"headerlink\" title=\"4.2 数据倾斜的解决\"></a>4.2 数据倾斜的解决</h2><h3 id=\"4-2-1-keyBy-后的聚合操作存在数据倾斜\"><a href=\"#4-2-1-keyBy-后的聚合操作存在数据倾斜\" class=\"headerlink\" title=\"4.2.1    keyBy 后的聚合操作存在数据倾斜\"></a>4.2.1    keyBy 后的聚合操作存在数据倾斜</h3><h4 id=\"1）为什么不能直接用二次聚合来处理（没有卵用）\"><a href=\"#1）为什么不能直接用二次聚合来处理（没有卵用）\" class=\"headerlink\" title=\"1）为什么不能直接用二次聚合来处理（没有卵用）\"></a>1）为什么不能直接用二次聚合来处理（没有卵用）</h4><p>Flink是实时流处理，如果keyby之后的聚合操作存在数据倾斜，且没有开窗口（没攒批）的情况下，简单的认为使用两阶段聚合，是不能解决问题的。因为这个时候Flink是来一条处理一条，且向下游发送一条结果，对于原来 keyby的维度（第二阶段聚合）来讲，数据量并没有减少，且结果重复计算（非 FlinkSQL，未使用回撤流），如下图所示：</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1654692995562-f3b6caac-04e3-45ac-87bc-92286cb10e2b.png\" alt=\"img\"></p>\n<h4 id=\"2）使用-LocalKeyBy-的思想\"><a href=\"#2）使用-LocalKeyBy-的思想\" class=\"headerlink\" title=\"2）使用 LocalKeyBy 的思想\"></a>2）使用 LocalKeyBy 的思想</h4><p>在 keyBy 上游算子数据发送之前，首先在上游算子的本地对数据进行聚合后，再发送到下游，使下游接收到的数据量大大减少，从而使得 keyBy 之后的聚合操作不再是任务的瓶颈。类似 MapReduce中 Combiner的思想，但是这要求聚合操作必须是多条数据或者一批数据才能聚合，单条数据没有办法通过聚合来减少数据量。从 FlinkLocalKeyBy实现原理来讲，必然会存在一个积攒批次的过程，在上游算子中必须攒够一定的数据量，对这些数据聚合后再发送到下游。</p>\n<h4 id=\"实现方式：\"><a href=\"#实现方式：\" class=\"headerlink\" title=\"实现方式：\"></a>实现方式：</h4><ul>\n<li>DataStreamAPI 需要自己写代码实现</li>\n<li>SQL 可以指定参数，开启miniBatch 和 LocalGlobal 功能（推荐，后续介绍）</li>\n</ul>\n<h3 id=\"4-1-1-keyBy之前发生数据倾斜\"><a href=\"#4-1-1-keyBy之前发生数据倾斜\" class=\"headerlink\" title=\"4.1.1    keyBy之前发生数据倾斜\"></a>4.1.1    keyBy之前发生数据倾斜</h3><p>如果 keyBy 之前就存在数据倾斜，上游算子的某些实例可能处理的数据较多，某些实例可能处理的数据较少，产生该情况可能是因为数据源的数据本身就不均匀，例如由于某些原因 Kafka 的 topic 中某些 partition 的数据量较大，某些 partition 的数据量较少。</p>\n<p>对于不存在 keyBy 的 Flink 任务也会出现该情况。</p>\n<p>这种情况，需要让 Flink 任务强制进行shuffle。使用 shuffle、rebalance 或 rescale</p>\n<p>算子即可将数据均匀分配，从而解决数据倾斜的问题。</p>\n<h3 id=\"4-1-2-keyBy-后的窗口聚合操作存在数据倾斜\"><a href=\"#4-1-2-keyBy-后的窗口聚合操作存在数据倾斜\" class=\"headerlink\" title=\"4.1.2    keyBy 后的窗口聚合操作存在数据倾斜\"></a>4.1.2    keyBy 后的窗口聚合操作存在数据倾斜</h3><p>因为使用了窗口，变成了有界数据（攒批）的处理，窗口默认是触发时才会输出一条结果发往下游，所以可以使用两阶段聚合的方式：</p>\n<h4 id=\"1）实现思路：\"><a href=\"#1）实现思路：\" class=\"headerlink\" title=\"1）实现思路：\"></a>1）实现思路：</h4><ul>\n<li>第一阶段聚合：key拼接随机数前缀或后缀，进行 keyby、开窗、聚合</li>\n</ul>\n<p><strong>注意：聚合完不再是 WindowedStream，要获取 WindowEnd 作为窗口标记作为第二阶段分组依据，避免不同窗口的结果聚合到一起）</strong></p>\n<ul>\n<li>第二阶段聚合：按照原来的 key 及windowEnd 作keyby、聚合</li>\n</ul>\n<p>SQL写法参考：<a href=\"https://zhuanlan.zhihu.com/p/197299746\">https://zhuanlan.zhihu.com/p/197299746</a></p>\n","site":{"data":{"link":[{"class_name":"友情链接","class_desc":"那些人，那些事","link_list":[{"name":"张洪Heo","link":"https://blog.zhheo.com/","avatar":"https://npm.elemecdn.com/guli-heo/img/avatar2.png","descr":"分享设计与科技生活"},{"name":"瞬間の筆記","link":"https://hikki.site","descr":"喜欢的东西就努力去追求，万一成功了呢!","avatar":"https://cdn.jsdelivr.net/gh/0000rookie/imgs/202206120315.png"}]}]}},"excerpt":"","more":"<h1 id=\"内存设置（1CPU配置4G内存）\"><a href=\"#内存设置（1CPU配置4G内存）\" class=\"headerlink\" title=\"内存设置（1CPU配置4G内存）\"></a>内存设置（1CPU配置4G内存）</h1><blockquote>\n<p>bin&#x2F;flink run \\</p>\n<p>-t yarn-per-job \\</p>\n<p>-d \\</p>\n<p>-p 5 \\ 指定并行度</p>\n<p>-Dyarn.application.queue&#x3D;test \\ 指定yarn队列</p>\n<p>-Djobmanager.memory.process.size&#x3D;2048mb \\ JM2~4G足够</p>\n<p>-Dtaskmanager.memory.process.size&#x3D;6144mb \\ 单个TM2~8G足够</p>\n<p>-Dtaskmanager.numberOfTaskSlots&#x3D;2 \\ <strong>与容器核数1core：1slot或1core：2slot</strong></p>\n<p>-c com.atguigu.app.dwd.LogBaseApp \\</p>\n<p>&#x2F;opt&#x2F;module&#x2F;gmall-flink&#x2F;gmall-realtime-1.0-SNAPSHOT-jar-with-dependencies.jar</p>\n</blockquote>\n<p>Flink是实时流处理，关键在于资源情况能不能抗住高峰时期每秒的数据量，通常用QPS&#x2F;TPS来描述数据情况。</p>\n<h2 id=\"TaskManager-内存模型\"><a href=\"#TaskManager-内存模型\" class=\"headerlink\" title=\"TaskManager 内存模型\"></a>TaskManager 内存模型</h2><p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1654665961981-86c260ab-5310-4674-ac61-6a1d1f738f18.png\" alt=\"img\"></p>\n<h3 id=\"1、内存模型详解\"><a href=\"#1、内存模型详解\" class=\"headerlink\" title=\"1、内存模型详解\"></a>1、内存模型详解</h3><h4 id=\"JVM-特定内存：JVM-本身使用的内存，包含-JVM-的-metaspace-和-over-head\"><a href=\"#JVM-特定内存：JVM-本身使用的内存，包含-JVM-的-metaspace-和-over-head\" class=\"headerlink\" title=\"JVM 特定内存：JVM 本身使用的内存，包含 JVM 的 metaspace 和 over-head\"></a>JVM 特定内存：JVM 本身使用的内存，包含 JVM 的 metaspace 和 over-head</h4><p>1）JVMmetaspace：JVM 元空间</p>\n<p>taskmanager.memory.jvm-metaspace.size，默认 256mb</p>\n<p>2）JVMover-head执行开销：JVM执行时自身所需要的内容，包括线程堆栈、IO、编译缓存等所使用的内存。</p>\n<p>taskmanager.memory.jvm-overhead.fraction，默认 0.1</p>\n<p>taskmanager.memory.jvm-overhead.min，默认 192mb</p>\n<p>taskmanager.memory.jvm-overhead.max，默认 1gb</p>\n<p><strong>总进程内存*fraction，如果小于配置的 min（或大于配置的 max）大小，则使用 min&#x2F;max</strong></p>\n<p><strong>大小</strong></p>\n<h4 id=\"框架内存：Flink-框架，即-TaskManager-本身所占用的内存，不计入-Slot-的资源中。\"><a href=\"#框架内存：Flink-框架，即-TaskManager-本身所占用的内存，不计入-Slot-的资源中。\" class=\"headerlink\" title=\"框架内存：Flink 框架，即 TaskManager 本身所占用的内存，不计入 Slot 的资源中。\"></a>框架内存：Flink 框架，即 TaskManager 本身所占用的内存，不计入 Slot 的资源中。</h4><p>堆内：taskmanager.memory.framework.heap.size，默认 128MB</p>\n<p>堆外：taskmanager.memory.framework.off-heap.size，默认 128MB</p>\n<h4 id=\"Task内存：Task执行用户代码时所使用的内存\"><a href=\"#Task内存：Task执行用户代码时所使用的内存\" class=\"headerlink\" title=\"Task内存：Task执行用户代码时所使用的内存\"></a>Task内存：Task执行用户代码时所使用的内存</h4><p>堆内：taskmanager.memory.task.heap.size，默认 none，由 Flink 内存扣除掉其他部分的内存得到。</p>\n<p>堆外：taskmanager.memory.task.off-heap.size，默认 0，表示不使用堆外内存</p>\n<h4 id=\"网络内存：网络数据交换所使用的堆外内存大小，如网络数据交换缓冲区\"><a href=\"#网络内存：网络数据交换所使用的堆外内存大小，如网络数据交换缓冲区\" class=\"headerlink\" title=\"网络内存：网络数据交换所使用的堆外内存大小，如网络数据交换缓冲区\"></a>网络内存：网络数据交换所使用的堆外内存大小，如网络数据交换缓冲区</h4><p><strong>堆外：</strong></p>\n<p>taskmanager.memory.network.fraction，默认 0.1</p>\n<p>taskmanager.memory.network.min，默认 64mb</p>\n<p>taskmanager.memory.network.max，默认 1gb</p>\n<p><strong>Flink 内存*fraction，如果小于配置的 min（或大于配置的 max）大小，则使用 min&#x2F;max大小</strong></p>\n<h4 id=\"托管内存：用于-RocksDBStateBackend-的本地内存和批的排序、哈希表、缓存中间结果。\"><a href=\"#托管内存：用于-RocksDBStateBackend-的本地内存和批的排序、哈希表、缓存中间结果。\" class=\"headerlink\" title=\"托管内存：用于 RocksDBStateBackend 的本地内存和批的排序、哈希表、缓存中间结果。\"></a>托管内存：用于 RocksDBStateBackend 的本地内存和批的排序、哈希表、缓存中间结果。</h4><p>堆外：taskmanager.memory.managed.fraction，默认 0.4</p>\n<p>taskmanager.memory.managed.size，默认 none</p>\n<p><strong>如果 size 没指定，则等于 Flink 内存*fraction</strong></p>\n<h2 id=\"2、案例分析\"><a href=\"#2、案例分析\" class=\"headerlink\" title=\"2、案例分析\"></a>2、案例分析</h2><p>基于Yarn模式，一般参数指定的是总进程内存，taskmanager.memory.process.size，比如指定为 4G，每一块内存得到大小如下：</p>\n<p>（1）计算 Flink 内存</p>\n<p>JVM 元空间 256m</p>\n<p>JVM 执行开销： 4g*0.1&#x3D;409.6m，在[192m,1g]之间，最终结果 409.6m</p>\n<p>Flink 内存&#x3D;4g-256m-409.6m&#x3D;3430.4m</p>\n<p>（2）网络内存&#x3D;3430.4m*0.1&#x3D;343.04m，在[64m,1g]之间，最终结果 343.04m</p>\n<p>（3）托管内存&#x3D;3430.4m*0.4&#x3D;1372.16m</p>\n<p>（4）框架内存，堆内和堆外都是 128m</p>\n<p>（5）Task堆内内存&#x3D;3430.4m-128m-128m-343.04m-1372.16m&#x3D;1459.2m</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1654667261844-9b48b348-1bcb-4ca8-b556-f63a3680cf83.png\" alt=\"img\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1654667279269-d43c4812-9561-433a-83fe-a8d70b5fb5b9.png\" alt=\"img\"></p>\n<h3 id=\"所以进程内存给多大，每一部分内存需不需要调整，可以看内存的使用率来调整。\"><a href=\"#所以进程内存给多大，每一部分内存需不需要调整，可以看内存的使用率来调整。\" class=\"headerlink\" title=\"所以进程内存给多大，每一部分内存需不需要调整，可以看内存的使用率来调整。\"></a>所以进程内存给多大，每一部分内存需不需要调整，可以看内存的使用率来调整。</h3><h2 id=\"合理利用-cpu-资源\"><a href=\"#合理利用-cpu-资源\" class=\"headerlink\" title=\"合理利用 cpu 资源\"></a>合理利用 cpu 资源</h2><p>Yarn 的<strong>容量调度器</strong>默认情况下是使用“DefaultResourceCalculator”分配策略，只根据内存调度资源，所以在 Yarn 的资源管理页面上看到每个容器的 vcore 个数还是 1。</p>\n<p>可以修改策略为 DominantResourceCalculator，该资源计算器在计算资源的时候会综合考虑 cpu 和内存的情况。在capacity-scheduler.xml 中修改属性:</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>yarn.scheduler.capacity.resource-calculator<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">  <span class=\"comment\">&lt;!-- &lt;value&gt;org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator&lt;/value&gt; --&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>org.apache.hadoop.yarn.util.resource.DominantResourceCalculator<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n\n<h3 id=\"1-1-1-使用DefaultResourceCalculator-策略\"><a href=\"#1-1-1-使用DefaultResourceCalculator-策略\" class=\"headerlink\" title=\"1.1.1    使用DefaultResourceCalculator 策略\"></a>1.1.1    使用DefaultResourceCalculator 策略</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/flink run \\</span><br><span class=\"line\">-t yarn-per-job \\</span><br><span class=\"line\">-d \\</span><br><span class=\"line\">-p 5 \\</span><br><span class=\"line\">-Drest.flamegraph.enabled=true \\</span><br><span class=\"line\">-Dyarn.application.queue=test \\</span><br><span class=\"line\">-Djobmanager.memory.process.size=1024mb \\</span><br><span class=\"line\">-Dtaskmanager.memory.process.size=4096mb \\</span><br><span class=\"line\">-Dtaskmanager.numberOfTaskSlots=2 \\</span><br><span class=\"line\">-c com.atguigu.flink.tuning.UvDemo \\</span><br><span class=\"line\">/opt/module/flink-1.13.1/myjar/flink-tuning-1.0-SNAPSHOT.jar</span><br></pre></td></tr></table></figure>\n\n<p>可以看到一个容器只有一个 vcore：</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1654668251950-033e4bc0-4b65-4fe8-b309-45a29956922b.png\" alt=\"img\"></p>\n<h3 id=\"1-1-2-使用DominantResourceCalculator-策略\"><a href=\"#1-1-2-使用DominantResourceCalculator-策略\" class=\"headerlink\" title=\"1.1.2    使用DominantResourceCalculator 策略\"></a>1.1.2    使用DominantResourceCalculator 策略</h3><p>修改后 yarn 配置后，分发配置并重启 yarn，再次提交 flink 作业：</p>\n<blockquote>\n<p>bin&#x2F;flinkrun\\</p>\n<p>-tyarn-per-job\\</p>\n<p>-d\\</p>\n<p>-p5\\</p>\n<p>-Drest.flamegraph.enabled&#x3D;true\\</p>\n<p>-Dyarn.application.queue&#x3D;test\\</p>\n<p>-Djobmanager.memory.process.size&#x3D;1024mb \\</p>\n<p>-Dtaskmanager.memory.process.size&#x3D;4096mb\\</p>\n<p>-Dtaskmanager.numberOfTaskSlots&#x3D;2\\</p>\n<p>-ccom.atguigu.flink.tuning.UvDemo\\</p>\n<p>&#x2F;opt&#x2F;module&#x2F;flink-1.13.1&#x2F;myjar&#x2F;flink-tuning-1.0-SNAPSHOT.jar</p>\n</blockquote>\n<p>看到容器的 vcore 数变了:</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1654668344371-82744e2d-89b2-4fab-8a09-f77475df1088.png\" alt=\"img\"></p>\n<p>JobManager1 个，占用 1 个容器，vcore&#x3D;1</p>\n<p>TaskManager3 个，占用 3 个容器，每个容器 vcore&#x3D;2，总 vcore&#x3D;2*3&#x3D;6，因为默认单个容器的 vcore 数&#x3D;单 TM 的slot 数</p>\n<h3 id=\"1-1-3-使用-DominantResourceCalculator-策略并指定容器vcore-数\"><a href=\"#1-1-3-使用-DominantResourceCalculator-策略并指定容器vcore-数\" class=\"headerlink\" title=\"1.1.3    使用 DominantResourceCalculator 策略并指定容器vcore 数\"></a>1.1.3    使用 DominantResourceCalculator 策略并指定容器<strong>vcore 数</strong></h3><p>指定yarn 容器的 vcore 数，提交：</p>\n<blockquote>\n<p>bin&#x2F;flinkrun\\</p>\n<p>-tyarn-per-job\\</p>\n<p>-d\\</p>\n<p>-p5\\</p>\n<p>-Drest.flamegraph.enabled&#x3D;true\\</p>\n<p>-Dyarn.application.queue&#x3D;test\\</p>\n<p>-Dyarn.containers.vcores&#x3D;3\\</p>\n<p> -Djobmanager.memory.process.size&#x3D;1024mb \\ -Dtaskmanager.memory.process.size&#x3D;4096mb \\ -Dtaskmanager.numberOfTaskSlots&#x3D;2 \\ -c com.atguigu.flink.tuning.UvDemo \\ &#x2F;opt&#x2F;module&#x2F;flink-1.13.1&#x2F;myjar&#x2F;flink-tuning-1.0-SNAPSHOT.jar  </p>\n</blockquote>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1654668509233-7292aa6f-0e54-4799-ba38-ab72659ef824.png\" alt=\"img\"></p>\n<p>JobManager1 个，占用 1 个容器，vcore&#x3D;1</p>\n<p>TaskManager3 个，占用 3 个容器，每个容器vcore &#x3D;3，总 vcore&#x3D;3*3&#x3D;9</p>\n<h1 id=\"RocksDB大状态调优\"><a href=\"#RocksDB大状态调优\" class=\"headerlink\" title=\"RocksDB大状态调优\"></a>RocksDB大状态调优</h1><p>RocksDB 是基于 LSM Tree 实现的（类似HBase），写数据都是先缓存到内存中，所以RocksDB 的写请求效率比较高。RocksDB 使用内存结合磁盘的方式来存储数据，每次获取数据时，先从内存中 blockcache 中查找，如果内存中没有再去磁盘中查询。优化后差不多单并行度 TPS 5000 record&#x2F;s。<strong>使用RocksDB 时，状态大小仅受可用磁盘空间量的限制，性能瓶颈主要在于 RocksDB对磁盘的读请求，每次读写操作都必须对数据进行反序列化或者序列化。</strong>所以当处理性能不够时，仅需要横向扩展并行度即可提高整个Job 的吞吐量。</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1654669015363-a35261ab-d4ff-4068-a013-eecfe78a5c7d.png\" alt=\"img\"></p>\n<p>从 Flink1.10 开始，Flink 默认将 RocksDB 的内存大小配置为每个 taskslot 的托管内存。调试内存性能的问题主要是通过调整配置项 taskmanager.memory.managed.size或者 taskmanager.memory.managed.fraction以增加 Flink 的托管内存(即堆外的托管内存)。进一步可以调整一些参数进行高级性能调优，这些参数也可以在应用程序中通过RocksDBStateBackend.setRocksDBOptions(RocksDBOptionsFactory)指定。下面介绍</p>\n<p>提高资源利用率的几个重要配置：</p>\n<h3 id=\"2-1-1-开启State访问性能监控\"><a href=\"#2-1-1-开启State访问性能监控\" class=\"headerlink\" title=\"2.1.1   开启State访问性能监控\"></a>2.1.1   开启State访问性能监控</h3><p>Flink 1.13 中引入了 State 访问的性能监控，即 latency trackig state。此功能不局限于 StateBackend 的类型，自定义实现的 StateBackend 也可以复用此功能。</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1654670053632-0e169f44-1340-4202-ab6a-bd9a6173a14a.png\" alt=\"img\"></p>\n<p>State访问性能监控会产生一定的性能影响，所以，默认每 100次做一次取样(sample)，对不同的 StateBackend 性能损失影响不同：</p>\n<ul>\n<li>对于 RocksDBStateBackend，性能损失大概在 1% 左右</li>\n<li>对于 HeapStateBackend，性能损失最多可达 10%</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">state.backend.latency-track.keyed-state-enabled：true</span> <span class=\"comment\">#启用访问状态的性能监控 </span></span><br><span class=\"line\"><span class=\"attr\">state.backend.latency-track.sample-interval:</span> <span class=\"number\">100</span> <span class=\"comment\">#采样间隔 </span></span><br><span class=\"line\"><span class=\"attr\">state.backend.latency-track.history-size:</span> <span class=\"number\">128</span> <span class=\"comment\">#保留的采样数据个数，越大越精确 </span></span><br><span class=\"line\"><span class=\"attr\">state.backend.latency-track.state-name-as-variable:</span> <span class=\"literal\">true</span> <span class=\"comment\">#将状态名作为变量  </span></span><br></pre></td></tr></table></figure>\n\n<p>正常开启第一个参数即可。</p>\n<blockquote>\n<p>bin&#x2F;flink run \\</p>\n<p>-t yarn-per-job \\</p>\n<p>-d \\</p>\n<p>-p 5 \\</p>\n<p>-Drest.flamegraph.enabled&#x3D;true \\</p>\n<p>-Dyarn.application.queue&#x3D;test \\</p>\n<p>-Djobmanager.memory.process.size&#x3D;1024mb \\</p>\n<p>-Dtaskmanager.memory.process.size&#x3D;4096mb \\</p>\n<p>-Dtaskmanager.numberOfTaskSlots&#x3D;2 \\</p>\n<p> -Dstate.backend.latency-track.keyed-state-enabled&#x3D;true \\ </p>\n<p>-c com.atguigu.flink.tuning.RocksdbTuning \\ &#x2F;opt&#x2F;module&#x2F;flink-1.13.1&#x2F;myjar&#x2F;flink-tuning-1.0-SNAPSHOT.jar  </p>\n</blockquote>\n<h3 id=\"2-1-2-开启增量检查点和本地恢复\"><a href=\"#2-1-2-开启增量检查点和本地恢复\" class=\"headerlink\" title=\"2.1.2    开启增量检查点和本地恢复\"></a>2.1.2    开启增量检查点和本地恢复</h3><p>1）开启增量检查点</p>\n<p>RocksDB 是目前唯一可用于支持有状态流处理应用程序增量检查点的状态后端，可以修改参数开启增量检查点：</p>\n<p>state.backend.incremental: true #默认 false，改为 true。 </p>\n<p>或代码中指定 new EmbeddedRocksDBStateBackend(true)  </p>\n<p>2）开启本地恢复</p>\n<p>当 Flink任务失败时，可以基于本地的状态信息进行恢复任务，可能不需要从 hdfs拉取数据。本地恢复目前仅涵盖键控类型的状态后端（RocksDB），MemoryStateBackend不支持本地恢复并忽略此选项。</p>\n<p>state.backend.local-recovery:true</p>\n<h3 id=\"2-1-3-调整预定义选项\"><a href=\"#2-1-3-调整预定义选项\" class=\"headerlink\" title=\"2.1.3    调整预定义选项\"></a>2.1.3    调整预定义选项</h3><p>Flink针对不同的设置为 RocksDB提供了一些预定义的选项集合,其中包含了后续提到的一些参数，如果调整预定义选项后还达不到预期，再去调整后面的 block、writebuffer等参数。</p>\n<p>当 前 支 持 的 预 定 义 选 项 有   DEFAULT 、 SPINNING_DISK_OPTIMIZED 、</p>\n<p>SPINNING_DISK_OPTIMIZED_HIGH_MEM 或FLASH_SSD_OPTIMIZED。有条件上 SSD</p>\n<p>的，可以指定为 FLASH_SSD_OPTIMIZED</p>\n<p> state.backend.rocksdb.predefined-options： SPINNING_DISK_OPTIMIZED_HIGH_MEM #设置为机械硬盘+内存模式  </p>\n<h3 id=\"2-1-4-增大-block-缓存\"><a href=\"#2-1-4-增大-block-缓存\" class=\"headerlink\" title=\"2.1.4    增大 block 缓存\"></a>2.1.4    增大 block 缓存</h3><p>整个 RocksDB 共享一个 blockcache，读数据时内存的 cache 大小，该参数越大读</p>\n<p>数据时缓存命中率越高，默认大小为8MB，建议设置到64~256MB。</p>\n<p>state.backend.rocksdb.block.cache-size:64m     #默认8m  </p>\n<h3 id=\"2-1-5-增大writebuffer-和-level-阈值大小\"><a href=\"#2-1-5-增大writebuffer-和-level-阈值大小\" class=\"headerlink\" title=\"2.1.5    增大writebuffer 和 level 阈值大小\"></a>2.1.5    增大writebuffer 和 level 阈值大小</h3><p>RocksDB 中，每个 State 使用一个 ColumnFamily，每个 ColumnFamily 使用独占的 writebuffer，默认 64MB，建议调大。</p>\n<p>调整这个参数通常要适当增加 L1层的大小阈值 max-size-level-base，默认 256m。</p>\n<p>该值太小会造成能存放的 SST 文件过少，层级变多造成查找困难，太大会造成文件过多，合并困难。建议设为 target_file_size_base（默认 64MB） 的倍数，且不能太小，例如 5<del>10倍，即 320</del>640MB。</p>\n<p>state.backend.rocksdb.writebuffer.size: 128m</p>\n<p>state.backend.rocksdb.compaction.level.max-size-level-base:320m   </p>\n<h3 id=\"2-1-6-增大write-buffer-数量\"><a href=\"#2-1-6-增大write-buffer-数量\" class=\"headerlink\" title=\"2.1.6    增大write buffer 数量\"></a>2.1.6    增大write buffer 数量</h3><p>每个 ColumnFamily对应的 writebuffer 最大数量，这实际上是内存中“只读内存表“的最大数量，默认值是 2。对于机械磁盘来说，如果内存足够大，可以调大到 5左右</p>\n<p>state.backend.rocksdb.writebuffer.count:5                                                                     </p>\n<h3 id=\"2-1-7-增大后台线程数和writebuffer-合并数\"><a href=\"#2-1-7-增大后台线程数和writebuffer-合并数\" class=\"headerlink\" title=\"2.1.7    增大后台线程数和writebuffer 合并数\"></a>2.1.7    增大后台线程数和writebuffer 合并数</h3><p>1）增大线程数</p>\n<p>用于后台 flush和合并 sst文件的线程数，默认为 1，建议调大，机械硬盘用户可以改为 4等更大的值</p>\n<p>state.backend.rocksdb.thread.num: 4                                                                             </p>\n<p>2）增大writebuffer 最小合并数</p>\n<p>将数据从 writebuffer 中 flush 到磁盘时，需要合并的 writebuffer 最小数量，默认</p>\n<p>值为 1，可以调成 3。</p>\n<p>state.backend.rocksdb.writebuffer.number-to-merge:3                                             </p>\n<h3 id=\"2-1-8-开启分区索引功能\"><a href=\"#2-1-8-开启分区索引功能\" class=\"headerlink\" title=\"2.1.8    开启分区索引功能\"></a>2.1.8    开启分区索引功能</h3><p>Flink1.13 中对 RocksDB 增加了分区索引功能，复用了 RocksDB 的partitionedIndex&amp;filter 功能，简单来说就是对 RocksDB 的 partitionedIndex 做了多级索引。也就是将内存中的最上层常驻，下层根据需要再 load回来，这样就大大降低了数据 Swap竞争。线上测试中，相对于<strong>内存比较小</strong>的场景中，性能提升 10 倍左右。如果在内存管控下 Rocksdb 性能不如预期的话，这也能成为一个性能优化点。</p>\n<p>state.backend.rocksdb.memory.partitioned-index-filters:true   #默认false                </p>\n<p><strong>2.1.9</strong>    <strong>参数设定案例</strong></p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/flinkrun\\</span><br><span class=\"line\">-tyarn-per-job\\</span><br><span class=\"line\">-d\\</span><br><span class=\"line\">-p5\\</span><br><span class=\"line\">-Drest.flamegraph.enabled=<span class=\"literal\">true</span>\\</span><br><span class=\"line\">-Dyarn.application.queue=<span class=\"built_in\">test</span>\\</span><br><span class=\"line\">-Djobmanager.memory.process.size=1024mb \\</span><br><span class=\"line\">-Dtaskmanager.memory.process.size=4096mb\\</span><br><span class=\"line\">-Dtaskmanager.numberOfTaskSlots=2\\</span><br><span class=\"line\">-Dstate.backend.incremental=<span class=\"literal\">true</span>\\</span><br><span class=\"line\">-Dstate.backend.local-recovery=<span class=\"literal\">true</span>\\</span><br><span class=\"line\">-Dstate.backend.rocksdb.predefined-options=SPINNING_DISK_OPTIMIZED_HIGH_MEM\\</span><br><span class=\"line\">-Dstate.backend.rocksdb.block.cache-size=64m\\</span><br><span class=\"line\">-Dstate.backend.rocksdb.writebuffer.size=128m\\</span><br><span class=\"line\">-Dstate.backend.rocksdb.compaction.level.max-size-level-base=320m\\</span><br><span class=\"line\">-Dstate.backend.rocksdb.writebuffer.count=5 \\</span><br><span class=\"line\">-Dstate.backend.rocksdb.thread.num=4\\</span><br><span class=\"line\">-Dstate.backend.rocksdb.writebuffer.number-to-merge=3\\</span><br><span class=\"line\">-Dstate.backend.rocksdb.memory.partitioned-index-filters=<span class=\"literal\">true</span>\\</span><br><span class=\"line\">-Dstate.backend.latency-track.keyed-state-enabled=<span class=\"literal\">true</span>\\</span><br><span class=\"line\">-ccom.atguigu.flink.tuning.RocksdbTuning\\</span><br><span class=\"line\">/opt/module/flink-1.13.1/myjar/flink-tuning-1.0-SNAPSHOT.jar</span><br></pre></td></tr></table></figure>\n\n\n\n<h3 id=\"设置本地-RocksDB-多目录\"><a href=\"#设置本地-RocksDB-多目录\" class=\"headerlink\" title=\"设置本地 RocksDB 多目录\"></a>设置本地 RocksDB 多目录</h3><p>在flink-conf.yaml 中配置：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">state.backend.rocksdb.localdir: /data1/flink/rocksdb,/data2/flink/rocksdb,/data3/flink/rocksdb</span><br></pre></td></tr></table></figure>\n\n\n\n<p>注意：不要配置单块磁盘的多个目录，务必将目录配置到多块不同的磁盘上，让多块磁盘来分担压力。<strong>当设置多个 RocksDB 本地磁盘目录时，Flink 会<strong><strong>随机选择</strong></strong>要使用的目录，所以就可能存在三个并行度共用同一目录的情况。</strong>如果服务器磁盘数较多，一般不会出现该情况，但是如果任务重启后吞吐量较低，可以检查是否发生了多个并行度共用同一块磁盘的情况。</p>\n<p><strong>当一个 TaskManager 包含 3 个 slot 时，那么单个服务器上的三个并行度都对磁盘造成频繁读写，从而导致三个并行度的之间相互争抢同一个磁盘 io，这样务必导致三个并行度的吞吐量都会下降。设置多目录实现三个并行度使用不同的硬盘从而减少资源竞争。</strong></p>\n<p>如下所示是测试过程中磁盘的 IO 使用率，可以看出三个大状态算子的并行度分别对应了三块磁盘，这三块磁盘的 IO 平均使用率都保持在 45% 左右，IO 最高使用率几乎都是 100%，而其他磁盘的 IO 平均使用率相对低很多。<strong>由此可见使用 RocksDB 做为状态后端且有大状态的频繁读取时， 对磁盘IO性能消耗确实比较大。</strong></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1654662632337-7fe1e6c6-5fe2-412e-82e8-77f3c81458b7.png\" alt=\"img\"></p>\n<p>如下图所示，其中两个并行度共用了 sdb 磁盘，一个并行度使用 sdj磁盘。可以看到 sdb 磁盘的 IO 使用率已经达到了 91.6%，就会导致 sdb 磁盘对应的两个并行度吞吐量大大降低，从而使得整个 Flink 任务吞吐量降低。<strong>如果每个服务器上有一两块 SSD，强烈建议将 RocksDB 的本地磁盘目录配置到 SSD 的目录下</strong>，<strong>从 HDD 改为 SSD 对于性能的提升可能比配置 10 个优化参数更有效。</strong></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1654662673431-6575b710-490c-49c4-bec7-f4b7964b3fc7.png\" alt=\"img\"></p>\n<ul>\n<li><strong>state.backend.incremental：</strong>开启增量检查点，默认false，改为true。</li>\n<li><strong>state.backend.rocksdb.predefined-options：</strong>SPINNING_DISK_OPTIMIZED_HIGH_MEM设置为机械硬盘+内存模式，有条件上SSD，指定为FLASH_SSD_OPTIMIZED</li>\n<li><strong>state.backend.rocksdb.block.cache-size</strong>: 整个 RocksDB 共享一个 block cache，读数据时内存的 cache 大小，该参数越大读数据时缓存命中率越高，默认大小为 8 MB，建议设置到 64 ~ 256 MB。</li>\n<li><strong>state.backend.rocksdb.thread.num</strong>: 用于后台 flush 和合并 sst 文件的线程数，默认为 1，建议调大，机械硬盘用户可以改为 4 等更大的值。</li>\n<li><strong>state.backend.rocksdb.writebuffer.size</strong>: RocksDB 中，每个 State 使用一个 Column Family，每个 Column Family 使用独占的 write buffer，建议调大，例如：32M</li>\n<li><strong>state.backend.rocksdb.writebuffer.count</strong>: 每个 Column Family 对应的 writebuffer 数目，默认值是 2，对于机械磁盘来说，如果内存⾜够大，可以调大到 5 左右</li>\n<li><strong>state.backend.rocksdb.writebuffer.number-to-merge</strong>: 将数据从 writebuffer 中 flush 到磁盘时，需要合并的 writebuffer 数量，默认值为 1，可以调成3。</li>\n<li><strong>state.backend.local-recovery</strong>: 设置本地恢复，当 Flink 任务失败时，可以基于本地的状态信息进行恢复任务，可能不需要从 hdfs 拉取数据</li>\n</ul>\n<h2 id=\"Checkpoint设置\"><a href=\"#Checkpoint设置\" class=\"headerlink\" title=\"Checkpoint设置\"></a>Checkpoint设置</h2><p>一般我们的 Checkpoint 时间间隔可以设置为分钟级别（1<del>5分钟），例如 1 分钟、3 分钟，对于状态很大的任务每次 Checkpoint 访问 HDFS 比较耗时，可以设置为 5</del>10 分钟一次Checkpoint，并且调大两次 Checkpoint 之间的暂停间隔，例如设置两次Checkpoint 之间至少暂停 4或8 分钟。</p>\n<p>同时，也需要考虑时效性的要求,需要在时效性和性能之间做一个平衡，如果时效性要求高，结合 end- to-end 时长，设置秒级或毫秒级。</p>\n<p>如果 Checkpoint 语义配置为 EXACTLY_ONCE，那么在 Checkpoint 过程中还会存在 barrier 对齐的过程，可以通过 Flink Web UI 的 Checkpoint 选项卡来查看 Checkpoint 过程中各阶段的耗时情况，从而确定到底是哪个阶段导致 Checkpoint 时间过长然后针对性的解决问题。</p>\n<p>RocksDB相关参数在1.3中已说明，可以在flink-conf.yaml指定，也可以在Job的代码中调用API单独指定，这里不再列出。</p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 使⽤ RocksDBStateBackend 做为状态后端，并开启增量 Checkpoint</span></span><br><span class=\"line\"><span class=\"type\">RocksDBStateBackend</span> rocksDBStateBackend = <span class=\"keyword\">new</span> <span class=\"type\">RocksDBStateBackend</span>(<span class=\"string\">&quot;hdfs://hadoop102:8020/flink/checkpoints&quot;</span>, <span class=\"literal\">true</span>);</span><br><span class=\"line\">env.setStateBackend(rocksDBStateBackend);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 开启Checkpoint，间隔为 3 分钟</span></span><br><span class=\"line\">env.enableCheckpointing(<span class=\"type\">TimeUnit</span>.<span class=\"type\">MINUTES</span>.toMillis(<span class=\"number\">3</span>));</span><br><span class=\"line\"><span class=\"comment\">// 配置 Checkpoint</span></span><br><span class=\"line\"><span class=\"type\">CheckpointConfig</span> checkpointConf = env.getCheckpointConfig();</span><br><span class=\"line\">checkpointConf.setCheckpointingMode(<span class=\"type\">CheckpointingMode</span>.<span class=\"type\">EXACTLY_ONCE</span>)</span><br><span class=\"line\"><span class=\"comment\">// 最小间隔 4分钟</span></span><br><span class=\"line\">checkpointConf.setMinPauseBetweenCheckpoints(<span class=\"type\">TimeUnit</span>.<span class=\"type\">MINUTES</span>.toMillis(<span class=\"number\">4</span>))</span><br><span class=\"line\"><span class=\"comment\">// 超时时间 10分钟</span></span><br><span class=\"line\">checkpointConf.setCheckpointTimeout(<span class=\"type\">TimeUnit</span>.<span class=\"type\">MINUTES</span>.toMillis(<span class=\"number\">10</span>));</span><br><span class=\"line\"><span class=\"comment\">// 保存checkpoint</span></span><br><span class=\"line\">checkpointConf.enableExternalizedCheckpoints(</span><br><span class=\"line\"><span class=\"type\">CheckpointConfig</span>.<span class=\"type\">ExternalizedCheckpointCleanup</span>.<span class=\"type\">RETAIN_ON_CANCELLATION</span>);</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"反压处理\"><a href=\"#反压处理\" class=\"headerlink\" title=\"反压处理\"></a>反压处理</h1><h2 id=\"3-1-概述\"><a href=\"#3-1-概述\" class=\"headerlink\" title=\"3.1 概述\"></a>3.1 概述</h2><p>Flink 网络流控及反压的介绍：</p>\n<p><a href=\"https://flink-learning.org.cn/article/detail/138316d1556f8f9d34e517d04d670626\">https://flink-learning.org.cn/article/detail/138316d1556f8f9d34e517d04d670626</a></p>\n<h3 id=\"3-1-1-反压的理解\"><a href=\"#3-1-1-反压的理解\" class=\"headerlink\" title=\"3.1.1    反压的理解\"></a>3.1.1    反压的理解</h3><p>简单来说，Flink 拓扑中每个节点（Task）间的数据都以阻塞队列的方式传输，下游来不及消费导致队列被占满后，上游的生产也会被阻塞，最终导致数据源的摄入被阻塞。</p>\n<p>反压（BackPressure）通常产生于这样的场景：短时间的负载高峰导致系统接收数据的速率远高于它处理数据的速率。许多日常问题都会导致反压，例如，垃圾回收停顿可能会导致流入的数据快速堆积，或遇到大促、秒杀活动导致流量陡增。</p>\n<h3 id=\"3-1-2-反压的危害\"><a href=\"#3-1-2-反压的危害\" class=\"headerlink\" title=\"3.1.2    反压的危害\"></a>3.1.2    反压的危害</h3><p>反压如果不能得到正确的处理，可能会影响到 checkpoint时长和 state大小，甚至可能会导致资源耗尽甚至系统崩溃。</p>\n<ul>\n<li>1）影响 checkpoint 时长：barrier 不会越过普通数据，数据处理被阻塞也会导致checkpointbarrier 流经整个数据管道的时长变长，导致 checkpoint 总体时间（End toEndDuration）变长。</li>\n<li>2）影响 state 大小：barrier 对齐时，接受到较快的输入管道的 barrier 后，它后面数据会被缓存起来但不处理，直到较慢的输入管道的 barrier 也到达，这些被缓存的数据会被放到 state 里面，导致 checkpoint 变大。</li>\n</ul>\n<p>这两个影响对于生产环境的作业来说是十分危险的，因为 checkpoint 是保证数据一致性的关键，checkpoint 时间变长有可能导致 checkpoint<strong>超时失败</strong>，而 state 大小同样可能拖慢 checkpoint 甚至导致 <strong>OOM</strong>（使用 Heap-basedStateBackend）或者物理内存使用<strong>超出容器资源</strong>（使用 RocksDBStateBackend）的稳定性问题。</p>\n<p><strong>因此，我们在生产中要尽量避免出现反压的情况。</strong></p>\n<h2 id=\"3-2-定位反压节点\"><a href=\"#3-2-定位反压节点\" class=\"headerlink\" title=\"3.2 定位反压节点\"></a>3.2 定位反压节点</h2><p>解决反压首先要做的是定位到造成反压的节点，排查的时候，先把operatorchain 禁用，方便定位到具体算子。</p>\n<p>提交UvDemo:</p>\n<blockquote>\n<p>bin&#x2F;flinkrun\\</p>\n<p>-tyarn-per-job\\</p>\n<p>-d\\</p>\n<p>-p5 \\</p>\n<p>-Drest.flamegraph.enabled&#x3D;true\\</p>\n<p>-Dyarn.application.queue&#x3D;test\\</p>\n<p>-Djobmanager.memory.process.size&#x3D;1024mb \\</p>\n<p>-Dtaskmanager.memory.process.size&#x3D;2048mb\\</p>\n<p>-Dtaskmanager.numberOfTaskSlots&#x3D;2\\</p>\n<p>-ccom.atguigu.flink.tuning.UvDemo \\</p>\n<p>&#x2F;opt&#x2F;module&#x2F;flink-1.13.1&#x2F;myjar&#x2F;flink-tuning-1.0-SNAPSHOT.jar</p>\n</blockquote>\n<h3 id=\"3-2-1-利用-FlinkWebUI-定位\"><a href=\"#3-2-1-利用-FlinkWebUI-定位\" class=\"headerlink\" title=\"3.2.1    利用 FlinkWebUI 定位\"></a>3.2.1    利用 FlinkWebUI 定位</h3><p>FlinkWebUI 的反压监控提供了 SubTask 级别的反压监控，1.13 版本以前是通过周期性对  Task  线程的栈信息采样，得到线程被阻塞在请求  Buffer（意味着被下游队列阻塞）</p>\n<p>的频率来判断该节点是否处于反压状态。默认配置下，这个频率在 0.1以下则为 OK，0.1</p>\n<p>至 0.5为 LOW，而超过 0.5则为 HIGH。</p>\n<p>Flink1.13 优化了反压检测的逻辑（使用基于任务 Mailbox计时，而不在再于堆栈采样），并且重新实现了作业图的 UI展示：Flink现在在 UI 上通过颜色和数值来展示繁忙和反压的程度。</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1654674284140-b680f841-3ad4-4250-87fd-8c331333f1f5.png\" alt=\"img\"></p>\n<p>1）通过WebUI看到 Map算子处于反压：</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1654674446026-5ec8c33c-cadc-44c9-9d00-b644899f52d6.png\" alt=\"img\"></p>\n<p>3）分析瓶颈算子</p>\n<p>如果处于反压状态，那么有两种可能性：</p>\n<p>（1）  该节点的发送速率跟不上它的产生数据速率。这一般会发生在一条输入多条输出的 Operator（比如 flatmap）。这种情况，该节点是反压的根源节点，它是从 SourceTask到 Sink Task 的第一个出现反压的节点。<strong>（很少出现，表现为：反压算子一进多出，后面的算子处理速度慢，从这个反压算子开始，后面的算子都反压了。图示，绿色为反压节点：</strong></p>\n<p><strong>（OK-&gt; OK-&gt;</strong> <strong>反</strong> <strong>-&gt;反 -&gt; 反 ）</strong></p>\n<p><strong>一进多出，输入缓存区使用率可能高也可能低，输出缓存区使用率高</strong></p>\n<p>（2）  下游的节点接受速率较慢，通过反压机制限制了该节点的发送速率。这种情况，需要继续排查下游节点，一直找到第一个为OK的一般就是根源节点。<strong>（表现为：这个反压算子处理速度慢，阻塞了前面的算子，导致前面的算子反压了，其后面的算子表现为不反压。图示，绿色为反压节点：</strong></p>\n<p>​      <strong>（反 -&gt; 反 -&gt;</strong> <strong>OK</strong>-&gt; OK-&gt; OK）</p>\n<p><strong>输入缓存区使用率高，输出缓存区使用率低</strong></p>\n<p>总体来看，如果我们找到第一个出现反压的节点，反压根源要么是就这个节点，要么是它紧接着的下游节点。</p>\n<p>通常来讲，第二种情况更常见。如果无法确定，还需要结合 Metrics进一步判断。</p>\n<h3 id=\"3-2-2-利用-Metrics-定位\"><a href=\"#3-2-2-利用-Metrics-定位\" class=\"headerlink\" title=\"3.2.2    利用 Metrics 定位\"></a>3.2.2    利用 Metrics 定位</h3><p>监控反压时会用到的 Metrics 主要和 Channel 接受端的 Buffer 使用率有关，最为</p>\n<p>有用的是以下几个 Metrics:</p>\n<table>\n<thead>\n<tr>\n<th><strong>Metris</strong></th>\n<th><strong>描述</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>outPoolUsage</td>\n<td>发送端 Buffer 的使用率</td>\n</tr>\n<tr>\n<td>inPoolUsage</td>\n<td>接收端 Buffer 的使用率</td>\n</tr>\n<tr>\n<td>floatingBuffersUsage（1.9 以上）</td>\n<td>接收端 FloatingBuffer 的使用率</td>\n</tr>\n<tr>\n<td>exclusiveBuffersUsage（1.9 以上）</td>\n<td>接收端 ExclusiveBuffer 的使用率</td>\n</tr>\n</tbody></table>\n<p>其中 inPoolUsage &#x3D; floatingBuffersUsage + exclusiveBuffersUsage。</p>\n<h4 id=\"1）根据指标分析反压\"><a href=\"#1）根据指标分析反压\" class=\"headerlink\" title=\"1）根据指标分析反压\"></a>1）根据指标分析反压</h4><p>分析反压的大致思路是：如果一个 Subtask 的发送端 Buffer占用率很高，则表明它被下游反压限速了；如果一个 Subtask 的接受端 Buffer 占用很高，则表明它将反压传导至上游。反压情况可以根据以下表格进行对号入座(1.9 以上):</p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th><strong>outPoolUsage</strong> <strong>低</strong></th>\n<th><strong>outPoolUsage</strong> <strong>高</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>inPoolUsage</strong> <strong>低</strong></td>\n<td>正常</td>\n<td>被下游反压，处于临时情况（还没传递到上游）</td>\n</tr>\n<tr>\n<td>可能是反压的根源，一条输入多条输出的场景</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td><strong>inPoolUsage</strong> <strong>高</strong></td>\n<td>如果上游所有 outPoolUsage 都是低，有可能最终可能导致反压（还没传递到上游）</td>\n<td>被下游反压</td>\n</tr>\n<tr>\n<td>如果上游的 outPoolUsage 是高，则为反压根源</td>\n<td></td>\n<td></td>\n</tr>\n</tbody></table>\n<h4 id=\"2）可以进一步分析数据传输\"><a href=\"#2）可以进一步分析数据传输\" class=\"headerlink\" title=\"2）可以进一步分析数据传输\"></a>2）可以进一步分析数据传输</h4><p>Flink1.9 及以上版本，还可以根据 floatingBuffersUsage&#x2F;exclusiveBuffersUsage 以及其上游 Task 的 outPoolUsage 来进行进一步的分析一个 Subtask 和其上游Subtask 的数据传输。</p>\n<p>在流量较大时，Channel  的  ExclusiveBuffer  可能会被写满，此时  Flink  会向  BufferPool 申请剩余的 FloatingBuffer。这些 <strong>FloatingBuffer 属于备用 Buffer。</strong></p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th><strong>exclusiveBuffersUsage</strong> <strong>低</strong></th>\n<th><strong>exclusiveBuffersUsage</strong> <strong>高</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>floatingBuffersUsage</strong> <strong>低</strong>所有上游<strong>outPoolUsage</strong> <strong>低</strong></td>\n<td>正常</td>\n<td></td>\n</tr>\n<tr>\n<td><strong>floatingBuffersUsage</strong> <strong>低</strong>上游某个<strong>outPoolUsage</strong> <strong>高</strong></td>\n<td>潜在的网络瓶颈</td>\n<td></td>\n</tr>\n<tr>\n<td><strong>floatingBuffersUsage</strong>高所有上游<strong>outPoolUsage</strong> <strong>低</strong></td>\n<td>最终对部分inputChannel 反压（正在传递）</td>\n<td>最终对大多数或所有   inputChannel反压（正在传递）</td>\n</tr>\n<tr>\n<td><strong>floatingBuffersUsage</strong>高上游某个<strong>outPoolUsage</strong> <strong>高</strong></td>\n<td>只对部分 inputChannel 反压</td>\n<td>对大多数或所有 inputChannel 反压</td>\n</tr>\n</tbody></table>\n<p>总结：</p>\n<ul>\n<li>1）floatingBuffersUsage 为高，则表明反压正在传导至上游</li>\n<li>2）同时 exclusiveBuffersUsage 为低，则表明可能有倾斜</li>\n</ul>\n<p>比如，floatingBuffersUsage 高、exclusiveBuffersUsage 低为有倾斜，因为少数</p>\n<p>channel 占用了大部分的 FloatingBuffer。</p>\n<h2 id=\"3-3-反压的原因及处理\"><a href=\"#3-3-反压的原因及处理\" class=\"headerlink\" title=\"3.3 反压的原因及处理\"></a>3.3 反压的原因及处理</h2><p>注意：反压可能是暂时的，可能是由于负载高峰、CheckPoint 或作业重启引起的数据积压而导致反压。如果反压是暂时的，应该忽略它。另外，请记住，断断续续的反压会影响我们分析和解决问题。</p>\n<p>定位到反压节点后，分析造成原因的办法主要是观察 TaskThread。按照下面的顺序，一步一步去排查。</p>\n<h3 id=\"3-3-1-查看是否数据倾斜\"><a href=\"#3-3-1-查看是否数据倾斜\" class=\"headerlink\" title=\"3.3.1    查看是否数据倾斜\"></a>3.3.1    查看是否数据倾斜</h3><p><strong>在实践中，很多情况下的反压是由于数据倾斜造成的，这点我们可以通过 Web UI各</strong></p>\n<p><strong>个 SubTask 的 RecordsSent 和 RecordReceived 来确认，另外 Checkpointdetail里不同 SubTask 的 Statesize 也是一个分析数据倾斜的有用指标。</strong></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1654675365111-f2598a4c-7ae6-4c6b-852b-a2c31b53623e.png\" alt=\"img\"></p>\n<p>（关于数据倾斜的详细解决方案，会在下一章节详细讨论）</p>\n<h3 id=\"3-3-2-使用火焰图分析\"><a href=\"#3-3-2-使用火焰图分析\" class=\"headerlink\" title=\"3.3.2    使用火焰图分析\"></a>3.3.2    使用火焰图分析</h3><p>如果不是数据倾斜，最常见的问题可能是用户代码的执行效率问题（频繁被阻塞或者性能问题），需要找到瓶颈算子中的哪部分计算逻辑消耗巨大。</p>\n<p>最有用的办法就是对 TaskManager 进行 CPUprofile，从中我们可以分析到 TaskThread 是否跑满一个 CPU 核：如果是的话要分析 CPU 主要花费在哪些函数里面；如果不是的话要看 TaskThread 阻塞在哪里，可能是用户函数本身有些同步的调用，可能是checkpoint 或者 GC 等系统活动导致的暂时系统暂停。</p>\n<h4 id=\"1）开启火焰图功能\"><a href=\"#1）开启火焰图功能\" class=\"headerlink\" title=\"1）开启火焰图功能\"></a>1）开启火焰图功能</h4><p>Flink1.13直接在 WebUI提供 JVM的 CPU 火焰图，这将大大简化性能瓶颈的分析，默认是不开启的，需要修改参数：</p>\n<p>rest.flamegraph.enabled:true#默认false                                                                          </p>\n<p>也可以在提交时指定：</p>\n<blockquote>\n<p>bin&#x2F;flinkrun\\</p>\n<p>-tyarn-per-job\\</p>\n<p>-d\\</p>\n<p>-p5 \\</p>\n<p>-Drest.flamegraph.enabled&#x3D;true\\</p>\n<p>-Dyarn.application.queue&#x3D;test\\</p>\n<p>-Drest.flamegraph.enabled&#x3D;true\\</p>\n<p>-Djobmanager.memory.process.size&#x3D;1024mb \\</p>\n<p>-Dtaskmanager.memory.process.size&#x3D;2048mb\\</p>\n<p>-Dtaskmanager.numberOfTaskSlots&#x3D;2\\</p>\n<p>-ccom.atguigu.flink.tuning.UvDemo \\</p>\n<p>&#x2F;opt&#x2F;module&#x2F;flink-1.13.1&#x2F;myjar&#x2F;flink-tuning-1.0-SNAPSHOT.jar</p>\n</blockquote>\n<h4 id=\"2）WebUI-查看火焰图\"><a href=\"#2）WebUI-查看火焰图\" class=\"headerlink\" title=\"2）WebUI 查看火焰图\"></a>2）WebUI 查看火焰图</h4><p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1654675647317-7df4c4eb-e01f-4637-9d0e-a9980331f2c2.png\" alt=\"img\"></p>\n<p>火焰图是通过对堆栈跟踪进行多次采样来构建的。每个方法调用都由一个条形表示，其中条形的长度与其在样本中出现的次数成正比。</p>\n<ul>\n<li>On-CPU: 处于 [RUNNABLE, NEW]状态的线程</li>\n<li>Off-CPU: 处于 [TIMED_WAITING, WAITING, BLOCKED]的线程，用于查看在样本中发现的阻塞调用。</li>\n</ul>\n<h4 id=\"3）分析火焰图\"><a href=\"#3）分析火焰图\" class=\"headerlink\" title=\"3）分析火焰图\"></a>3）分析火焰图</h4><p>颜色没有特殊含义，具体查看：</p>\n<ul>\n<li>纵向是调用链，从下往上，顶部就是正在执行的函数</li>\n<li>横向是样本出现次数，可以理解为执行时长。</li>\n</ul>\n<p><strong>看顶层的哪个函数占据的宽度最大。只要有”平顶”（plateaus），就表示该函数可能存在性能问题。</strong></p>\n<p>如果是 Flink1.13 以前的版本，可以手动做火焰图：</p>\n<p>如何生成火焰图：<a href=\"http://www.54tianzhisheng.cn/2020/10/05/flink-jvm-profiler/\">http://www.54tianzhisheng.cn/2020/10/05/flink-jvm-profiler/</a></p>\n<h3 id=\"3-3-3-分析GC-情况\"><a href=\"#3-3-3-分析GC-情况\" class=\"headerlink\" title=\"3.3.3    分析GC 情况\"></a>3.3.3    分析GC 情况</h3><p>TaskManager 的内存以及 GC 问题也可能会导致反压，包括 TaskManagerJVM 各区内存不合理导致的频繁 FullGC 甚至失联。通常建议使用默认的 G1 垃圾回收器。</p>\n<p>可以通过打印 GC 日志（-XX:+PrintGCDetails），使用 GC 分析器（GCViewer 工具）来验证是否处于这种情况。</p>\n<ul>\n<li>在 Flink 提交脚本中,设置 JVM 参数，打印 GC 日志：</li>\n</ul>\n<blockquote>\n<p>bin&#x2F;flinkrun\\</p>\n<p>-tyarn-per-job\\</p>\n<p>-d\\</p>\n<p>-p5 \\</p>\n<p>-Drest.flamegraph.enabled&#x3D;true\\</p>\n<p>-Denv.java.opts&#x3D;”-XX:+PrintGCDetails-XX:+PrintGCDateStamps”\\</p>\n<p>-Dyarn.application.queue&#x3D;test\\</p>\n<p>-Djobmanager.memory.process.size&#x3D;1024mb \\</p>\n<p>-Dtaskmanager.memory.process.size&#x3D;2048mb\\</p>\n<p>-Dtaskmanager.numberOfTaskSlots&#x3D;2\\</p>\n<p>-ccom.atguigu.flink.tuning.UvDemo \\</p>\n<p>&#x2F;opt&#x2F;module&#x2F;flink-1.13.1&#x2F;myjar&#x2F;flink-tuning-1.0-SNAPSHOT.jar</p>\n</blockquote>\n<ul>\n<li>下载 GC 日志的方式：</li>\n</ul>\n<p>因为是 onyarn 模式，运行的节点一个一个找比较麻烦。可以打开 WebUI，选择JobManager 或者 TaskManager，点击 Stdout，即可看到 GC 日志，点击下载按钮即可将 GC日志通过 HTTP的方式下载下来。</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1654679097595-18b82b7c-8bd5-4d21-b720-44c795ce377a.png\" alt=\"img\"></p>\n<ul>\n<li>分析 GC 日志：</li>\n</ul>\n<p>通过 GC 日志分析出单个 FlinkTaskmanager 堆总大小、年轻代、老年代分配的内存空间、FullGC 后老年代剩余大小等，相关指标定义可以去 Github 具体查看。</p>\n<p>GCViewer 地址：<a href=\"https://github.com/chewiebug/GCViewer\">https://github.com/chewiebug/GCViewer</a></p>\n<p>Linux 下分析：</p>\n<p>java -jargcviewer_1.3.4.jargc.log                                                                                    </p>\n<p>Windows 下分析：</p>\n<p>直接双击gcviewer_1.3.4.jar，打开GUI界面，选择gc的log打开         </p>\n<p>​                      </p>\n<p>扩展：最重要的指标是FullGC 后，老年代剩余大小这个指标，按照《Java 性能优化权威指南》这本书 Java 堆大小计算法则，设 FullGC 后老年代剩余大小空间为 M，那么堆的大小建议 3<del>4 倍 M，新生代为 1</del>1.5 倍 M，老年代应为 2~3 倍 M。</p>\n<h3 id=\"3-3-4-外部组件交互\"><a href=\"#3-3-4-外部组件交互\" class=\"headerlink\" title=\"3.3.4    外部组件交互\"></a>3.3.4    外部组件交互</h3><p>如果发现我们的 Source端数据读取性能比较低或者 Sink端写入性能较差，需要检查第三方组件是否遇到瓶颈，还有就是做维表join时的性能问题。</p>\n<p>例如：</p>\n<p>Kafka集群是否需要扩容，Kafka 连接器是否并行度较低</p>\n<p>HBase的 rowkey 是否遇到热点问题，是否请求处理不过来</p>\n<p>ClickHouse并发能力较弱，是否达到瓶颈</p>\n<p>……</p>\n<p>关于第三方组件的性能问题，需要结合具体的组件来分析，最常用的思路：</p>\n<ul>\n<li>1）异步 io+热缓存来优化读写性能</li>\n<li>2）先攒批再读写维表join参考：</li>\n</ul>\n<p><a href=\"https://flink-learning.org.cn/article/detail/b8df32fbc6542257a5b449114e137cc3\">https://flink-learning.org.cn/article/detail/b8df32fbc6542257a5b449114e137cc3</a></p>\n<p><a href=\"https://www.jianshu.com/p/a62fa483ff54\">https://www.jianshu.com/p/a62fa483ff54</a></p>\n<h1 id=\"四、数据倾斜\"><a href=\"#四、数据倾斜\" class=\"headerlink\" title=\"四、数据倾斜\"></a>四、数据倾斜</h1><h2 id=\"4-1-判断是否存在数据倾斜\"><a href=\"#4-1-判断是否存在数据倾斜\" class=\"headerlink\" title=\"4.1  判断是否存在数据倾斜\"></a>4.1  判断是否存在数据倾斜</h2><p>相同 Task 的多个 Subtask 中， 个别 Subtask 接收到的数据量明显大于其他Subtask 接收到的数据量，通过 FlinkWebUI 可以精确地看到每个 Subtask 处理了多少数据，即可判断出 Flink 任务是否存在数据倾斜。通常，数据倾斜也会引起反压。</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1654692839400-88f4eb2d-9389-4011-a676-2f6da336cb39.png\" alt=\"img\"></p>\n<p>另外， 有时 Checkpointdetail 里不同 SubTask 的 Statesize 也是一个分析数据倾斜的有用指标。</p>\n<h2 id=\"4-2-数据倾斜的解决\"><a href=\"#4-2-数据倾斜的解决\" class=\"headerlink\" title=\"4.2 数据倾斜的解决\"></a>4.2 数据倾斜的解决</h2><h3 id=\"4-2-1-keyBy-后的聚合操作存在数据倾斜\"><a href=\"#4-2-1-keyBy-后的聚合操作存在数据倾斜\" class=\"headerlink\" title=\"4.2.1    keyBy 后的聚合操作存在数据倾斜\"></a>4.2.1    keyBy 后的聚合操作存在数据倾斜</h3><h4 id=\"1）为什么不能直接用二次聚合来处理（没有卵用）\"><a href=\"#1）为什么不能直接用二次聚合来处理（没有卵用）\" class=\"headerlink\" title=\"1）为什么不能直接用二次聚合来处理（没有卵用）\"></a>1）为什么不能直接用二次聚合来处理（没有卵用）</h4><p>Flink是实时流处理，如果keyby之后的聚合操作存在数据倾斜，且没有开窗口（没攒批）的情况下，简单的认为使用两阶段聚合，是不能解决问题的。因为这个时候Flink是来一条处理一条，且向下游发送一条结果，对于原来 keyby的维度（第二阶段聚合）来讲，数据量并没有减少，且结果重复计算（非 FlinkSQL，未使用回撤流），如下图所示：</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1654692995562-f3b6caac-04e3-45ac-87bc-92286cb10e2b.png\" alt=\"img\"></p>\n<h4 id=\"2）使用-LocalKeyBy-的思想\"><a href=\"#2）使用-LocalKeyBy-的思想\" class=\"headerlink\" title=\"2）使用 LocalKeyBy 的思想\"></a>2）使用 LocalKeyBy 的思想</h4><p>在 keyBy 上游算子数据发送之前，首先在上游算子的本地对数据进行聚合后，再发送到下游，使下游接收到的数据量大大减少，从而使得 keyBy 之后的聚合操作不再是任务的瓶颈。类似 MapReduce中 Combiner的思想，但是这要求聚合操作必须是多条数据或者一批数据才能聚合，单条数据没有办法通过聚合来减少数据量。从 FlinkLocalKeyBy实现原理来讲，必然会存在一个积攒批次的过程，在上游算子中必须攒够一定的数据量，对这些数据聚合后再发送到下游。</p>\n<h4 id=\"实现方式：\"><a href=\"#实现方式：\" class=\"headerlink\" title=\"实现方式：\"></a>实现方式：</h4><ul>\n<li>DataStreamAPI 需要自己写代码实现</li>\n<li>SQL 可以指定参数，开启miniBatch 和 LocalGlobal 功能（推荐，后续介绍）</li>\n</ul>\n<h3 id=\"4-1-1-keyBy之前发生数据倾斜\"><a href=\"#4-1-1-keyBy之前发生数据倾斜\" class=\"headerlink\" title=\"4.1.1    keyBy之前发生数据倾斜\"></a>4.1.1    keyBy之前发生数据倾斜</h3><p>如果 keyBy 之前就存在数据倾斜，上游算子的某些实例可能处理的数据较多，某些实例可能处理的数据较少，产生该情况可能是因为数据源的数据本身就不均匀，例如由于某些原因 Kafka 的 topic 中某些 partition 的数据量较大，某些 partition 的数据量较少。</p>\n<p>对于不存在 keyBy 的 Flink 任务也会出现该情况。</p>\n<p>这种情况，需要让 Flink 任务强制进行shuffle。使用 shuffle、rebalance 或 rescale</p>\n<p>算子即可将数据均匀分配，从而解决数据倾斜的问题。</p>\n<h3 id=\"4-1-2-keyBy-后的窗口聚合操作存在数据倾斜\"><a href=\"#4-1-2-keyBy-后的窗口聚合操作存在数据倾斜\" class=\"headerlink\" title=\"4.1.2    keyBy 后的窗口聚合操作存在数据倾斜\"></a>4.1.2    keyBy 后的窗口聚合操作存在数据倾斜</h3><p>因为使用了窗口，变成了有界数据（攒批）的处理，窗口默认是触发时才会输出一条结果发往下游，所以可以使用两阶段聚合的方式：</p>\n<h4 id=\"1）实现思路：\"><a href=\"#1）实现思路：\" class=\"headerlink\" title=\"1）实现思路：\"></a>1）实现思路：</h4><ul>\n<li>第一阶段聚合：key拼接随机数前缀或后缀，进行 keyby、开窗、聚合</li>\n</ul>\n<p><strong>注意：聚合完不再是 WindowedStream，要获取 WindowEnd 作为窗口标记作为第二阶段分组依据，避免不同窗口的结果聚合到一起）</strong></p>\n<ul>\n<li>第二阶段聚合：按照原来的 key 及windowEnd 作keyby、聚合</li>\n</ul>\n<p>SQL写法参考：<a href=\"https://zhuanlan.zhihu.com/p/197299746\">https://zhuanlan.zhihu.com/p/197299746</a></p>\n"},{"title":"HBase如何实现MVCC？","top_img":"linear-gradient(20deg, #0062be, #925696, #cc426e, #fb0347)","date":"2022-07-05T07:13:53.000Z","updated":"2022-07-05T07:13:53.000Z","cover":"https://tvax3.sinaimg.cn/large/0084aYsLly1grnkfb3zyvj31hc0tndku.jpg","description":null,"keywords":null,"_content":"\n## HBase的事务一致性保证\n\n**HBase 是一个强一致性数据库，不是“最终一致性”数据库，官网给出的介绍**\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657001617770-e017f8b5-f8c4-4b1e-9721-a934e51df162.png)\n\n> - 每个值只出现在一个 Region\n> - 同一时间一个 Region 只分配给一个 RS\n> - 行内的 mutation 操作都是原子的\n\n**HBase 降低可用性提高了一致性。**\n\n当某台 RS fail 的时候，它管理的 Region failover 到其他 RS 时，需要根据 WAL（Write-Ahead Logging）来 redo (redolog，有一种日志文件叫做重做日志文件)，\n这时候进行 redo 的 Region 应该是不可用的，所以 HBase 降低了可用性，提高了一致性。\n\n设想一下，如果 redo 的 Region 能够响应请求，那么可用性提高了，则必然返回不一致的数据(因为 redo 可能还没完成)，那么 HBase 就降低一致性来提高可用性了。\n\n## HBase MVCC实现流程\n\n数据库为了保证一致性，在执行读写操作时往往会对数据做一些锁操作，比如两个client同时修改一条数据，我们无法确定最终的数据到底是哪一个client执行的结果，所以需要通过加锁来保证数据的一致性。\n\n但是锁操作的代价是比较大的，往往需要对加锁操作进行优化，主流的数据库Mysql，PG等都采用MVCC（多版本并发控制）来尽量避免使用不必要的锁以提高性能。本文主要介绍HBase的MVCC实现机制。\n\n在讲解HBase的MVCC之前，我们先了解一下现有的隔离级别，sql标准定义了4种隔离级别：\n\n> 1.read uncommitted    读未提交\n>\n> 2.read committed        读已提交\n>\n> 3.repeatable read        可重复读\n>\n> 4.serializable               可串行化\n\n**HBase不支持跨行事务，目前只支持单行级别的read uncommitted和read committed隔离级别。下面主要讲解HBase的read committed实现机制。**\n\n\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657001352637-015609d0-a12b-4a30-b262-8869b85c9b85.png)\n\nHBase采用LSM树结构，当client发送数据给regionserver端时，regionserver会将数据写入对应的region中，region是由一个memstore和多个storeFile组成，我们可以将memstore看做是一个skipList（跳表），所有写入的数据首先存放在memstore中，当memstore增大到指定的大小后，memstore中的数据flush到磁盘生成一个新的storeFile。\n\n### HBase的写入主要分两步：\n\n> **1.数据首先写入memstore**\n>\n> **2.数据写入WAL**\n>\n> 写入WAL的目的是为了持久化，防止memstore中的数据还未落盘时宕机造成的数据丢失，只有数据写入WAL成功之后才会认为该数据写入成功。\n>\n\n**下面我们考虑一个问题：**\n\n根据前面的讨论可知，假如数据已经写入memstore，但还没有写入WAL，此时认为该条数据还没有写成功，如果按照read committed隔离界别的定义，用户在进行查询操作时（尤其是查询memstore时），是不应该看到这条数据的，那HBase是如何区分正在写入和写入成功的数据呢？\n\n我们可以简单理解HBase在每次put操作时，都会为该操作分配一个id，可以类比mysql里面的事务id，是本次put的唯一标识，该id是region级别递增的，并且每个region还有一个MVCC控制中心，它还同时维护了两个pos：一个readpoint，一个writepoint。readpoint指向目前已经插入完成的id，当put操作完成时会更新readpoint；而writepoint指向目前正在插入的最大id，可以认为writepoint永远和最新申请的put的事务id是一样的。\n\n\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657001352762-41efd7fd-cfbd-4077-b218-c451a0d80e5c.png)\n\n**下面我们画图解释：**\n\n1.client插入数据时（这里的client我们可以理解为是regionserver），首先会向MVCC控制中心（MultiVersionConsistencyControl类）申请最新的事务id，其实就是返回write point++，每一个region各自拥有一个独立MVCC控制中心。\n\n2.假设初始状态read和write point都指向2，表明目前没有正在进行的put操作，新的put请求过来时，该region的MVCC控制中心向它自己维护的队列中插入一个新的entry，表示发起了一个新的put事务，并且第一步中将write point++。\n\n3.向client返回本次事务的id为3.\n\n4.client向memstore中插入数据，并且该数据附带本次事务的id号：3\n\n5.将本次的put操作写入WAL，写入成功后代表数据写入成功\n\n6.此时移动read point至3，表示任何MVCC值小于等于3的数据此时都可以被新创建的scan查询检索到。\n\nscan执行查询操作时，首先会向MVCC控制中心拿到目前的read point，然后对memstore和storeFiles进行查询，并过滤掉MVCC值大于本次scan MVCC的数据，保证了scan不会检索到还未提交成功的数据。这也说明HBase默认即为read committed级别，只不过是单行事务。\n\n\n\n\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657001352817-f8176f99-9cd4-477c-ac8e-153fdc023be7.png)\n\n真正业务场景下是会有很多个client同时写入的，此时不管向MVCC申请事务id还是更新read point都会涉及到多用户竞争的情况。如图client A B C分别写入了数据de/fg/hi，有可能A C已经写入成功了，而B还未执行完，下面我们看一下MVCC控制中心是如何协调并发请求的。\n\n先介绍一下MVCC控制中心–**MultiVersionConsistencyControl**类.\n\n**它包含了三个重要的成员：**\n\n1.memstoreRead：即我们提到的read point，记录可以已执行完毕的事务id\n\n2.memstoreWrite：即我们提到的write point，记录当前正在执行的最大事务id\n\n3.writeQueue：一个LinkedList，每一个元素是一个WriteEntry对象。\n\n**WriteEntry类包含两个属性：**\n\n1.writeNumber：事务id\n\n2.completed： True/False，数据写入成功后，写入线程会将其设置为True\n\n\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657001352718-eea3b630-fac5-4e86-8c07-7629c40cb12e.png)\n\n**下面详细解释MVCC控制中心针对多用户请求是如何做到同步的：**\n\n1.当一个client写入数据时，首先lock住MVCC控制中心的写入队列LinkedList，并向其插入一个新的entry，并将之前的write point+1赋予entry的num（write point+1也是同步操作），表示发起了一个新的写入事务。Flag值此时为False，表名目前事务还未完成，数据还在写入过程中。\n\n2.第二步client将数据写入memstore和WAL，此时认为数据已经持久化，可以结束该事务。\n\n3.client调用MVCC控制中心的completeMemstoreInsert(num)方法，该方法采用synchronized关键字，可以理解就是同步方法，将该num对应的entry的Flag设置为True，表示该entry对应的事务完成。但是单单将Flag设置为True是不够的，我们的最终目的是要让scan能够看到最新写入完成的数据，也就是说还需要更新read point。\n\n4.更新read point：同样在completeMemstoreInsert方法中完成，每一个client将其对应的entry的Flag设置为True后，都会去按照队列顺序，从read point开始遍历，假如遍历到的entry的Flag为True，则将read point更新至此位置，直到遇到Flag为False的位置时停止。也就是说每个client写入之后，都会尽力去将read point更新到目前最大连续的已经完成的事务的点（因为是有可能后开始的事务先于之前的事务完成）。\n\n看到这里，可能大家会想了，那假如事务A先于事务C，事务A还未完成，但事务C已经完成，事务C也只能将read point更新到事务A之前的位置，如果此时事务C返回写入成功，那按道理来说scan是应该能够查到事务C的数据，但是由于read point没有更新到C，就会造成一个现象就是：事务C明明提示执行成功，但是查询的时候却看不到。\n\n所以上面说的第4步其实还并没有完，client在执行completeMemstoreInsert后，还会执行一个waitForRead(entry)方法，参数的entry就是该事务对应的entry，该方法会一直等待read point大于等于该entry的num时才会返回，这样保证了事务有序完成。\n\n以上就是HBase写入时MVCC的工作流程，scan就比较好理解了，每一个scan请求都会申请一个readpoint，保证了该read point之后的事务不会被检索到。\n\n\n\n**说明**：HBase也同样支持read uncommitted级别，也就是我们在查询的时候将scan的mvcc值设置为一个超大的值，大于目前所有申请的MVCC值，那么查询时同样会返回正在写入的数据。\n\n","source":"_posts/bigdata/HBase如何实现MVCC.md","raw":"---\ntitle: HBase如何实现MVCC？\ntags:\n  - 'HBase'\n  - 'MVCC'\ncategories:\n  - [bigdata,HBase]\ntop_img: 'linear-gradient(20deg, #0062be, #925696, #cc426e, #fb0347)'\ndate: 2022-07-05 15:13:53\nupdated: 2022-07-05 15:13:53\ncover:\ndescription:\nkeywords:\n---\n\n## HBase的事务一致性保证\n\n**HBase 是一个强一致性数据库，不是“最终一致性”数据库，官网给出的介绍**\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657001617770-e017f8b5-f8c4-4b1e-9721-a934e51df162.png)\n\n> - 每个值只出现在一个 Region\n> - 同一时间一个 Region 只分配给一个 RS\n> - 行内的 mutation 操作都是原子的\n\n**HBase 降低可用性提高了一致性。**\n\n当某台 RS fail 的时候，它管理的 Region failover 到其他 RS 时，需要根据 WAL（Write-Ahead Logging）来 redo (redolog，有一种日志文件叫做重做日志文件)，\n这时候进行 redo 的 Region 应该是不可用的，所以 HBase 降低了可用性，提高了一致性。\n\n设想一下，如果 redo 的 Region 能够响应请求，那么可用性提高了，则必然返回不一致的数据(因为 redo 可能还没完成)，那么 HBase 就降低一致性来提高可用性了。\n\n## HBase MVCC实现流程\n\n数据库为了保证一致性，在执行读写操作时往往会对数据做一些锁操作，比如两个client同时修改一条数据，我们无法确定最终的数据到底是哪一个client执行的结果，所以需要通过加锁来保证数据的一致性。\n\n但是锁操作的代价是比较大的，往往需要对加锁操作进行优化，主流的数据库Mysql，PG等都采用MVCC（多版本并发控制）来尽量避免使用不必要的锁以提高性能。本文主要介绍HBase的MVCC实现机制。\n\n在讲解HBase的MVCC之前，我们先了解一下现有的隔离级别，sql标准定义了4种隔离级别：\n\n> 1.read uncommitted    读未提交\n>\n> 2.read committed        读已提交\n>\n> 3.repeatable read        可重复读\n>\n> 4.serializable               可串行化\n\n**HBase不支持跨行事务，目前只支持单行级别的read uncommitted和read committed隔离级别。下面主要讲解HBase的read committed实现机制。**\n\n\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657001352637-015609d0-a12b-4a30-b262-8869b85c9b85.png)\n\nHBase采用LSM树结构，当client发送数据给regionserver端时，regionserver会将数据写入对应的region中，region是由一个memstore和多个storeFile组成，我们可以将memstore看做是一个skipList（跳表），所有写入的数据首先存放在memstore中，当memstore增大到指定的大小后，memstore中的数据flush到磁盘生成一个新的storeFile。\n\n### HBase的写入主要分两步：\n\n> **1.数据首先写入memstore**\n>\n> **2.数据写入WAL**\n>\n> 写入WAL的目的是为了持久化，防止memstore中的数据还未落盘时宕机造成的数据丢失，只有数据写入WAL成功之后才会认为该数据写入成功。\n>\n\n**下面我们考虑一个问题：**\n\n根据前面的讨论可知，假如数据已经写入memstore，但还没有写入WAL，此时认为该条数据还没有写成功，如果按照read committed隔离界别的定义，用户在进行查询操作时（尤其是查询memstore时），是不应该看到这条数据的，那HBase是如何区分正在写入和写入成功的数据呢？\n\n我们可以简单理解HBase在每次put操作时，都会为该操作分配一个id，可以类比mysql里面的事务id，是本次put的唯一标识，该id是region级别递增的，并且每个region还有一个MVCC控制中心，它还同时维护了两个pos：一个readpoint，一个writepoint。readpoint指向目前已经插入完成的id，当put操作完成时会更新readpoint；而writepoint指向目前正在插入的最大id，可以认为writepoint永远和最新申请的put的事务id是一样的。\n\n\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657001352762-41efd7fd-cfbd-4077-b218-c451a0d80e5c.png)\n\n**下面我们画图解释：**\n\n1.client插入数据时（这里的client我们可以理解为是regionserver），首先会向MVCC控制中心（MultiVersionConsistencyControl类）申请最新的事务id，其实就是返回write point++，每一个region各自拥有一个独立MVCC控制中心。\n\n2.假设初始状态read和write point都指向2，表明目前没有正在进行的put操作，新的put请求过来时，该region的MVCC控制中心向它自己维护的队列中插入一个新的entry，表示发起了一个新的put事务，并且第一步中将write point++。\n\n3.向client返回本次事务的id为3.\n\n4.client向memstore中插入数据，并且该数据附带本次事务的id号：3\n\n5.将本次的put操作写入WAL，写入成功后代表数据写入成功\n\n6.此时移动read point至3，表示任何MVCC值小于等于3的数据此时都可以被新创建的scan查询检索到。\n\nscan执行查询操作时，首先会向MVCC控制中心拿到目前的read point，然后对memstore和storeFiles进行查询，并过滤掉MVCC值大于本次scan MVCC的数据，保证了scan不会检索到还未提交成功的数据。这也说明HBase默认即为read committed级别，只不过是单行事务。\n\n\n\n\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657001352817-f8176f99-9cd4-477c-ac8e-153fdc023be7.png)\n\n真正业务场景下是会有很多个client同时写入的，此时不管向MVCC申请事务id还是更新read point都会涉及到多用户竞争的情况。如图client A B C分别写入了数据de/fg/hi，有可能A C已经写入成功了，而B还未执行完，下面我们看一下MVCC控制中心是如何协调并发请求的。\n\n先介绍一下MVCC控制中心–**MultiVersionConsistencyControl**类.\n\n**它包含了三个重要的成员：**\n\n1.memstoreRead：即我们提到的read point，记录可以已执行完毕的事务id\n\n2.memstoreWrite：即我们提到的write point，记录当前正在执行的最大事务id\n\n3.writeQueue：一个LinkedList，每一个元素是一个WriteEntry对象。\n\n**WriteEntry类包含两个属性：**\n\n1.writeNumber：事务id\n\n2.completed： True/False，数据写入成功后，写入线程会将其设置为True\n\n\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657001352718-eea3b630-fac5-4e86-8c07-7629c40cb12e.png)\n\n**下面详细解释MVCC控制中心针对多用户请求是如何做到同步的：**\n\n1.当一个client写入数据时，首先lock住MVCC控制中心的写入队列LinkedList，并向其插入一个新的entry，并将之前的write point+1赋予entry的num（write point+1也是同步操作），表示发起了一个新的写入事务。Flag值此时为False，表名目前事务还未完成，数据还在写入过程中。\n\n2.第二步client将数据写入memstore和WAL，此时认为数据已经持久化，可以结束该事务。\n\n3.client调用MVCC控制中心的completeMemstoreInsert(num)方法，该方法采用synchronized关键字，可以理解就是同步方法，将该num对应的entry的Flag设置为True，表示该entry对应的事务完成。但是单单将Flag设置为True是不够的，我们的最终目的是要让scan能够看到最新写入完成的数据，也就是说还需要更新read point。\n\n4.更新read point：同样在completeMemstoreInsert方法中完成，每一个client将其对应的entry的Flag设置为True后，都会去按照队列顺序，从read point开始遍历，假如遍历到的entry的Flag为True，则将read point更新至此位置，直到遇到Flag为False的位置时停止。也就是说每个client写入之后，都会尽力去将read point更新到目前最大连续的已经完成的事务的点（因为是有可能后开始的事务先于之前的事务完成）。\n\n看到这里，可能大家会想了，那假如事务A先于事务C，事务A还未完成，但事务C已经完成，事务C也只能将read point更新到事务A之前的位置，如果此时事务C返回写入成功，那按道理来说scan是应该能够查到事务C的数据，但是由于read point没有更新到C，就会造成一个现象就是：事务C明明提示执行成功，但是查询的时候却看不到。\n\n所以上面说的第4步其实还并没有完，client在执行completeMemstoreInsert后，还会执行一个waitForRead(entry)方法，参数的entry就是该事务对应的entry，该方法会一直等待read point大于等于该entry的num时才会返回，这样保证了事务有序完成。\n\n以上就是HBase写入时MVCC的工作流程，scan就比较好理解了，每一个scan请求都会申请一个readpoint，保证了该read point之后的事务不会被检索到。\n\n\n\n**说明**：HBase也同样支持read uncommitted级别，也就是我们在查询的时候将scan的mvcc值设置为一个超大的值，大于目前所有申请的MVCC值，那么查询时同样会返回正在写入的数据。\n\n","slug":"bigdata/HBase如何实现MVCC","published":1,"comments":1,"layout":"post","photos":[],"link":"","_id":"cl9y38dsd0019fwui7ax57un2","content":"<h2 id=\"HBase的事务一致性保证\"><a href=\"#HBase的事务一致性保证\" class=\"headerlink\" title=\"HBase的事务一致性保证\"></a>HBase的事务一致性保证</h2><p><strong>HBase 是一个强一致性数据库，不是“最终一致性”数据库，官网给出的介绍</strong></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657001617770-e017f8b5-f8c4-4b1e-9721-a934e51df162.png\" alt=\"img\"></p>\n<blockquote>\n<ul>\n<li>每个值只出现在一个 Region</li>\n<li>同一时间一个 Region 只分配给一个 RS</li>\n<li>行内的 mutation 操作都是原子的</li>\n</ul>\n</blockquote>\n<p><strong>HBase 降低可用性提高了一致性。</strong></p>\n<p>当某台 RS fail 的时候，它管理的 Region failover 到其他 RS 时，需要根据 WAL（Write-Ahead Logging）来 redo (redolog，有一种日志文件叫做重做日志文件)，<br>这时候进行 redo 的 Region 应该是不可用的，所以 HBase 降低了可用性，提高了一致性。</p>\n<p>设想一下，如果 redo 的 Region 能够响应请求，那么可用性提高了，则必然返回不一致的数据(因为 redo 可能还没完成)，那么 HBase 就降低一致性来提高可用性了。</p>\n<h2 id=\"HBase-MVCC实现流程\"><a href=\"#HBase-MVCC实现流程\" class=\"headerlink\" title=\"HBase MVCC实现流程\"></a>HBase MVCC实现流程</h2><p>数据库为了保证一致性，在执行读写操作时往往会对数据做一些锁操作，比如两个client同时修改一条数据，我们无法确定最终的数据到底是哪一个client执行的结果，所以需要通过加锁来保证数据的一致性。</p>\n<p>但是锁操作的代价是比较大的，往往需要对加锁操作进行优化，主流的数据库Mysql，PG等都采用MVCC（多版本并发控制）来尽量避免使用不必要的锁以提高性能。本文主要介绍HBase的MVCC实现机制。</p>\n<p>在讲解HBase的MVCC之前，我们先了解一下现有的隔离级别，sql标准定义了4种隔离级别：</p>\n<blockquote>\n<p>1.read uncommitted    读未提交</p>\n<p>2.read committed        读已提交</p>\n<p>3.repeatable read        可重复读</p>\n<p>4.serializable               可串行化</p>\n</blockquote>\n<p><strong>HBase不支持跨行事务，目前只支持单行级别的read uncommitted和read committed隔离级别。下面主要讲解HBase的read committed实现机制。</strong></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657001352637-015609d0-a12b-4a30-b262-8869b85c9b85.png\" alt=\"img\"></p>\n<p>HBase采用LSM树结构，当client发送数据给regionserver端时，regionserver会将数据写入对应的region中，region是由一个memstore和多个storeFile组成，我们可以将memstore看做是一个skipList（跳表），所有写入的数据首先存放在memstore中，当memstore增大到指定的大小后，memstore中的数据flush到磁盘生成一个新的storeFile。</p>\n<h3 id=\"HBase的写入主要分两步：\"><a href=\"#HBase的写入主要分两步：\" class=\"headerlink\" title=\"HBase的写入主要分两步：\"></a>HBase的写入主要分两步：</h3><blockquote>\n<p><strong>1.数据首先写入memstore</strong></p>\n<p><strong>2.数据写入WAL</strong></p>\n<p>写入WAL的目的是为了持久化，防止memstore中的数据还未落盘时宕机造成的数据丢失，只有数据写入WAL成功之后才会认为该数据写入成功。</p>\n</blockquote>\n<p><strong>下面我们考虑一个问题：</strong></p>\n<p>根据前面的讨论可知，假如数据已经写入memstore，但还没有写入WAL，此时认为该条数据还没有写成功，如果按照read committed隔离界别的定义，用户在进行查询操作时（尤其是查询memstore时），是不应该看到这条数据的，那HBase是如何区分正在写入和写入成功的数据呢？</p>\n<p>我们可以简单理解HBase在每次put操作时，都会为该操作分配一个id，可以类比mysql里面的事务id，是本次put的唯一标识，该id是region级别递增的，并且每个region还有一个MVCC控制中心，它还同时维护了两个pos：一个readpoint，一个writepoint。readpoint指向目前已经插入完成的id，当put操作完成时会更新readpoint；而writepoint指向目前正在插入的最大id，可以认为writepoint永远和最新申请的put的事务id是一样的。</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657001352762-41efd7fd-cfbd-4077-b218-c451a0d80e5c.png\" alt=\"img\"></p>\n<p><strong>下面我们画图解释：</strong></p>\n<p>1.client插入数据时（这里的client我们可以理解为是regionserver），首先会向MVCC控制中心（MultiVersionConsistencyControl类）申请最新的事务id，其实就是返回write point++，每一个region各自拥有一个独立MVCC控制中心。</p>\n<p>2.假设初始状态read和write point都指向2，表明目前没有正在进行的put操作，新的put请求过来时，该region的MVCC控制中心向它自己维护的队列中插入一个新的entry，表示发起了一个新的put事务，并且第一步中将write point++。</p>\n<p>3.向client返回本次事务的id为3.</p>\n<p>4.client向memstore中插入数据，并且该数据附带本次事务的id号：3</p>\n<p>5.将本次的put操作写入WAL，写入成功后代表数据写入成功</p>\n<p>6.此时移动read point至3，表示任何MVCC值小于等于3的数据此时都可以被新创建的scan查询检索到。</p>\n<p>scan执行查询操作时，首先会向MVCC控制中心拿到目前的read point，然后对memstore和storeFiles进行查询，并过滤掉MVCC值大于本次scan MVCC的数据，保证了scan不会检索到还未提交成功的数据。这也说明HBase默认即为read committed级别，只不过是单行事务。</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657001352817-f8176f99-9cd4-477c-ac8e-153fdc023be7.png\" alt=\"img\"></p>\n<p>真正业务场景下是会有很多个client同时写入的，此时不管向MVCC申请事务id还是更新read point都会涉及到多用户竞争的情况。如图client A B C分别写入了数据de&#x2F;fg&#x2F;hi，有可能A C已经写入成功了，而B还未执行完，下面我们看一下MVCC控制中心是如何协调并发请求的。</p>\n<p>先介绍一下MVCC控制中心–<strong>MultiVersionConsistencyControl</strong>类.</p>\n<p><strong>它包含了三个重要的成员：</strong></p>\n<p>1.memstoreRead：即我们提到的read point，记录可以已执行完毕的事务id</p>\n<p>2.memstoreWrite：即我们提到的write point，记录当前正在执行的最大事务id</p>\n<p>3.writeQueue：一个LinkedList，每一个元素是一个WriteEntry对象。</p>\n<p><strong>WriteEntry类包含两个属性：</strong></p>\n<p>1.writeNumber：事务id</p>\n<p>2.completed： True&#x2F;False，数据写入成功后，写入线程会将其设置为True</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657001352718-eea3b630-fac5-4e86-8c07-7629c40cb12e.png\" alt=\"img\"></p>\n<p><strong>下面详细解释MVCC控制中心针对多用户请求是如何做到同步的：</strong></p>\n<p>1.当一个client写入数据时，首先lock住MVCC控制中心的写入队列LinkedList，并向其插入一个新的entry，并将之前的write point+1赋予entry的num（write point+1也是同步操作），表示发起了一个新的写入事务。Flag值此时为False，表名目前事务还未完成，数据还在写入过程中。</p>\n<p>2.第二步client将数据写入memstore和WAL，此时认为数据已经持久化，可以结束该事务。</p>\n<p>3.client调用MVCC控制中心的completeMemstoreInsert(num)方法，该方法采用synchronized关键字，可以理解就是同步方法，将该num对应的entry的Flag设置为True，表示该entry对应的事务完成。但是单单将Flag设置为True是不够的，我们的最终目的是要让scan能够看到最新写入完成的数据，也就是说还需要更新read point。</p>\n<p>4.更新read point：同样在completeMemstoreInsert方法中完成，每一个client将其对应的entry的Flag设置为True后，都会去按照队列顺序，从read point开始遍历，假如遍历到的entry的Flag为True，则将read point更新至此位置，直到遇到Flag为False的位置时停止。也就是说每个client写入之后，都会尽力去将read point更新到目前最大连续的已经完成的事务的点（因为是有可能后开始的事务先于之前的事务完成）。</p>\n<p>看到这里，可能大家会想了，那假如事务A先于事务C，事务A还未完成，但事务C已经完成，事务C也只能将read point更新到事务A之前的位置，如果此时事务C返回写入成功，那按道理来说scan是应该能够查到事务C的数据，但是由于read point没有更新到C，就会造成一个现象就是：事务C明明提示执行成功，但是查询的时候却看不到。</p>\n<p>所以上面说的第4步其实还并没有完，client在执行completeMemstoreInsert后，还会执行一个waitForRead(entry)方法，参数的entry就是该事务对应的entry，该方法会一直等待read point大于等于该entry的num时才会返回，这样保证了事务有序完成。</p>\n<p>以上就是HBase写入时MVCC的工作流程，scan就比较好理解了，每一个scan请求都会申请一个readpoint，保证了该read point之后的事务不会被检索到。</p>\n<p><strong>说明</strong>：HBase也同样支持read uncommitted级别，也就是我们在查询的时候将scan的mvcc值设置为一个超大的值，大于目前所有申请的MVCC值，那么查询时同样会返回正在写入的数据。</p>\n","site":{"data":{"link":[{"class_name":"友情链接","class_desc":"那些人，那些事","link_list":[{"name":"张洪Heo","link":"https://blog.zhheo.com/","avatar":"https://npm.elemecdn.com/guli-heo/img/avatar2.png","descr":"分享设计与科技生活"},{"name":"瞬間の筆記","link":"https://hikki.site","descr":"喜欢的东西就努力去追求，万一成功了呢!","avatar":"https://cdn.jsdelivr.net/gh/0000rookie/imgs/202206120315.png"}]}]}},"excerpt":"","more":"<h2 id=\"HBase的事务一致性保证\"><a href=\"#HBase的事务一致性保证\" class=\"headerlink\" title=\"HBase的事务一致性保证\"></a>HBase的事务一致性保证</h2><p><strong>HBase 是一个强一致性数据库，不是“最终一致性”数据库，官网给出的介绍</strong></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657001617770-e017f8b5-f8c4-4b1e-9721-a934e51df162.png\" alt=\"img\"></p>\n<blockquote>\n<ul>\n<li>每个值只出现在一个 Region</li>\n<li>同一时间一个 Region 只分配给一个 RS</li>\n<li>行内的 mutation 操作都是原子的</li>\n</ul>\n</blockquote>\n<p><strong>HBase 降低可用性提高了一致性。</strong></p>\n<p>当某台 RS fail 的时候，它管理的 Region failover 到其他 RS 时，需要根据 WAL（Write-Ahead Logging）来 redo (redolog，有一种日志文件叫做重做日志文件)，<br>这时候进行 redo 的 Region 应该是不可用的，所以 HBase 降低了可用性，提高了一致性。</p>\n<p>设想一下，如果 redo 的 Region 能够响应请求，那么可用性提高了，则必然返回不一致的数据(因为 redo 可能还没完成)，那么 HBase 就降低一致性来提高可用性了。</p>\n<h2 id=\"HBase-MVCC实现流程\"><a href=\"#HBase-MVCC实现流程\" class=\"headerlink\" title=\"HBase MVCC实现流程\"></a>HBase MVCC实现流程</h2><p>数据库为了保证一致性，在执行读写操作时往往会对数据做一些锁操作，比如两个client同时修改一条数据，我们无法确定最终的数据到底是哪一个client执行的结果，所以需要通过加锁来保证数据的一致性。</p>\n<p>但是锁操作的代价是比较大的，往往需要对加锁操作进行优化，主流的数据库Mysql，PG等都采用MVCC（多版本并发控制）来尽量避免使用不必要的锁以提高性能。本文主要介绍HBase的MVCC实现机制。</p>\n<p>在讲解HBase的MVCC之前，我们先了解一下现有的隔离级别，sql标准定义了4种隔离级别：</p>\n<blockquote>\n<p>1.read uncommitted    读未提交</p>\n<p>2.read committed        读已提交</p>\n<p>3.repeatable read        可重复读</p>\n<p>4.serializable               可串行化</p>\n</blockquote>\n<p><strong>HBase不支持跨行事务，目前只支持单行级别的read uncommitted和read committed隔离级别。下面主要讲解HBase的read committed实现机制。</strong></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657001352637-015609d0-a12b-4a30-b262-8869b85c9b85.png\" alt=\"img\"></p>\n<p>HBase采用LSM树结构，当client发送数据给regionserver端时，regionserver会将数据写入对应的region中，region是由一个memstore和多个storeFile组成，我们可以将memstore看做是一个skipList（跳表），所有写入的数据首先存放在memstore中，当memstore增大到指定的大小后，memstore中的数据flush到磁盘生成一个新的storeFile。</p>\n<h3 id=\"HBase的写入主要分两步：\"><a href=\"#HBase的写入主要分两步：\" class=\"headerlink\" title=\"HBase的写入主要分两步：\"></a>HBase的写入主要分两步：</h3><blockquote>\n<p><strong>1.数据首先写入memstore</strong></p>\n<p><strong>2.数据写入WAL</strong></p>\n<p>写入WAL的目的是为了持久化，防止memstore中的数据还未落盘时宕机造成的数据丢失，只有数据写入WAL成功之后才会认为该数据写入成功。</p>\n</blockquote>\n<p><strong>下面我们考虑一个问题：</strong></p>\n<p>根据前面的讨论可知，假如数据已经写入memstore，但还没有写入WAL，此时认为该条数据还没有写成功，如果按照read committed隔离界别的定义，用户在进行查询操作时（尤其是查询memstore时），是不应该看到这条数据的，那HBase是如何区分正在写入和写入成功的数据呢？</p>\n<p>我们可以简单理解HBase在每次put操作时，都会为该操作分配一个id，可以类比mysql里面的事务id，是本次put的唯一标识，该id是region级别递增的，并且每个region还有一个MVCC控制中心，它还同时维护了两个pos：一个readpoint，一个writepoint。readpoint指向目前已经插入完成的id，当put操作完成时会更新readpoint；而writepoint指向目前正在插入的最大id，可以认为writepoint永远和最新申请的put的事务id是一样的。</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657001352762-41efd7fd-cfbd-4077-b218-c451a0d80e5c.png\" alt=\"img\"></p>\n<p><strong>下面我们画图解释：</strong></p>\n<p>1.client插入数据时（这里的client我们可以理解为是regionserver），首先会向MVCC控制中心（MultiVersionConsistencyControl类）申请最新的事务id，其实就是返回write point++，每一个region各自拥有一个独立MVCC控制中心。</p>\n<p>2.假设初始状态read和write point都指向2，表明目前没有正在进行的put操作，新的put请求过来时，该region的MVCC控制中心向它自己维护的队列中插入一个新的entry，表示发起了一个新的put事务，并且第一步中将write point++。</p>\n<p>3.向client返回本次事务的id为3.</p>\n<p>4.client向memstore中插入数据，并且该数据附带本次事务的id号：3</p>\n<p>5.将本次的put操作写入WAL，写入成功后代表数据写入成功</p>\n<p>6.此时移动read point至3，表示任何MVCC值小于等于3的数据此时都可以被新创建的scan查询检索到。</p>\n<p>scan执行查询操作时，首先会向MVCC控制中心拿到目前的read point，然后对memstore和storeFiles进行查询，并过滤掉MVCC值大于本次scan MVCC的数据，保证了scan不会检索到还未提交成功的数据。这也说明HBase默认即为read committed级别，只不过是单行事务。</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657001352817-f8176f99-9cd4-477c-ac8e-153fdc023be7.png\" alt=\"img\"></p>\n<p>真正业务场景下是会有很多个client同时写入的，此时不管向MVCC申请事务id还是更新read point都会涉及到多用户竞争的情况。如图client A B C分别写入了数据de&#x2F;fg&#x2F;hi，有可能A C已经写入成功了，而B还未执行完，下面我们看一下MVCC控制中心是如何协调并发请求的。</p>\n<p>先介绍一下MVCC控制中心–<strong>MultiVersionConsistencyControl</strong>类.</p>\n<p><strong>它包含了三个重要的成员：</strong></p>\n<p>1.memstoreRead：即我们提到的read point，记录可以已执行完毕的事务id</p>\n<p>2.memstoreWrite：即我们提到的write point，记录当前正在执行的最大事务id</p>\n<p>3.writeQueue：一个LinkedList，每一个元素是一个WriteEntry对象。</p>\n<p><strong>WriteEntry类包含两个属性：</strong></p>\n<p>1.writeNumber：事务id</p>\n<p>2.completed： True&#x2F;False，数据写入成功后，写入线程会将其设置为True</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657001352718-eea3b630-fac5-4e86-8c07-7629c40cb12e.png\" alt=\"img\"></p>\n<p><strong>下面详细解释MVCC控制中心针对多用户请求是如何做到同步的：</strong></p>\n<p>1.当一个client写入数据时，首先lock住MVCC控制中心的写入队列LinkedList，并向其插入一个新的entry，并将之前的write point+1赋予entry的num（write point+1也是同步操作），表示发起了一个新的写入事务。Flag值此时为False，表名目前事务还未完成，数据还在写入过程中。</p>\n<p>2.第二步client将数据写入memstore和WAL，此时认为数据已经持久化，可以结束该事务。</p>\n<p>3.client调用MVCC控制中心的completeMemstoreInsert(num)方法，该方法采用synchronized关键字，可以理解就是同步方法，将该num对应的entry的Flag设置为True，表示该entry对应的事务完成。但是单单将Flag设置为True是不够的，我们的最终目的是要让scan能够看到最新写入完成的数据，也就是说还需要更新read point。</p>\n<p>4.更新read point：同样在completeMemstoreInsert方法中完成，每一个client将其对应的entry的Flag设置为True后，都会去按照队列顺序，从read point开始遍历，假如遍历到的entry的Flag为True，则将read point更新至此位置，直到遇到Flag为False的位置时停止。也就是说每个client写入之后，都会尽力去将read point更新到目前最大连续的已经完成的事务的点（因为是有可能后开始的事务先于之前的事务完成）。</p>\n<p>看到这里，可能大家会想了，那假如事务A先于事务C，事务A还未完成，但事务C已经完成，事务C也只能将read point更新到事务A之前的位置，如果此时事务C返回写入成功，那按道理来说scan是应该能够查到事务C的数据，但是由于read point没有更新到C，就会造成一个现象就是：事务C明明提示执行成功，但是查询的时候却看不到。</p>\n<p>所以上面说的第4步其实还并没有完，client在执行completeMemstoreInsert后，还会执行一个waitForRead(entry)方法，参数的entry就是该事务对应的entry，该方法会一直等待read point大于等于该entry的num时才会返回，这样保证了事务有序完成。</p>\n<p>以上就是HBase写入时MVCC的工作流程，scan就比较好理解了，每一个scan请求都会申请一个readpoint，保证了该read point之后的事务不会被检索到。</p>\n<p><strong>说明</strong>：HBase也同样支持read uncommitted级别，也就是我们在查询的时候将scan的mvcc值设置为一个超大的值，大于目前所有申请的MVCC值，那么查询时同样会返回正在写入的数据。</p>\n"},{"title":"Kyuubi-从入门到跑路","date":"2022-10-30T08:24:47.000Z","updated":"2022-10-30T08:24:47.000Z","cover":"https://tva3.sinaimg.cn/large/0084aYsLgy1h22161jezaj30xc0f0dh1.jpg","top_img":null,"description":null,"keywords":null,"_content":"\n> Kyuubi 将 Spark ThriftServer 的使用扩展为基于统一接口的多租户模型，并依靠多租户的概念与集群管理器交互，最终获得资源共享/隔离和数据安全的能力。Kyuubi Server 和 Engine 的松耦合架构大大提高了服务本身的并发性和服务稳定性。\n\n## What-Kyuubi是什么\n\nApache Kyuubi (Incubating)，一个分布式和多租户网关，用于在 Lakehouse 上提供 Serverless SQL。\n\n> 简单的来说Kyuubi就是一个SQL网关，用来将用户需要执行的SQL交给对应的计算引擎执行，如Spark、Flink等。作为一个优秀的网关，Kyuubi理所当然的实现了负载均衡、HA、多租户等功能。\n>\n> 正是这些功能，保证了Spark SQL可以真正的在企业内可用、好运、稳定的运行。\n\n![image.png](https://cdn.nlark.com/yuque/0/2022/png/2500465/1667120616678-362b15b3-89ac-4b49-961f-71d1b0eeda4e.png)\n\n## Why-为什么需要Kyuubi\n\n- 当然是Spark Thrift Server不好用，甚至可以说在生产上不可用（不支持HA和多租户），Spark SQL无法大展拳脚，因此诞生了Kyuubi。\n\n## How\n\n ### How: Kyuubi on Spark最佳实践\n\n- spark-defaults.conf配置\n\n```yaml\n#\n# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n\n# Default system properties included when running spark-submit.\n# This is useful for setting default environmental settings.\n\n# Example:\n# spark.master                     spark://master:7077\n# spark.eventLog.enabled           true\n# spark.eventLog.dir               hdfs://namenode:8021/directory\n# spark.serializer                 org.apache.spark.serializer.KryoSerializer\n# spark.driver.memory              5g\n# spark.executor.extraJavaOptions  -XX:+PrintGCDetails -Dkey=value -Dnumbers=\"one two three\"\n\n\n## Spark on Yarn config\nspark.master=yarn\nspark.executor.cores=1\nspark.yarn.am.memory=512m\nspark.driver.memory=1g\nspark.driver.memoryOverheadFactor=0.10\nspark.executor.memory=1g\nspark.executor.memoryOverheadFactor=0.10\n\n## Spark DRA config\nspark.dynamicAllocation.enabled=true\n# false if perfer shuffle tracking than ESS\nspark.shuffle.service.enabled=true\n# 理想情况下，三者的大小关系应为minExecutors<= initialExecutors< maxExecutors\nspark.dynamicAllocation.initialExecutors=10\nspark.dynamicAllocation.minExecutors=10\nspark.dynamicAllocation.maxExecutors=500\n# adjust spark.dynamicAllocation.executorAllocationRatio a bit lower to reduce the number of executors w.r.t. full parallelism.\nspark.dynamicAllocation.executorAllocationRatio=0.5\n# If one executor reached the maximum idle timeout, it will be removed.\nspark.dynamicAllocation.executorIdleTimeout=60s\nspark.dynamicAllocation.cachedExecutorIdleTimeout=30min\n# true if perfer shuffle tracking than ESS\nspark.dynamicAllocation.shuffleTracking.enabled=false\nspark.dynamicAllocation.shuffleTracking.timeout=30min\n# 如果 DRA 发现有待处理的任务积压超过超时，将请求新的执行程序，由以下配置控制。\nspark.dynamicAllocation.schedulerBacklogTimeout=1s\nspark.dynamicAllocation.sustainedSchedulerBacklogTimeout=1s\nspark.cleaner.periodicGC.interval=5min\n\n\n## Spark ESS config: DRA依赖于ESS，不过在Spark3后可以启用shuffleTracking后也可以启用DRA\n#  spark.shuffle.service.enabled=true   开启Spark ESS，前面已配置\nspark.shuffle.service.port=7337\nspark.shuffle.useOldFetchProtocol=true\n\n\n## Spark AQE config\nspark.sql.adaptive.enabled=true\nspark.sql.adaptive.forceApply=false\nspark.sql.adaptive.logLevel=info\n# 如果我们用HDFS读写数据，匹配HDFS的块大小应该是最好的选择，即128MB或256MB。\nspark.sql.adaptive.advisoryPartitionSizeInBytes=256m\nspark.sql.adaptive.coalescePartitions.enabled=true\nspark.sql.adaptive.coalescePartitions.minPartitionNum=1\n# 它代表合并之前的洗牌分区的初始数量。最好明确设置它而不是回退到spark.sql.shuffle.partitions.\nspark.sql.adaptive.coalescePartitions.initialPartitionNum=8192\nspark.sql.adaptive.fetchShuffleBlocksInBatch=true\nspark.sql.adaptive.localShuffleReader.enabled=true\nspark.sql.adaptive.skewJoin.enabled=true\nspark.sql.adaptive.skewJoin.skewedPartitionFactor=5\nspark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes=400m\nspark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin=0.2\nspark.sql.adaptive.optimizer.excludedRules\nspark.sql.autoBroadcastJoinThreshold=-1\n\n\n## Spark Doc: Tuning Guide\nspark.serializer=org.apache.spark.serializer.KryoSerializer\nspark.yarn.jars=hdfs://hadoop122:9000/spark-yarn/jars/*.jar\n# TODO-Push-based shuffle overview待启用\n```\n\n## Extension\n\n### 基于MySQL自定义认证\n\n```scala\npackage cn.jxau\n\nimport org.apache.kyuubi.service.authentication.PasswdAuthenticationProvider\n\nimport java.sql.{Connection, DriverManager}\nimport javax.security.sasl.AuthenticationException\n\nclass SimpleAuthenticationProvider extends PasswdAuthenticationProvider {\n\n  override def authenticate(user: String, password: String): Unit = {\n\n    val pwd: String = ConnectionFactory().authById(user)\n\n    if (pwd.equals(\"\"))\n      throw new AuthenticationException(s\"auth fail, no user\")\n    else if (!pwd.equals(password))\n      throw new AuthenticationException(s\"auth fail, pwd wrong\")\n  }\n\n}\n\ncase class ConnectionFactory() {\n\n  val database = \"test\"\n  val table = \"tb_score\"\n\n  // 访问本地MySQL服务器，通过3306端口访问mysql数据库\n  val url = s\"jdbc:mysql://172.29.130.156:3306/$database?useUnicode=true&characterEncoding=utf-8&useSSL=false\"\n  //驱动名称\n  val driver = \"com.mysql.cj.jdbc.Driver\"\n\n  //用户名\n  val username = \"root\"\n  //密码\n  val password = \"1234\"\n  //初始化数据连接\n  var connection: Connection = _\n\n  def authById(id: String): String ={\n    var pwd = \"\"\n\n    try {\n      //注册Driver\n      Class.forName(driver)\n      //得到连接\n      connection = DriverManager.getConnection(url, username, password)\n      val statement = connection.createStatement\n\n      //执行查询语句，并返回结果\n      val rs = statement.executeQuery(s\"SELECT subject FROM $table WHERE userid = $id\")\n\n      //打印返回结果\n      while (rs.next) {\n        pwd = rs.getString(\"subject\")\n      }\n\n      pwd match {\n        case \"\" => \"\"\n        case _ => pwd\n      }\n\n    } catch {\n      case exception: Exception => {\n        exception.printStackTrace()\n        throw exception\n      }\n    }finally {\n      if (connection != null){\n        connection.close()\n      }\n    }\n  }\n\n  def apply(): ConnectionFactory = ConnectionFactory()\n\n}\n```\n\n","source":"_posts/bigdata/Kyuubi-从入门到跑路.md","raw":"---\ntitle: Kyuubi-从入门到跑路\ntags:\n  - 'Kyuubi'\ncategories:\n  - [bigdata,Kyuubi]\ndate: 2022-10-30 16:24:47\nupdated: 2022-10-30 16:24:47\ncover:\ntop_img:\ndescription:\nkeywords:\n---\n\n> Kyuubi 将 Spark ThriftServer 的使用扩展为基于统一接口的多租户模型，并依靠多租户的概念与集群管理器交互，最终获得资源共享/隔离和数据安全的能力。Kyuubi Server 和 Engine 的松耦合架构大大提高了服务本身的并发性和服务稳定性。\n\n## What-Kyuubi是什么\n\nApache Kyuubi (Incubating)，一个分布式和多租户网关，用于在 Lakehouse 上提供 Serverless SQL。\n\n> 简单的来说Kyuubi就是一个SQL网关，用来将用户需要执行的SQL交给对应的计算引擎执行，如Spark、Flink等。作为一个优秀的网关，Kyuubi理所当然的实现了负载均衡、HA、多租户等功能。\n>\n> 正是这些功能，保证了Spark SQL可以真正的在企业内可用、好运、稳定的运行。\n\n![image.png](https://cdn.nlark.com/yuque/0/2022/png/2500465/1667120616678-362b15b3-89ac-4b49-961f-71d1b0eeda4e.png)\n\n## Why-为什么需要Kyuubi\n\n- 当然是Spark Thrift Server不好用，甚至可以说在生产上不可用（不支持HA和多租户），Spark SQL无法大展拳脚，因此诞生了Kyuubi。\n\n## How\n\n ### How: Kyuubi on Spark最佳实践\n\n- spark-defaults.conf配置\n\n```yaml\n#\n# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n\n# Default system properties included when running spark-submit.\n# This is useful for setting default environmental settings.\n\n# Example:\n# spark.master                     spark://master:7077\n# spark.eventLog.enabled           true\n# spark.eventLog.dir               hdfs://namenode:8021/directory\n# spark.serializer                 org.apache.spark.serializer.KryoSerializer\n# spark.driver.memory              5g\n# spark.executor.extraJavaOptions  -XX:+PrintGCDetails -Dkey=value -Dnumbers=\"one two three\"\n\n\n## Spark on Yarn config\nspark.master=yarn\nspark.executor.cores=1\nspark.yarn.am.memory=512m\nspark.driver.memory=1g\nspark.driver.memoryOverheadFactor=0.10\nspark.executor.memory=1g\nspark.executor.memoryOverheadFactor=0.10\n\n## Spark DRA config\nspark.dynamicAllocation.enabled=true\n# false if perfer shuffle tracking than ESS\nspark.shuffle.service.enabled=true\n# 理想情况下，三者的大小关系应为minExecutors<= initialExecutors< maxExecutors\nspark.dynamicAllocation.initialExecutors=10\nspark.dynamicAllocation.minExecutors=10\nspark.dynamicAllocation.maxExecutors=500\n# adjust spark.dynamicAllocation.executorAllocationRatio a bit lower to reduce the number of executors w.r.t. full parallelism.\nspark.dynamicAllocation.executorAllocationRatio=0.5\n# If one executor reached the maximum idle timeout, it will be removed.\nspark.dynamicAllocation.executorIdleTimeout=60s\nspark.dynamicAllocation.cachedExecutorIdleTimeout=30min\n# true if perfer shuffle tracking than ESS\nspark.dynamicAllocation.shuffleTracking.enabled=false\nspark.dynamicAllocation.shuffleTracking.timeout=30min\n# 如果 DRA 发现有待处理的任务积压超过超时，将请求新的执行程序，由以下配置控制。\nspark.dynamicAllocation.schedulerBacklogTimeout=1s\nspark.dynamicAllocation.sustainedSchedulerBacklogTimeout=1s\nspark.cleaner.periodicGC.interval=5min\n\n\n## Spark ESS config: DRA依赖于ESS，不过在Spark3后可以启用shuffleTracking后也可以启用DRA\n#  spark.shuffle.service.enabled=true   开启Spark ESS，前面已配置\nspark.shuffle.service.port=7337\nspark.shuffle.useOldFetchProtocol=true\n\n\n## Spark AQE config\nspark.sql.adaptive.enabled=true\nspark.sql.adaptive.forceApply=false\nspark.sql.adaptive.logLevel=info\n# 如果我们用HDFS读写数据，匹配HDFS的块大小应该是最好的选择，即128MB或256MB。\nspark.sql.adaptive.advisoryPartitionSizeInBytes=256m\nspark.sql.adaptive.coalescePartitions.enabled=true\nspark.sql.adaptive.coalescePartitions.minPartitionNum=1\n# 它代表合并之前的洗牌分区的初始数量。最好明确设置它而不是回退到spark.sql.shuffle.partitions.\nspark.sql.adaptive.coalescePartitions.initialPartitionNum=8192\nspark.sql.adaptive.fetchShuffleBlocksInBatch=true\nspark.sql.adaptive.localShuffleReader.enabled=true\nspark.sql.adaptive.skewJoin.enabled=true\nspark.sql.adaptive.skewJoin.skewedPartitionFactor=5\nspark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes=400m\nspark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin=0.2\nspark.sql.adaptive.optimizer.excludedRules\nspark.sql.autoBroadcastJoinThreshold=-1\n\n\n## Spark Doc: Tuning Guide\nspark.serializer=org.apache.spark.serializer.KryoSerializer\nspark.yarn.jars=hdfs://hadoop122:9000/spark-yarn/jars/*.jar\n# TODO-Push-based shuffle overview待启用\n```\n\n## Extension\n\n### 基于MySQL自定义认证\n\n```scala\npackage cn.jxau\n\nimport org.apache.kyuubi.service.authentication.PasswdAuthenticationProvider\n\nimport java.sql.{Connection, DriverManager}\nimport javax.security.sasl.AuthenticationException\n\nclass SimpleAuthenticationProvider extends PasswdAuthenticationProvider {\n\n  override def authenticate(user: String, password: String): Unit = {\n\n    val pwd: String = ConnectionFactory().authById(user)\n\n    if (pwd.equals(\"\"))\n      throw new AuthenticationException(s\"auth fail, no user\")\n    else if (!pwd.equals(password))\n      throw new AuthenticationException(s\"auth fail, pwd wrong\")\n  }\n\n}\n\ncase class ConnectionFactory() {\n\n  val database = \"test\"\n  val table = \"tb_score\"\n\n  // 访问本地MySQL服务器，通过3306端口访问mysql数据库\n  val url = s\"jdbc:mysql://172.29.130.156:3306/$database?useUnicode=true&characterEncoding=utf-8&useSSL=false\"\n  //驱动名称\n  val driver = \"com.mysql.cj.jdbc.Driver\"\n\n  //用户名\n  val username = \"root\"\n  //密码\n  val password = \"1234\"\n  //初始化数据连接\n  var connection: Connection = _\n\n  def authById(id: String): String ={\n    var pwd = \"\"\n\n    try {\n      //注册Driver\n      Class.forName(driver)\n      //得到连接\n      connection = DriverManager.getConnection(url, username, password)\n      val statement = connection.createStatement\n\n      //执行查询语句，并返回结果\n      val rs = statement.executeQuery(s\"SELECT subject FROM $table WHERE userid = $id\")\n\n      //打印返回结果\n      while (rs.next) {\n        pwd = rs.getString(\"subject\")\n      }\n\n      pwd match {\n        case \"\" => \"\"\n        case _ => pwd\n      }\n\n    } catch {\n      case exception: Exception => {\n        exception.printStackTrace()\n        throw exception\n      }\n    }finally {\n      if (connection != null){\n        connection.close()\n      }\n    }\n  }\n\n  def apply(): ConnectionFactory = ConnectionFactory()\n\n}\n```\n\n","slug":"bigdata/Kyuubi-从入门到跑路","published":1,"comments":1,"layout":"post","photos":[],"link":"","_id":"cl9y38dse001cfwuib946eogz","content":"<blockquote>\n<p>Kyuubi 将 Spark ThriftServer 的使用扩展为基于统一接口的多租户模型，并依靠多租户的概念与集群管理器交互，最终获得资源共享&#x2F;隔离和数据安全的能力。Kyuubi Server 和 Engine 的松耦合架构大大提高了服务本身的并发性和服务稳定性。</p>\n</blockquote>\n<h2 id=\"What-Kyuubi是什么\"><a href=\"#What-Kyuubi是什么\" class=\"headerlink\" title=\"What-Kyuubi是什么\"></a>What-Kyuubi是什么</h2><p>Apache Kyuubi (Incubating)，一个分布式和多租户网关，用于在 Lakehouse 上提供 Serverless SQL。</p>\n<blockquote>\n<p>简单的来说Kyuubi就是一个SQL网关，用来将用户需要执行的SQL交给对应的计算引擎执行，如Spark、Flink等。作为一个优秀的网关，Kyuubi理所当然的实现了负载均衡、HA、多租户等功能。</p>\n<p>正是这些功能，保证了Spark SQL可以真正的在企业内可用、好运、稳定的运行。</p>\n</blockquote>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1667120616678-362b15b3-89ac-4b49-961f-71d1b0eeda4e.png\" alt=\"image.png\"></p>\n<h2 id=\"Why-为什么需要Kyuubi\"><a href=\"#Why-为什么需要Kyuubi\" class=\"headerlink\" title=\"Why-为什么需要Kyuubi\"></a>Why-为什么需要Kyuubi</h2><ul>\n<li>当然是Spark Thrift Server不好用，甚至可以说在生产上不可用（不支持HA和多租户），Spark SQL无法大展拳脚，因此诞生了Kyuubi。</li>\n</ul>\n<h2 id=\"How\"><a href=\"#How\" class=\"headerlink\" title=\"How\"></a>How</h2><h3 id=\"How-Kyuubi-on-Spark最佳实践\"><a href=\"#How-Kyuubi-on-Spark最佳实践\" class=\"headerlink\" title=\"How: Kyuubi on Spark最佳实践\"></a>How: Kyuubi on Spark最佳实践</h3><ul>\n<li>spark-defaults.conf配置</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"><span class=\"comment\"># Licensed to the Apache Software Foundation (ASF) under one or more</span></span><br><span class=\"line\"><span class=\"comment\"># contributor license agreements.  See the NOTICE file distributed with</span></span><br><span class=\"line\"><span class=\"comment\"># this work for additional information regarding copyright ownership.</span></span><br><span class=\"line\"><span class=\"comment\"># The ASF licenses this file to You under the Apache License, Version 2.0</span></span><br><span class=\"line\"><span class=\"comment\"># (the &quot;License&quot;); you may not use this file except in compliance with</span></span><br><span class=\"line\"><span class=\"comment\"># the License.  You may obtain a copy of the License at</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"><span class=\"comment\">#    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"><span class=\"comment\"># Unless required by applicable law or agreed to in writing, software</span></span><br><span class=\"line\"><span class=\"comment\"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class=\"line\"><span class=\"comment\"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class=\"line\"><span class=\"comment\"># See the License for the specific language governing permissions and</span></span><br><span class=\"line\"><span class=\"comment\"># limitations under the License.</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Default system properties included when running spark-submit.</span></span><br><span class=\"line\"><span class=\"comment\"># This is useful for setting default environmental settings.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Example:</span></span><br><span class=\"line\"><span class=\"comment\"># spark.master                     spark://master:7077</span></span><br><span class=\"line\"><span class=\"comment\"># spark.eventLog.enabled           true</span></span><br><span class=\"line\"><span class=\"comment\"># spark.eventLog.dir               hdfs://namenode:8021/directory</span></span><br><span class=\"line\"><span class=\"comment\"># spark.serializer                 org.apache.spark.serializer.KryoSerializer</span></span><br><span class=\"line\"><span class=\"comment\"># spark.driver.memory              5g</span></span><br><span class=\"line\"><span class=\"comment\"># spark.executor.extraJavaOptions  -XX:+PrintGCDetails -Dkey=value -Dnumbers=&quot;one two three&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## Spark on Yarn config</span></span><br><span class=\"line\"><span class=\"string\">spark.master=yarn</span></span><br><span class=\"line\"><span class=\"string\">spark.executor.cores=1</span></span><br><span class=\"line\"><span class=\"string\">spark.yarn.am.memory=512m</span></span><br><span class=\"line\"><span class=\"string\">spark.driver.memory=1g</span></span><br><span class=\"line\"><span class=\"string\">spark.driver.memoryOverheadFactor=0.10</span></span><br><span class=\"line\"><span class=\"string\">spark.executor.memory=1g</span></span><br><span class=\"line\"><span class=\"string\">spark.executor.memoryOverheadFactor=0.10</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## Spark DRA config</span></span><br><span class=\"line\"><span class=\"string\">spark.dynamicAllocation.enabled=true</span></span><br><span class=\"line\"><span class=\"comment\"># false if perfer shuffle tracking than ESS</span></span><br><span class=\"line\"><span class=\"string\">spark.shuffle.service.enabled=true</span></span><br><span class=\"line\"><span class=\"comment\"># 理想情况下，三者的大小关系应为minExecutors&lt;= initialExecutors&lt; maxExecutors</span></span><br><span class=\"line\"><span class=\"string\">spark.dynamicAllocation.initialExecutors=10</span></span><br><span class=\"line\"><span class=\"string\">spark.dynamicAllocation.minExecutors=10</span></span><br><span class=\"line\"><span class=\"string\">spark.dynamicAllocation.maxExecutors=500</span></span><br><span class=\"line\"><span class=\"comment\"># adjust spark.dynamicAllocation.executorAllocationRatio a bit lower to reduce the number of executors w.r.t. full parallelism.</span></span><br><span class=\"line\"><span class=\"string\">spark.dynamicAllocation.executorAllocationRatio=0.5</span></span><br><span class=\"line\"><span class=\"comment\"># If one executor reached the maximum idle timeout, it will be removed.</span></span><br><span class=\"line\"><span class=\"string\">spark.dynamicAllocation.executorIdleTimeout=60s</span></span><br><span class=\"line\"><span class=\"string\">spark.dynamicAllocation.cachedExecutorIdleTimeout=30min</span></span><br><span class=\"line\"><span class=\"comment\"># true if perfer shuffle tracking than ESS</span></span><br><span class=\"line\"><span class=\"string\">spark.dynamicAllocation.shuffleTracking.enabled=false</span></span><br><span class=\"line\"><span class=\"string\">spark.dynamicAllocation.shuffleTracking.timeout=30min</span></span><br><span class=\"line\"><span class=\"comment\"># 如果 DRA 发现有待处理的任务积压超过超时，将请求新的执行程序，由以下配置控制。</span></span><br><span class=\"line\"><span class=\"string\">spark.dynamicAllocation.schedulerBacklogTimeout=1s</span></span><br><span class=\"line\"><span class=\"string\">spark.dynamicAllocation.sustainedSchedulerBacklogTimeout=1s</span></span><br><span class=\"line\"><span class=\"string\">spark.cleaner.periodicGC.interval=5min</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## Spark ESS config: DRA依赖于ESS，不过在Spark3后可以启用shuffleTracking后也可以启用DRA</span></span><br><span class=\"line\"><span class=\"comment\">#  spark.shuffle.service.enabled=true   开启Spark ESS，前面已配置</span></span><br><span class=\"line\"><span class=\"string\">spark.shuffle.service.port=7337</span></span><br><span class=\"line\"><span class=\"string\">spark.shuffle.useOldFetchProtocol=true</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## Spark AQE config</span></span><br><span class=\"line\"><span class=\"string\">spark.sql.adaptive.enabled=true</span></span><br><span class=\"line\"><span class=\"string\">spark.sql.adaptive.forceApply=false</span></span><br><span class=\"line\"><span class=\"string\">spark.sql.adaptive.logLevel=info</span></span><br><span class=\"line\"><span class=\"comment\"># 如果我们用HDFS读写数据，匹配HDFS的块大小应该是最好的选择，即128MB或256MB。</span></span><br><span class=\"line\"><span class=\"string\">spark.sql.adaptive.advisoryPartitionSizeInBytes=256m</span></span><br><span class=\"line\"><span class=\"string\">spark.sql.adaptive.coalescePartitions.enabled=true</span></span><br><span class=\"line\"><span class=\"string\">spark.sql.adaptive.coalescePartitions.minPartitionNum=1</span></span><br><span class=\"line\"><span class=\"comment\"># 它代表合并之前的洗牌分区的初始数量。最好明确设置它而不是回退到spark.sql.shuffle.partitions.</span></span><br><span class=\"line\"><span class=\"string\">spark.sql.adaptive.coalescePartitions.initialPartitionNum=8192</span></span><br><span class=\"line\"><span class=\"string\">spark.sql.adaptive.fetchShuffleBlocksInBatch=true</span></span><br><span class=\"line\"><span class=\"string\">spark.sql.adaptive.localShuffleReader.enabled=true</span></span><br><span class=\"line\"><span class=\"string\">spark.sql.adaptive.skewJoin.enabled=true</span></span><br><span class=\"line\"><span class=\"string\">spark.sql.adaptive.skewJoin.skewedPartitionFactor=5</span></span><br><span class=\"line\"><span class=\"string\">spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes=400m</span></span><br><span class=\"line\"><span class=\"string\">spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin=0.2</span></span><br><span class=\"line\"><span class=\"string\">spark.sql.adaptive.optimizer.excludedRules</span></span><br><span class=\"line\"><span class=\"string\">spark.sql.autoBroadcastJoinThreshold=-1</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## Spark Doc: Tuning Guide</span></span><br><span class=\"line\"><span class=\"string\">spark.serializer=org.apache.spark.serializer.KryoSerializer</span></span><br><span class=\"line\"><span class=\"string\">spark.yarn.jars=hdfs://hadoop122:9000/spark-yarn/jars/*.jar</span></span><br><span class=\"line\"><span class=\"comment\"># TODO-Push-based shuffle overview待启用</span></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Extension\"><a href=\"#Extension\" class=\"headerlink\" title=\"Extension\"></a>Extension</h2><h3 id=\"基于MySQL自定义认证\"><a href=\"#基于MySQL自定义认证\" class=\"headerlink\" title=\"基于MySQL自定义认证\"></a>基于MySQL自定义认证</h3><figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> cn.jxau</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.kyuubi.service.authentication.<span class=\"type\">PasswdAuthenticationProvider</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> java.sql.&#123;<span class=\"type\">Connection</span>, <span class=\"type\">DriverManager</span>&#125;</span><br><span class=\"line\"><span class=\"keyword\">import</span> javax.security.sasl.<span class=\"type\">AuthenticationException</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">SimpleAuthenticationProvider</span> <span class=\"keyword\">extends</span> <span class=\"title\">PasswdAuthenticationProvider</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">override</span> <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">authenticate</span></span>(user: <span class=\"type\">String</span>, password: <span class=\"type\">String</span>): <span class=\"type\">Unit</span> = &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">val</span> pwd: <span class=\"type\">String</span> = <span class=\"type\">ConnectionFactory</span>().authById(user)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (pwd.equals(<span class=\"string\">&quot;&quot;</span>))</span><br><span class=\"line\">      <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> <span class=\"type\">AuthenticationException</span>(<span class=\"string\">s&quot;auth fail, no user&quot;</span>)</span><br><span class=\"line\">    <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (!pwd.equals(password))</span><br><span class=\"line\">      <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> <span class=\"type\">AuthenticationException</span>(<span class=\"string\">s&quot;auth fail, pwd wrong&quot;</span>)</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">case</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">ConnectionFactory</span>(<span class=\"params\"></span>) </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">val</span> database = <span class=\"string\">&quot;test&quot;</span></span><br><span class=\"line\">  <span class=\"keyword\">val</span> table = <span class=\"string\">&quot;tb_score&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"comment\">// 访问本地MySQL服务器，通过3306端口访问mysql数据库</span></span><br><span class=\"line\">  <span class=\"keyword\">val</span> url = <span class=\"string\">s&quot;jdbc:mysql://172.29.130.156:3306/<span class=\"subst\">$database</span>?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false&quot;</span></span><br><span class=\"line\">  <span class=\"comment\">//驱动名称</span></span><br><span class=\"line\">  <span class=\"keyword\">val</span> driver = <span class=\"string\">&quot;com.mysql.cj.jdbc.Driver&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"comment\">//用户名</span></span><br><span class=\"line\">  <span class=\"keyword\">val</span> username = <span class=\"string\">&quot;root&quot;</span></span><br><span class=\"line\">  <span class=\"comment\">//密码</span></span><br><span class=\"line\">  <span class=\"keyword\">val</span> password = <span class=\"string\">&quot;1234&quot;</span></span><br><span class=\"line\">  <span class=\"comment\">//初始化数据连接</span></span><br><span class=\"line\">  <span class=\"keyword\">var</span> connection: <span class=\"type\">Connection</span> = _</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">authById</span></span>(id: <span class=\"type\">String</span>): <span class=\"type\">String</span> =&#123;</span><br><span class=\"line\">    <span class=\"keyword\">var</span> pwd = <span class=\"string\">&quot;&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">      <span class=\"comment\">//注册Driver</span></span><br><span class=\"line\">      <span class=\"type\">Class</span>.forName(driver)</span><br><span class=\"line\">      <span class=\"comment\">//得到连接</span></span><br><span class=\"line\">      connection = <span class=\"type\">DriverManager</span>.getConnection(url, username, password)</span><br><span class=\"line\">      <span class=\"keyword\">val</span> statement = connection.createStatement</span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"comment\">//执行查询语句，并返回结果</span></span><br><span class=\"line\">      <span class=\"keyword\">val</span> rs = statement.executeQuery(<span class=\"string\">s&quot;SELECT subject FROM <span class=\"subst\">$table</span> WHERE userid = <span class=\"subst\">$id</span>&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"comment\">//打印返回结果</span></span><br><span class=\"line\">      <span class=\"keyword\">while</span> (rs.next) &#123;</span><br><span class=\"line\">        pwd = rs.getString(<span class=\"string\">&quot;subject&quot;</span>)</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">      pwd <span class=\"keyword\">match</span> &#123;</span><br><span class=\"line\">        <span class=\"keyword\">case</span> <span class=\"string\">&quot;&quot;</span> =&gt; <span class=\"string\">&quot;&quot;</span></span><br><span class=\"line\">        <span class=\"keyword\">case</span> _ =&gt; pwd</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    &#125; <span class=\"keyword\">catch</span> &#123;</span><br><span class=\"line\">      <span class=\"keyword\">case</span> exception: <span class=\"type\">Exception</span> =&gt; &#123;</span><br><span class=\"line\">        exception.printStackTrace()</span><br><span class=\"line\">        <span class=\"keyword\">throw</span> exception</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;<span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">      <span class=\"keyword\">if</span> (connection != <span class=\"literal\">null</span>)&#123;</span><br><span class=\"line\">        connection.close()</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">apply</span></span>(): <span class=\"type\">ConnectionFactory</span> = <span class=\"type\">ConnectionFactory</span>()</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n","site":{"data":{"link":[{"class_name":"友情链接","class_desc":"那些人，那些事","link_list":[{"name":"张洪Heo","link":"https://blog.zhheo.com/","avatar":"https://npm.elemecdn.com/guli-heo/img/avatar2.png","descr":"分享设计与科技生活"},{"name":"瞬間の筆記","link":"https://hikki.site","descr":"喜欢的东西就努力去追求，万一成功了呢!","avatar":"https://cdn.jsdelivr.net/gh/0000rookie/imgs/202206120315.png"}]}]}},"excerpt":"","more":"<blockquote>\n<p>Kyuubi 将 Spark ThriftServer 的使用扩展为基于统一接口的多租户模型，并依靠多租户的概念与集群管理器交互，最终获得资源共享&#x2F;隔离和数据安全的能力。Kyuubi Server 和 Engine 的松耦合架构大大提高了服务本身的并发性和服务稳定性。</p>\n</blockquote>\n<h2 id=\"What-Kyuubi是什么\"><a href=\"#What-Kyuubi是什么\" class=\"headerlink\" title=\"What-Kyuubi是什么\"></a>What-Kyuubi是什么</h2><p>Apache Kyuubi (Incubating)，一个分布式和多租户网关，用于在 Lakehouse 上提供 Serverless SQL。</p>\n<blockquote>\n<p>简单的来说Kyuubi就是一个SQL网关，用来将用户需要执行的SQL交给对应的计算引擎执行，如Spark、Flink等。作为一个优秀的网关，Kyuubi理所当然的实现了负载均衡、HA、多租户等功能。</p>\n<p>正是这些功能，保证了Spark SQL可以真正的在企业内可用、好运、稳定的运行。</p>\n</blockquote>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1667120616678-362b15b3-89ac-4b49-961f-71d1b0eeda4e.png\" alt=\"image.png\"></p>\n<h2 id=\"Why-为什么需要Kyuubi\"><a href=\"#Why-为什么需要Kyuubi\" class=\"headerlink\" title=\"Why-为什么需要Kyuubi\"></a>Why-为什么需要Kyuubi</h2><ul>\n<li>当然是Spark Thrift Server不好用，甚至可以说在生产上不可用（不支持HA和多租户），Spark SQL无法大展拳脚，因此诞生了Kyuubi。</li>\n</ul>\n<h2 id=\"How\"><a href=\"#How\" class=\"headerlink\" title=\"How\"></a>How</h2><h3 id=\"How-Kyuubi-on-Spark最佳实践\"><a href=\"#How-Kyuubi-on-Spark最佳实践\" class=\"headerlink\" title=\"How: Kyuubi on Spark最佳实践\"></a>How: Kyuubi on Spark最佳实践</h3><ul>\n<li>spark-defaults.conf配置</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"><span class=\"comment\"># Licensed to the Apache Software Foundation (ASF) under one or more</span></span><br><span class=\"line\"><span class=\"comment\"># contributor license agreements.  See the NOTICE file distributed with</span></span><br><span class=\"line\"><span class=\"comment\"># this work for additional information regarding copyright ownership.</span></span><br><span class=\"line\"><span class=\"comment\"># The ASF licenses this file to You under the Apache License, Version 2.0</span></span><br><span class=\"line\"><span class=\"comment\"># (the &quot;License&quot;); you may not use this file except in compliance with</span></span><br><span class=\"line\"><span class=\"comment\"># the License.  You may obtain a copy of the License at</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"><span class=\"comment\">#    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"><span class=\"comment\"># Unless required by applicable law or agreed to in writing, software</span></span><br><span class=\"line\"><span class=\"comment\"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class=\"line\"><span class=\"comment\"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class=\"line\"><span class=\"comment\"># See the License for the specific language governing permissions and</span></span><br><span class=\"line\"><span class=\"comment\"># limitations under the License.</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Default system properties included when running spark-submit.</span></span><br><span class=\"line\"><span class=\"comment\"># This is useful for setting default environmental settings.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Example:</span></span><br><span class=\"line\"><span class=\"comment\"># spark.master                     spark://master:7077</span></span><br><span class=\"line\"><span class=\"comment\"># spark.eventLog.enabled           true</span></span><br><span class=\"line\"><span class=\"comment\"># spark.eventLog.dir               hdfs://namenode:8021/directory</span></span><br><span class=\"line\"><span class=\"comment\"># spark.serializer                 org.apache.spark.serializer.KryoSerializer</span></span><br><span class=\"line\"><span class=\"comment\"># spark.driver.memory              5g</span></span><br><span class=\"line\"><span class=\"comment\"># spark.executor.extraJavaOptions  -XX:+PrintGCDetails -Dkey=value -Dnumbers=&quot;one two three&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## Spark on Yarn config</span></span><br><span class=\"line\"><span class=\"string\">spark.master=yarn</span></span><br><span class=\"line\"><span class=\"string\">spark.executor.cores=1</span></span><br><span class=\"line\"><span class=\"string\">spark.yarn.am.memory=512m</span></span><br><span class=\"line\"><span class=\"string\">spark.driver.memory=1g</span></span><br><span class=\"line\"><span class=\"string\">spark.driver.memoryOverheadFactor=0.10</span></span><br><span class=\"line\"><span class=\"string\">spark.executor.memory=1g</span></span><br><span class=\"line\"><span class=\"string\">spark.executor.memoryOverheadFactor=0.10</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## Spark DRA config</span></span><br><span class=\"line\"><span class=\"string\">spark.dynamicAllocation.enabled=true</span></span><br><span class=\"line\"><span class=\"comment\"># false if perfer shuffle tracking than ESS</span></span><br><span class=\"line\"><span class=\"string\">spark.shuffle.service.enabled=true</span></span><br><span class=\"line\"><span class=\"comment\"># 理想情况下，三者的大小关系应为minExecutors&lt;= initialExecutors&lt; maxExecutors</span></span><br><span class=\"line\"><span class=\"string\">spark.dynamicAllocation.initialExecutors=10</span></span><br><span class=\"line\"><span class=\"string\">spark.dynamicAllocation.minExecutors=10</span></span><br><span class=\"line\"><span class=\"string\">spark.dynamicAllocation.maxExecutors=500</span></span><br><span class=\"line\"><span class=\"comment\"># adjust spark.dynamicAllocation.executorAllocationRatio a bit lower to reduce the number of executors w.r.t. full parallelism.</span></span><br><span class=\"line\"><span class=\"string\">spark.dynamicAllocation.executorAllocationRatio=0.5</span></span><br><span class=\"line\"><span class=\"comment\"># If one executor reached the maximum idle timeout, it will be removed.</span></span><br><span class=\"line\"><span class=\"string\">spark.dynamicAllocation.executorIdleTimeout=60s</span></span><br><span class=\"line\"><span class=\"string\">spark.dynamicAllocation.cachedExecutorIdleTimeout=30min</span></span><br><span class=\"line\"><span class=\"comment\"># true if perfer shuffle tracking than ESS</span></span><br><span class=\"line\"><span class=\"string\">spark.dynamicAllocation.shuffleTracking.enabled=false</span></span><br><span class=\"line\"><span class=\"string\">spark.dynamicAllocation.shuffleTracking.timeout=30min</span></span><br><span class=\"line\"><span class=\"comment\"># 如果 DRA 发现有待处理的任务积压超过超时，将请求新的执行程序，由以下配置控制。</span></span><br><span class=\"line\"><span class=\"string\">spark.dynamicAllocation.schedulerBacklogTimeout=1s</span></span><br><span class=\"line\"><span class=\"string\">spark.dynamicAllocation.sustainedSchedulerBacklogTimeout=1s</span></span><br><span class=\"line\"><span class=\"string\">spark.cleaner.periodicGC.interval=5min</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## Spark ESS config: DRA依赖于ESS，不过在Spark3后可以启用shuffleTracking后也可以启用DRA</span></span><br><span class=\"line\"><span class=\"comment\">#  spark.shuffle.service.enabled=true   开启Spark ESS，前面已配置</span></span><br><span class=\"line\"><span class=\"string\">spark.shuffle.service.port=7337</span></span><br><span class=\"line\"><span class=\"string\">spark.shuffle.useOldFetchProtocol=true</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## Spark AQE config</span></span><br><span class=\"line\"><span class=\"string\">spark.sql.adaptive.enabled=true</span></span><br><span class=\"line\"><span class=\"string\">spark.sql.adaptive.forceApply=false</span></span><br><span class=\"line\"><span class=\"string\">spark.sql.adaptive.logLevel=info</span></span><br><span class=\"line\"><span class=\"comment\"># 如果我们用HDFS读写数据，匹配HDFS的块大小应该是最好的选择，即128MB或256MB。</span></span><br><span class=\"line\"><span class=\"string\">spark.sql.adaptive.advisoryPartitionSizeInBytes=256m</span></span><br><span class=\"line\"><span class=\"string\">spark.sql.adaptive.coalescePartitions.enabled=true</span></span><br><span class=\"line\"><span class=\"string\">spark.sql.adaptive.coalescePartitions.minPartitionNum=1</span></span><br><span class=\"line\"><span class=\"comment\"># 它代表合并之前的洗牌分区的初始数量。最好明确设置它而不是回退到spark.sql.shuffle.partitions.</span></span><br><span class=\"line\"><span class=\"string\">spark.sql.adaptive.coalescePartitions.initialPartitionNum=8192</span></span><br><span class=\"line\"><span class=\"string\">spark.sql.adaptive.fetchShuffleBlocksInBatch=true</span></span><br><span class=\"line\"><span class=\"string\">spark.sql.adaptive.localShuffleReader.enabled=true</span></span><br><span class=\"line\"><span class=\"string\">spark.sql.adaptive.skewJoin.enabled=true</span></span><br><span class=\"line\"><span class=\"string\">spark.sql.adaptive.skewJoin.skewedPartitionFactor=5</span></span><br><span class=\"line\"><span class=\"string\">spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes=400m</span></span><br><span class=\"line\"><span class=\"string\">spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin=0.2</span></span><br><span class=\"line\"><span class=\"string\">spark.sql.adaptive.optimizer.excludedRules</span></span><br><span class=\"line\"><span class=\"string\">spark.sql.autoBroadcastJoinThreshold=-1</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## Spark Doc: Tuning Guide</span></span><br><span class=\"line\"><span class=\"string\">spark.serializer=org.apache.spark.serializer.KryoSerializer</span></span><br><span class=\"line\"><span class=\"string\">spark.yarn.jars=hdfs://hadoop122:9000/spark-yarn/jars/*.jar</span></span><br><span class=\"line\"><span class=\"comment\"># TODO-Push-based shuffle overview待启用</span></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Extension\"><a href=\"#Extension\" class=\"headerlink\" title=\"Extension\"></a>Extension</h2><h3 id=\"基于MySQL自定义认证\"><a href=\"#基于MySQL自定义认证\" class=\"headerlink\" title=\"基于MySQL自定义认证\"></a>基于MySQL自定义认证</h3><figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> cn.jxau</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.kyuubi.service.authentication.<span class=\"type\">PasswdAuthenticationProvider</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> java.sql.&#123;<span class=\"type\">Connection</span>, <span class=\"type\">DriverManager</span>&#125;</span><br><span class=\"line\"><span class=\"keyword\">import</span> javax.security.sasl.<span class=\"type\">AuthenticationException</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">SimpleAuthenticationProvider</span> <span class=\"keyword\">extends</span> <span class=\"title\">PasswdAuthenticationProvider</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">override</span> <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">authenticate</span></span>(user: <span class=\"type\">String</span>, password: <span class=\"type\">String</span>): <span class=\"type\">Unit</span> = &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">val</span> pwd: <span class=\"type\">String</span> = <span class=\"type\">ConnectionFactory</span>().authById(user)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (pwd.equals(<span class=\"string\">&quot;&quot;</span>))</span><br><span class=\"line\">      <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> <span class=\"type\">AuthenticationException</span>(<span class=\"string\">s&quot;auth fail, no user&quot;</span>)</span><br><span class=\"line\">    <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (!pwd.equals(password))</span><br><span class=\"line\">      <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> <span class=\"type\">AuthenticationException</span>(<span class=\"string\">s&quot;auth fail, pwd wrong&quot;</span>)</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">case</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">ConnectionFactory</span>(<span class=\"params\"></span>) </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">val</span> database = <span class=\"string\">&quot;test&quot;</span></span><br><span class=\"line\">  <span class=\"keyword\">val</span> table = <span class=\"string\">&quot;tb_score&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"comment\">// 访问本地MySQL服务器，通过3306端口访问mysql数据库</span></span><br><span class=\"line\">  <span class=\"keyword\">val</span> url = <span class=\"string\">s&quot;jdbc:mysql://172.29.130.156:3306/<span class=\"subst\">$database</span>?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false&quot;</span></span><br><span class=\"line\">  <span class=\"comment\">//驱动名称</span></span><br><span class=\"line\">  <span class=\"keyword\">val</span> driver = <span class=\"string\">&quot;com.mysql.cj.jdbc.Driver&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"comment\">//用户名</span></span><br><span class=\"line\">  <span class=\"keyword\">val</span> username = <span class=\"string\">&quot;root&quot;</span></span><br><span class=\"line\">  <span class=\"comment\">//密码</span></span><br><span class=\"line\">  <span class=\"keyword\">val</span> password = <span class=\"string\">&quot;1234&quot;</span></span><br><span class=\"line\">  <span class=\"comment\">//初始化数据连接</span></span><br><span class=\"line\">  <span class=\"keyword\">var</span> connection: <span class=\"type\">Connection</span> = _</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">authById</span></span>(id: <span class=\"type\">String</span>): <span class=\"type\">String</span> =&#123;</span><br><span class=\"line\">    <span class=\"keyword\">var</span> pwd = <span class=\"string\">&quot;&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">      <span class=\"comment\">//注册Driver</span></span><br><span class=\"line\">      <span class=\"type\">Class</span>.forName(driver)</span><br><span class=\"line\">      <span class=\"comment\">//得到连接</span></span><br><span class=\"line\">      connection = <span class=\"type\">DriverManager</span>.getConnection(url, username, password)</span><br><span class=\"line\">      <span class=\"keyword\">val</span> statement = connection.createStatement</span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"comment\">//执行查询语句，并返回结果</span></span><br><span class=\"line\">      <span class=\"keyword\">val</span> rs = statement.executeQuery(<span class=\"string\">s&quot;SELECT subject FROM <span class=\"subst\">$table</span> WHERE userid = <span class=\"subst\">$id</span>&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"comment\">//打印返回结果</span></span><br><span class=\"line\">      <span class=\"keyword\">while</span> (rs.next) &#123;</span><br><span class=\"line\">        pwd = rs.getString(<span class=\"string\">&quot;subject&quot;</span>)</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">      pwd <span class=\"keyword\">match</span> &#123;</span><br><span class=\"line\">        <span class=\"keyword\">case</span> <span class=\"string\">&quot;&quot;</span> =&gt; <span class=\"string\">&quot;&quot;</span></span><br><span class=\"line\">        <span class=\"keyword\">case</span> _ =&gt; pwd</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    &#125; <span class=\"keyword\">catch</span> &#123;</span><br><span class=\"line\">      <span class=\"keyword\">case</span> exception: <span class=\"type\">Exception</span> =&gt; &#123;</span><br><span class=\"line\">        exception.printStackTrace()</span><br><span class=\"line\">        <span class=\"keyword\">throw</span> exception</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;<span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">      <span class=\"keyword\">if</span> (connection != <span class=\"literal\">null</span>)&#123;</span><br><span class=\"line\">        connection.close()</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">apply</span></span>(): <span class=\"type\">ConnectionFactory</span> = <span class=\"type\">ConnectionFactory</span>()</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n"},{"title":"When：何时需要进行Doris Compaction调优","top_img":"/img/bg/banner.gif","date":"2022-09-03T15:40:51.000Z","updated":"2022-09-03T15:40:51.000Z","cover":"https://tva4.sinaimg.cn/large/0084aYsLgy1gy51ogkzs9j31hc0m843g.jpg","description":null,"keywords":null,"_content":"\n> 本篇将从实际使用场景的角度出发，介绍 Compaction 的调优思路和策略。通过本文将了解到 Compaction 相关的日志分析、参数调整和 API 的使用。\n\n## 什么情况下需要调整 Compaction 参数\n\nCompaction 的目的是合并多个数据版本，一是避免在读取时大量的 Merge 操作，二是避免大量的数据版本导致的随机IO。**并且在这个过程中，Compaction 操作不能占用太多的系统资源。所以我们可以以结果为导向，从以下两个方面反推是否需要调整 Compaction 策略。**\n\n1. 检查数据版本是否有堆积。\n\n2. 检查 IO 和内存资源是否被 Compaction 任务过多的占用。\n\n### 查看数据版本数量变化趋势\n\nDoris 提供数据版本数量的监控数据。如果你部署了 Prometheus + Grafana 的监控，则可以通过 Grafana 仪表盘的 BE Base Compaction Score 和 BE Cumu Compaction Score 图表查看到这个监控数据的趋势图：\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1662264565446-6e38cc7f-eb01-441c-a6f0-4988b07c4835.png)\n\n> 这个图表展示的是每个 BE 节点，所有 Tablet 中数据版本最多的那个 Tablet 的版本数量，可以反映出当前版本堆积情况。\n> 部署方式参阅：http://doris.incubator.apache.org/master/zh-CN/administrator-guide/operation/monitor-alert.html\n\n如果没有安装这个监控，如果你是用的 Palo 0.14.7 版本以上，也可以通过以下命令在命令行查看这个监控数据的趋势图：\n\n```shell\n\nmysql> ADMIN SHOW BACKEND METRIC (\"nodes\" = \"30746894\", \"metrics\" = \"BE_BASE_COMPACTION_SCORE\", \"time\" = \"last 4 hours\");\nmysql> ADMIN SHOW BACKEND METRIC (\"nodes\" = \"30746894\", \"metrics\" = \"BE_CUMU_COMPACTION_SCORE\", \"time\" = \"last 4 hours\");\n```\n\n注意这里有两个指标，分别表示 Base Compaction 和 Cumulative Compaction 所对应的版本数量。**在大部分情况下，我们只需要查看 Cumulative Compaction 的指标，即可大致了解集群的数据版本堆积情况。**\n\n**版本是否堆积没有一个明确的界限，而是根据使用场景和查询延迟进行判断的一个经验值。**我们可以按照以下步骤进行简单的推断：\n\n> 1. 观察数据版本数量的趋势，如果趋势平稳，则说明 Compaction 和导入速度基本持平。如果呈上升态势，则说明 Compaction 速度跟不上导入速度了。如果呈下降态势，说明 Compaction 速度超过了导入速度。**如果呈上升态势，或在平稳状态但数值较高，则需要考虑调整 Compaction 参数以加快 Compaction 的进度。**\n>\n> 2. **通常版本数量维持在 100 以内可以视为正常。而在大部分批量导入或低频导入场景下，版本数量通常为10-20甚至更低。**\n\n### 查看Compaction资源占用\nCompaction 资源占用主要是 IO 和 内存。\n\n对于 Compaction 占用的内存，可以在浏览器打开以下链接：http://be_host:webserver_port/mem_tracker在搜索框中输入 AutoCompaction：\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1662265200095-5cf34b92-10de-4d1f-80c3-4dfcc0fd49fd.png)\n\n则可以查看当前Compaction的内存开销和历史峰值开销。\n\n而对于 IO 操作，目前还没有提供单独的 Compaction 操作的 IO 监控，我们只能根据集群整体的 IO 利用率情况来做判断。我们可以查看监控图 Disk IO util：\n\n![图片](https://mmbiz.qpic.cn/mmbiz_png/eGOhXuI8cBaCgNjQSRHmVYlEkMEIH7OGlBmYBlAkJLj3MjeJTTiauBiaYFeia8zf5s2fvImSlPwthGKZSO8oeFzNg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)\n\n或者通过命令在命令行查看（Palo 0.14.7 以上版本）：\n\n```shell\n\nmysql> ADMIN SHOW BACKEND METRIC (\"nodes\" = \"30746894\", \"metrics\" = \"BE_DISK_IO\", \"time\" = \"last 4 hours\");\n```\n\n这个监控展示的是每个 BE 节点上磁盘的 IO util 指标。数值越高表示IO越繁忙。**当然大部分情况下 IO 资源都是查询请求消耗的，这个监控主要用于指导我们是否需要增加或减少 Compaction 任务数。**\n\n## Compaction 调优策略\n\n如果版本数量有上升趋势或者数值较高，则可以从以下两方面优化 Compaction：\n\n1. 修改 Compaction 线程数，使得同时能够执行更多的 Compaction 任务。\n\n2. 优化单个 Compaction 的执行逻辑，使数据版本数量维持在一个合理范围。\n\n### 优化前的准备工作\n\n在优化 Compaction 执行逻辑之前，我们需要使用一些命令来进一步查看一些Compaction的细节信息。\n\n首先，我们通过监控图找到一个版本数量最高的 BE 节点。然后执行以下命令分析日志：\n\n```shell\n\n$> grep \"succeed to do base\" log/be.INFO.log.20210505-142010 |tail -n 100\n$> grep \"succeed to do cumu\" log/be.INFO.log.20210505-142010 |tail -n 100\n```\n\n以上两个命令可以查看最近100个执行完成的 compaction 任务：\n\n```shell\n\nI0505 17:06:56.143455   675 compaction.cpp:135] succeed to do cumulative compaction. tablet=106827682.505347040.d040c1cdf71e5c95-3a002a06127ccd86, output_version=2-2631, current_max_version=2633, disk=/home/disk6/palo.HDD, segments=57. elapsed time=2.29371s. cumulative_compaction_policy=SIZE_BASED.\nI0505 17:06:56.520058   666 compaction.cpp:135] succeed to do cumulative compaction. tablet=106822189.1661856168.654562832a620ea6-46fe84c73ea84795, output_version=2-3247, current_max_version=3250, disk=/home/disk2/palo.HDD, segments=22. elapsed time=2.66858s. cumulative_compaction_policy=SIZE_BASED.\n```\n\n通过日志时间可以判断 Compaction 是否在持续正确的执行，通过 elapsed time 可以观察每个任务的执行时间。\n\n我们还可以执行以下命令展示最近100个 compaction 任务的配额（permits）：\n\n```shell\n\n$> grep \"permits\" log/be.INFO |tail -n 100\n\nI0505 17:04:07.120920   667 compaction.cpp:83] start cumulative compaction. tablet=106827970.777011641.9c474de1b8ba9199-4addeb135d6834ac, output_version=2-2623, permits: 39\nI0505 17:04:13.898777   672 compaction.cpp:83] start cumulative compaction. tablet=106822777.1948936074.a44ac9462e79b76d-4a33ee39559bb0bf, output_version=2-3238, permits: 22\n```\n\n配额和版本数量成正比。\n\n我们可以找到 permits 较大的一个任务对应的 tablet id，如上图permit 为 39 的任务的 tablet id 为 106827970，然后继续分析这个 tablet 的 compaction 情况。\n\n通过 MySQL 客户端连接 Doris 集群后，执行：\n\n```shell\n\nmysql> show tablet 106827970;\n+--------------------------+-----------+---------------+-----------+---------+----------+-------------+----------+--------+----------------------------------------------------------------------------+\n| DbName                   | TableName | PartitionName | IndexName | DbId    | TableId  | PartitionId | IndexId  | IsSync | DetailCmd                                                                  |\n+--------------------------+-----------+---------------+-----------+---------+----------+-------------+----------+--------+----------------------------------------------------------------------------+\n| default_cluster:test     | tbl1      | p20210505     | tbl1      | 3828954 | 63708800 | 106826829   | 63709761 | true   | SHOW PROC '/dbs/3828954/63708800/partitions/106826829/63709761/106827970'; |\n+--------------------------+-----------+---------------+-----------+---------+----------+-------------+----------+--------+----------------------------------------------------------------------------+\n```\n\n然后执行后面的 SHOW PROC 语句，我们可以获得这个 tablet 所有副本的详细信息。其中 VersionCount 列表示对应副本的数据版本数量。我们可以选取一个 VersionCount 较大的副本，在浏览器打开 CompactionStatus 列显示的 URL，得到如下Json结果：\n\n```json\n\n{\n    \"cumulative policy type\": \"SIZE_BASED\",\n    \"cumulative point\": 18438,\n    \"last cumulative failure time\": \"1970-01-01 08:00:00.000\",\n    \"last base failure time\": \"1970-01-01 08:00:00.000\",\n    \"last cumulative success time\": \"2021-05-05 17:18:48.904\",\n    \"last base success time\": \"2021-05-05 16:14:49.786\",\n    \"rowsets\": [\n        \"[0-17444] 13 DATA NONOVERLAPPING 0200000000b1fb8d344f83103113563dd81740036795499d 2.86 GB\",\n        \"[17445-17751] 1 DATA NONOVERLAPPING 0200000000b25183344f83103113563dd81740036795499d 68.61 MB\",\n        \"[17752-18089] 1 DATA NONOVERLAPPING 0200000000b2b9a2344f83103113563dd81740036795499d 74.52 MB\",\n        \"[18090-18437] 1 DATA NONOVERLAPPING 0200000000b32686344f83103113563dd81740036795499d 76.41 MB\",\n        \"[18438-18678] 1 DATA NONOVERLAPPING 0200000000b37084344f83103113563dd81740036795499d 53.07 MB\",\n        \"[18679-18679] 1 DATA NONOVERLAPPING 0200000000b36d87344f83103113563dd81740036795499d 3.11 KB\",\n        \"[18680-18680] 1 DATA NONOVERLAPPING 0200000000b36d70344f83103113563dd81740036795499d 258.40 KB\",\n        \"[18681-18681] 1 DATA NONOVERLAPPING 0200000000b36da0344f83103113563dd81740036795499d 266.98 KB\",\n    ],\n    \"stale_rowsets\": [\n    ],\n    \"stale version path\": [\n    ]\n}\n```\n\n这里我们可以看到一个 tablet 的 Cumulative Point，最近一次成功、失败的 BC/CC 任务时间，以及每个 rowset 的版本信息。如上面这个示例，我们可以得出以下结论：\n\n> 1. 基线数据量大约在2-3GB，增量rowset增长到几十MB后就会晋升到BC任务区。\n>\n> 2. 新增rowset数据量很小，且版本增长较快，说明这是一个高频小批量的导入场景。\n\n我们还可以进一步的通过以下命令分析指定 tablet id 的日志\n\n```shell\n\n# 查看 tablet 48062815 最近十个任务的配额情况\n$> grep permits log/be.INFO |grep 48062815 |tail -n 10\n\n# 查看 tablet 48062815 最近十个执行完成的 compaction 任务\n$> grep \"succeed to do\" log/be.INFO |grep 48062815 |tail -n 10\n```\n\n另外，我们还可以在浏览器打开以下 URL，查看一个 BE 节点当前正在执行的 compaction 任务：be_host:webserver_port/api/compaction/run_status\n\n```json\n\n{\n    \"CumulativeCompaction\": {\n        \"/home/disk2/palo\": [],\n        \"/home/disk1/palo\": [\n            \"48061239\"\n        ]\n    },\n    \"BaseCompaction\": {\n        \"/home/disk2/palo\": [],\n        \"/home/disk1/palo\": [\n            \"48062815\",\n            \"48061276\"\n        ]\n    }\n}\n```\n\n这个接口可以看到每个磁盘上当前正在执行的 compaction 任务。\n\n通过以上一系列的分析，我们应该可以对系统的 Compaction 情况有以下判断：\n\n> 1. Compaction 任务的执行频率、每个任务大致的执行耗时。\n>\n> 2. 指定节点数据版本数量的变化情况。\n>\n> 3. 指定 tablet 数据版本的变化情况，以及 compaction 的频率。\n>\n\n这些结论将指导我们对 Compaction 进行调优。\n\n### 修改 Compaction 线程数\n\n**增加 Compaction 线程数是一个非常直接的加速 Compaction 的方法。**但是更多的任务意味着更大的 IO 和 内存开销。尤其在机械磁盘上，因为随机读写问题，有时可能单线程串行执行的效率会高于多线程并行执行。Doris 默认配置为每块盘两个 Compaction 任务（这也是最小的合法配置），最多 10 个任务。如果磁盘数量多于 5，在内存允许的情况下，可以修改 max_compaction_threads 参数增加总任务数，以保证每块盘可以执行两个 Compaction 任务。\n\n对于机械磁盘，不建议增加每块盘的任务数。对于固态硬盘，可以考虑修改 compaction_task_num_per_disk 参数适当增加每块盘的任务数，如修改为 4。**注意修改这个参数的同时可能还需同步修改 max_compaction_threads，使得 max_compaction_threads 大于等于 compaction_task_num_per_disk * 磁盘数量。**\n\n### 优化单个 Compaction 任务逻辑\n\n这个优化方式比较复杂，我们尝试从几个场景出发来说明：\n\n#### **场景一：基线数据量大，Base Compaction 任务执行时间长。**\n\nBC 任务执行时间长，意味着一个任务会长时间占用 Compaction 工作线程，从而导致其他 tablet 的 compaction 任务时间被挤占。如果是因为 0 号版本的基线数据量较大导致，则我们可以考虑尽量推迟增量rowset 晋升到 BC 任务区的时间。以下两个参数将影响这个逻辑：\n\n> cumulative_size_based_promotion_ratio：默认 0.05，基线数据量乘以这个系数，即晋升阈值。可以调大这个系数来提高晋升阈值。\n>\n> cumulative_size_based_promotion_size_mbytes：默认 1024MB。如果增量rowset的数据量大于这个值，则会忽略第一个参数的阈值直接晋升。因此需要同时调整这个参数来提升晋升阈值。\n\n当然，提升晋升阈值，会导致单个 BC 任务需要处理更大的数据量，耗时更长，但是总体的数据量会减少。举个例子。基线数据大小为 1024GB，假设晋升阈值分别为 100MB 和 200MB。数据导入速度为 100MB/分钟。每5个版本执行一次 BC。那么理论上在10分钟内，阈值为 100MB 时，BC 任务处理的总数据量为 （1024 + 100 * 5）* 2 = 3048MB。阈值为 200MB 是，BC 任务处理的总数据量为 (1024 + 200 * 5) = 2024 MB。\n\n#### **场景二：增量数据版本数量增长较快，Cumulative Compaction 处理过多版本，耗时较长。**\n\nmax_cumulative_compaction_num_singleton_deltas 参数控制一个 CC 任务最多合并多少个数据版本，默认值为 1000。我们考虑这样一种场景：针对某一个 tablet，其数据版本的增长速度为 1个/秒。而其 CC 任务的执行时间 + 调度时间是 1000秒（即单个 CC 任务的执行时间加上Compaction再一次调度到这个 tablet 的时间总和）。那么我们可能会看到这个 tablet 的版本数量在 1-1000之间浮动（这里我们忽略基线版本数量）。因为在下一次 CC 任务执行前的 1000 秒内，又会累积 1000 个版本。\n\n这种情况可能导致这个 tablet 的读取效率很不稳定。这时我们可以尝试调小 max_cumulative_compaction_num_singleton_deltas 这个参数，这样一个 CC 所要合并的版本数更少，执行时间更短，执行频率会更高。还是刚才这个场景，假设参数调整到500，而对应的 CC 任务的执行时间 + 调度时间也降低到 500，则理论上这个 tablet 的版本数量将会在 1-500 之间浮动，相比于之前，版本数量更稳定。\n\n当然这个只是理论数值，实际情况还要考虑任务的具体执行时间、调度情况等等。\n\n## 手动 Compaction\n\n某些情况下，自动 Compaction 策略可能无法选取到某些 tablet，这时我们可能需要通过 Compaction 接口来主动触发指定 tablet 的 Compaction。我们以 curl 命令举例：\n\n```shell\n\ncurl -X POST http://192.168.1.1:8040/api/compaction/run?tablet_id=106818600\\&schema_hash=6979334\\&compact_type=cumulative\n```\n\n这里我们指定 id 为 106818600，schema hash 为 6979334 的 tablet 进行 Cumulative Compaction（compact_type参数为 base 则触发 Base Compaction）。其中 schema hash 可以通过 SHOW TABLET tablet_id 命令得到的 SHOW PROC 命令获取。\n如果提交成功，则会返回：\n\n```json\n{\"status\": \"Success\", \"msg\": \"compaction task is successfully triggered.\"}\n```\n\n这是一个异步操作，命令只是提交compaction 任务，之后我们可以通过以下 API 来查看任务是否在运行：\n\n```shell\n\ncurl -X GET http://192.168.1.1:8040/api/compaction/run_status?tablet_id=106818600\\&schema_hash=6979334\n```\n\n返回结果：\n\n```json\n\n{\n    \"status\" : \"Success\",\n    \"run_status\" : false,\n    \"msg\" : \"compaction task for this tablet is running\",\n    \"tablet_id\" : 106818600,\n    \"schema_hash\" : 6979334,\n    \"compact_type\" : \"cumulative\"\n}\n```\n\n当然也可以直接查看 tablet 的版本情况：\n\n```shell\n\ncurl -X GET http://192.168.1.1:8040/api/compaction/show?tablet_id=106818600\\&schema_hash=6979334\n```\n\n## END\n\nCompaction 策略是 Doris 比较复杂的一个数据处理逻辑，需要考虑的状态和情况非常多，因此也在不断完善中，最终希望能够自动的适配各种负载场景，减轻运维压力。","source":"_posts/bigdata/When：何时需要进行Doris Compaction调优.md","raw":"---\ntitle: When：何时需要进行Doris Compaction调优\ntags:\n  - 'Doris'\ncategories:\n  - [Doris]\ntop_img: '/img/bg/banner.gif'\ndate: 2022-09-03 23:40:51\nupdated: 2022-09-03 23:40:51\ncover:\ndescription:\nkeywords:\n---\n\n> 本篇将从实际使用场景的角度出发，介绍 Compaction 的调优思路和策略。通过本文将了解到 Compaction 相关的日志分析、参数调整和 API 的使用。\n\n## 什么情况下需要调整 Compaction 参数\n\nCompaction 的目的是合并多个数据版本，一是避免在读取时大量的 Merge 操作，二是避免大量的数据版本导致的随机IO。**并且在这个过程中，Compaction 操作不能占用太多的系统资源。所以我们可以以结果为导向，从以下两个方面反推是否需要调整 Compaction 策略。**\n\n1. 检查数据版本是否有堆积。\n\n2. 检查 IO 和内存资源是否被 Compaction 任务过多的占用。\n\n### 查看数据版本数量变化趋势\n\nDoris 提供数据版本数量的监控数据。如果你部署了 Prometheus + Grafana 的监控，则可以通过 Grafana 仪表盘的 BE Base Compaction Score 和 BE Cumu Compaction Score 图表查看到这个监控数据的趋势图：\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1662264565446-6e38cc7f-eb01-441c-a6f0-4988b07c4835.png)\n\n> 这个图表展示的是每个 BE 节点，所有 Tablet 中数据版本最多的那个 Tablet 的版本数量，可以反映出当前版本堆积情况。\n> 部署方式参阅：http://doris.incubator.apache.org/master/zh-CN/administrator-guide/operation/monitor-alert.html\n\n如果没有安装这个监控，如果你是用的 Palo 0.14.7 版本以上，也可以通过以下命令在命令行查看这个监控数据的趋势图：\n\n```shell\n\nmysql> ADMIN SHOW BACKEND METRIC (\"nodes\" = \"30746894\", \"metrics\" = \"BE_BASE_COMPACTION_SCORE\", \"time\" = \"last 4 hours\");\nmysql> ADMIN SHOW BACKEND METRIC (\"nodes\" = \"30746894\", \"metrics\" = \"BE_CUMU_COMPACTION_SCORE\", \"time\" = \"last 4 hours\");\n```\n\n注意这里有两个指标，分别表示 Base Compaction 和 Cumulative Compaction 所对应的版本数量。**在大部分情况下，我们只需要查看 Cumulative Compaction 的指标，即可大致了解集群的数据版本堆积情况。**\n\n**版本是否堆积没有一个明确的界限，而是根据使用场景和查询延迟进行判断的一个经验值。**我们可以按照以下步骤进行简单的推断：\n\n> 1. 观察数据版本数量的趋势，如果趋势平稳，则说明 Compaction 和导入速度基本持平。如果呈上升态势，则说明 Compaction 速度跟不上导入速度了。如果呈下降态势，说明 Compaction 速度超过了导入速度。**如果呈上升态势，或在平稳状态但数值较高，则需要考虑调整 Compaction 参数以加快 Compaction 的进度。**\n>\n> 2. **通常版本数量维持在 100 以内可以视为正常。而在大部分批量导入或低频导入场景下，版本数量通常为10-20甚至更低。**\n\n### 查看Compaction资源占用\nCompaction 资源占用主要是 IO 和 内存。\n\n对于 Compaction 占用的内存，可以在浏览器打开以下链接：http://be_host:webserver_port/mem_tracker在搜索框中输入 AutoCompaction：\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1662265200095-5cf34b92-10de-4d1f-80c3-4dfcc0fd49fd.png)\n\n则可以查看当前Compaction的内存开销和历史峰值开销。\n\n而对于 IO 操作，目前还没有提供单独的 Compaction 操作的 IO 监控，我们只能根据集群整体的 IO 利用率情况来做判断。我们可以查看监控图 Disk IO util：\n\n![图片](https://mmbiz.qpic.cn/mmbiz_png/eGOhXuI8cBaCgNjQSRHmVYlEkMEIH7OGlBmYBlAkJLj3MjeJTTiauBiaYFeia8zf5s2fvImSlPwthGKZSO8oeFzNg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)\n\n或者通过命令在命令行查看（Palo 0.14.7 以上版本）：\n\n```shell\n\nmysql> ADMIN SHOW BACKEND METRIC (\"nodes\" = \"30746894\", \"metrics\" = \"BE_DISK_IO\", \"time\" = \"last 4 hours\");\n```\n\n这个监控展示的是每个 BE 节点上磁盘的 IO util 指标。数值越高表示IO越繁忙。**当然大部分情况下 IO 资源都是查询请求消耗的，这个监控主要用于指导我们是否需要增加或减少 Compaction 任务数。**\n\n## Compaction 调优策略\n\n如果版本数量有上升趋势或者数值较高，则可以从以下两方面优化 Compaction：\n\n1. 修改 Compaction 线程数，使得同时能够执行更多的 Compaction 任务。\n\n2. 优化单个 Compaction 的执行逻辑，使数据版本数量维持在一个合理范围。\n\n### 优化前的准备工作\n\n在优化 Compaction 执行逻辑之前，我们需要使用一些命令来进一步查看一些Compaction的细节信息。\n\n首先，我们通过监控图找到一个版本数量最高的 BE 节点。然后执行以下命令分析日志：\n\n```shell\n\n$> grep \"succeed to do base\" log/be.INFO.log.20210505-142010 |tail -n 100\n$> grep \"succeed to do cumu\" log/be.INFO.log.20210505-142010 |tail -n 100\n```\n\n以上两个命令可以查看最近100个执行完成的 compaction 任务：\n\n```shell\n\nI0505 17:06:56.143455   675 compaction.cpp:135] succeed to do cumulative compaction. tablet=106827682.505347040.d040c1cdf71e5c95-3a002a06127ccd86, output_version=2-2631, current_max_version=2633, disk=/home/disk6/palo.HDD, segments=57. elapsed time=2.29371s. cumulative_compaction_policy=SIZE_BASED.\nI0505 17:06:56.520058   666 compaction.cpp:135] succeed to do cumulative compaction. tablet=106822189.1661856168.654562832a620ea6-46fe84c73ea84795, output_version=2-3247, current_max_version=3250, disk=/home/disk2/palo.HDD, segments=22. elapsed time=2.66858s. cumulative_compaction_policy=SIZE_BASED.\n```\n\n通过日志时间可以判断 Compaction 是否在持续正确的执行，通过 elapsed time 可以观察每个任务的执行时间。\n\n我们还可以执行以下命令展示最近100个 compaction 任务的配额（permits）：\n\n```shell\n\n$> grep \"permits\" log/be.INFO |tail -n 100\n\nI0505 17:04:07.120920   667 compaction.cpp:83] start cumulative compaction. tablet=106827970.777011641.9c474de1b8ba9199-4addeb135d6834ac, output_version=2-2623, permits: 39\nI0505 17:04:13.898777   672 compaction.cpp:83] start cumulative compaction. tablet=106822777.1948936074.a44ac9462e79b76d-4a33ee39559bb0bf, output_version=2-3238, permits: 22\n```\n\n配额和版本数量成正比。\n\n我们可以找到 permits 较大的一个任务对应的 tablet id，如上图permit 为 39 的任务的 tablet id 为 106827970，然后继续分析这个 tablet 的 compaction 情况。\n\n通过 MySQL 客户端连接 Doris 集群后，执行：\n\n```shell\n\nmysql> show tablet 106827970;\n+--------------------------+-----------+---------------+-----------+---------+----------+-------------+----------+--------+----------------------------------------------------------------------------+\n| DbName                   | TableName | PartitionName | IndexName | DbId    | TableId  | PartitionId | IndexId  | IsSync | DetailCmd                                                                  |\n+--------------------------+-----------+---------------+-----------+---------+----------+-------------+----------+--------+----------------------------------------------------------------------------+\n| default_cluster:test     | tbl1      | p20210505     | tbl1      | 3828954 | 63708800 | 106826829   | 63709761 | true   | SHOW PROC '/dbs/3828954/63708800/partitions/106826829/63709761/106827970'; |\n+--------------------------+-----------+---------------+-----------+---------+----------+-------------+----------+--------+----------------------------------------------------------------------------+\n```\n\n然后执行后面的 SHOW PROC 语句，我们可以获得这个 tablet 所有副本的详细信息。其中 VersionCount 列表示对应副本的数据版本数量。我们可以选取一个 VersionCount 较大的副本，在浏览器打开 CompactionStatus 列显示的 URL，得到如下Json结果：\n\n```json\n\n{\n    \"cumulative policy type\": \"SIZE_BASED\",\n    \"cumulative point\": 18438,\n    \"last cumulative failure time\": \"1970-01-01 08:00:00.000\",\n    \"last base failure time\": \"1970-01-01 08:00:00.000\",\n    \"last cumulative success time\": \"2021-05-05 17:18:48.904\",\n    \"last base success time\": \"2021-05-05 16:14:49.786\",\n    \"rowsets\": [\n        \"[0-17444] 13 DATA NONOVERLAPPING 0200000000b1fb8d344f83103113563dd81740036795499d 2.86 GB\",\n        \"[17445-17751] 1 DATA NONOVERLAPPING 0200000000b25183344f83103113563dd81740036795499d 68.61 MB\",\n        \"[17752-18089] 1 DATA NONOVERLAPPING 0200000000b2b9a2344f83103113563dd81740036795499d 74.52 MB\",\n        \"[18090-18437] 1 DATA NONOVERLAPPING 0200000000b32686344f83103113563dd81740036795499d 76.41 MB\",\n        \"[18438-18678] 1 DATA NONOVERLAPPING 0200000000b37084344f83103113563dd81740036795499d 53.07 MB\",\n        \"[18679-18679] 1 DATA NONOVERLAPPING 0200000000b36d87344f83103113563dd81740036795499d 3.11 KB\",\n        \"[18680-18680] 1 DATA NONOVERLAPPING 0200000000b36d70344f83103113563dd81740036795499d 258.40 KB\",\n        \"[18681-18681] 1 DATA NONOVERLAPPING 0200000000b36da0344f83103113563dd81740036795499d 266.98 KB\",\n    ],\n    \"stale_rowsets\": [\n    ],\n    \"stale version path\": [\n    ]\n}\n```\n\n这里我们可以看到一个 tablet 的 Cumulative Point，最近一次成功、失败的 BC/CC 任务时间，以及每个 rowset 的版本信息。如上面这个示例，我们可以得出以下结论：\n\n> 1. 基线数据量大约在2-3GB，增量rowset增长到几十MB后就会晋升到BC任务区。\n>\n> 2. 新增rowset数据量很小，且版本增长较快，说明这是一个高频小批量的导入场景。\n\n我们还可以进一步的通过以下命令分析指定 tablet id 的日志\n\n```shell\n\n# 查看 tablet 48062815 最近十个任务的配额情况\n$> grep permits log/be.INFO |grep 48062815 |tail -n 10\n\n# 查看 tablet 48062815 最近十个执行完成的 compaction 任务\n$> grep \"succeed to do\" log/be.INFO |grep 48062815 |tail -n 10\n```\n\n另外，我们还可以在浏览器打开以下 URL，查看一个 BE 节点当前正在执行的 compaction 任务：be_host:webserver_port/api/compaction/run_status\n\n```json\n\n{\n    \"CumulativeCompaction\": {\n        \"/home/disk2/palo\": [],\n        \"/home/disk1/palo\": [\n            \"48061239\"\n        ]\n    },\n    \"BaseCompaction\": {\n        \"/home/disk2/palo\": [],\n        \"/home/disk1/palo\": [\n            \"48062815\",\n            \"48061276\"\n        ]\n    }\n}\n```\n\n这个接口可以看到每个磁盘上当前正在执行的 compaction 任务。\n\n通过以上一系列的分析，我们应该可以对系统的 Compaction 情况有以下判断：\n\n> 1. Compaction 任务的执行频率、每个任务大致的执行耗时。\n>\n> 2. 指定节点数据版本数量的变化情况。\n>\n> 3. 指定 tablet 数据版本的变化情况，以及 compaction 的频率。\n>\n\n这些结论将指导我们对 Compaction 进行调优。\n\n### 修改 Compaction 线程数\n\n**增加 Compaction 线程数是一个非常直接的加速 Compaction 的方法。**但是更多的任务意味着更大的 IO 和 内存开销。尤其在机械磁盘上，因为随机读写问题，有时可能单线程串行执行的效率会高于多线程并行执行。Doris 默认配置为每块盘两个 Compaction 任务（这也是最小的合法配置），最多 10 个任务。如果磁盘数量多于 5，在内存允许的情况下，可以修改 max_compaction_threads 参数增加总任务数，以保证每块盘可以执行两个 Compaction 任务。\n\n对于机械磁盘，不建议增加每块盘的任务数。对于固态硬盘，可以考虑修改 compaction_task_num_per_disk 参数适当增加每块盘的任务数，如修改为 4。**注意修改这个参数的同时可能还需同步修改 max_compaction_threads，使得 max_compaction_threads 大于等于 compaction_task_num_per_disk * 磁盘数量。**\n\n### 优化单个 Compaction 任务逻辑\n\n这个优化方式比较复杂，我们尝试从几个场景出发来说明：\n\n#### **场景一：基线数据量大，Base Compaction 任务执行时间长。**\n\nBC 任务执行时间长，意味着一个任务会长时间占用 Compaction 工作线程，从而导致其他 tablet 的 compaction 任务时间被挤占。如果是因为 0 号版本的基线数据量较大导致，则我们可以考虑尽量推迟增量rowset 晋升到 BC 任务区的时间。以下两个参数将影响这个逻辑：\n\n> cumulative_size_based_promotion_ratio：默认 0.05，基线数据量乘以这个系数，即晋升阈值。可以调大这个系数来提高晋升阈值。\n>\n> cumulative_size_based_promotion_size_mbytes：默认 1024MB。如果增量rowset的数据量大于这个值，则会忽略第一个参数的阈值直接晋升。因此需要同时调整这个参数来提升晋升阈值。\n\n当然，提升晋升阈值，会导致单个 BC 任务需要处理更大的数据量，耗时更长，但是总体的数据量会减少。举个例子。基线数据大小为 1024GB，假设晋升阈值分别为 100MB 和 200MB。数据导入速度为 100MB/分钟。每5个版本执行一次 BC。那么理论上在10分钟内，阈值为 100MB 时，BC 任务处理的总数据量为 （1024 + 100 * 5）* 2 = 3048MB。阈值为 200MB 是，BC 任务处理的总数据量为 (1024 + 200 * 5) = 2024 MB。\n\n#### **场景二：增量数据版本数量增长较快，Cumulative Compaction 处理过多版本，耗时较长。**\n\nmax_cumulative_compaction_num_singleton_deltas 参数控制一个 CC 任务最多合并多少个数据版本，默认值为 1000。我们考虑这样一种场景：针对某一个 tablet，其数据版本的增长速度为 1个/秒。而其 CC 任务的执行时间 + 调度时间是 1000秒（即单个 CC 任务的执行时间加上Compaction再一次调度到这个 tablet 的时间总和）。那么我们可能会看到这个 tablet 的版本数量在 1-1000之间浮动（这里我们忽略基线版本数量）。因为在下一次 CC 任务执行前的 1000 秒内，又会累积 1000 个版本。\n\n这种情况可能导致这个 tablet 的读取效率很不稳定。这时我们可以尝试调小 max_cumulative_compaction_num_singleton_deltas 这个参数，这样一个 CC 所要合并的版本数更少，执行时间更短，执行频率会更高。还是刚才这个场景，假设参数调整到500，而对应的 CC 任务的执行时间 + 调度时间也降低到 500，则理论上这个 tablet 的版本数量将会在 1-500 之间浮动，相比于之前，版本数量更稳定。\n\n当然这个只是理论数值，实际情况还要考虑任务的具体执行时间、调度情况等等。\n\n## 手动 Compaction\n\n某些情况下，自动 Compaction 策略可能无法选取到某些 tablet，这时我们可能需要通过 Compaction 接口来主动触发指定 tablet 的 Compaction。我们以 curl 命令举例：\n\n```shell\n\ncurl -X POST http://192.168.1.1:8040/api/compaction/run?tablet_id=106818600\\&schema_hash=6979334\\&compact_type=cumulative\n```\n\n这里我们指定 id 为 106818600，schema hash 为 6979334 的 tablet 进行 Cumulative Compaction（compact_type参数为 base 则触发 Base Compaction）。其中 schema hash 可以通过 SHOW TABLET tablet_id 命令得到的 SHOW PROC 命令获取。\n如果提交成功，则会返回：\n\n```json\n{\"status\": \"Success\", \"msg\": \"compaction task is successfully triggered.\"}\n```\n\n这是一个异步操作，命令只是提交compaction 任务，之后我们可以通过以下 API 来查看任务是否在运行：\n\n```shell\n\ncurl -X GET http://192.168.1.1:8040/api/compaction/run_status?tablet_id=106818600\\&schema_hash=6979334\n```\n\n返回结果：\n\n```json\n\n{\n    \"status\" : \"Success\",\n    \"run_status\" : false,\n    \"msg\" : \"compaction task for this tablet is running\",\n    \"tablet_id\" : 106818600,\n    \"schema_hash\" : 6979334,\n    \"compact_type\" : \"cumulative\"\n}\n```\n\n当然也可以直接查看 tablet 的版本情况：\n\n```shell\n\ncurl -X GET http://192.168.1.1:8040/api/compaction/show?tablet_id=106818600\\&schema_hash=6979334\n```\n\n## END\n\nCompaction 策略是 Doris 比较复杂的一个数据处理逻辑，需要考虑的状态和情况非常多，因此也在不断完善中，最终希望能够自动的适配各种负载场景，减轻运维压力。","slug":"bigdata/When：何时需要进行Doris Compaction调优","published":1,"comments":1,"layout":"post","photos":[],"link":"","_id":"cl9y38dsf001ffwuihhin3n5o","content":"<blockquote>\n<p>本篇将从实际使用场景的角度出发，介绍 Compaction 的调优思路和策略。通过本文将了解到 Compaction 相关的日志分析、参数调整和 API 的使用。</p>\n</blockquote>\n<h2 id=\"什么情况下需要调整-Compaction-参数\"><a href=\"#什么情况下需要调整-Compaction-参数\" class=\"headerlink\" title=\"什么情况下需要调整 Compaction 参数\"></a>什么情况下需要调整 Compaction 参数</h2><p>Compaction 的目的是合并多个数据版本，一是避免在读取时大量的 Merge 操作，二是避免大量的数据版本导致的随机IO。<strong>并且在这个过程中，Compaction 操作不能占用太多的系统资源。所以我们可以以结果为导向，从以下两个方面反推是否需要调整 Compaction 策略。</strong></p>\n<ol>\n<li><p>检查数据版本是否有堆积。</p>\n</li>\n<li><p>检查 IO 和内存资源是否被 Compaction 任务过多的占用。</p>\n</li>\n</ol>\n<h3 id=\"查看数据版本数量变化趋势\"><a href=\"#查看数据版本数量变化趋势\" class=\"headerlink\" title=\"查看数据版本数量变化趋势\"></a>查看数据版本数量变化趋势</h3><p>Doris 提供数据版本数量的监控数据。如果你部署了 Prometheus + Grafana 的监控，则可以通过 Grafana 仪表盘的 BE Base Compaction Score 和 BE Cumu Compaction Score 图表查看到这个监控数据的趋势图：</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1662264565446-6e38cc7f-eb01-441c-a6f0-4988b07c4835.png\" alt=\"img\"></p>\n<blockquote>\n<p>这个图表展示的是每个 BE 节点，所有 Tablet 中数据版本最多的那个 Tablet 的版本数量，可以反映出当前版本堆积情况。<br>部署方式参阅：<a href=\"http://doris.incubator.apache.org/master/zh-CN/administrator-guide/operation/monitor-alert.html\">http://doris.incubator.apache.org/master/zh-CN/administrator-guide/operation/monitor-alert.html</a></p>\n</blockquote>\n<p>如果没有安装这个监控，如果你是用的 Palo 0.14.7 版本以上，也可以通过以下命令在命令行查看这个监控数据的趋势图：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\">mysql&gt; </span><span class=\"language-bash\">ADMIN SHOW BACKEND METRIC (<span class=\"string\">&quot;nodes&quot;</span> = <span class=\"string\">&quot;30746894&quot;</span>, <span class=\"string\">&quot;metrics&quot;</span> = <span class=\"string\">&quot;BE_BASE_COMPACTION_SCORE&quot;</span>, <span class=\"string\">&quot;time&quot;</span> = <span class=\"string\">&quot;last 4 hours&quot;</span>);</span></span><br><span class=\"line\"><span class=\"meta prompt_\">mysql&gt; </span><span class=\"language-bash\">ADMIN SHOW BACKEND METRIC (<span class=\"string\">&quot;nodes&quot;</span> = <span class=\"string\">&quot;30746894&quot;</span>, <span class=\"string\">&quot;metrics&quot;</span> = <span class=\"string\">&quot;BE_CUMU_COMPACTION_SCORE&quot;</span>, <span class=\"string\">&quot;time&quot;</span> = <span class=\"string\">&quot;last 4 hours&quot;</span>);</span></span><br></pre></td></tr></table></figure>\n\n<p>注意这里有两个指标，分别表示 Base Compaction 和 Cumulative Compaction 所对应的版本数量。<strong>在大部分情况下，我们只需要查看 Cumulative Compaction 的指标，即可大致了解集群的数据版本堆积情况。</strong></p>\n<p><strong>版本是否堆积没有一个明确的界限，而是根据使用场景和查询延迟进行判断的一个经验值。</strong>我们可以按照以下步骤进行简单的推断：</p>\n<blockquote>\n<ol>\n<li><p>观察数据版本数量的趋势，如果趋势平稳，则说明 Compaction 和导入速度基本持平。如果呈上升态势，则说明 Compaction 速度跟不上导入速度了。如果呈下降态势，说明 Compaction 速度超过了导入速度。<strong>如果呈上升态势，或在平稳状态但数值较高，则需要考虑调整 Compaction 参数以加快 Compaction 的进度。</strong></p>\n</li>\n<li><p><strong>通常版本数量维持在 100 以内可以视为正常。而在大部分批量导入或低频导入场景下，版本数量通常为10-20甚至更低。</strong></p>\n</li>\n</ol>\n</blockquote>\n<h3 id=\"查看Compaction资源占用\"><a href=\"#查看Compaction资源占用\" class=\"headerlink\" title=\"查看Compaction资源占用\"></a>查看Compaction资源占用</h3><p>Compaction 资源占用主要是 IO 和 内存。</p>\n<p>对于 Compaction 占用的内存，可以在浏览器打开以下链接：<a href=\"http://be_host:webserver_port/mem_tracker在搜索框中输入\">http://be_host:webserver_port/mem_tracker在搜索框中输入</a> AutoCompaction：</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1662265200095-5cf34b92-10de-4d1f-80c3-4dfcc0fd49fd.png\" alt=\"img\"></p>\n<p>则可以查看当前Compaction的内存开销和历史峰值开销。</p>\n<p>而对于 IO 操作，目前还没有提供单独的 Compaction 操作的 IO 监控，我们只能根据集群整体的 IO 利用率情况来做判断。我们可以查看监控图 Disk IO util：</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/eGOhXuI8cBaCgNjQSRHmVYlEkMEIH7OGlBmYBlAkJLj3MjeJTTiauBiaYFeia8zf5s2fvImSlPwthGKZSO8oeFzNg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1\" alt=\"图片\"></p>\n<p>或者通过命令在命令行查看（Palo 0.14.7 以上版本）：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\">mysql&gt; </span><span class=\"language-bash\">ADMIN SHOW BACKEND METRIC (<span class=\"string\">&quot;nodes&quot;</span> = <span class=\"string\">&quot;30746894&quot;</span>, <span class=\"string\">&quot;metrics&quot;</span> = <span class=\"string\">&quot;BE_DISK_IO&quot;</span>, <span class=\"string\">&quot;time&quot;</span> = <span class=\"string\">&quot;last 4 hours&quot;</span>);</span></span><br></pre></td></tr></table></figure>\n\n<p>这个监控展示的是每个 BE 节点上磁盘的 IO util 指标。数值越高表示IO越繁忙。<strong>当然大部分情况下 IO 资源都是查询请求消耗的，这个监控主要用于指导我们是否需要增加或减少 Compaction 任务数。</strong></p>\n<h2 id=\"Compaction-调优策略\"><a href=\"#Compaction-调优策略\" class=\"headerlink\" title=\"Compaction 调优策略\"></a>Compaction 调优策略</h2><p>如果版本数量有上升趋势或者数值较高，则可以从以下两方面优化 Compaction：</p>\n<ol>\n<li><p>修改 Compaction 线程数，使得同时能够执行更多的 Compaction 任务。</p>\n</li>\n<li><p>优化单个 Compaction 的执行逻辑，使数据版本数量维持在一个合理范围。</p>\n</li>\n</ol>\n<h3 id=\"优化前的准备工作\"><a href=\"#优化前的准备工作\" class=\"headerlink\" title=\"优化前的准备工作\"></a>优化前的准备工作</h3><p>在优化 Compaction 执行逻辑之前，我们需要使用一些命令来进一步查看一些Compaction的细节信息。</p>\n<p>首先，我们通过监控图找到一个版本数量最高的 BE 节点。然后执行以下命令分析日志：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\">$</span><span class=\"language-bash\">&gt; grep <span class=\"string\">&quot;succeed to do base&quot;</span> <span class=\"built_in\">log</span>/be.INFO.log.20210505-142010 |<span class=\"built_in\">tail</span> -n 100</span></span><br><span class=\"line\"><span class=\"meta prompt_\">$</span><span class=\"language-bash\">&gt; grep <span class=\"string\">&quot;succeed to do cumu&quot;</span> <span class=\"built_in\">log</span>/be.INFO.log.20210505-142010 |<span class=\"built_in\">tail</span> -n 100</span></span><br></pre></td></tr></table></figure>\n\n<p>以上两个命令可以查看最近100个执行完成的 compaction 任务：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">I0505 17:06:56.143455   675 compaction.cpp:135] succeed to do cumulative compaction. tablet=106827682.505347040.d040c1cdf71e5c95-3a002a06127ccd86, output_version=2-2631, current_max_version=2633, disk=/home/disk6/palo.HDD, segments=57. elapsed time=2.29371s. cumulative_compaction_policy=SIZE_BASED.</span><br><span class=\"line\">I0505 17:06:56.520058   666 compaction.cpp:135] succeed to do cumulative compaction. tablet=106822189.1661856168.654562832a620ea6-46fe84c73ea84795, output_version=2-3247, current_max_version=3250, disk=/home/disk2/palo.HDD, segments=22. elapsed time=2.66858s. cumulative_compaction_policy=SIZE_BASED.</span><br></pre></td></tr></table></figure>\n\n<p>通过日志时间可以判断 Compaction 是否在持续正确的执行，通过 elapsed time 可以观察每个任务的执行时间。</p>\n<p>我们还可以执行以下命令展示最近100个 compaction 任务的配额（permits）：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\">$</span><span class=\"language-bash\">&gt; grep <span class=\"string\">&quot;permits&quot;</span> <span class=\"built_in\">log</span>/be.INFO |<span class=\"built_in\">tail</span> -n 100</span></span><br><span class=\"line\"></span><br><span class=\"line\">I0505 17:04:07.120920   667 compaction.cpp:83] start cumulative compaction. tablet=106827970.777011641.9c474de1b8ba9199-4addeb135d6834ac, output_version=2-2623, permits: 39</span><br><span class=\"line\">I0505 17:04:13.898777   672 compaction.cpp:83] start cumulative compaction. tablet=106822777.1948936074.a44ac9462e79b76d-4a33ee39559bb0bf, output_version=2-3238, permits: 22</span><br></pre></td></tr></table></figure>\n\n<p>配额和版本数量成正比。</p>\n<p>我们可以找到 permits 较大的一个任务对应的 tablet id，如上图permit 为 39 的任务的 tablet id 为 106827970，然后继续分析这个 tablet 的 compaction 情况。</p>\n<p>通过 MySQL 客户端连接 Doris 集群后，执行：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\">mysql&gt; </span><span class=\"language-bash\">show tablet 106827970;</span></span><br><span class=\"line\">+--------------------------+-----------+---------------+-----------+---------+----------+-------------+----------+--------+----------------------------------------------------------------------------+</span><br><span class=\"line\">| DbName                   | TableName | PartitionName | IndexName | DbId    | TableId  | PartitionId | IndexId  | IsSync | DetailCmd                                                                  |</span><br><span class=\"line\">+--------------------------+-----------+---------------+-----------+---------+----------+-------------+----------+--------+----------------------------------------------------------------------------+</span><br><span class=\"line\">| default_cluster:test     | tbl1      | p20210505     | tbl1      | 3828954 | 63708800 | 106826829   | 63709761 | true   | SHOW PROC &#x27;/dbs/3828954/63708800/partitions/106826829/63709761/106827970&#x27;; |</span><br><span class=\"line\">+--------------------------+-----------+---------------+-----------+---------+----------+-------------+----------+--------+----------------------------------------------------------------------------+</span><br></pre></td></tr></table></figure>\n\n<p>然后执行后面的 SHOW PROC 语句，我们可以获得这个 tablet 所有副本的详细信息。其中 VersionCount 列表示对应副本的数据版本数量。我们可以选取一个 VersionCount 较大的副本，在浏览器打开 CompactionStatus 列显示的 URL，得到如下Json结果：</p>\n<figure class=\"highlight json\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">    <span class=\"attr\">&quot;cumulative policy type&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;SIZE_BASED&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">    <span class=\"attr\">&quot;cumulative point&quot;</span><span class=\"punctuation\">:</span> <span class=\"number\">18438</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">    <span class=\"attr\">&quot;last cumulative failure time&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;1970-01-01 08:00:00.000&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">    <span class=\"attr\">&quot;last base failure time&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;1970-01-01 08:00:00.000&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">    <span class=\"attr\">&quot;last cumulative success time&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;2021-05-05 17:18:48.904&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">    <span class=\"attr\">&quot;last base success time&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;2021-05-05 16:14:49.786&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">    <span class=\"attr\">&quot;rowsets&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">[</span></span><br><span class=\"line\">        <span class=\"string\">&quot;[0-17444] 13 DATA NONOVERLAPPING 0200000000b1fb8d344f83103113563dd81740036795499d 2.86 GB&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">        <span class=\"string\">&quot;[17445-17751] 1 DATA NONOVERLAPPING 0200000000b25183344f83103113563dd81740036795499d 68.61 MB&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">        <span class=\"string\">&quot;[17752-18089] 1 DATA NONOVERLAPPING 0200000000b2b9a2344f83103113563dd81740036795499d 74.52 MB&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">        <span class=\"string\">&quot;[18090-18437] 1 DATA NONOVERLAPPING 0200000000b32686344f83103113563dd81740036795499d 76.41 MB&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">        <span class=\"string\">&quot;[18438-18678] 1 DATA NONOVERLAPPING 0200000000b37084344f83103113563dd81740036795499d 53.07 MB&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">        <span class=\"string\">&quot;[18679-18679] 1 DATA NONOVERLAPPING 0200000000b36d87344f83103113563dd81740036795499d 3.11 KB&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">        <span class=\"string\">&quot;[18680-18680] 1 DATA NONOVERLAPPING 0200000000b36d70344f83103113563dd81740036795499d 258.40 KB&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">        <span class=\"string\">&quot;[18681-18681] 1 DATA NONOVERLAPPING 0200000000b36da0344f83103113563dd81740036795499d 266.98 KB&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">    <span class=\"punctuation\">]</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">    <span class=\"attr\">&quot;stale_rowsets&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">[</span></span><br><span class=\"line\">    <span class=\"punctuation\">]</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">    <span class=\"attr\">&quot;stale version path&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">[</span></span><br><span class=\"line\">    <span class=\"punctuation\">]</span></span><br><span class=\"line\"><span class=\"punctuation\">&#125;</span></span><br></pre></td></tr></table></figure>\n\n<p>这里我们可以看到一个 tablet 的 Cumulative Point，最近一次成功、失败的 BC&#x2F;CC 任务时间，以及每个 rowset 的版本信息。如上面这个示例，我们可以得出以下结论：</p>\n<blockquote>\n<ol>\n<li><p>基线数据量大约在2-3GB，增量rowset增长到几十MB后就会晋升到BC任务区。</p>\n</li>\n<li><p>新增rowset数据量很小，且版本增长较快，说明这是一个高频小批量的导入场景。</p>\n</li>\n</ol>\n</blockquote>\n<p>我们还可以进一步的通过以下命令分析指定 tablet id 的日志</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">查看 tablet 48062815 最近十个任务的配额情况</span></span><br><span class=\"line\"><span class=\"meta prompt_\">$</span><span class=\"language-bash\">&gt; grep permits <span class=\"built_in\">log</span>/be.INFO |grep 48062815 |<span class=\"built_in\">tail</span> -n 10</span></span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">查看 tablet 48062815 最近十个执行完成的 compaction 任务</span></span><br><span class=\"line\"><span class=\"meta prompt_\">$</span><span class=\"language-bash\">&gt; grep <span class=\"string\">&quot;succeed to do&quot;</span> <span class=\"built_in\">log</span>/be.INFO |grep 48062815 |<span class=\"built_in\">tail</span> -n 10</span></span><br></pre></td></tr></table></figure>\n\n<p>另外，我们还可以在浏览器打开以下 URL，查看一个 BE 节点当前正在执行的 compaction 任务：be_host:webserver_port&#x2F;api&#x2F;compaction&#x2F;run_status</p>\n<figure class=\"highlight json\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">    <span class=\"attr\">&quot;CumulativeCompaction&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;/home/disk2/palo&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">[</span><span class=\"punctuation\">]</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;/home/disk1/palo&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">[</span></span><br><span class=\"line\">            <span class=\"string\">&quot;48061239&quot;</span></span><br><span class=\"line\">        <span class=\"punctuation\">]</span></span><br><span class=\"line\">    <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">    <span class=\"attr\">&quot;BaseCompaction&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;/home/disk2/palo&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">[</span><span class=\"punctuation\">]</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;/home/disk1/palo&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">[</span></span><br><span class=\"line\">            <span class=\"string\">&quot;48062815&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"string\">&quot;48061276&quot;</span></span><br><span class=\"line\">        <span class=\"punctuation\">]</span></span><br><span class=\"line\">    <span class=\"punctuation\">&#125;</span></span><br><span class=\"line\"><span class=\"punctuation\">&#125;</span></span><br></pre></td></tr></table></figure>\n\n<p>这个接口可以看到每个磁盘上当前正在执行的 compaction 任务。</p>\n<p>通过以上一系列的分析，我们应该可以对系统的 Compaction 情况有以下判断：</p>\n<blockquote>\n<ol>\n<li><p>Compaction 任务的执行频率、每个任务大致的执行耗时。</p>\n</li>\n<li><p>指定节点数据版本数量的变化情况。</p>\n</li>\n<li><p>指定 tablet 数据版本的变化情况，以及 compaction 的频率。</p>\n</li>\n</ol>\n</blockquote>\n<p>这些结论将指导我们对 Compaction 进行调优。</p>\n<h3 id=\"修改-Compaction-线程数\"><a href=\"#修改-Compaction-线程数\" class=\"headerlink\" title=\"修改 Compaction 线程数\"></a>修改 Compaction 线程数</h3><p><strong>增加 Compaction 线程数是一个非常直接的加速 Compaction 的方法。</strong>但是更多的任务意味着更大的 IO 和 内存开销。尤其在机械磁盘上，因为随机读写问题，有时可能单线程串行执行的效率会高于多线程并行执行。Doris 默认配置为每块盘两个 Compaction 任务（这也是最小的合法配置），最多 10 个任务。如果磁盘数量多于 5，在内存允许的情况下，可以修改 max_compaction_threads 参数增加总任务数，以保证每块盘可以执行两个 Compaction 任务。</p>\n<p>对于机械磁盘，不建议增加每块盘的任务数。对于固态硬盘，可以考虑修改 compaction_task_num_per_disk 参数适当增加每块盘的任务数，如修改为 4。<strong>注意修改这个参数的同时可能还需同步修改 max_compaction_threads，使得 max_compaction_threads 大于等于 compaction_task_num_per_disk * 磁盘数量。</strong></p>\n<h3 id=\"优化单个-Compaction-任务逻辑\"><a href=\"#优化单个-Compaction-任务逻辑\" class=\"headerlink\" title=\"优化单个 Compaction 任务逻辑\"></a>优化单个 Compaction 任务逻辑</h3><p>这个优化方式比较复杂，我们尝试从几个场景出发来说明：</p>\n<h4 id=\"场景一：基线数据量大，Base-Compaction-任务执行时间长。\"><a href=\"#场景一：基线数据量大，Base-Compaction-任务执行时间长。\" class=\"headerlink\" title=\"场景一：基线数据量大，Base Compaction 任务执行时间长。\"></a><strong>场景一：基线数据量大，Base Compaction 任务执行时间长。</strong></h4><p>BC 任务执行时间长，意味着一个任务会长时间占用 Compaction 工作线程，从而导致其他 tablet 的 compaction 任务时间被挤占。如果是因为 0 号版本的基线数据量较大导致，则我们可以考虑尽量推迟增量rowset 晋升到 BC 任务区的时间。以下两个参数将影响这个逻辑：</p>\n<blockquote>\n<p>cumulative_size_based_promotion_ratio：默认 0.05，基线数据量乘以这个系数，即晋升阈值。可以调大这个系数来提高晋升阈值。</p>\n<p>cumulative_size_based_promotion_size_mbytes：默认 1024MB。如果增量rowset的数据量大于这个值，则会忽略第一个参数的阈值直接晋升。因此需要同时调整这个参数来提升晋升阈值。</p>\n</blockquote>\n<p>当然，提升晋升阈值，会导致单个 BC 任务需要处理更大的数据量，耗时更长，但是总体的数据量会减少。举个例子。基线数据大小为 1024GB，假设晋升阈值分别为 100MB 和 200MB。数据导入速度为 100MB&#x2F;分钟。每5个版本执行一次 BC。那么理论上在10分钟内，阈值为 100MB 时，BC 任务处理的总数据量为 （1024 + 100 * 5）* 2 &#x3D; 3048MB。阈值为 200MB 是，BC 任务处理的总数据量为 (1024 + 200 * 5) &#x3D; 2024 MB。</p>\n<h4 id=\"场景二：增量数据版本数量增长较快，Cumulative-Compaction-处理过多版本，耗时较长。\"><a href=\"#场景二：增量数据版本数量增长较快，Cumulative-Compaction-处理过多版本，耗时较长。\" class=\"headerlink\" title=\"场景二：增量数据版本数量增长较快，Cumulative Compaction 处理过多版本，耗时较长。\"></a><strong>场景二：增量数据版本数量增长较快，Cumulative Compaction 处理过多版本，耗时较长。</strong></h4><p>max_cumulative_compaction_num_singleton_deltas 参数控制一个 CC 任务最多合并多少个数据版本，默认值为 1000。我们考虑这样一种场景：针对某一个 tablet，其数据版本的增长速度为 1个&#x2F;秒。而其 CC 任务的执行时间 + 调度时间是 1000秒（即单个 CC 任务的执行时间加上Compaction再一次调度到这个 tablet 的时间总和）。那么我们可能会看到这个 tablet 的版本数量在 1-1000之间浮动（这里我们忽略基线版本数量）。因为在下一次 CC 任务执行前的 1000 秒内，又会累积 1000 个版本。</p>\n<p>这种情况可能导致这个 tablet 的读取效率很不稳定。这时我们可以尝试调小 max_cumulative_compaction_num_singleton_deltas 这个参数，这样一个 CC 所要合并的版本数更少，执行时间更短，执行频率会更高。还是刚才这个场景，假设参数调整到500，而对应的 CC 任务的执行时间 + 调度时间也降低到 500，则理论上这个 tablet 的版本数量将会在 1-500 之间浮动，相比于之前，版本数量更稳定。</p>\n<p>当然这个只是理论数值，实际情况还要考虑任务的具体执行时间、调度情况等等。</p>\n<h2 id=\"手动-Compaction\"><a href=\"#手动-Compaction\" class=\"headerlink\" title=\"手动 Compaction\"></a>手动 Compaction</h2><p>某些情况下，自动 Compaction 策略可能无法选取到某些 tablet，这时我们可能需要通过 Compaction 接口来主动触发指定 tablet 的 Compaction。我们以 curl 命令举例：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">curl -X POST http://192.168.1.1:8040/api/compaction/run?tablet_id=106818600\\&amp;schema_hash=6979334\\&amp;compact_type=cumulative</span><br></pre></td></tr></table></figure>\n\n<p>这里我们指定 id 为 106818600，schema hash 为 6979334 的 tablet 进行 Cumulative Compaction（compact_type参数为 base 则触发 Base Compaction）。其中 schema hash 可以通过 SHOW TABLET tablet_id 命令得到的 SHOW PROC 命令获取。<br>如果提交成功，则会返回：</p>\n<figure class=\"highlight json\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"punctuation\">&#123;</span><span class=\"attr\">&quot;status&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;Success&quot;</span><span class=\"punctuation\">,</span> <span class=\"attr\">&quot;msg&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;compaction task is successfully triggered.&quot;</span><span class=\"punctuation\">&#125;</span></span><br></pre></td></tr></table></figure>\n\n<p>这是一个异步操作，命令只是提交compaction 任务，之后我们可以通过以下 API 来查看任务是否在运行：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">curl -X GET http://192.168.1.1:8040/api/compaction/run_status?tablet_id=106818600\\&amp;schema_hash=6979334</span><br></pre></td></tr></table></figure>\n\n<p>返回结果：</p>\n<figure class=\"highlight json\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">    <span class=\"attr\">&quot;status&quot;</span> <span class=\"punctuation\">:</span> <span class=\"string\">&quot;Success&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">    <span class=\"attr\">&quot;run_status&quot;</span> <span class=\"punctuation\">:</span> <span class=\"keyword\">false</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">    <span class=\"attr\">&quot;msg&quot;</span> <span class=\"punctuation\">:</span> <span class=\"string\">&quot;compaction task for this tablet is running&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">    <span class=\"attr\">&quot;tablet_id&quot;</span> <span class=\"punctuation\">:</span> <span class=\"number\">106818600</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">    <span class=\"attr\">&quot;schema_hash&quot;</span> <span class=\"punctuation\">:</span> <span class=\"number\">6979334</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">    <span class=\"attr\">&quot;compact_type&quot;</span> <span class=\"punctuation\">:</span> <span class=\"string\">&quot;cumulative&quot;</span></span><br><span class=\"line\"><span class=\"punctuation\">&#125;</span></span><br></pre></td></tr></table></figure>\n\n<p>当然也可以直接查看 tablet 的版本情况：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">curl -X GET http://192.168.1.1:8040/api/compaction/show?tablet_id=106818600\\&amp;schema_hash=6979334</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"END\"><a href=\"#END\" class=\"headerlink\" title=\"END\"></a>END</h2><p>Compaction 策略是 Doris 比较复杂的一个数据处理逻辑，需要考虑的状态和情况非常多，因此也在不断完善中，最终希望能够自动的适配各种负载场景，减轻运维压力。</p>\n","site":{"data":{"link":[{"class_name":"友情链接","class_desc":"那些人，那些事","link_list":[{"name":"张洪Heo","link":"https://blog.zhheo.com/","avatar":"https://npm.elemecdn.com/guli-heo/img/avatar2.png","descr":"分享设计与科技生活"},{"name":"瞬間の筆記","link":"https://hikki.site","descr":"喜欢的东西就努力去追求，万一成功了呢!","avatar":"https://cdn.jsdelivr.net/gh/0000rookie/imgs/202206120315.png"}]}]}},"excerpt":"","more":"<blockquote>\n<p>本篇将从实际使用场景的角度出发，介绍 Compaction 的调优思路和策略。通过本文将了解到 Compaction 相关的日志分析、参数调整和 API 的使用。</p>\n</blockquote>\n<h2 id=\"什么情况下需要调整-Compaction-参数\"><a href=\"#什么情况下需要调整-Compaction-参数\" class=\"headerlink\" title=\"什么情况下需要调整 Compaction 参数\"></a>什么情况下需要调整 Compaction 参数</h2><p>Compaction 的目的是合并多个数据版本，一是避免在读取时大量的 Merge 操作，二是避免大量的数据版本导致的随机IO。<strong>并且在这个过程中，Compaction 操作不能占用太多的系统资源。所以我们可以以结果为导向，从以下两个方面反推是否需要调整 Compaction 策略。</strong></p>\n<ol>\n<li><p>检查数据版本是否有堆积。</p>\n</li>\n<li><p>检查 IO 和内存资源是否被 Compaction 任务过多的占用。</p>\n</li>\n</ol>\n<h3 id=\"查看数据版本数量变化趋势\"><a href=\"#查看数据版本数量变化趋势\" class=\"headerlink\" title=\"查看数据版本数量变化趋势\"></a>查看数据版本数量变化趋势</h3><p>Doris 提供数据版本数量的监控数据。如果你部署了 Prometheus + Grafana 的监控，则可以通过 Grafana 仪表盘的 BE Base Compaction Score 和 BE Cumu Compaction Score 图表查看到这个监控数据的趋势图：</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1662264565446-6e38cc7f-eb01-441c-a6f0-4988b07c4835.png\" alt=\"img\"></p>\n<blockquote>\n<p>这个图表展示的是每个 BE 节点，所有 Tablet 中数据版本最多的那个 Tablet 的版本数量，可以反映出当前版本堆积情况。<br>部署方式参阅：<a href=\"http://doris.incubator.apache.org/master/zh-CN/administrator-guide/operation/monitor-alert.html\">http://doris.incubator.apache.org/master/zh-CN/administrator-guide/operation/monitor-alert.html</a></p>\n</blockquote>\n<p>如果没有安装这个监控，如果你是用的 Palo 0.14.7 版本以上，也可以通过以下命令在命令行查看这个监控数据的趋势图：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\">mysql&gt; </span><span class=\"language-bash\">ADMIN SHOW BACKEND METRIC (<span class=\"string\">&quot;nodes&quot;</span> = <span class=\"string\">&quot;30746894&quot;</span>, <span class=\"string\">&quot;metrics&quot;</span> = <span class=\"string\">&quot;BE_BASE_COMPACTION_SCORE&quot;</span>, <span class=\"string\">&quot;time&quot;</span> = <span class=\"string\">&quot;last 4 hours&quot;</span>);</span></span><br><span class=\"line\"><span class=\"meta prompt_\">mysql&gt; </span><span class=\"language-bash\">ADMIN SHOW BACKEND METRIC (<span class=\"string\">&quot;nodes&quot;</span> = <span class=\"string\">&quot;30746894&quot;</span>, <span class=\"string\">&quot;metrics&quot;</span> = <span class=\"string\">&quot;BE_CUMU_COMPACTION_SCORE&quot;</span>, <span class=\"string\">&quot;time&quot;</span> = <span class=\"string\">&quot;last 4 hours&quot;</span>);</span></span><br></pre></td></tr></table></figure>\n\n<p>注意这里有两个指标，分别表示 Base Compaction 和 Cumulative Compaction 所对应的版本数量。<strong>在大部分情况下，我们只需要查看 Cumulative Compaction 的指标，即可大致了解集群的数据版本堆积情况。</strong></p>\n<p><strong>版本是否堆积没有一个明确的界限，而是根据使用场景和查询延迟进行判断的一个经验值。</strong>我们可以按照以下步骤进行简单的推断：</p>\n<blockquote>\n<ol>\n<li><p>观察数据版本数量的趋势，如果趋势平稳，则说明 Compaction 和导入速度基本持平。如果呈上升态势，则说明 Compaction 速度跟不上导入速度了。如果呈下降态势，说明 Compaction 速度超过了导入速度。<strong>如果呈上升态势，或在平稳状态但数值较高，则需要考虑调整 Compaction 参数以加快 Compaction 的进度。</strong></p>\n</li>\n<li><p><strong>通常版本数量维持在 100 以内可以视为正常。而在大部分批量导入或低频导入场景下，版本数量通常为10-20甚至更低。</strong></p>\n</li>\n</ol>\n</blockquote>\n<h3 id=\"查看Compaction资源占用\"><a href=\"#查看Compaction资源占用\" class=\"headerlink\" title=\"查看Compaction资源占用\"></a>查看Compaction资源占用</h3><p>Compaction 资源占用主要是 IO 和 内存。</p>\n<p>对于 Compaction 占用的内存，可以在浏览器打开以下链接：<a href=\"http://be_host:webserver_port/mem_tracker在搜索框中输入\">http://be_host:webserver_port/mem_tracker在搜索框中输入</a> AutoCompaction：</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1662265200095-5cf34b92-10de-4d1f-80c3-4dfcc0fd49fd.png\" alt=\"img\"></p>\n<p>则可以查看当前Compaction的内存开销和历史峰值开销。</p>\n<p>而对于 IO 操作，目前还没有提供单独的 Compaction 操作的 IO 监控，我们只能根据集群整体的 IO 利用率情况来做判断。我们可以查看监控图 Disk IO util：</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/eGOhXuI8cBaCgNjQSRHmVYlEkMEIH7OGlBmYBlAkJLj3MjeJTTiauBiaYFeia8zf5s2fvImSlPwthGKZSO8oeFzNg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1\" alt=\"图片\"></p>\n<p>或者通过命令在命令行查看（Palo 0.14.7 以上版本）：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\">mysql&gt; </span><span class=\"language-bash\">ADMIN SHOW BACKEND METRIC (<span class=\"string\">&quot;nodes&quot;</span> = <span class=\"string\">&quot;30746894&quot;</span>, <span class=\"string\">&quot;metrics&quot;</span> = <span class=\"string\">&quot;BE_DISK_IO&quot;</span>, <span class=\"string\">&quot;time&quot;</span> = <span class=\"string\">&quot;last 4 hours&quot;</span>);</span></span><br></pre></td></tr></table></figure>\n\n<p>这个监控展示的是每个 BE 节点上磁盘的 IO util 指标。数值越高表示IO越繁忙。<strong>当然大部分情况下 IO 资源都是查询请求消耗的，这个监控主要用于指导我们是否需要增加或减少 Compaction 任务数。</strong></p>\n<h2 id=\"Compaction-调优策略\"><a href=\"#Compaction-调优策略\" class=\"headerlink\" title=\"Compaction 调优策略\"></a>Compaction 调优策略</h2><p>如果版本数量有上升趋势或者数值较高，则可以从以下两方面优化 Compaction：</p>\n<ol>\n<li><p>修改 Compaction 线程数，使得同时能够执行更多的 Compaction 任务。</p>\n</li>\n<li><p>优化单个 Compaction 的执行逻辑，使数据版本数量维持在一个合理范围。</p>\n</li>\n</ol>\n<h3 id=\"优化前的准备工作\"><a href=\"#优化前的准备工作\" class=\"headerlink\" title=\"优化前的准备工作\"></a>优化前的准备工作</h3><p>在优化 Compaction 执行逻辑之前，我们需要使用一些命令来进一步查看一些Compaction的细节信息。</p>\n<p>首先，我们通过监控图找到一个版本数量最高的 BE 节点。然后执行以下命令分析日志：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\">$</span><span class=\"language-bash\">&gt; grep <span class=\"string\">&quot;succeed to do base&quot;</span> <span class=\"built_in\">log</span>/be.INFO.log.20210505-142010 |<span class=\"built_in\">tail</span> -n 100</span></span><br><span class=\"line\"><span class=\"meta prompt_\">$</span><span class=\"language-bash\">&gt; grep <span class=\"string\">&quot;succeed to do cumu&quot;</span> <span class=\"built_in\">log</span>/be.INFO.log.20210505-142010 |<span class=\"built_in\">tail</span> -n 100</span></span><br></pre></td></tr></table></figure>\n\n<p>以上两个命令可以查看最近100个执行完成的 compaction 任务：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">I0505 17:06:56.143455   675 compaction.cpp:135] succeed to do cumulative compaction. tablet=106827682.505347040.d040c1cdf71e5c95-3a002a06127ccd86, output_version=2-2631, current_max_version=2633, disk=/home/disk6/palo.HDD, segments=57. elapsed time=2.29371s. cumulative_compaction_policy=SIZE_BASED.</span><br><span class=\"line\">I0505 17:06:56.520058   666 compaction.cpp:135] succeed to do cumulative compaction. tablet=106822189.1661856168.654562832a620ea6-46fe84c73ea84795, output_version=2-3247, current_max_version=3250, disk=/home/disk2/palo.HDD, segments=22. elapsed time=2.66858s. cumulative_compaction_policy=SIZE_BASED.</span><br></pre></td></tr></table></figure>\n\n<p>通过日志时间可以判断 Compaction 是否在持续正确的执行，通过 elapsed time 可以观察每个任务的执行时间。</p>\n<p>我们还可以执行以下命令展示最近100个 compaction 任务的配额（permits）：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\">$</span><span class=\"language-bash\">&gt; grep <span class=\"string\">&quot;permits&quot;</span> <span class=\"built_in\">log</span>/be.INFO |<span class=\"built_in\">tail</span> -n 100</span></span><br><span class=\"line\"></span><br><span class=\"line\">I0505 17:04:07.120920   667 compaction.cpp:83] start cumulative compaction. tablet=106827970.777011641.9c474de1b8ba9199-4addeb135d6834ac, output_version=2-2623, permits: 39</span><br><span class=\"line\">I0505 17:04:13.898777   672 compaction.cpp:83] start cumulative compaction. tablet=106822777.1948936074.a44ac9462e79b76d-4a33ee39559bb0bf, output_version=2-3238, permits: 22</span><br></pre></td></tr></table></figure>\n\n<p>配额和版本数量成正比。</p>\n<p>我们可以找到 permits 较大的一个任务对应的 tablet id，如上图permit 为 39 的任务的 tablet id 为 106827970，然后继续分析这个 tablet 的 compaction 情况。</p>\n<p>通过 MySQL 客户端连接 Doris 集群后，执行：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\">mysql&gt; </span><span class=\"language-bash\">show tablet 106827970;</span></span><br><span class=\"line\">+--------------------------+-----------+---------------+-----------+---------+----------+-------------+----------+--------+----------------------------------------------------------------------------+</span><br><span class=\"line\">| DbName                   | TableName | PartitionName | IndexName | DbId    | TableId  | PartitionId | IndexId  | IsSync | DetailCmd                                                                  |</span><br><span class=\"line\">+--------------------------+-----------+---------------+-----------+---------+----------+-------------+----------+--------+----------------------------------------------------------------------------+</span><br><span class=\"line\">| default_cluster:test     | tbl1      | p20210505     | tbl1      | 3828954 | 63708800 | 106826829   | 63709761 | true   | SHOW PROC &#x27;/dbs/3828954/63708800/partitions/106826829/63709761/106827970&#x27;; |</span><br><span class=\"line\">+--------------------------+-----------+---------------+-----------+---------+----------+-------------+----------+--------+----------------------------------------------------------------------------+</span><br></pre></td></tr></table></figure>\n\n<p>然后执行后面的 SHOW PROC 语句，我们可以获得这个 tablet 所有副本的详细信息。其中 VersionCount 列表示对应副本的数据版本数量。我们可以选取一个 VersionCount 较大的副本，在浏览器打开 CompactionStatus 列显示的 URL，得到如下Json结果：</p>\n<figure class=\"highlight json\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">    <span class=\"attr\">&quot;cumulative policy type&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;SIZE_BASED&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">    <span class=\"attr\">&quot;cumulative point&quot;</span><span class=\"punctuation\">:</span> <span class=\"number\">18438</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">    <span class=\"attr\">&quot;last cumulative failure time&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;1970-01-01 08:00:00.000&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">    <span class=\"attr\">&quot;last base failure time&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;1970-01-01 08:00:00.000&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">    <span class=\"attr\">&quot;last cumulative success time&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;2021-05-05 17:18:48.904&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">    <span class=\"attr\">&quot;last base success time&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;2021-05-05 16:14:49.786&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">    <span class=\"attr\">&quot;rowsets&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">[</span></span><br><span class=\"line\">        <span class=\"string\">&quot;[0-17444] 13 DATA NONOVERLAPPING 0200000000b1fb8d344f83103113563dd81740036795499d 2.86 GB&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">        <span class=\"string\">&quot;[17445-17751] 1 DATA NONOVERLAPPING 0200000000b25183344f83103113563dd81740036795499d 68.61 MB&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">        <span class=\"string\">&quot;[17752-18089] 1 DATA NONOVERLAPPING 0200000000b2b9a2344f83103113563dd81740036795499d 74.52 MB&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">        <span class=\"string\">&quot;[18090-18437] 1 DATA NONOVERLAPPING 0200000000b32686344f83103113563dd81740036795499d 76.41 MB&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">        <span class=\"string\">&quot;[18438-18678] 1 DATA NONOVERLAPPING 0200000000b37084344f83103113563dd81740036795499d 53.07 MB&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">        <span class=\"string\">&quot;[18679-18679] 1 DATA NONOVERLAPPING 0200000000b36d87344f83103113563dd81740036795499d 3.11 KB&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">        <span class=\"string\">&quot;[18680-18680] 1 DATA NONOVERLAPPING 0200000000b36d70344f83103113563dd81740036795499d 258.40 KB&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">        <span class=\"string\">&quot;[18681-18681] 1 DATA NONOVERLAPPING 0200000000b36da0344f83103113563dd81740036795499d 266.98 KB&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">    <span class=\"punctuation\">]</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">    <span class=\"attr\">&quot;stale_rowsets&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">[</span></span><br><span class=\"line\">    <span class=\"punctuation\">]</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">    <span class=\"attr\">&quot;stale version path&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">[</span></span><br><span class=\"line\">    <span class=\"punctuation\">]</span></span><br><span class=\"line\"><span class=\"punctuation\">&#125;</span></span><br></pre></td></tr></table></figure>\n\n<p>这里我们可以看到一个 tablet 的 Cumulative Point，最近一次成功、失败的 BC&#x2F;CC 任务时间，以及每个 rowset 的版本信息。如上面这个示例，我们可以得出以下结论：</p>\n<blockquote>\n<ol>\n<li><p>基线数据量大约在2-3GB，增量rowset增长到几十MB后就会晋升到BC任务区。</p>\n</li>\n<li><p>新增rowset数据量很小，且版本增长较快，说明这是一个高频小批量的导入场景。</p>\n</li>\n</ol>\n</blockquote>\n<p>我们还可以进一步的通过以下命令分析指定 tablet id 的日志</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">查看 tablet 48062815 最近十个任务的配额情况</span></span><br><span class=\"line\"><span class=\"meta prompt_\">$</span><span class=\"language-bash\">&gt; grep permits <span class=\"built_in\">log</span>/be.INFO |grep 48062815 |<span class=\"built_in\">tail</span> -n 10</span></span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">查看 tablet 48062815 最近十个执行完成的 compaction 任务</span></span><br><span class=\"line\"><span class=\"meta prompt_\">$</span><span class=\"language-bash\">&gt; grep <span class=\"string\">&quot;succeed to do&quot;</span> <span class=\"built_in\">log</span>/be.INFO |grep 48062815 |<span class=\"built_in\">tail</span> -n 10</span></span><br></pre></td></tr></table></figure>\n\n<p>另外，我们还可以在浏览器打开以下 URL，查看一个 BE 节点当前正在执行的 compaction 任务：be_host:webserver_port&#x2F;api&#x2F;compaction&#x2F;run_status</p>\n<figure class=\"highlight json\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">    <span class=\"attr\">&quot;CumulativeCompaction&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;/home/disk2/palo&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">[</span><span class=\"punctuation\">]</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;/home/disk1/palo&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">[</span></span><br><span class=\"line\">            <span class=\"string\">&quot;48061239&quot;</span></span><br><span class=\"line\">        <span class=\"punctuation\">]</span></span><br><span class=\"line\">    <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">    <span class=\"attr\">&quot;BaseCompaction&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;/home/disk2/palo&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">[</span><span class=\"punctuation\">]</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;/home/disk1/palo&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">[</span></span><br><span class=\"line\">            <span class=\"string\">&quot;48062815&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"string\">&quot;48061276&quot;</span></span><br><span class=\"line\">        <span class=\"punctuation\">]</span></span><br><span class=\"line\">    <span class=\"punctuation\">&#125;</span></span><br><span class=\"line\"><span class=\"punctuation\">&#125;</span></span><br></pre></td></tr></table></figure>\n\n<p>这个接口可以看到每个磁盘上当前正在执行的 compaction 任务。</p>\n<p>通过以上一系列的分析，我们应该可以对系统的 Compaction 情况有以下判断：</p>\n<blockquote>\n<ol>\n<li><p>Compaction 任务的执行频率、每个任务大致的执行耗时。</p>\n</li>\n<li><p>指定节点数据版本数量的变化情况。</p>\n</li>\n<li><p>指定 tablet 数据版本的变化情况，以及 compaction 的频率。</p>\n</li>\n</ol>\n</blockquote>\n<p>这些结论将指导我们对 Compaction 进行调优。</p>\n<h3 id=\"修改-Compaction-线程数\"><a href=\"#修改-Compaction-线程数\" class=\"headerlink\" title=\"修改 Compaction 线程数\"></a>修改 Compaction 线程数</h3><p><strong>增加 Compaction 线程数是一个非常直接的加速 Compaction 的方法。</strong>但是更多的任务意味着更大的 IO 和 内存开销。尤其在机械磁盘上，因为随机读写问题，有时可能单线程串行执行的效率会高于多线程并行执行。Doris 默认配置为每块盘两个 Compaction 任务（这也是最小的合法配置），最多 10 个任务。如果磁盘数量多于 5，在内存允许的情况下，可以修改 max_compaction_threads 参数增加总任务数，以保证每块盘可以执行两个 Compaction 任务。</p>\n<p>对于机械磁盘，不建议增加每块盘的任务数。对于固态硬盘，可以考虑修改 compaction_task_num_per_disk 参数适当增加每块盘的任务数，如修改为 4。<strong>注意修改这个参数的同时可能还需同步修改 max_compaction_threads，使得 max_compaction_threads 大于等于 compaction_task_num_per_disk * 磁盘数量。</strong></p>\n<h3 id=\"优化单个-Compaction-任务逻辑\"><a href=\"#优化单个-Compaction-任务逻辑\" class=\"headerlink\" title=\"优化单个 Compaction 任务逻辑\"></a>优化单个 Compaction 任务逻辑</h3><p>这个优化方式比较复杂，我们尝试从几个场景出发来说明：</p>\n<h4 id=\"场景一：基线数据量大，Base-Compaction-任务执行时间长。\"><a href=\"#场景一：基线数据量大，Base-Compaction-任务执行时间长。\" class=\"headerlink\" title=\"场景一：基线数据量大，Base Compaction 任务执行时间长。\"></a><strong>场景一：基线数据量大，Base Compaction 任务执行时间长。</strong></h4><p>BC 任务执行时间长，意味着一个任务会长时间占用 Compaction 工作线程，从而导致其他 tablet 的 compaction 任务时间被挤占。如果是因为 0 号版本的基线数据量较大导致，则我们可以考虑尽量推迟增量rowset 晋升到 BC 任务区的时间。以下两个参数将影响这个逻辑：</p>\n<blockquote>\n<p>cumulative_size_based_promotion_ratio：默认 0.05，基线数据量乘以这个系数，即晋升阈值。可以调大这个系数来提高晋升阈值。</p>\n<p>cumulative_size_based_promotion_size_mbytes：默认 1024MB。如果增量rowset的数据量大于这个值，则会忽略第一个参数的阈值直接晋升。因此需要同时调整这个参数来提升晋升阈值。</p>\n</blockquote>\n<p>当然，提升晋升阈值，会导致单个 BC 任务需要处理更大的数据量，耗时更长，但是总体的数据量会减少。举个例子。基线数据大小为 1024GB，假设晋升阈值分别为 100MB 和 200MB。数据导入速度为 100MB&#x2F;分钟。每5个版本执行一次 BC。那么理论上在10分钟内，阈值为 100MB 时，BC 任务处理的总数据量为 （1024 + 100 * 5）* 2 &#x3D; 3048MB。阈值为 200MB 是，BC 任务处理的总数据量为 (1024 + 200 * 5) &#x3D; 2024 MB。</p>\n<h4 id=\"场景二：增量数据版本数量增长较快，Cumulative-Compaction-处理过多版本，耗时较长。\"><a href=\"#场景二：增量数据版本数量增长较快，Cumulative-Compaction-处理过多版本，耗时较长。\" class=\"headerlink\" title=\"场景二：增量数据版本数量增长较快，Cumulative Compaction 处理过多版本，耗时较长。\"></a><strong>场景二：增量数据版本数量增长较快，Cumulative Compaction 处理过多版本，耗时较长。</strong></h4><p>max_cumulative_compaction_num_singleton_deltas 参数控制一个 CC 任务最多合并多少个数据版本，默认值为 1000。我们考虑这样一种场景：针对某一个 tablet，其数据版本的增长速度为 1个&#x2F;秒。而其 CC 任务的执行时间 + 调度时间是 1000秒（即单个 CC 任务的执行时间加上Compaction再一次调度到这个 tablet 的时间总和）。那么我们可能会看到这个 tablet 的版本数量在 1-1000之间浮动（这里我们忽略基线版本数量）。因为在下一次 CC 任务执行前的 1000 秒内，又会累积 1000 个版本。</p>\n<p>这种情况可能导致这个 tablet 的读取效率很不稳定。这时我们可以尝试调小 max_cumulative_compaction_num_singleton_deltas 这个参数，这样一个 CC 所要合并的版本数更少，执行时间更短，执行频率会更高。还是刚才这个场景，假设参数调整到500，而对应的 CC 任务的执行时间 + 调度时间也降低到 500，则理论上这个 tablet 的版本数量将会在 1-500 之间浮动，相比于之前，版本数量更稳定。</p>\n<p>当然这个只是理论数值，实际情况还要考虑任务的具体执行时间、调度情况等等。</p>\n<h2 id=\"手动-Compaction\"><a href=\"#手动-Compaction\" class=\"headerlink\" title=\"手动 Compaction\"></a>手动 Compaction</h2><p>某些情况下，自动 Compaction 策略可能无法选取到某些 tablet，这时我们可能需要通过 Compaction 接口来主动触发指定 tablet 的 Compaction。我们以 curl 命令举例：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">curl -X POST http://192.168.1.1:8040/api/compaction/run?tablet_id=106818600\\&amp;schema_hash=6979334\\&amp;compact_type=cumulative</span><br></pre></td></tr></table></figure>\n\n<p>这里我们指定 id 为 106818600，schema hash 为 6979334 的 tablet 进行 Cumulative Compaction（compact_type参数为 base 则触发 Base Compaction）。其中 schema hash 可以通过 SHOW TABLET tablet_id 命令得到的 SHOW PROC 命令获取。<br>如果提交成功，则会返回：</p>\n<figure class=\"highlight json\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"punctuation\">&#123;</span><span class=\"attr\">&quot;status&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;Success&quot;</span><span class=\"punctuation\">,</span> <span class=\"attr\">&quot;msg&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;compaction task is successfully triggered.&quot;</span><span class=\"punctuation\">&#125;</span></span><br></pre></td></tr></table></figure>\n\n<p>这是一个异步操作，命令只是提交compaction 任务，之后我们可以通过以下 API 来查看任务是否在运行：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">curl -X GET http://192.168.1.1:8040/api/compaction/run_status?tablet_id=106818600\\&amp;schema_hash=6979334</span><br></pre></td></tr></table></figure>\n\n<p>返回结果：</p>\n<figure class=\"highlight json\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">    <span class=\"attr\">&quot;status&quot;</span> <span class=\"punctuation\">:</span> <span class=\"string\">&quot;Success&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">    <span class=\"attr\">&quot;run_status&quot;</span> <span class=\"punctuation\">:</span> <span class=\"keyword\">false</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">    <span class=\"attr\">&quot;msg&quot;</span> <span class=\"punctuation\">:</span> <span class=\"string\">&quot;compaction task for this tablet is running&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">    <span class=\"attr\">&quot;tablet_id&quot;</span> <span class=\"punctuation\">:</span> <span class=\"number\">106818600</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">    <span class=\"attr\">&quot;schema_hash&quot;</span> <span class=\"punctuation\">:</span> <span class=\"number\">6979334</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">    <span class=\"attr\">&quot;compact_type&quot;</span> <span class=\"punctuation\">:</span> <span class=\"string\">&quot;cumulative&quot;</span></span><br><span class=\"line\"><span class=\"punctuation\">&#125;</span></span><br></pre></td></tr></table></figure>\n\n<p>当然也可以直接查看 tablet 的版本情况：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">curl -X GET http://192.168.1.1:8040/api/compaction/show?tablet_id=106818600\\&amp;schema_hash=6979334</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"END\"><a href=\"#END\" class=\"headerlink\" title=\"END\"></a>END</h2><p>Compaction 策略是 Doris 比较复杂的一个数据处理逻辑，需要考虑的状态和情况非常多，因此也在不断完善中，最终希望能够自动的适配各种负载场景，减轻运维压力。</p>\n"},{"title":"Doris性能优化（一）","top_img":"linear-gradient(20deg, #0062be, #925696, #cc426e, #fb0347)","date":"2022-08-21T03:36:49.000Z","updated":"2022-08-21T03:36:49.000Z","cover":"https://tvax3.sinaimg.cn/large/0084aYsLly1grnkfb3zyvj31hc0tndku.jpg","description":null,"keywords":null,"_content":"\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1661053317299-dab15028-4e02-434a-9ba5-46139e3dd653.png)\n\n## 优化的两个基本原则\n\n ![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1661059787313-f1d0fe57-5d60-46f1-ac16-c43dcbced951.png)\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1661059855537-2648b01f-7178-4a29-90df-67abf615a084.png)\n\n## Runtime Filter\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1661059946818-7c38a11c-6224-4a72-9cda-e9ac0b7efc03.png)\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1661059996873-d7ed6ddc-e561-4f6e-a349-5934c237c4d7.png)\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1661060032139-d4765d59-b2e2-4d03-b533-df3607280f9b.png)\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1661060077007-f152de7c-3761-4779-8106-2a81c0c2a90e.png)\n","source":"_posts/bigdata/doris性能优化（一）.md","raw":"---\ntitle: Doris性能优化（一）\ntags:\n  - 'Doris'\ncategories:\n  - [bigdata,Doris]\ntop_img: 'linear-gradient(20deg, #0062be, #925696, #cc426e, #fb0347)'\ndate: 2022-08-21 11:36:49\nupdated: 2022-08-21 11:36:49\ncover:\ndescription:\nkeywords:\n---\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1661053317299-dab15028-4e02-434a-9ba5-46139e3dd653.png)\n\n## 优化的两个基本原则\n\n ![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1661059787313-f1d0fe57-5d60-46f1-ac16-c43dcbced951.png)\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1661059855537-2648b01f-7178-4a29-90df-67abf615a084.png)\n\n## Runtime Filter\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1661059946818-7c38a11c-6224-4a72-9cda-e9ac0b7efc03.png)\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1661059996873-d7ed6ddc-e561-4f6e-a349-5934c237c4d7.png)\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1661060032139-d4765d59-b2e2-4d03-b533-df3607280f9b.png)\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1661060077007-f152de7c-3761-4779-8106-2a81c0c2a90e.png)\n","slug":"bigdata/doris性能优化（一）","published":1,"comments":1,"layout":"post","photos":[],"link":"","_id":"cl9y38dsg001hfwuidmlwdi2m","content":"<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1661053317299-dab15028-4e02-434a-9ba5-46139e3dd653.png\" alt=\"img\"></p>\n<h2 id=\"优化的两个基本原则\"><a href=\"#优化的两个基本原则\" class=\"headerlink\" title=\"优化的两个基本原则\"></a>优化的两个基本原则</h2><p> <img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1661059787313-f1d0fe57-5d60-46f1-ac16-c43dcbced951.png\" alt=\"img\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1661059855537-2648b01f-7178-4a29-90df-67abf615a084.png\" alt=\"img\"></p>\n<h2 id=\"Runtime-Filter\"><a href=\"#Runtime-Filter\" class=\"headerlink\" title=\"Runtime Filter\"></a>Runtime Filter</h2><p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1661059946818-7c38a11c-6224-4a72-9cda-e9ac0b7efc03.png\" alt=\"img\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1661059996873-d7ed6ddc-e561-4f6e-a349-5934c237c4d7.png\" alt=\"img\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1661060032139-d4765d59-b2e2-4d03-b533-df3607280f9b.png\" alt=\"img\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1661060077007-f152de7c-3761-4779-8106-2a81c0c2a90e.png\" alt=\"img\"></p>\n","site":{"data":{"link":[{"class_name":"友情链接","class_desc":"那些人，那些事","link_list":[{"name":"张洪Heo","link":"https://blog.zhheo.com/","avatar":"https://npm.elemecdn.com/guli-heo/img/avatar2.png","descr":"分享设计与科技生活"},{"name":"瞬間の筆記","link":"https://hikki.site","descr":"喜欢的东西就努力去追求，万一成功了呢!","avatar":"https://cdn.jsdelivr.net/gh/0000rookie/imgs/202206120315.png"}]}]}},"excerpt":"","more":"<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1661053317299-dab15028-4e02-434a-9ba5-46139e3dd653.png\" alt=\"img\"></p>\n<h2 id=\"优化的两个基本原则\"><a href=\"#优化的两个基本原则\" class=\"headerlink\" title=\"优化的两个基本原则\"></a>优化的两个基本原则</h2><p> <img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1661059787313-f1d0fe57-5d60-46f1-ac16-c43dcbced951.png\" alt=\"img\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1661059855537-2648b01f-7178-4a29-90df-67abf615a084.png\" alt=\"img\"></p>\n<h2 id=\"Runtime-Filter\"><a href=\"#Runtime-Filter\" class=\"headerlink\" title=\"Runtime Filter\"></a>Runtime Filter</h2><p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1661059946818-7c38a11c-6224-4a72-9cda-e9ac0b7efc03.png\" alt=\"img\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1661059996873-d7ed6ddc-e561-4f6e-a349-5934c237c4d7.png\" alt=\"img\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1661060032139-d4765d59-b2e2-4d03-b533-df3607280f9b.png\" alt=\"img\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1661060077007-f152de7c-3761-4779-8106-2a81c0c2a90e.png\" alt=\"img\"></p>\n"},{"title":"Yarn容量调度器和公平调度器的异同","top_img":"linear-gradient(20deg, #0062be, #925696, #cc426e, #fb0347)","date":"2022-07-05T10:20:39.000Z","updated":"2022-07-05T10:20:39.000Z","cover":"https://zfh-tuchuang.oss-cn-shanghai.aliyuncs.com/img/site-backgound.jpg","description":null,"keywords":null,"_content":"\n> 理想情况下，我们应用对Yarn资源的请求应该立刻得到满足，但现实情况资源往往是有限的，特别是在一个很繁忙的集群，一个应用资源的请求经常需要等待一段时间才能的到相应的资源。在Yarn中，负责给应用分配资源的就是Scheduler。其实调度本身就是一个难题，很难找到一个完美的策略可以解决所有的应用场景。为此，Yarn提供了多种调度器和可配置的策略供我们选择。\n>\n> ## Capacity Scheduler(容量调度器)\n>\n> 对于Capacity调度器，有一个专门的队列用来运行小任务，但是为小任务专门设置一个队列会预先占用一定的集群资源，这就导致大任务的执行时间会落后于使用FIFO调度器时的时间。用这个资源调度器，就可以配置yarn资源队列，这个后面后介绍用到。\n>\n> ## Fair Scheduler(公平调度器)\n>\n> **Fair调度器的设计目标是为所有的应用分配公平的资源**（对公平的定义可以通过参数来设置）。当然，公平调度在也可以在多个队列间工作。\n>\n> 举个例子，假设有两个用户A和B，他们分别拥有一个队列。当A启动一个job而B没有任务时，A会获得全部集群资源；当B启动一个job后，A的job会继续运行，不过一会儿之后两个任务会各自获得一半的集群资源。如果此时B再启动第二个job并且其它job还在运行，则它将会和B的第一个job共享B这个队列的资源，也就是B的两个job会用于四分之一的集群资源，而A的job仍然用于集群一半的资源，结果就是资源最终在两个用户之间平等的共享。\n>\n> **在Fair调度器中，我们不需要预先占用一定的系统资源，Fair调度器会为所有运行的job动态的调整系统资源。**当第一个大job提交时，只有这一个job在运行，此时它获得了所有集群资源；当第二个小任务提交后，Fair调度器会分配一半资源给这个小任务，让这两个任务公平的共享集群资源。 \n>\n> a) 公平调度器，就是能够共享整个集群的资源 \n>\n> b) 不用预先占用资源，每一个作业都是共享的 \n>\n> c) 每当提交一个作业的时候，就会占用整个资源。如果再提交一个作业，那么第一个作业就会分给第二个作业一部分资源，第一个作业也就释放一部分资源。再提交其他的作业时，也同理。。。。也就是说每一个作业进来，都有机会获取资源。\n\n# Yarn调度器和调度算法\n\n目前，Hadoop作业调度器主要有三种: FIFO、容量(Capacity Scheduler)和公平(Fair Scheduler)。\n\nApache Hadoop-1.x默认调度器是FIFO；\n\nApache hadoop-2.7.2之后默认调度器是容量调度器Capacity Scheduler\n\nApache hadoop-3.2.2默认调度器是公平调度器Fair Scheduler。\n\nCDH 框架默认调度器是 Fair Scheduler。\n\n## 一、容量调度器(Capacity Scheduler)\n\n### 1. 容量调度器特点\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657019460282-1d05ddc1-06a3-4931-b8ac-96ededf60c3b.png)\n\n1. 多队列 ：每个队列可配置一定的资源量，每个队列内部采用FIFO调度策略；\n2. 容量保证：管理员可为每个队列设置资源最低保证和资源使用上线；\n3. 灵活性：如果一个队列中的资源有剩余，可以暂时共享给那些需要资源的队列，而一旦该队列有新的应用程序提交，则其他队列借调的资源会归还给该队列；\n4. 多租户：\n\na. 支持多用户共享集群和多应用程序同时运行；\n\nb. 为了防止同一个用户的作业独占队列中的资源，该调度器会对同一用户提交的作业所占资源进行限定。\n\n### 2. 容量调度器资源分配算法\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657018164262-f5e7e270-fc4c-41e8-ba92-cac2a508bcdb.png)\n\n## 二、公平调度器(Fair Scheduler)\n\n### 1. 公平调度器特点\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657019558958-d7f020f1-230e-4855-92f8-11c473379a18.png)\n\n### 与容量调度器相同点:\n\n1. 多队列 ：每个队列可配置一定的资源量。\n2. 容量保证：管理员可为每个队列设置资源最低保证和资源使用上线；\n3. 灵活性：如果一个队列中的资源有剩余，可以暂时共享给那些需要资源的队列，而一旦该队列有新的应用程序提交，则其他队列借调的资源会归还给该队列；\n4. 多租户：\n\n1. 1.  支持多用户共享集群和多应用程序同时运行；\n   2.  为了防止同一个用户的作业独占队列中的资源，该调度器会对同一用户提交的作业所占资源进行限定。\n\n### 与容量调度器不同点:\n\n#### 核心调度策略不同\n\n容量调度器： 优先选择资源利用率低的队列；\n\n公平调度器：优先选择对资源缺额比例大的。\n\n#### 每个队列可以单独设置资源分配方式\n\n**容量调度器：FIFO、DRF(内存+CPU)；**\n\n**公平调度器：FIFO、FAIR、DRF。**\n\n#### 队列任务平行度不同\n\n公平调度器：多队列，同一时间队列中多任务按照缺额执行，队列并行度大于队列个数\n\n容量调度器：多队列，同一时间队列中只有一个任务执行，队列中按照先进先出分配任务，队列并行度等于队列个数。\n\n## Fair策略\n\nFair策略是公平调度器默认的队列分配方式\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657018698231-b7ca6c87-74ef-4128-8c05-89fbbab59881.png)\n","source":"_posts/bigdata/yarn公平和容量调度器的异同.md","raw":"---\ntitle: Yarn容量调度器和公平调度器的异同\ntags:\n  - 'yarn'\n  - 'hadoop'\ncategories:\n  - [bigdata,yarn]\ntop_img: 'linear-gradient(20deg, #0062be, #925696, #cc426e, #fb0347)'\ndate: 2022-07-05 18:20:39\nupdated: 2022-07-05 18:20:39\ncover:\ndescription:\nkeywords:\n---\n\n> 理想情况下，我们应用对Yarn资源的请求应该立刻得到满足，但现实情况资源往往是有限的，特别是在一个很繁忙的集群，一个应用资源的请求经常需要等待一段时间才能的到相应的资源。在Yarn中，负责给应用分配资源的就是Scheduler。其实调度本身就是一个难题，很难找到一个完美的策略可以解决所有的应用场景。为此，Yarn提供了多种调度器和可配置的策略供我们选择。\n>\n> ## Capacity Scheduler(容量调度器)\n>\n> 对于Capacity调度器，有一个专门的队列用来运行小任务，但是为小任务专门设置一个队列会预先占用一定的集群资源，这就导致大任务的执行时间会落后于使用FIFO调度器时的时间。用这个资源调度器，就可以配置yarn资源队列，这个后面后介绍用到。\n>\n> ## Fair Scheduler(公平调度器)\n>\n> **Fair调度器的设计目标是为所有的应用分配公平的资源**（对公平的定义可以通过参数来设置）。当然，公平调度在也可以在多个队列间工作。\n>\n> 举个例子，假设有两个用户A和B，他们分别拥有一个队列。当A启动一个job而B没有任务时，A会获得全部集群资源；当B启动一个job后，A的job会继续运行，不过一会儿之后两个任务会各自获得一半的集群资源。如果此时B再启动第二个job并且其它job还在运行，则它将会和B的第一个job共享B这个队列的资源，也就是B的两个job会用于四分之一的集群资源，而A的job仍然用于集群一半的资源，结果就是资源最终在两个用户之间平等的共享。\n>\n> **在Fair调度器中，我们不需要预先占用一定的系统资源，Fair调度器会为所有运行的job动态的调整系统资源。**当第一个大job提交时，只有这一个job在运行，此时它获得了所有集群资源；当第二个小任务提交后，Fair调度器会分配一半资源给这个小任务，让这两个任务公平的共享集群资源。 \n>\n> a) 公平调度器，就是能够共享整个集群的资源 \n>\n> b) 不用预先占用资源，每一个作业都是共享的 \n>\n> c) 每当提交一个作业的时候，就会占用整个资源。如果再提交一个作业，那么第一个作业就会分给第二个作业一部分资源，第一个作业也就释放一部分资源。再提交其他的作业时，也同理。。。。也就是说每一个作业进来，都有机会获取资源。\n\n# Yarn调度器和调度算法\n\n目前，Hadoop作业调度器主要有三种: FIFO、容量(Capacity Scheduler)和公平(Fair Scheduler)。\n\nApache Hadoop-1.x默认调度器是FIFO；\n\nApache hadoop-2.7.2之后默认调度器是容量调度器Capacity Scheduler\n\nApache hadoop-3.2.2默认调度器是公平调度器Fair Scheduler。\n\nCDH 框架默认调度器是 Fair Scheduler。\n\n## 一、容量调度器(Capacity Scheduler)\n\n### 1. 容量调度器特点\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657019460282-1d05ddc1-06a3-4931-b8ac-96ededf60c3b.png)\n\n1. 多队列 ：每个队列可配置一定的资源量，每个队列内部采用FIFO调度策略；\n2. 容量保证：管理员可为每个队列设置资源最低保证和资源使用上线；\n3. 灵活性：如果一个队列中的资源有剩余，可以暂时共享给那些需要资源的队列，而一旦该队列有新的应用程序提交，则其他队列借调的资源会归还给该队列；\n4. 多租户：\n\na. 支持多用户共享集群和多应用程序同时运行；\n\nb. 为了防止同一个用户的作业独占队列中的资源，该调度器会对同一用户提交的作业所占资源进行限定。\n\n### 2. 容量调度器资源分配算法\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657018164262-f5e7e270-fc4c-41e8-ba92-cac2a508bcdb.png)\n\n## 二、公平调度器(Fair Scheduler)\n\n### 1. 公平调度器特点\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657019558958-d7f020f1-230e-4855-92f8-11c473379a18.png)\n\n### 与容量调度器相同点:\n\n1. 多队列 ：每个队列可配置一定的资源量。\n2. 容量保证：管理员可为每个队列设置资源最低保证和资源使用上线；\n3. 灵活性：如果一个队列中的资源有剩余，可以暂时共享给那些需要资源的队列，而一旦该队列有新的应用程序提交，则其他队列借调的资源会归还给该队列；\n4. 多租户：\n\n1. 1.  支持多用户共享集群和多应用程序同时运行；\n   2.  为了防止同一个用户的作业独占队列中的资源，该调度器会对同一用户提交的作业所占资源进行限定。\n\n### 与容量调度器不同点:\n\n#### 核心调度策略不同\n\n容量调度器： 优先选择资源利用率低的队列；\n\n公平调度器：优先选择对资源缺额比例大的。\n\n#### 每个队列可以单独设置资源分配方式\n\n**容量调度器：FIFO、DRF(内存+CPU)；**\n\n**公平调度器：FIFO、FAIR、DRF。**\n\n#### 队列任务平行度不同\n\n公平调度器：多队列，同一时间队列中多任务按照缺额执行，队列并行度大于队列个数\n\n容量调度器：多队列，同一时间队列中只有一个任务执行，队列中按照先进先出分配任务，队列并行度等于队列个数。\n\n## Fair策略\n\nFair策略是公平调度器默认的队列分配方式\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657018698231-b7ca6c87-74ef-4128-8c05-89fbbab59881.png)\n","slug":"bigdata/yarn公平和容量调度器的异同","published":1,"comments":1,"layout":"post","photos":[],"link":"","_id":"cl9y38dsh001lfwuidu7cd6fs","content":"<blockquote>\n<p>理想情况下，我们应用对Yarn资源的请求应该立刻得到满足，但现实情况资源往往是有限的，特别是在一个很繁忙的集群，一个应用资源的请求经常需要等待一段时间才能的到相应的资源。在Yarn中，负责给应用分配资源的就是Scheduler。其实调度本身就是一个难题，很难找到一个完美的策略可以解决所有的应用场景。为此，Yarn提供了多种调度器和可配置的策略供我们选择。</p>\n<h2 id=\"Capacity-Scheduler-容量调度器\"><a href=\"#Capacity-Scheduler-容量调度器\" class=\"headerlink\" title=\"Capacity Scheduler(容量调度器)\"></a>Capacity Scheduler(容量调度器)</h2><p>对于Capacity调度器，有一个专门的队列用来运行小任务，但是为小任务专门设置一个队列会预先占用一定的集群资源，这就导致大任务的执行时间会落后于使用FIFO调度器时的时间。用这个资源调度器，就可以配置yarn资源队列，这个后面后介绍用到。</p>\n<h2 id=\"Fair-Scheduler-公平调度器\"><a href=\"#Fair-Scheduler-公平调度器\" class=\"headerlink\" title=\"Fair Scheduler(公平调度器)\"></a>Fair Scheduler(公平调度器)</h2><p><strong>Fair调度器的设计目标是为所有的应用分配公平的资源</strong>（对公平的定义可以通过参数来设置）。当然，公平调度在也可以在多个队列间工作。</p>\n<p>举个例子，假设有两个用户A和B，他们分别拥有一个队列。当A启动一个job而B没有任务时，A会获得全部集群资源；当B启动一个job后，A的job会继续运行，不过一会儿之后两个任务会各自获得一半的集群资源。如果此时B再启动第二个job并且其它job还在运行，则它将会和B的第一个job共享B这个队列的资源，也就是B的两个job会用于四分之一的集群资源，而A的job仍然用于集群一半的资源，结果就是资源最终在两个用户之间平等的共享。</p>\n<p><strong>在Fair调度器中，我们不需要预先占用一定的系统资源，Fair调度器会为所有运行的job动态的调整系统资源。</strong>当第一个大job提交时，只有这一个job在运行，此时它获得了所有集群资源；当第二个小任务提交后，Fair调度器会分配一半资源给这个小任务，让这两个任务公平的共享集群资源。 </p>\n<p>a) 公平调度器，就是能够共享整个集群的资源 </p>\n<p>b) 不用预先占用资源，每一个作业都是共享的 </p>\n<p>c) 每当提交一个作业的时候，就会占用整个资源。如果再提交一个作业，那么第一个作业就会分给第二个作业一部分资源，第一个作业也就释放一部分资源。再提交其他的作业时，也同理。。。。也就是说每一个作业进来，都有机会获取资源。</p>\n</blockquote>\n<h1 id=\"Yarn调度器和调度算法\"><a href=\"#Yarn调度器和调度算法\" class=\"headerlink\" title=\"Yarn调度器和调度算法\"></a>Yarn调度器和调度算法</h1><p>目前，Hadoop作业调度器主要有三种: FIFO、容量(Capacity Scheduler)和公平(Fair Scheduler)。</p>\n<p>Apache Hadoop-1.x默认调度器是FIFO；</p>\n<p>Apache hadoop-2.7.2之后默认调度器是容量调度器Capacity Scheduler</p>\n<p>Apache hadoop-3.2.2默认调度器是公平调度器Fair Scheduler。</p>\n<p>CDH 框架默认调度器是 Fair Scheduler。</p>\n<h2 id=\"一、容量调度器-Capacity-Scheduler\"><a href=\"#一、容量调度器-Capacity-Scheduler\" class=\"headerlink\" title=\"一、容量调度器(Capacity Scheduler)\"></a>一、容量调度器(Capacity Scheduler)</h2><h3 id=\"1-容量调度器特点\"><a href=\"#1-容量调度器特点\" class=\"headerlink\" title=\"1. 容量调度器特点\"></a>1. 容量调度器特点</h3><p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657019460282-1d05ddc1-06a3-4931-b8ac-96ededf60c3b.png\" alt=\"img\"></p>\n<ol>\n<li>多队列 ：每个队列可配置一定的资源量，每个队列内部采用FIFO调度策略；</li>\n<li>容量保证：管理员可为每个队列设置资源最低保证和资源使用上线；</li>\n<li>灵活性：如果一个队列中的资源有剩余，可以暂时共享给那些需要资源的队列，而一旦该队列有新的应用程序提交，则其他队列借调的资源会归还给该队列；</li>\n<li>多租户：</li>\n</ol>\n<p>a. 支持多用户共享集群和多应用程序同时运行；</p>\n<p>b. 为了防止同一个用户的作业独占队列中的资源，该调度器会对同一用户提交的作业所占资源进行限定。</p>\n<h3 id=\"2-容量调度器资源分配算法\"><a href=\"#2-容量调度器资源分配算法\" class=\"headerlink\" title=\"2. 容量调度器资源分配算法\"></a>2. 容量调度器资源分配算法</h3><p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657018164262-f5e7e270-fc4c-41e8-ba92-cac2a508bcdb.png\" alt=\"img\"></p>\n<h2 id=\"二、公平调度器-Fair-Scheduler\"><a href=\"#二、公平调度器-Fair-Scheduler\" class=\"headerlink\" title=\"二、公平调度器(Fair Scheduler)\"></a>二、公平调度器(Fair Scheduler)</h2><h3 id=\"1-公平调度器特点\"><a href=\"#1-公平调度器特点\" class=\"headerlink\" title=\"1. 公平调度器特点\"></a>1. 公平调度器特点</h3><p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657019558958-d7f020f1-230e-4855-92f8-11c473379a18.png\" alt=\"img\"></p>\n<h3 id=\"与容量调度器相同点\"><a href=\"#与容量调度器相同点\" class=\"headerlink\" title=\"与容量调度器相同点:\"></a>与容量调度器相同点:</h3><ol>\n<li><p>多队列 ：每个队列可配置一定的资源量。</p>\n</li>\n<li><p>容量保证：管理员可为每个队列设置资源最低保证和资源使用上线；</p>\n</li>\n<li><p>灵活性：如果一个队列中的资源有剩余，可以暂时共享给那些需要资源的队列，而一旦该队列有新的应用程序提交，则其他队列借调的资源会归还给该队列；</p>\n</li>\n<li><p>多租户：</p>\n</li>\n<li><ol>\n<li>支持多用户共享集群和多应用程序同时运行；</li>\n<li>为了防止同一个用户的作业独占队列中的资源，该调度器会对同一用户提交的作业所占资源进行限定。</li>\n</ol>\n</li>\n</ol>\n<h3 id=\"与容量调度器不同点\"><a href=\"#与容量调度器不同点\" class=\"headerlink\" title=\"与容量调度器不同点:\"></a>与容量调度器不同点:</h3><h4 id=\"核心调度策略不同\"><a href=\"#核心调度策略不同\" class=\"headerlink\" title=\"核心调度策略不同\"></a>核心调度策略不同</h4><p>容量调度器： 优先选择资源利用率低的队列；</p>\n<p>公平调度器：优先选择对资源缺额比例大的。</p>\n<h4 id=\"每个队列可以单独设置资源分配方式\"><a href=\"#每个队列可以单独设置资源分配方式\" class=\"headerlink\" title=\"每个队列可以单独设置资源分配方式\"></a>每个队列可以单独设置资源分配方式</h4><p><strong>容量调度器：FIFO、DRF(内存+CPU)；</strong></p>\n<p><strong>公平调度器：FIFO、FAIR、DRF。</strong></p>\n<h4 id=\"队列任务平行度不同\"><a href=\"#队列任务平行度不同\" class=\"headerlink\" title=\"队列任务平行度不同\"></a>队列任务平行度不同</h4><p>公平调度器：多队列，同一时间队列中多任务按照缺额执行，队列并行度大于队列个数</p>\n<p>容量调度器：多队列，同一时间队列中只有一个任务执行，队列中按照先进先出分配任务，队列并行度等于队列个数。</p>\n<h2 id=\"Fair策略\"><a href=\"#Fair策略\" class=\"headerlink\" title=\"Fair策略\"></a>Fair策略</h2><p>Fair策略是公平调度器默认的队列分配方式</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657018698231-b7ca6c87-74ef-4128-8c05-89fbbab59881.png\" alt=\"img\"></p>\n","site":{"data":{"link":[{"class_name":"友情链接","class_desc":"那些人，那些事","link_list":[{"name":"张洪Heo","link":"https://blog.zhheo.com/","avatar":"https://npm.elemecdn.com/guli-heo/img/avatar2.png","descr":"分享设计与科技生活"},{"name":"瞬間の筆記","link":"https://hikki.site","descr":"喜欢的东西就努力去追求，万一成功了呢!","avatar":"https://cdn.jsdelivr.net/gh/0000rookie/imgs/202206120315.png"}]}]}},"excerpt":"","more":"<blockquote>\n<p>理想情况下，我们应用对Yarn资源的请求应该立刻得到满足，但现实情况资源往往是有限的，特别是在一个很繁忙的集群，一个应用资源的请求经常需要等待一段时间才能的到相应的资源。在Yarn中，负责给应用分配资源的就是Scheduler。其实调度本身就是一个难题，很难找到一个完美的策略可以解决所有的应用场景。为此，Yarn提供了多种调度器和可配置的策略供我们选择。</p>\n<h2 id=\"Capacity-Scheduler-容量调度器\"><a href=\"#Capacity-Scheduler-容量调度器\" class=\"headerlink\" title=\"Capacity Scheduler(容量调度器)\"></a>Capacity Scheduler(容量调度器)</h2><p>对于Capacity调度器，有一个专门的队列用来运行小任务，但是为小任务专门设置一个队列会预先占用一定的集群资源，这就导致大任务的执行时间会落后于使用FIFO调度器时的时间。用这个资源调度器，就可以配置yarn资源队列，这个后面后介绍用到。</p>\n<h2 id=\"Fair-Scheduler-公平调度器\"><a href=\"#Fair-Scheduler-公平调度器\" class=\"headerlink\" title=\"Fair Scheduler(公平调度器)\"></a>Fair Scheduler(公平调度器)</h2><p><strong>Fair调度器的设计目标是为所有的应用分配公平的资源</strong>（对公平的定义可以通过参数来设置）。当然，公平调度在也可以在多个队列间工作。</p>\n<p>举个例子，假设有两个用户A和B，他们分别拥有一个队列。当A启动一个job而B没有任务时，A会获得全部集群资源；当B启动一个job后，A的job会继续运行，不过一会儿之后两个任务会各自获得一半的集群资源。如果此时B再启动第二个job并且其它job还在运行，则它将会和B的第一个job共享B这个队列的资源，也就是B的两个job会用于四分之一的集群资源，而A的job仍然用于集群一半的资源，结果就是资源最终在两个用户之间平等的共享。</p>\n<p><strong>在Fair调度器中，我们不需要预先占用一定的系统资源，Fair调度器会为所有运行的job动态的调整系统资源。</strong>当第一个大job提交时，只有这一个job在运行，此时它获得了所有集群资源；当第二个小任务提交后，Fair调度器会分配一半资源给这个小任务，让这两个任务公平的共享集群资源。 </p>\n<p>a) 公平调度器，就是能够共享整个集群的资源 </p>\n<p>b) 不用预先占用资源，每一个作业都是共享的 </p>\n<p>c) 每当提交一个作业的时候，就会占用整个资源。如果再提交一个作业，那么第一个作业就会分给第二个作业一部分资源，第一个作业也就释放一部分资源。再提交其他的作业时，也同理。。。。也就是说每一个作业进来，都有机会获取资源。</p>\n</blockquote>\n<h1 id=\"Yarn调度器和调度算法\"><a href=\"#Yarn调度器和调度算法\" class=\"headerlink\" title=\"Yarn调度器和调度算法\"></a>Yarn调度器和调度算法</h1><p>目前，Hadoop作业调度器主要有三种: FIFO、容量(Capacity Scheduler)和公平(Fair Scheduler)。</p>\n<p>Apache Hadoop-1.x默认调度器是FIFO；</p>\n<p>Apache hadoop-2.7.2之后默认调度器是容量调度器Capacity Scheduler</p>\n<p>Apache hadoop-3.2.2默认调度器是公平调度器Fair Scheduler。</p>\n<p>CDH 框架默认调度器是 Fair Scheduler。</p>\n<h2 id=\"一、容量调度器-Capacity-Scheduler\"><a href=\"#一、容量调度器-Capacity-Scheduler\" class=\"headerlink\" title=\"一、容量调度器(Capacity Scheduler)\"></a>一、容量调度器(Capacity Scheduler)</h2><h3 id=\"1-容量调度器特点\"><a href=\"#1-容量调度器特点\" class=\"headerlink\" title=\"1. 容量调度器特点\"></a>1. 容量调度器特点</h3><p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657019460282-1d05ddc1-06a3-4931-b8ac-96ededf60c3b.png\" alt=\"img\"></p>\n<ol>\n<li>多队列 ：每个队列可配置一定的资源量，每个队列内部采用FIFO调度策略；</li>\n<li>容量保证：管理员可为每个队列设置资源最低保证和资源使用上线；</li>\n<li>灵活性：如果一个队列中的资源有剩余，可以暂时共享给那些需要资源的队列，而一旦该队列有新的应用程序提交，则其他队列借调的资源会归还给该队列；</li>\n<li>多租户：</li>\n</ol>\n<p>a. 支持多用户共享集群和多应用程序同时运行；</p>\n<p>b. 为了防止同一个用户的作业独占队列中的资源，该调度器会对同一用户提交的作业所占资源进行限定。</p>\n<h3 id=\"2-容量调度器资源分配算法\"><a href=\"#2-容量调度器资源分配算法\" class=\"headerlink\" title=\"2. 容量调度器资源分配算法\"></a>2. 容量调度器资源分配算法</h3><p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657018164262-f5e7e270-fc4c-41e8-ba92-cac2a508bcdb.png\" alt=\"img\"></p>\n<h2 id=\"二、公平调度器-Fair-Scheduler\"><a href=\"#二、公平调度器-Fair-Scheduler\" class=\"headerlink\" title=\"二、公平调度器(Fair Scheduler)\"></a>二、公平调度器(Fair Scheduler)</h2><h3 id=\"1-公平调度器特点\"><a href=\"#1-公平调度器特点\" class=\"headerlink\" title=\"1. 公平调度器特点\"></a>1. 公平调度器特点</h3><p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657019558958-d7f020f1-230e-4855-92f8-11c473379a18.png\" alt=\"img\"></p>\n<h3 id=\"与容量调度器相同点\"><a href=\"#与容量调度器相同点\" class=\"headerlink\" title=\"与容量调度器相同点:\"></a>与容量调度器相同点:</h3><ol>\n<li><p>多队列 ：每个队列可配置一定的资源量。</p>\n</li>\n<li><p>容量保证：管理员可为每个队列设置资源最低保证和资源使用上线；</p>\n</li>\n<li><p>灵活性：如果一个队列中的资源有剩余，可以暂时共享给那些需要资源的队列，而一旦该队列有新的应用程序提交，则其他队列借调的资源会归还给该队列；</p>\n</li>\n<li><p>多租户：</p>\n</li>\n<li><ol>\n<li>支持多用户共享集群和多应用程序同时运行；</li>\n<li>为了防止同一个用户的作业独占队列中的资源，该调度器会对同一用户提交的作业所占资源进行限定。</li>\n</ol>\n</li>\n</ol>\n<h3 id=\"与容量调度器不同点\"><a href=\"#与容量调度器不同点\" class=\"headerlink\" title=\"与容量调度器不同点:\"></a>与容量调度器不同点:</h3><h4 id=\"核心调度策略不同\"><a href=\"#核心调度策略不同\" class=\"headerlink\" title=\"核心调度策略不同\"></a>核心调度策略不同</h4><p>容量调度器： 优先选择资源利用率低的队列；</p>\n<p>公平调度器：优先选择对资源缺额比例大的。</p>\n<h4 id=\"每个队列可以单独设置资源分配方式\"><a href=\"#每个队列可以单独设置资源分配方式\" class=\"headerlink\" title=\"每个队列可以单独设置资源分配方式\"></a>每个队列可以单独设置资源分配方式</h4><p><strong>容量调度器：FIFO、DRF(内存+CPU)；</strong></p>\n<p><strong>公平调度器：FIFO、FAIR、DRF。</strong></p>\n<h4 id=\"队列任务平行度不同\"><a href=\"#队列任务平行度不同\" class=\"headerlink\" title=\"队列任务平行度不同\"></a>队列任务平行度不同</h4><p>公平调度器：多队列，同一时间队列中多任务按照缺额执行，队列并行度大于队列个数</p>\n<p>容量调度器：多队列，同一时间队列中只有一个任务执行，队列中按照先进先出分配任务，队列并行度等于队列个数。</p>\n<h2 id=\"Fair策略\"><a href=\"#Fair策略\" class=\"headerlink\" title=\"Fair策略\"></a>Fair策略</h2><p>Fair策略是公平调度器默认的队列分配方式</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657018698231-b7ca6c87-74ef-4128-8c05-89fbbab59881.png\" alt=\"img\"></p>\n"},{"title":"一文搞懂Kudu的整体架构","top_img":"linear-gradient(20deg, #0062be, #925696, #cc426e, #fb0347)","date":"2022-07-01T12:31:02.000Z","updated":"2022-07-01T12:31:02.000Z","cover":"https://tvax4.sinaimg.cn/large/0084aYsLgy1h3jum72m7kj31220e6jsc.jpg","description":null,"keywords":null,"_content":"\n\n> Kudu是典型的Master-Slave架构，基于LSM优化写入性能，但同时读性能会低（相较于Parquet）。Kudu基于Raft协议实现了Master和Slave Tablet节点的数据的一致性，以及选举功能，保证了容错性和高可用。\n>\n> Kudu是完全的列式存储引擎，可以针对性的编码和压缩，提高了IO性能。HBase是基于列族的，No Schema的NoSQL、KV数据库，无法进行针对性的编码和压缩，同时一般情况只会用一个列族，其实HBase退化为行存储引擎。\n>\n> Kudu通过WAL和Raft保证了分布式数据的一致性。\n>\n> kudu相对于HBase，牺牲了一定的写入性能--->Kudu在写入数据的时候，需要先检查一遍唯一主键是否存在，如果存在会报错，同样更新数据的时候，同样需要先查找主键是否存在。因此Insert和Update等所有操作比HBase多了，`先读一次`的开销，而HBase所有的操作都是转化为直接写入，因此写的性能相较于HBase有一定的劣势。\n>\n> Kudu牺牲写的性能，但是保证了一个主键，只会存在于一个RowSet中，而HBase的RowKey可能会在多个HFlie中。减少了IO，提升了读性能，特别是在大量写入，少量更新的情况下。\n\n\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1655346605849-a27b0f24-9a73-486d-9797-0009ce3bc3dc.png?x-oss-process=image%2Fresize%2Cw_1080%2Climit_0)\n\n**Table：**具有Schema和全局有序主键的表。一张表有多个Tablet，多个Tablet包含表的全部数据。\n**Tablet：**Kudu的表Table被水平分割为多段，Tablet是Kudu表的一个片段（分区），每个Tablet存储一段连续范围的数据（会记录开始Key和结束Key），且两个Tablet间不会有重复范围的数据。一个Tablet会复制（逻辑复制而非物理复制，副本中的内容不是实际的数据，而是操作该副本上的数据时对应的更改信息）多个副本在多台TServer上，其中一个副本为Leader Tablet，其他则为Follower Tablet。只有Leader Tablet响应写请求，任何Tablet副本可以响应读请求。\n**TabletServer：**简称TServer，负责数据存储Tablet、提供数据读写服务、编码、压缩、合并和复制。一个TServer可以是某些Tablet的Leader，也可以是某些Tablet的Follower，一个Tablet可以被多个TServer服务（多对多关系）。TServer会定期（默认1s）向Master发送心跳。\n**Catalog Table：**目录表，用户不可直接读取或写入，仅由Master维护，存储两类元数据：表元数据（Schema信息，位置和状态）和Tablet元数据（所有TServer的列表、每个TServer包含哪些Tablet副本、Tablet的开始Key和结束Key）。Catalog Table只存储在Master节点，也是以Tablet的形式，数据量不会很大，只有一个分区，随着Master启动而被全量加载到内存。\n**Master：**负责集群管理和元数据管理。具体：跟踪所有Tablets、TServer、Catalog Table和其他相关的元数据。协调客户端做元数据操作，比如创建一个新表，客户端向Master发起请求，Master写入其WAL并得到其他Master同意后将新表的元数据写入Catalog Table，并协调TServer创建Tablet。\n**WAL：**一个仅支持追加写的预写日志，无论Master还是Tablet都有预写日志，任何对表的修改都会在该表对应的WAL中写入条目(entry)，其他副本在数据相对落后时可以通过WAL赶上来。\n**逻辑复制：**Kudu基于Raft协议在集群中对每个Tablet都存储多个副本，副本中的内容不是实际的数据，而是操作该副本上的数据时对应的更改信息。Insert和Update操作会走网络IO，但Delete操作不会，压缩数据也不会走网络。\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1656670281157-814d5745-2416-468f-8c68-44c63244069f.png)\n\n\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1655346605725-aa6706b6-8453-45b7-b084-18a05394f969.png?x-oss-process=image%2Fresize%2Cw_829%2Climit_0)\n\n\n\n如图，Table分为若干Tablet；Tablet包含Metadata和RowSet，RowSet包含一个MemRowSet及若干个DiskRowSet，DiskRowSet中包含一个BloomFile、AdhocIndex、BaseData、DeltaMem及若干个RedoFile和UndoFile（UndoFile一般情况下只有一个）。\n**MemRowSet：**插入新数据及更新已在MemRowSet中的数据，数据结构是B+树，主键在非叶子节点，数据都在叶子节点。MemRowSet写满后会将数据刷到磁盘形成若干个DiskRowSet。每次达到1G或者120s时生成一个DiskRowSet，DiskRowSet按列存储，类似Parquet。\n**DiskRowSet：**DiskRowSets存储文件格式为CFile。DiskRowSet分为BaseData和DeltaFile。这里每个Column被存储在一个相邻的数据区域，这个数据区域被分为多个小的Page，每个Column Page都可以使用一些Encoding以及Compression算法。后台会定期对DiskRowSet做Compaction，以删除没用的数据及合并历史数据，减少查询过程中的IO开销。\n**BaseData：**DiskRowSet刷写完成的数据，CFile，按列存储，主键有序。BaseData不可变，类似Parquet。\n**BloomFile：**根据一个DiskRowSet中的Key生成一个BloomFilter，用于快速模糊定位某个key是否在DiskRowSet中存在。\n**AdhocIndex：**存放主键的索引，用于定位Key在DiskRowSet中的具体哪个偏移位置。\n**DeltaMemStore：**每份DiskRowSet都对应内存中一个DeltaMemStore，负责记录这个DiskRowSet上BaseData发生后续变更的数据，先写到内存中，写满后Flush到磁盘生成RedoFile。DeltaMemStore的组织方式与MemRowSet相同，也维护一个B+树。\n**DeltaFile：**DeltaMemStore到一定大小会存储到磁盘形成DeltaFile，分为UndoFile和RedoFile。\n**RedoFile：**重做文件，记录上一次Flush生成BaseData之后发生变更数据。DeltaMemStore写满之后，也会刷成CFile，不过与BaseData分开存储，名为RedoFile。UndoFile和RedoFile与关系型数据库中的Undo日子和Redo日志类似。\n**UndoFile：**撤销文件，记录上一次Flush生成BaseData之前时间的历史数据，Kudu通过UndoFile可以读到历史某个时间点的数据。UndoFile一般只有一份。默认UndoFile保存15分钟，Kudu可以查询到15分钟内某列的内容，超过15分钟后会过期，该UndoFile被删除。\n\nDeltaFile(主要是RedoFile)会不断增加，产生大量小文件，不Compaction肯定影响性能，所以就有了下面两种合并方式：\n\n- Minor Compaction：多个DeltaFile进行合并生成一个大的DeltaFile。默认是1000个DeltaFile进行合并一次。\n- Major Compaction：RedoFile文件的大小和BaseData的文件的比例为0.1的时候，会将RedoFile合并进入BaseData，Kudu记录所有更新操作并保存为UndoFile。\n  补充一下：合并和重写BaseData是成本很高的，会产生大量IO操作，Kudu不会将全部DeltaFile合并进BaseData。如果只更新几行数据，但要重写BaseData，费力不讨好，所以Kudu会在某个特定列需要大量更新时再把BaseData与DeltaFile合并。未合并的RedoFile会继续保留等待后续合并操作。\n\n**Kudu读流程：**\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1656670543950-cf2edd8b-55d4-4eb2-b224-78d3c1d9aa31.png)\n\n1. Client发送读请求，Master根据主键范围确定到包含所需数据的所有Tablet位置和信息。\n2. Client找到所需Tablet所在TServer，TServer接受读请求。\n3. 如果要读取的数据位于内存，先从内存（MemRowSet，DeltaMemStore）读取数据，根据读取请求包含的时间戳前提交的更新合并成最终数据。\n4. 如果要读取的数据位于磁盘（DiskRowSet，DeltaFile），在DeltaFile的UndoFile、RedoFile中找目标数据相关的改动，根据读取请求包含的时间戳合并成最新数据并返回。\n\n**Kudu写流程：**\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1656670544082-37d8b7e9-de97-46c0-9ded-20ad7ae15c16.png)\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1656670544010-1315c073-bd11-488c-a780-ffbf553002bb.png)\n\n1. Client向Master发起写请求，Master找到对应的Tablet元数据信息，检查请求数据是否符合表结构。\n2. 因为Kudu不允许有主键重复的记录，所以需要判断主键是否已经存在，先查询主键范围，如果不在范围内则准备写MemRowSet。\n3. 如果在主键范围内，先通过主键Key的布隆过滤器快速模糊查找，未命中则准备写MemRowSet。\n4. 如果BloomFilter命中，则查询索引，如果没命中索引则准备写MemRowSet，如果命中了主键索引就报错：主键重复。\n5. 写入MemRowSet前先被提交到一个Tablet的WAL预写日志，并根据Raft一致性算法取得Follower Tablets的同意，然后才会被写入到其中一个Tablet的MemRowSet中。为了在MemRowSet中支持多版本并发控制(MVCC)，对最近插入的行(即尚未刷新到磁盘的新的行)的更新和删除操作将被追加到MemRowSet中的原始行之后以生成重做(REDO)记录的列表。\n6. MemRowSet写满后，Kudu将数据每行相邻的列分为不同的区间，每个列为一个区间，Flush到DiskRowSet。\n\n**Kudu更新流程：**\n\n1. Client发送更新请求，Master获取表的相关信息，表的所有Tablet信息。\n2. Kudu检查是否符合表结构。\n3. 如果需要更新的数据在MemRowSet，B+树找到待更新数据所在叶子节点，然后将更新操作记录在所在行中一个Mutation链表中；Kudu采用了MVCC(多版本并发控制，实现读和写的并行，任何写都是插入)思想，将更改的数据以链表形式追加到叶子节点后面，避免在树上进行更新和删除操作。\n4. 如果需要更新的数据在DiskRowSet，找到其所在的DiskRowSet，前面提到每个DiskRowSet都会在内存中有一个DeltaMemStore，将更新操作记录在DeltaMemStore，达到一定大小才会生成DeltaFile到磁盘。\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1655346605651-12519d77-90d0-4e92-8def-a832ad06c4b5.png)\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1655346609884-6c6502ed-d74e-4796-b91c-875a4792c2e9.png?x-oss-process=image%2Fresize%2Cw_913%2Climit_0)\n\n\n\n","source":"_posts/bigdata/一文搞懂Kudu的整体架构.md","raw":"---\ntitle: 一文搞懂Kudu的整体架构\ntags:\n  - 'kudu'\ncategories:\n  - [bigdata,kudu]\ntop_img: 'linear-gradient(20deg, #0062be, #925696, #cc426e, #fb0347)'\ndate: 2022-07-01 20:31:02\nupdated: 2022-07-01 20:31:02\ncover:\ndescription:\nkeywords:\n---\n\n\n> Kudu是典型的Master-Slave架构，基于LSM优化写入性能，但同时读性能会低（相较于Parquet）。Kudu基于Raft协议实现了Master和Slave Tablet节点的数据的一致性，以及选举功能，保证了容错性和高可用。\n>\n> Kudu是完全的列式存储引擎，可以针对性的编码和压缩，提高了IO性能。HBase是基于列族的，No Schema的NoSQL、KV数据库，无法进行针对性的编码和压缩，同时一般情况只会用一个列族，其实HBase退化为行存储引擎。\n>\n> Kudu通过WAL和Raft保证了分布式数据的一致性。\n>\n> kudu相对于HBase，牺牲了一定的写入性能--->Kudu在写入数据的时候，需要先检查一遍唯一主键是否存在，如果存在会报错，同样更新数据的时候，同样需要先查找主键是否存在。因此Insert和Update等所有操作比HBase多了，`先读一次`的开销，而HBase所有的操作都是转化为直接写入，因此写的性能相较于HBase有一定的劣势。\n>\n> Kudu牺牲写的性能，但是保证了一个主键，只会存在于一个RowSet中，而HBase的RowKey可能会在多个HFlie中。减少了IO，提升了读性能，特别是在大量写入，少量更新的情况下。\n\n\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1655346605849-a27b0f24-9a73-486d-9797-0009ce3bc3dc.png?x-oss-process=image%2Fresize%2Cw_1080%2Climit_0)\n\n**Table：**具有Schema和全局有序主键的表。一张表有多个Tablet，多个Tablet包含表的全部数据。\n**Tablet：**Kudu的表Table被水平分割为多段，Tablet是Kudu表的一个片段（分区），每个Tablet存储一段连续范围的数据（会记录开始Key和结束Key），且两个Tablet间不会有重复范围的数据。一个Tablet会复制（逻辑复制而非物理复制，副本中的内容不是实际的数据，而是操作该副本上的数据时对应的更改信息）多个副本在多台TServer上，其中一个副本为Leader Tablet，其他则为Follower Tablet。只有Leader Tablet响应写请求，任何Tablet副本可以响应读请求。\n**TabletServer：**简称TServer，负责数据存储Tablet、提供数据读写服务、编码、压缩、合并和复制。一个TServer可以是某些Tablet的Leader，也可以是某些Tablet的Follower，一个Tablet可以被多个TServer服务（多对多关系）。TServer会定期（默认1s）向Master发送心跳。\n**Catalog Table：**目录表，用户不可直接读取或写入，仅由Master维护，存储两类元数据：表元数据（Schema信息，位置和状态）和Tablet元数据（所有TServer的列表、每个TServer包含哪些Tablet副本、Tablet的开始Key和结束Key）。Catalog Table只存储在Master节点，也是以Tablet的形式，数据量不会很大，只有一个分区，随着Master启动而被全量加载到内存。\n**Master：**负责集群管理和元数据管理。具体：跟踪所有Tablets、TServer、Catalog Table和其他相关的元数据。协调客户端做元数据操作，比如创建一个新表，客户端向Master发起请求，Master写入其WAL并得到其他Master同意后将新表的元数据写入Catalog Table，并协调TServer创建Tablet。\n**WAL：**一个仅支持追加写的预写日志，无论Master还是Tablet都有预写日志，任何对表的修改都会在该表对应的WAL中写入条目(entry)，其他副本在数据相对落后时可以通过WAL赶上来。\n**逻辑复制：**Kudu基于Raft协议在集群中对每个Tablet都存储多个副本，副本中的内容不是实际的数据，而是操作该副本上的数据时对应的更改信息。Insert和Update操作会走网络IO，但Delete操作不会，压缩数据也不会走网络。\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1656670281157-814d5745-2416-468f-8c68-44c63244069f.png)\n\n\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1655346605725-aa6706b6-8453-45b7-b084-18a05394f969.png?x-oss-process=image%2Fresize%2Cw_829%2Climit_0)\n\n\n\n如图，Table分为若干Tablet；Tablet包含Metadata和RowSet，RowSet包含一个MemRowSet及若干个DiskRowSet，DiskRowSet中包含一个BloomFile、AdhocIndex、BaseData、DeltaMem及若干个RedoFile和UndoFile（UndoFile一般情况下只有一个）。\n**MemRowSet：**插入新数据及更新已在MemRowSet中的数据，数据结构是B+树，主键在非叶子节点，数据都在叶子节点。MemRowSet写满后会将数据刷到磁盘形成若干个DiskRowSet。每次达到1G或者120s时生成一个DiskRowSet，DiskRowSet按列存储，类似Parquet。\n**DiskRowSet：**DiskRowSets存储文件格式为CFile。DiskRowSet分为BaseData和DeltaFile。这里每个Column被存储在一个相邻的数据区域，这个数据区域被分为多个小的Page，每个Column Page都可以使用一些Encoding以及Compression算法。后台会定期对DiskRowSet做Compaction，以删除没用的数据及合并历史数据，减少查询过程中的IO开销。\n**BaseData：**DiskRowSet刷写完成的数据，CFile，按列存储，主键有序。BaseData不可变，类似Parquet。\n**BloomFile：**根据一个DiskRowSet中的Key生成一个BloomFilter，用于快速模糊定位某个key是否在DiskRowSet中存在。\n**AdhocIndex：**存放主键的索引，用于定位Key在DiskRowSet中的具体哪个偏移位置。\n**DeltaMemStore：**每份DiskRowSet都对应内存中一个DeltaMemStore，负责记录这个DiskRowSet上BaseData发生后续变更的数据，先写到内存中，写满后Flush到磁盘生成RedoFile。DeltaMemStore的组织方式与MemRowSet相同，也维护一个B+树。\n**DeltaFile：**DeltaMemStore到一定大小会存储到磁盘形成DeltaFile，分为UndoFile和RedoFile。\n**RedoFile：**重做文件，记录上一次Flush生成BaseData之后发生变更数据。DeltaMemStore写满之后，也会刷成CFile，不过与BaseData分开存储，名为RedoFile。UndoFile和RedoFile与关系型数据库中的Undo日子和Redo日志类似。\n**UndoFile：**撤销文件，记录上一次Flush生成BaseData之前时间的历史数据，Kudu通过UndoFile可以读到历史某个时间点的数据。UndoFile一般只有一份。默认UndoFile保存15分钟，Kudu可以查询到15分钟内某列的内容，超过15分钟后会过期，该UndoFile被删除。\n\nDeltaFile(主要是RedoFile)会不断增加，产生大量小文件，不Compaction肯定影响性能，所以就有了下面两种合并方式：\n\n- Minor Compaction：多个DeltaFile进行合并生成一个大的DeltaFile。默认是1000个DeltaFile进行合并一次。\n- Major Compaction：RedoFile文件的大小和BaseData的文件的比例为0.1的时候，会将RedoFile合并进入BaseData，Kudu记录所有更新操作并保存为UndoFile。\n  补充一下：合并和重写BaseData是成本很高的，会产生大量IO操作，Kudu不会将全部DeltaFile合并进BaseData。如果只更新几行数据，但要重写BaseData，费力不讨好，所以Kudu会在某个特定列需要大量更新时再把BaseData与DeltaFile合并。未合并的RedoFile会继续保留等待后续合并操作。\n\n**Kudu读流程：**\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1656670543950-cf2edd8b-55d4-4eb2-b224-78d3c1d9aa31.png)\n\n1. Client发送读请求，Master根据主键范围确定到包含所需数据的所有Tablet位置和信息。\n2. Client找到所需Tablet所在TServer，TServer接受读请求。\n3. 如果要读取的数据位于内存，先从内存（MemRowSet，DeltaMemStore）读取数据，根据读取请求包含的时间戳前提交的更新合并成最终数据。\n4. 如果要读取的数据位于磁盘（DiskRowSet，DeltaFile），在DeltaFile的UndoFile、RedoFile中找目标数据相关的改动，根据读取请求包含的时间戳合并成最新数据并返回。\n\n**Kudu写流程：**\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1656670544082-37d8b7e9-de97-46c0-9ded-20ad7ae15c16.png)\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1656670544010-1315c073-bd11-488c-a780-ffbf553002bb.png)\n\n1. Client向Master发起写请求，Master找到对应的Tablet元数据信息，检查请求数据是否符合表结构。\n2. 因为Kudu不允许有主键重复的记录，所以需要判断主键是否已经存在，先查询主键范围，如果不在范围内则准备写MemRowSet。\n3. 如果在主键范围内，先通过主键Key的布隆过滤器快速模糊查找，未命中则准备写MemRowSet。\n4. 如果BloomFilter命中，则查询索引，如果没命中索引则准备写MemRowSet，如果命中了主键索引就报错：主键重复。\n5. 写入MemRowSet前先被提交到一个Tablet的WAL预写日志，并根据Raft一致性算法取得Follower Tablets的同意，然后才会被写入到其中一个Tablet的MemRowSet中。为了在MemRowSet中支持多版本并发控制(MVCC)，对最近插入的行(即尚未刷新到磁盘的新的行)的更新和删除操作将被追加到MemRowSet中的原始行之后以生成重做(REDO)记录的列表。\n6. MemRowSet写满后，Kudu将数据每行相邻的列分为不同的区间，每个列为一个区间，Flush到DiskRowSet。\n\n**Kudu更新流程：**\n\n1. Client发送更新请求，Master获取表的相关信息，表的所有Tablet信息。\n2. Kudu检查是否符合表结构。\n3. 如果需要更新的数据在MemRowSet，B+树找到待更新数据所在叶子节点，然后将更新操作记录在所在行中一个Mutation链表中；Kudu采用了MVCC(多版本并发控制，实现读和写的并行，任何写都是插入)思想，将更改的数据以链表形式追加到叶子节点后面，避免在树上进行更新和删除操作。\n4. 如果需要更新的数据在DiskRowSet，找到其所在的DiskRowSet，前面提到每个DiskRowSet都会在内存中有一个DeltaMemStore，将更新操作记录在DeltaMemStore，达到一定大小才会生成DeltaFile到磁盘。\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1655346605651-12519d77-90d0-4e92-8def-a832ad06c4b5.png)\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1655346609884-6c6502ed-d74e-4796-b91c-875a4792c2e9.png?x-oss-process=image%2Fresize%2Cw_913%2Climit_0)\n\n\n\n","slug":"bigdata/一文搞懂Kudu的整体架构","published":1,"comments":1,"layout":"post","photos":[],"link":"","_id":"cl9y38dsi001mfwui8a63cqyt","content":"<blockquote>\n<p>Kudu是典型的Master-Slave架构，基于LSM优化写入性能，但同时读性能会低（相较于Parquet）。Kudu基于Raft协议实现了Master和Slave Tablet节点的数据的一致性，以及选举功能，保证了容错性和高可用。</p>\n<p>Kudu是完全的列式存储引擎，可以针对性的编码和压缩，提高了IO性能。HBase是基于列族的，No Schema的NoSQL、KV数据库，无法进行针对性的编码和压缩，同时一般情况只会用一个列族，其实HBase退化为行存储引擎。</p>\n<p>Kudu通过WAL和Raft保证了分布式数据的一致性。</p>\n<p>kudu相对于HBase，牺牲了一定的写入性能—&gt;Kudu在写入数据的时候，需要先检查一遍唯一主键是否存在，如果存在会报错，同样更新数据的时候，同样需要先查找主键是否存在。因此Insert和Update等所有操作比HBase多了，<code>先读一次</code>的开销，而HBase所有的操作都是转化为直接写入，因此写的性能相较于HBase有一定的劣势。</p>\n<p>Kudu牺牲写的性能，但是保证了一个主键，只会存在于一个RowSet中，而HBase的RowKey可能会在多个HFlie中。减少了IO，提升了读性能，特别是在大量写入，少量更新的情况下。</p>\n</blockquote>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1655346605849-a27b0f24-9a73-486d-9797-0009ce3bc3dc.png?x-oss-process=image/resize,w_1080,limit_0\" alt=\"img\"></p>\n<p><strong>Table：</strong>具有Schema和全局有序主键的表。一张表有多个Tablet，多个Tablet包含表的全部数据。<br><strong>Tablet：</strong>Kudu的表Table被水平分割为多段，Tablet是Kudu表的一个片段（分区），每个Tablet存储一段连续范围的数据（会记录开始Key和结束Key），且两个Tablet间不会有重复范围的数据。一个Tablet会复制（逻辑复制而非物理复制，副本中的内容不是实际的数据，而是操作该副本上的数据时对应的更改信息）多个副本在多台TServer上，其中一个副本为Leader Tablet，其他则为Follower Tablet。只有Leader Tablet响应写请求，任何Tablet副本可以响应读请求。<br><strong>TabletServer：</strong>简称TServer，负责数据存储Tablet、提供数据读写服务、编码、压缩、合并和复制。一个TServer可以是某些Tablet的Leader，也可以是某些Tablet的Follower，一个Tablet可以被多个TServer服务（多对多关系）。TServer会定期（默认1s）向Master发送心跳。<br><strong>Catalog Table：</strong>目录表，用户不可直接读取或写入，仅由Master维护，存储两类元数据：表元数据（Schema信息，位置和状态）和Tablet元数据（所有TServer的列表、每个TServer包含哪些Tablet副本、Tablet的开始Key和结束Key）。Catalog Table只存储在Master节点，也是以Tablet的形式，数据量不会很大，只有一个分区，随着Master启动而被全量加载到内存。<br><strong>Master：</strong>负责集群管理和元数据管理。具体：跟踪所有Tablets、TServer、Catalog Table和其他相关的元数据。协调客户端做元数据操作，比如创建一个新表，客户端向Master发起请求，Master写入其WAL并得到其他Master同意后将新表的元数据写入Catalog Table，并协调TServer创建Tablet。<br><strong>WAL：</strong>一个仅支持追加写的预写日志，无论Master还是Tablet都有预写日志，任何对表的修改都会在该表对应的WAL中写入条目(entry)，其他副本在数据相对落后时可以通过WAL赶上来。<br><strong>逻辑复制：</strong>Kudu基于Raft协议在集群中对每个Tablet都存储多个副本，副本中的内容不是实际的数据，而是操作该副本上的数据时对应的更改信息。Insert和Update操作会走网络IO，但Delete操作不会，压缩数据也不会走网络。</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1656670281157-814d5745-2416-468f-8c68-44c63244069f.png\" alt=\"img\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1655346605725-aa6706b6-8453-45b7-b084-18a05394f969.png?x-oss-process=image/resize,w_829,limit_0\" alt=\"img\"></p>\n<p>如图，Table分为若干Tablet；Tablet包含Metadata和RowSet，RowSet包含一个MemRowSet及若干个DiskRowSet，DiskRowSet中包含一个BloomFile、AdhocIndex、BaseData、DeltaMem及若干个RedoFile和UndoFile（UndoFile一般情况下只有一个）。<br><strong>MemRowSet：</strong>插入新数据及更新已在MemRowSet中的数据，数据结构是B+树，主键在非叶子节点，数据都在叶子节点。MemRowSet写满后会将数据刷到磁盘形成若干个DiskRowSet。每次达到1G或者120s时生成一个DiskRowSet，DiskRowSet按列存储，类似Parquet。<br><strong>DiskRowSet：</strong>DiskRowSets存储文件格式为CFile。DiskRowSet分为BaseData和DeltaFile。这里每个Column被存储在一个相邻的数据区域，这个数据区域被分为多个小的Page，每个Column Page都可以使用一些Encoding以及Compression算法。后台会定期对DiskRowSet做Compaction，以删除没用的数据及合并历史数据，减少查询过程中的IO开销。<br><strong>BaseData：</strong>DiskRowSet刷写完成的数据，CFile，按列存储，主键有序。BaseData不可变，类似Parquet。<br><strong>BloomFile：</strong>根据一个DiskRowSet中的Key生成一个BloomFilter，用于快速模糊定位某个key是否在DiskRowSet中存在。<br><strong>AdhocIndex：</strong>存放主键的索引，用于定位Key在DiskRowSet中的具体哪个偏移位置。<br><strong>DeltaMemStore：</strong>每份DiskRowSet都对应内存中一个DeltaMemStore，负责记录这个DiskRowSet上BaseData发生后续变更的数据，先写到内存中，写满后Flush到磁盘生成RedoFile。DeltaMemStore的组织方式与MemRowSet相同，也维护一个B+树。<br><strong>DeltaFile：</strong>DeltaMemStore到一定大小会存储到磁盘形成DeltaFile，分为UndoFile和RedoFile。<br><strong>RedoFile：</strong>重做文件，记录上一次Flush生成BaseData之后发生变更数据。DeltaMemStore写满之后，也会刷成CFile，不过与BaseData分开存储，名为RedoFile。UndoFile和RedoFile与关系型数据库中的Undo日子和Redo日志类似。<br><strong>UndoFile：</strong>撤销文件，记录上一次Flush生成BaseData之前时间的历史数据，Kudu通过UndoFile可以读到历史某个时间点的数据。UndoFile一般只有一份。默认UndoFile保存15分钟，Kudu可以查询到15分钟内某列的内容，超过15分钟后会过期，该UndoFile被删除。</p>\n<p>DeltaFile(主要是RedoFile)会不断增加，产生大量小文件，不Compaction肯定影响性能，所以就有了下面两种合并方式：</p>\n<ul>\n<li>Minor Compaction：多个DeltaFile进行合并生成一个大的DeltaFile。默认是1000个DeltaFile进行合并一次。</li>\n<li>Major Compaction：RedoFile文件的大小和BaseData的文件的比例为0.1的时候，会将RedoFile合并进入BaseData，Kudu记录所有更新操作并保存为UndoFile。<br>补充一下：合并和重写BaseData是成本很高的，会产生大量IO操作，Kudu不会将全部DeltaFile合并进BaseData。如果只更新几行数据，但要重写BaseData，费力不讨好，所以Kudu会在某个特定列需要大量更新时再把BaseData与DeltaFile合并。未合并的RedoFile会继续保留等待后续合并操作。</li>\n</ul>\n<p><strong>Kudu读流程：</strong><br><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1656670543950-cf2edd8b-55d4-4eb2-b224-78d3c1d9aa31.png\" alt=\"img\"></p>\n<ol>\n<li>Client发送读请求，Master根据主键范围确定到包含所需数据的所有Tablet位置和信息。</li>\n<li>Client找到所需Tablet所在TServer，TServer接受读请求。</li>\n<li>如果要读取的数据位于内存，先从内存（MemRowSet，DeltaMemStore）读取数据，根据读取请求包含的时间戳前提交的更新合并成最终数据。</li>\n<li>如果要读取的数据位于磁盘（DiskRowSet，DeltaFile），在DeltaFile的UndoFile、RedoFile中找目标数据相关的改动，根据读取请求包含的时间戳合并成最新数据并返回。</li>\n</ol>\n<p><strong>Kudu写流程：</strong><br><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1656670544082-37d8b7e9-de97-46c0-9ded-20ad7ae15c16.png\" alt=\"img\"><br><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1656670544010-1315c073-bd11-488c-a780-ffbf553002bb.png\" alt=\"img\"></p>\n<ol>\n<li>Client向Master发起写请求，Master找到对应的Tablet元数据信息，检查请求数据是否符合表结构。</li>\n<li>因为Kudu不允许有主键重复的记录，所以需要判断主键是否已经存在，先查询主键范围，如果不在范围内则准备写MemRowSet。</li>\n<li>如果在主键范围内，先通过主键Key的布隆过滤器快速模糊查找，未命中则准备写MemRowSet。</li>\n<li>如果BloomFilter命中，则查询索引，如果没命中索引则准备写MemRowSet，如果命中了主键索引就报错：主键重复。</li>\n<li>写入MemRowSet前先被提交到一个Tablet的WAL预写日志，并根据Raft一致性算法取得Follower Tablets的同意，然后才会被写入到其中一个Tablet的MemRowSet中。为了在MemRowSet中支持多版本并发控制(MVCC)，对最近插入的行(即尚未刷新到磁盘的新的行)的更新和删除操作将被追加到MemRowSet中的原始行之后以生成重做(REDO)记录的列表。</li>\n<li>MemRowSet写满后，Kudu将数据每行相邻的列分为不同的区间，每个列为一个区间，Flush到DiskRowSet。</li>\n</ol>\n<p><strong>Kudu更新流程：</strong></p>\n<ol>\n<li>Client发送更新请求，Master获取表的相关信息，表的所有Tablet信息。</li>\n<li>Kudu检查是否符合表结构。</li>\n<li>如果需要更新的数据在MemRowSet，B+树找到待更新数据所在叶子节点，然后将更新操作记录在所在行中一个Mutation链表中；Kudu采用了MVCC(多版本并发控制，实现读和写的并行，任何写都是插入)思想，将更改的数据以链表形式追加到叶子节点后面，避免在树上进行更新和删除操作。</li>\n<li>如果需要更新的数据在DiskRowSet，找到其所在的DiskRowSet，前面提到每个DiskRowSet都会在内存中有一个DeltaMemStore，将更新操作记录在DeltaMemStore，达到一定大小才会生成DeltaFile到磁盘。</li>\n</ol>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1655346605651-12519d77-90d0-4e92-8def-a832ad06c4b5.png\" alt=\"img\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1655346609884-6c6502ed-d74e-4796-b91c-875a4792c2e9.png?x-oss-process=image/resize,w_913,limit_0\" alt=\"img\"></p>\n","site":{"data":{"link":[{"class_name":"友情链接","class_desc":"那些人，那些事","link_list":[{"name":"张洪Heo","link":"https://blog.zhheo.com/","avatar":"https://npm.elemecdn.com/guli-heo/img/avatar2.png","descr":"分享设计与科技生活"},{"name":"瞬間の筆記","link":"https://hikki.site","descr":"喜欢的东西就努力去追求，万一成功了呢!","avatar":"https://cdn.jsdelivr.net/gh/0000rookie/imgs/202206120315.png"}]}]}},"excerpt":"","more":"<blockquote>\n<p>Kudu是典型的Master-Slave架构，基于LSM优化写入性能，但同时读性能会低（相较于Parquet）。Kudu基于Raft协议实现了Master和Slave Tablet节点的数据的一致性，以及选举功能，保证了容错性和高可用。</p>\n<p>Kudu是完全的列式存储引擎，可以针对性的编码和压缩，提高了IO性能。HBase是基于列族的，No Schema的NoSQL、KV数据库，无法进行针对性的编码和压缩，同时一般情况只会用一个列族，其实HBase退化为行存储引擎。</p>\n<p>Kudu通过WAL和Raft保证了分布式数据的一致性。</p>\n<p>kudu相对于HBase，牺牲了一定的写入性能—&gt;Kudu在写入数据的时候，需要先检查一遍唯一主键是否存在，如果存在会报错，同样更新数据的时候，同样需要先查找主键是否存在。因此Insert和Update等所有操作比HBase多了，<code>先读一次</code>的开销，而HBase所有的操作都是转化为直接写入，因此写的性能相较于HBase有一定的劣势。</p>\n<p>Kudu牺牲写的性能，但是保证了一个主键，只会存在于一个RowSet中，而HBase的RowKey可能会在多个HFlie中。减少了IO，提升了读性能，特别是在大量写入，少量更新的情况下。</p>\n</blockquote>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1655346605849-a27b0f24-9a73-486d-9797-0009ce3bc3dc.png?x-oss-process=image/resize,w_1080,limit_0\" alt=\"img\"></p>\n<p><strong>Table：</strong>具有Schema和全局有序主键的表。一张表有多个Tablet，多个Tablet包含表的全部数据。<br><strong>Tablet：</strong>Kudu的表Table被水平分割为多段，Tablet是Kudu表的一个片段（分区），每个Tablet存储一段连续范围的数据（会记录开始Key和结束Key），且两个Tablet间不会有重复范围的数据。一个Tablet会复制（逻辑复制而非物理复制，副本中的内容不是实际的数据，而是操作该副本上的数据时对应的更改信息）多个副本在多台TServer上，其中一个副本为Leader Tablet，其他则为Follower Tablet。只有Leader Tablet响应写请求，任何Tablet副本可以响应读请求。<br><strong>TabletServer：</strong>简称TServer，负责数据存储Tablet、提供数据读写服务、编码、压缩、合并和复制。一个TServer可以是某些Tablet的Leader，也可以是某些Tablet的Follower，一个Tablet可以被多个TServer服务（多对多关系）。TServer会定期（默认1s）向Master发送心跳。<br><strong>Catalog Table：</strong>目录表，用户不可直接读取或写入，仅由Master维护，存储两类元数据：表元数据（Schema信息，位置和状态）和Tablet元数据（所有TServer的列表、每个TServer包含哪些Tablet副本、Tablet的开始Key和结束Key）。Catalog Table只存储在Master节点，也是以Tablet的形式，数据量不会很大，只有一个分区，随着Master启动而被全量加载到内存。<br><strong>Master：</strong>负责集群管理和元数据管理。具体：跟踪所有Tablets、TServer、Catalog Table和其他相关的元数据。协调客户端做元数据操作，比如创建一个新表，客户端向Master发起请求，Master写入其WAL并得到其他Master同意后将新表的元数据写入Catalog Table，并协调TServer创建Tablet。<br><strong>WAL：</strong>一个仅支持追加写的预写日志，无论Master还是Tablet都有预写日志，任何对表的修改都会在该表对应的WAL中写入条目(entry)，其他副本在数据相对落后时可以通过WAL赶上来。<br><strong>逻辑复制：</strong>Kudu基于Raft协议在集群中对每个Tablet都存储多个副本，副本中的内容不是实际的数据，而是操作该副本上的数据时对应的更改信息。Insert和Update操作会走网络IO，但Delete操作不会，压缩数据也不会走网络。</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1656670281157-814d5745-2416-468f-8c68-44c63244069f.png\" alt=\"img\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1655346605725-aa6706b6-8453-45b7-b084-18a05394f969.png?x-oss-process=image/resize,w_829,limit_0\" alt=\"img\"></p>\n<p>如图，Table分为若干Tablet；Tablet包含Metadata和RowSet，RowSet包含一个MemRowSet及若干个DiskRowSet，DiskRowSet中包含一个BloomFile、AdhocIndex、BaseData、DeltaMem及若干个RedoFile和UndoFile（UndoFile一般情况下只有一个）。<br><strong>MemRowSet：</strong>插入新数据及更新已在MemRowSet中的数据，数据结构是B+树，主键在非叶子节点，数据都在叶子节点。MemRowSet写满后会将数据刷到磁盘形成若干个DiskRowSet。每次达到1G或者120s时生成一个DiskRowSet，DiskRowSet按列存储，类似Parquet。<br><strong>DiskRowSet：</strong>DiskRowSets存储文件格式为CFile。DiskRowSet分为BaseData和DeltaFile。这里每个Column被存储在一个相邻的数据区域，这个数据区域被分为多个小的Page，每个Column Page都可以使用一些Encoding以及Compression算法。后台会定期对DiskRowSet做Compaction，以删除没用的数据及合并历史数据，减少查询过程中的IO开销。<br><strong>BaseData：</strong>DiskRowSet刷写完成的数据，CFile，按列存储，主键有序。BaseData不可变，类似Parquet。<br><strong>BloomFile：</strong>根据一个DiskRowSet中的Key生成一个BloomFilter，用于快速模糊定位某个key是否在DiskRowSet中存在。<br><strong>AdhocIndex：</strong>存放主键的索引，用于定位Key在DiskRowSet中的具体哪个偏移位置。<br><strong>DeltaMemStore：</strong>每份DiskRowSet都对应内存中一个DeltaMemStore，负责记录这个DiskRowSet上BaseData发生后续变更的数据，先写到内存中，写满后Flush到磁盘生成RedoFile。DeltaMemStore的组织方式与MemRowSet相同，也维护一个B+树。<br><strong>DeltaFile：</strong>DeltaMemStore到一定大小会存储到磁盘形成DeltaFile，分为UndoFile和RedoFile。<br><strong>RedoFile：</strong>重做文件，记录上一次Flush生成BaseData之后发生变更数据。DeltaMemStore写满之后，也会刷成CFile，不过与BaseData分开存储，名为RedoFile。UndoFile和RedoFile与关系型数据库中的Undo日子和Redo日志类似。<br><strong>UndoFile：</strong>撤销文件，记录上一次Flush生成BaseData之前时间的历史数据，Kudu通过UndoFile可以读到历史某个时间点的数据。UndoFile一般只有一份。默认UndoFile保存15分钟，Kudu可以查询到15分钟内某列的内容，超过15分钟后会过期，该UndoFile被删除。</p>\n<p>DeltaFile(主要是RedoFile)会不断增加，产生大量小文件，不Compaction肯定影响性能，所以就有了下面两种合并方式：</p>\n<ul>\n<li>Minor Compaction：多个DeltaFile进行合并生成一个大的DeltaFile。默认是1000个DeltaFile进行合并一次。</li>\n<li>Major Compaction：RedoFile文件的大小和BaseData的文件的比例为0.1的时候，会将RedoFile合并进入BaseData，Kudu记录所有更新操作并保存为UndoFile。<br>补充一下：合并和重写BaseData是成本很高的，会产生大量IO操作，Kudu不会将全部DeltaFile合并进BaseData。如果只更新几行数据，但要重写BaseData，费力不讨好，所以Kudu会在某个特定列需要大量更新时再把BaseData与DeltaFile合并。未合并的RedoFile会继续保留等待后续合并操作。</li>\n</ul>\n<p><strong>Kudu读流程：</strong><br><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1656670543950-cf2edd8b-55d4-4eb2-b224-78d3c1d9aa31.png\" alt=\"img\"></p>\n<ol>\n<li>Client发送读请求，Master根据主键范围确定到包含所需数据的所有Tablet位置和信息。</li>\n<li>Client找到所需Tablet所在TServer，TServer接受读请求。</li>\n<li>如果要读取的数据位于内存，先从内存（MemRowSet，DeltaMemStore）读取数据，根据读取请求包含的时间戳前提交的更新合并成最终数据。</li>\n<li>如果要读取的数据位于磁盘（DiskRowSet，DeltaFile），在DeltaFile的UndoFile、RedoFile中找目标数据相关的改动，根据读取请求包含的时间戳合并成最新数据并返回。</li>\n</ol>\n<p><strong>Kudu写流程：</strong><br><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1656670544082-37d8b7e9-de97-46c0-9ded-20ad7ae15c16.png\" alt=\"img\"><br><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1656670544010-1315c073-bd11-488c-a780-ffbf553002bb.png\" alt=\"img\"></p>\n<ol>\n<li>Client向Master发起写请求，Master找到对应的Tablet元数据信息，检查请求数据是否符合表结构。</li>\n<li>因为Kudu不允许有主键重复的记录，所以需要判断主键是否已经存在，先查询主键范围，如果不在范围内则准备写MemRowSet。</li>\n<li>如果在主键范围内，先通过主键Key的布隆过滤器快速模糊查找，未命中则准备写MemRowSet。</li>\n<li>如果BloomFilter命中，则查询索引，如果没命中索引则准备写MemRowSet，如果命中了主键索引就报错：主键重复。</li>\n<li>写入MemRowSet前先被提交到一个Tablet的WAL预写日志，并根据Raft一致性算法取得Follower Tablets的同意，然后才会被写入到其中一个Tablet的MemRowSet中。为了在MemRowSet中支持多版本并发控制(MVCC)，对最近插入的行(即尚未刷新到磁盘的新的行)的更新和删除操作将被追加到MemRowSet中的原始行之后以生成重做(REDO)记录的列表。</li>\n<li>MemRowSet写满后，Kudu将数据每行相邻的列分为不同的区间，每个列为一个区间，Flush到DiskRowSet。</li>\n</ol>\n<p><strong>Kudu更新流程：</strong></p>\n<ol>\n<li>Client发送更新请求，Master获取表的相关信息，表的所有Tablet信息。</li>\n<li>Kudu检查是否符合表结构。</li>\n<li>如果需要更新的数据在MemRowSet，B+树找到待更新数据所在叶子节点，然后将更新操作记录在所在行中一个Mutation链表中；Kudu采用了MVCC(多版本并发控制，实现读和写的并行，任何写都是插入)思想，将更改的数据以链表形式追加到叶子节点后面，避免在树上进行更新和删除操作。</li>\n<li>如果需要更新的数据在DiskRowSet，找到其所在的DiskRowSet，前面提到每个DiskRowSet都会在内存中有一个DeltaMemStore，将更新操作记录在DeltaMemStore，达到一定大小才会生成DeltaFile到磁盘。</li>\n</ol>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1655346605651-12519d77-90d0-4e92-8def-a832ad06c4b5.png\" alt=\"img\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1655346609884-6c6502ed-d74e-4796-b91c-875a4792c2e9.png?x-oss-process=image/resize,w_913,limit_0\" alt=\"img\"></p>\n"},{"title":"初入Flink Table && SQL","top_img":"linear-gradient(20deg, #0062be, #925696, #cc426e, #fb0347)","date":"2022-08-13T09:55:05.000Z","updated":"2022-08-13T09:55:05.000Z","cover":"https://tva4.sinaimg.cn/large/0084aYsLgy1gy51ogkzs9j31hc0m843g.jpg","description":null,"keywords":null,"_content":"\n# QuickStart\n\n- Table API 和 SQL 需要引入的依赖有两个：planner 和 bridge。\n\n  ```xml\n      <dependency>\n          <groupId>org.apache.flink</groupId>\n          <artifactId>flink-table-api-scala-bridge_${scala.version}</artifactId>\n          <version>${flink.version}</version>\n      </dependency>\n      <dependency>\n          <groupId>org.apache.flink</groupId>\n          <artifactId>flink-table-planner_${scala.version}</artifactId>\n          <version>${flink.version}</version>\n      </dependency>\n  ```\n\n- > 老版本planner已经被废除，只剩下blink\n  >\n  > The old planner has been removed in Flink 1.14. Please upgrade your table program to use the default planner (previously called the 'blink' planner).\n\n# Flink CDC SQL Demo\n\n- 1、下载Flink，下载`flink-sql-connector-mysql-cdc-2.3-SNAPSHOT.jar`依赖包，并将它们放到目录 `{flink_home}/lib/` 下.\n\n- 2、在 MySQL 数据库中准备数据，创建数据库和表 `products`，`orders`，并插入数据\n\n  ```sql\n  -- MySQL\n  CREATE DATABASE mydb;\n  USE mydb;\n  CREATE TABLE products (\n    id INTEGER NOT NULL AUTO_INCREMENT PRIMARY KEY,\n    name VARCHAR(255) NOT NULL,\n    description VARCHAR(512)\n  );\n  ALTER TABLE products AUTO_INCREMENT = 101;\n  \n  INSERT INTO products\n  VALUES (default,\"scooter\",\"Small 2-wheel scooter\"),\n         (default,\"car battery\",\"12V car battery\"),\n         (default,\"12-pack drill bits\",\"12-pack of drill bits with sizes ranging from #40 to #3\"),\n         (default,\"hammer\",\"12oz carpenter's hammer\"),\n         (default,\"hammer\",\"14oz carpenter's hammer\"),\n         (default,\"hammer\",\"16oz carpenter's hammer\"),\n         (default,\"rocks\",\"box of assorted rocks\"),\n         (default,\"jacket\",\"water resistent black wind breaker\"),\n         (default,\"spare tire\",\"24 inch spare tire\");\n  \n  CREATE TABLE orders (\n    order_id INTEGER NOT NULL AUTO_INCREMENT PRIMARY KEY,\n    order_date DATETIME NOT NULL,\n    customer_name VARCHAR(255) NOT NULL,\n    price DECIMAL(10, 5) NOT NULL,\n    product_id INTEGER NOT NULL,\n    order_status BOOLEAN NOT NULL -- Whether order has been placed\n  ) AUTO_INCREMENT = 10001;\n  \n  INSERT INTO orders\n  VALUES (default, '2020-07-30 10:08:22', 'Jark', 50.50, 102, false),\n         (default, '2020-07-30 10:11:09', 'Sally', 15.00, 105, false),\n         (default, '2020-07-30 12:00:30', 'Edward', 25.25, 106, false);\n  ```\n\n- 3、启动 Flink 集群和 Flink SQL CLI\n\n  > ./bin/start-cluster.sh\n  > ./bin/sql-client.sh\n\n- 4、在 Flink SQL CLI 中使用 Flink DDL 创建表\n\n  >首先，开启 checkpoint，每隔3秒做一次 checkpoint\n  >\n  >```\n  >-- Flink SQL                   \n  >Flink SQL> SET execution.checkpointing.interval = 3s;\n  >```\n  >\n  >然后, 对于数据库中的表 `products`, `orders`, `shipments`， 使用 Flink SQL CLI 创建对应的表，用于同步这些底层数据库表的数据\n  >\n  >```sql\n  >-- Flink SQL\n  >Flink SQL> CREATE TABLE products (\n  >    id INT,\n  >    name STRING,\n  >    description STRING,\n  >    PRIMARY KEY (id) NOT ENFORCED\n  >  ) WITH (\n  >    'connector' = 'mysql-cdc',\n  >    'hostname' = 'localhost',\n  >    'port' = '3306',\n  >    'username' = 'root',\n  >    'password' = '1234',\n  >    'database-name' = 'mydb',\n  >    'table-name' = 'products'\n  >  );\n  >\n  >Flink SQL> CREATE TABLE orders (\n  >   order_id INT,\n  >   order_date TIMESTAMP(0),\n  >   customer_name STRING,\n  >   price DECIMAL(10, 5),\n  >   product_id INT,\n  >   order_status BOOLEAN,\n  >   PRIMARY KEY (order_id) NOT ENFORCED\n  > ) WITH (\n  >   'connector' = 'mysql-cdc',\n  >   'hostname' = 'localhost',\n  >   'port' = '3306',\n  >   'username' = 'root',\n  >   'password' = '1234',\n  >   'database-name' = 'mydb',\n  >   'table-name' = 'orders'\n  > );\n  >```\n\n\n\n# SQL Client\n\n- CLI 为维护和可视化结果提供**三种模式**。\n\n- **表格模式**（table mode）在内存中实体化结果，并将结果用规则的分页表格可视化展示出来。执行如下命令启用：\n\n  ```text\n  SET 'sql-client.execution.result-mode' = 'table';\n  ```\n\n  **变更日志模式**（changelog mode）不会实体化和可视化结果，而是由插入（`+`）和撤销（`-`）组成的持续查询产生结果流。\n\n  ```text\n  SET 'sql-client.execution.result-mode' = 'changelog';\n  ```\n\n  **Tableau模式**（tableau mode）更接近传统的数据库，会将执行的结果以制表的形式直接打在屏幕之上。具体显示的内容会取决于作业 执行模式的不同(`execution.type`)：\n\n  ```text\n  SET 'sql-client.execution.result-mode' = 'tableau';\n  ```\n\n\n\n# MySQL开启binlog\n\n- 找到my.cnf文件\n\n  > mysql --help | grep 'Default options' -A 1\n\n```yaml\n#第一种方式:\n#开启binlog日志\nlog_bin=ON\n#binlog日志的基本文件名\nlog_bin_basename=/var/lib/mysql/mysql-bin\n#binlog文件的索引文件，管理所有binlog文件\nlog_bin_index=/var/lib/mysql/mysql-bin.index\n#配置serverid\nserver-id=1\n\n#第二种方式:\n#此一行等同于上面log_bin三行\nlog-bin=/var/lib/mysql/mysql-bin\n#配置serverid\nserver-id=1\n\n# Demo\nserver-id=1\nlog-bin=mysql-bin\nbinlog_format=row\nbinlog-do-db=mydb\n```\n\n\n\n# Code Repo\n\n- ```scala\n      // 从命令参数中读取hostname和port\n      val paramTool: ParameterTool = ParameterTool.fromArgs(args)\n      val hostname: String = paramTool.get(\"host\")\n      val port: Int = paramTool.getInt(\"port\")\n  ```\n","source":"_posts/bigdata/初入Flink-Table@SQL.md","raw":"---\ntitle: 初入Flink Table && SQL\ntags:\n  - 'Flink'\ncategories:\n  - [bigdata,Flink]\ntop_img: 'linear-gradient(20deg, #0062be, #925696, #cc426e, #fb0347)'\ndate: 2022-08-13 17:55:05\nupdated: 2022-08-13 17:55:05\ncover:\ndescription:\nkeywords:\n---\n\n# QuickStart\n\n- Table API 和 SQL 需要引入的依赖有两个：planner 和 bridge。\n\n  ```xml\n      <dependency>\n          <groupId>org.apache.flink</groupId>\n          <artifactId>flink-table-api-scala-bridge_${scala.version}</artifactId>\n          <version>${flink.version}</version>\n      </dependency>\n      <dependency>\n          <groupId>org.apache.flink</groupId>\n          <artifactId>flink-table-planner_${scala.version}</artifactId>\n          <version>${flink.version}</version>\n      </dependency>\n  ```\n\n- > 老版本planner已经被废除，只剩下blink\n  >\n  > The old planner has been removed in Flink 1.14. Please upgrade your table program to use the default planner (previously called the 'blink' planner).\n\n# Flink CDC SQL Demo\n\n- 1、下载Flink，下载`flink-sql-connector-mysql-cdc-2.3-SNAPSHOT.jar`依赖包，并将它们放到目录 `{flink_home}/lib/` 下.\n\n- 2、在 MySQL 数据库中准备数据，创建数据库和表 `products`，`orders`，并插入数据\n\n  ```sql\n  -- MySQL\n  CREATE DATABASE mydb;\n  USE mydb;\n  CREATE TABLE products (\n    id INTEGER NOT NULL AUTO_INCREMENT PRIMARY KEY,\n    name VARCHAR(255) NOT NULL,\n    description VARCHAR(512)\n  );\n  ALTER TABLE products AUTO_INCREMENT = 101;\n  \n  INSERT INTO products\n  VALUES (default,\"scooter\",\"Small 2-wheel scooter\"),\n         (default,\"car battery\",\"12V car battery\"),\n         (default,\"12-pack drill bits\",\"12-pack of drill bits with sizes ranging from #40 to #3\"),\n         (default,\"hammer\",\"12oz carpenter's hammer\"),\n         (default,\"hammer\",\"14oz carpenter's hammer\"),\n         (default,\"hammer\",\"16oz carpenter's hammer\"),\n         (default,\"rocks\",\"box of assorted rocks\"),\n         (default,\"jacket\",\"water resistent black wind breaker\"),\n         (default,\"spare tire\",\"24 inch spare tire\");\n  \n  CREATE TABLE orders (\n    order_id INTEGER NOT NULL AUTO_INCREMENT PRIMARY KEY,\n    order_date DATETIME NOT NULL,\n    customer_name VARCHAR(255) NOT NULL,\n    price DECIMAL(10, 5) NOT NULL,\n    product_id INTEGER NOT NULL,\n    order_status BOOLEAN NOT NULL -- Whether order has been placed\n  ) AUTO_INCREMENT = 10001;\n  \n  INSERT INTO orders\n  VALUES (default, '2020-07-30 10:08:22', 'Jark', 50.50, 102, false),\n         (default, '2020-07-30 10:11:09', 'Sally', 15.00, 105, false),\n         (default, '2020-07-30 12:00:30', 'Edward', 25.25, 106, false);\n  ```\n\n- 3、启动 Flink 集群和 Flink SQL CLI\n\n  > ./bin/start-cluster.sh\n  > ./bin/sql-client.sh\n\n- 4、在 Flink SQL CLI 中使用 Flink DDL 创建表\n\n  >首先，开启 checkpoint，每隔3秒做一次 checkpoint\n  >\n  >```\n  >-- Flink SQL                   \n  >Flink SQL> SET execution.checkpointing.interval = 3s;\n  >```\n  >\n  >然后, 对于数据库中的表 `products`, `orders`, `shipments`， 使用 Flink SQL CLI 创建对应的表，用于同步这些底层数据库表的数据\n  >\n  >```sql\n  >-- Flink SQL\n  >Flink SQL> CREATE TABLE products (\n  >    id INT,\n  >    name STRING,\n  >    description STRING,\n  >    PRIMARY KEY (id) NOT ENFORCED\n  >  ) WITH (\n  >    'connector' = 'mysql-cdc',\n  >    'hostname' = 'localhost',\n  >    'port' = '3306',\n  >    'username' = 'root',\n  >    'password' = '1234',\n  >    'database-name' = 'mydb',\n  >    'table-name' = 'products'\n  >  );\n  >\n  >Flink SQL> CREATE TABLE orders (\n  >   order_id INT,\n  >   order_date TIMESTAMP(0),\n  >   customer_name STRING,\n  >   price DECIMAL(10, 5),\n  >   product_id INT,\n  >   order_status BOOLEAN,\n  >   PRIMARY KEY (order_id) NOT ENFORCED\n  > ) WITH (\n  >   'connector' = 'mysql-cdc',\n  >   'hostname' = 'localhost',\n  >   'port' = '3306',\n  >   'username' = 'root',\n  >   'password' = '1234',\n  >   'database-name' = 'mydb',\n  >   'table-name' = 'orders'\n  > );\n  >```\n\n\n\n# SQL Client\n\n- CLI 为维护和可视化结果提供**三种模式**。\n\n- **表格模式**（table mode）在内存中实体化结果，并将结果用规则的分页表格可视化展示出来。执行如下命令启用：\n\n  ```text\n  SET 'sql-client.execution.result-mode' = 'table';\n  ```\n\n  **变更日志模式**（changelog mode）不会实体化和可视化结果，而是由插入（`+`）和撤销（`-`）组成的持续查询产生结果流。\n\n  ```text\n  SET 'sql-client.execution.result-mode' = 'changelog';\n  ```\n\n  **Tableau模式**（tableau mode）更接近传统的数据库，会将执行的结果以制表的形式直接打在屏幕之上。具体显示的内容会取决于作业 执行模式的不同(`execution.type`)：\n\n  ```text\n  SET 'sql-client.execution.result-mode' = 'tableau';\n  ```\n\n\n\n# MySQL开启binlog\n\n- 找到my.cnf文件\n\n  > mysql --help | grep 'Default options' -A 1\n\n```yaml\n#第一种方式:\n#开启binlog日志\nlog_bin=ON\n#binlog日志的基本文件名\nlog_bin_basename=/var/lib/mysql/mysql-bin\n#binlog文件的索引文件，管理所有binlog文件\nlog_bin_index=/var/lib/mysql/mysql-bin.index\n#配置serverid\nserver-id=1\n\n#第二种方式:\n#此一行等同于上面log_bin三行\nlog-bin=/var/lib/mysql/mysql-bin\n#配置serverid\nserver-id=1\n\n# Demo\nserver-id=1\nlog-bin=mysql-bin\nbinlog_format=row\nbinlog-do-db=mydb\n```\n\n\n\n# Code Repo\n\n- ```scala\n      // 从命令参数中读取hostname和port\n      val paramTool: ParameterTool = ParameterTool.fromArgs(args)\n      val hostname: String = paramTool.get(\"host\")\n      val port: Int = paramTool.getInt(\"port\")\n  ```\n","slug":"bigdata/初入Flink-Table@SQL","published":1,"comments":1,"layout":"post","photos":[],"link":"","_id":"cl9y38dsk001ofwuibzi58kdn","content":"<h1 id=\"QuickStart\"><a href=\"#QuickStart\" class=\"headerlink\" title=\"QuickStart\"></a>QuickStart</h1><ul>\n<li><p>Table API 和 SQL 需要引入的依赖有两个：planner 和 bridge。</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.flink<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>flink-table-api-scala-bridge_$&#123;scala.version&#125;<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>$&#123;flink.version&#125;<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.flink<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>flink-table-planner_$&#123;scala.version&#125;<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>$&#123;flink.version&#125;<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><blockquote>\n<p>老版本planner已经被废除，只剩下blink</p>\n<p>The old planner has been removed in Flink 1.14. Please upgrade your table program to use the default planner (previously called the ‘blink’ planner).</p>\n</blockquote>\n</li>\n</ul>\n<h1 id=\"Flink-CDC-SQL-Demo\"><a href=\"#Flink-CDC-SQL-Demo\" class=\"headerlink\" title=\"Flink CDC SQL Demo\"></a>Flink CDC SQL Demo</h1><ul>\n<li><p>1、下载Flink，下载<code>flink-sql-connector-mysql-cdc-2.3-SNAPSHOT.jar</code>依赖包，并将它们放到目录 <code>&#123;flink_home&#125;/lib/</code> 下.</p>\n</li>\n<li><p>2、在 MySQL 数据库中准备数据，创建数据库和表 <code>products</code>，<code>orders</code>，并插入数据</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">-- MySQL</span></span><br><span class=\"line\"><span class=\"keyword\">CREATE</span> DATABASE mydb;</span><br><span class=\"line\">USE mydb;</span><br><span class=\"line\"><span class=\"keyword\">CREATE</span> <span class=\"keyword\">TABLE</span> products (</span><br><span class=\"line\">  id <span class=\"type\">INTEGER</span> <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span> AUTO_INCREMENT <span class=\"keyword\">PRIMARY</span> KEY,</span><br><span class=\"line\">  name <span class=\"type\">VARCHAR</span>(<span class=\"number\">255</span>) <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  description <span class=\"type\">VARCHAR</span>(<span class=\"number\">512</span>)</span><br><span class=\"line\">);</span><br><span class=\"line\"><span class=\"keyword\">ALTER</span> <span class=\"keyword\">TABLE</span> products AUTO_INCREMENT <span class=\"operator\">=</span> <span class=\"number\">101</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">INSERT</span> <span class=\"keyword\">INTO</span> products</span><br><span class=\"line\"><span class=\"keyword\">VALUES</span> (<span class=\"keyword\">default</span>,&quot;scooter&quot;,&quot;Small 2-wheel scooter&quot;),</span><br><span class=\"line\">       (<span class=\"keyword\">default</span>,&quot;car battery&quot;,&quot;12V car battery&quot;),</span><br><span class=\"line\">       (<span class=\"keyword\">default</span>,&quot;12-pack drill bits&quot;,&quot;12-pack of drill bits with sizes ranging from #40 to #3&quot;),</span><br><span class=\"line\">       (<span class=\"keyword\">default</span>,&quot;hammer&quot;,&quot;12oz carpenter&#x27;s hammer&quot;),</span><br><span class=\"line\">       (<span class=\"keyword\">default</span>,&quot;hammer&quot;,&quot;14oz carpenter&#x27;s hammer&quot;),</span><br><span class=\"line\">       (<span class=\"keyword\">default</span>,&quot;hammer&quot;,&quot;16oz carpenter&#x27;s hammer&quot;),</span><br><span class=\"line\">       (<span class=\"keyword\">default</span>,&quot;rocks&quot;,&quot;box of assorted rocks&quot;),</span><br><span class=\"line\">       (<span class=\"keyword\">default</span>,&quot;jacket&quot;,&quot;water resistent black wind breaker&quot;),</span><br><span class=\"line\">       (<span class=\"keyword\">default</span>,&quot;spare tire&quot;,&quot;24 inch spare tire&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">CREATE</span> <span class=\"keyword\">TABLE</span> orders (</span><br><span class=\"line\">  order_id <span class=\"type\">INTEGER</span> <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span> AUTO_INCREMENT <span class=\"keyword\">PRIMARY</span> KEY,</span><br><span class=\"line\">  order_date DATETIME <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  customer_name <span class=\"type\">VARCHAR</span>(<span class=\"number\">255</span>) <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  price <span class=\"type\">DECIMAL</span>(<span class=\"number\">10</span>, <span class=\"number\">5</span>) <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  product_id <span class=\"type\">INTEGER</span> <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  order_status <span class=\"type\">BOOLEAN</span> <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span> <span class=\"comment\">-- Whether order has been placed</span></span><br><span class=\"line\">) AUTO_INCREMENT <span class=\"operator\">=</span> <span class=\"number\">10001</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">INSERT</span> <span class=\"keyword\">INTO</span> orders</span><br><span class=\"line\"><span class=\"keyword\">VALUES</span> (<span class=\"keyword\">default</span>, <span class=\"string\">&#x27;2020-07-30 10:08:22&#x27;</span>, <span class=\"string\">&#x27;Jark&#x27;</span>, <span class=\"number\">50.50</span>, <span class=\"number\">102</span>, <span class=\"literal\">false</span>),</span><br><span class=\"line\">       (<span class=\"keyword\">default</span>, <span class=\"string\">&#x27;2020-07-30 10:11:09&#x27;</span>, <span class=\"string\">&#x27;Sally&#x27;</span>, <span class=\"number\">15.00</span>, <span class=\"number\">105</span>, <span class=\"literal\">false</span>),</span><br><span class=\"line\">       (<span class=\"keyword\">default</span>, <span class=\"string\">&#x27;2020-07-30 12:00:30&#x27;</span>, <span class=\"string\">&#x27;Edward&#x27;</span>, <span class=\"number\">25.25</span>, <span class=\"number\">106</span>, <span class=\"literal\">false</span>);</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>3、启动 Flink 集群和 Flink SQL CLI</p>\n<blockquote>\n<p>.&#x2F;bin&#x2F;start-cluster.sh<br>.&#x2F;bin&#x2F;sql-client.sh</p>\n</blockquote>\n</li>\n<li><p>4、在 Flink SQL CLI 中使用 Flink DDL 创建表</p>\n<blockquote>\n<p>首先，开启 checkpoint，每隔3秒做一次 checkpoint</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt;-- Flink SQL                   </span><br><span class=\"line\">&gt;Flink SQL&gt; SET execution.checkpointing.interval = 3s;</span><br></pre></td></tr></table></figure>\n\n<p>然后, 对于数据库中的表 <code>products</code>, <code>orders</code>, <code>shipments</code>， 使用 Flink SQL CLI 创建对应的表，用于同步这些底层数据库表的数据</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"> <span class=\"operator\">&gt;</span><span class=\"comment\">-- Flink SQL</span></span><br><span class=\"line\"> <span class=\"operator\">&gt;</span>Flink <span class=\"keyword\">SQL</span><span class=\"operator\">&gt;</span> <span class=\"keyword\">CREATE</span> <span class=\"keyword\">TABLE</span> products (</span><br><span class=\"line\">   id <span class=\"type\">INT</span>,</span><br><span class=\"line\">   name STRING,</span><br><span class=\"line\">   description STRING,</span><br><span class=\"line\">   <span class=\"keyword\">PRIMARY</span> KEY (id) <span class=\"keyword\">NOT</span> ENFORCED</span><br><span class=\"line\"> ) <span class=\"keyword\">WITH</span> (</span><br><span class=\"line\">   <span class=\"string\">&#x27;connector&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;mysql-cdc&#x27;</span>,</span><br><span class=\"line\">   <span class=\"string\">&#x27;hostname&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;localhost&#x27;</span>,</span><br><span class=\"line\">   <span class=\"string\">&#x27;port&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;3306&#x27;</span>,</span><br><span class=\"line\">   <span class=\"string\">&#x27;username&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;root&#x27;</span>,</span><br><span class=\"line\">   <span class=\"string\">&#x27;password&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;1234&#x27;</span>,</span><br><span class=\"line\">   <span class=\"string\">&#x27;database-name&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;mydb&#x27;</span>,</span><br><span class=\"line\">   <span class=\"string\">&#x27;table-name&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;products&#x27;</span></span><br><span class=\"line\"> );</span><br><span class=\"line\"></span><br><span class=\"line\"> <span class=\"operator\">&gt;</span>Flink <span class=\"keyword\">SQL</span><span class=\"operator\">&gt;</span> <span class=\"keyword\">CREATE</span> <span class=\"keyword\">TABLE</span> orders (</span><br><span class=\"line\">  order_id <span class=\"type\">INT</span>,</span><br><span class=\"line\">  order_date <span class=\"type\">TIMESTAMP</span>(<span class=\"number\">0</span>),</span><br><span class=\"line\">  customer_name STRING,</span><br><span class=\"line\">  price <span class=\"type\">DECIMAL</span>(<span class=\"number\">10</span>, <span class=\"number\">5</span>),</span><br><span class=\"line\">  product_id <span class=\"type\">INT</span>,</span><br><span class=\"line\">  order_status <span class=\"type\">BOOLEAN</span>,</span><br><span class=\"line\">  <span class=\"keyword\">PRIMARY</span> KEY (order_id) <span class=\"keyword\">NOT</span> ENFORCED</span><br><span class=\"line\">) <span class=\"keyword\">WITH</span> (</span><br><span class=\"line\">  <span class=\"string\">&#x27;connector&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;mysql-cdc&#x27;</span>,</span><br><span class=\"line\">  <span class=\"string\">&#x27;hostname&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;localhost&#x27;</span>,</span><br><span class=\"line\">  <span class=\"string\">&#x27;port&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;3306&#x27;</span>,</span><br><span class=\"line\">  <span class=\"string\">&#x27;username&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;root&#x27;</span>,</span><br><span class=\"line\">  <span class=\"string\">&#x27;password&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;1234&#x27;</span>,</span><br><span class=\"line\">  <span class=\"string\">&#x27;database-name&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;mydb&#x27;</span>,</span><br><span class=\"line\">  <span class=\"string\">&#x27;table-name&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;orders&#x27;</span></span><br><span class=\"line\">);</span><br></pre></td></tr></table></figure></blockquote>\n</li>\n</ul>\n<h1 id=\"SQL-Client\"><a href=\"#SQL-Client\" class=\"headerlink\" title=\"SQL Client\"></a>SQL Client</h1><ul>\n<li><p>CLI 为维护和可视化结果提供<strong>三种模式</strong>。</p>\n</li>\n<li><p><strong>表格模式</strong>（table mode）在内存中实体化结果，并将结果用规则的分页表格可视化展示出来。执行如下命令启用：</p>\n<figure class=\"highlight text\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SET &#x27;sql-client.execution.result-mode&#x27; = &#x27;table&#x27;;</span><br></pre></td></tr></table></figure>\n\n<p><strong>变更日志模式</strong>（changelog mode）不会实体化和可视化结果，而是由插入（<code>+</code>）和撤销（<code>-</code>）组成的持续查询产生结果流。</p>\n<figure class=\"highlight text\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SET &#x27;sql-client.execution.result-mode&#x27; = &#x27;changelog&#x27;;</span><br></pre></td></tr></table></figure>\n\n<p><strong>Tableau模式</strong>（tableau mode）更接近传统的数据库，会将执行的结果以制表的形式直接打在屏幕之上。具体显示的内容会取决于作业 执行模式的不同(<code>execution.type</code>)：</p>\n<figure class=\"highlight text\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SET &#x27;sql-client.execution.result-mode&#x27; = &#x27;tableau&#x27;;</span><br></pre></td></tr></table></figure></li>\n</ul>\n<h1 id=\"MySQL开启binlog\"><a href=\"#MySQL开启binlog\" class=\"headerlink\" title=\"MySQL开启binlog\"></a>MySQL开启binlog</h1><ul>\n<li><p>找到my.cnf文件</p>\n<blockquote>\n<p>mysql –help | grep ‘Default options’ -A 1</p>\n</blockquote>\n</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#第一种方式:</span></span><br><span class=\"line\"><span class=\"comment\">#开启binlog日志</span></span><br><span class=\"line\"><span class=\"string\">log_bin=ON</span></span><br><span class=\"line\"><span class=\"comment\">#binlog日志的基本文件名</span></span><br><span class=\"line\"><span class=\"string\">log_bin_basename=/var/lib/mysql/mysql-bin</span></span><br><span class=\"line\"><span class=\"comment\">#binlog文件的索引文件，管理所有binlog文件</span></span><br><span class=\"line\"><span class=\"string\">log_bin_index=/var/lib/mysql/mysql-bin.index</span></span><br><span class=\"line\"><span class=\"comment\">#配置serverid</span></span><br><span class=\"line\"><span class=\"string\">server-id=1</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#第二种方式:</span></span><br><span class=\"line\"><span class=\"comment\">#此一行等同于上面log_bin三行</span></span><br><span class=\"line\"><span class=\"string\">log-bin=/var/lib/mysql/mysql-bin</span></span><br><span class=\"line\"><span class=\"comment\">#配置serverid</span></span><br><span class=\"line\"><span class=\"string\">server-id=1</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Demo</span></span><br><span class=\"line\"><span class=\"string\">server-id=1</span></span><br><span class=\"line\"><span class=\"string\">log-bin=mysql-bin</span></span><br><span class=\"line\"><span class=\"string\">binlog_format=row</span></span><br><span class=\"line\"><span class=\"string\">binlog-do-db=mydb</span></span><br></pre></td></tr></table></figure>\n\n\n\n<h1 id=\"Code-Repo\"><a href=\"#Code-Repo\" class=\"headerlink\" title=\"Code Repo\"></a>Code Repo</h1><ul>\n<li><pre><code class=\"scala\">    // 从命令参数中读取hostname和port\n    val paramTool: ParameterTool = ParameterTool.fromArgs(args)\n    val hostname: String = paramTool.get(&quot;host&quot;)\n    val port: Int = paramTool.getInt(&quot;port&quot;)\n</code></pre>\n</li>\n</ul>\n","site":{"data":{"link":[{"class_name":"友情链接","class_desc":"那些人，那些事","link_list":[{"name":"张洪Heo","link":"https://blog.zhheo.com/","avatar":"https://npm.elemecdn.com/guli-heo/img/avatar2.png","descr":"分享设计与科技生活"},{"name":"瞬間の筆記","link":"https://hikki.site","descr":"喜欢的东西就努力去追求，万一成功了呢!","avatar":"https://cdn.jsdelivr.net/gh/0000rookie/imgs/202206120315.png"}]}]}},"excerpt":"","more":"<h1 id=\"QuickStart\"><a href=\"#QuickStart\" class=\"headerlink\" title=\"QuickStart\"></a>QuickStart</h1><ul>\n<li><p>Table API 和 SQL 需要引入的依赖有两个：planner 和 bridge。</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.flink<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>flink-table-api-scala-bridge_$&#123;scala.version&#125;<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>$&#123;flink.version&#125;<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.flink<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>flink-table-planner_$&#123;scala.version&#125;<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>$&#123;flink.version&#125;<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><blockquote>\n<p>老版本planner已经被废除，只剩下blink</p>\n<p>The old planner has been removed in Flink 1.14. Please upgrade your table program to use the default planner (previously called the ‘blink’ planner).</p>\n</blockquote>\n</li>\n</ul>\n<h1 id=\"Flink-CDC-SQL-Demo\"><a href=\"#Flink-CDC-SQL-Demo\" class=\"headerlink\" title=\"Flink CDC SQL Demo\"></a>Flink CDC SQL Demo</h1><ul>\n<li><p>1、下载Flink，下载<code>flink-sql-connector-mysql-cdc-2.3-SNAPSHOT.jar</code>依赖包，并将它们放到目录 <code>&#123;flink_home&#125;/lib/</code> 下.</p>\n</li>\n<li><p>2、在 MySQL 数据库中准备数据，创建数据库和表 <code>products</code>，<code>orders</code>，并插入数据</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">-- MySQL</span></span><br><span class=\"line\"><span class=\"keyword\">CREATE</span> DATABASE mydb;</span><br><span class=\"line\">USE mydb;</span><br><span class=\"line\"><span class=\"keyword\">CREATE</span> <span class=\"keyword\">TABLE</span> products (</span><br><span class=\"line\">  id <span class=\"type\">INTEGER</span> <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span> AUTO_INCREMENT <span class=\"keyword\">PRIMARY</span> KEY,</span><br><span class=\"line\">  name <span class=\"type\">VARCHAR</span>(<span class=\"number\">255</span>) <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  description <span class=\"type\">VARCHAR</span>(<span class=\"number\">512</span>)</span><br><span class=\"line\">);</span><br><span class=\"line\"><span class=\"keyword\">ALTER</span> <span class=\"keyword\">TABLE</span> products AUTO_INCREMENT <span class=\"operator\">=</span> <span class=\"number\">101</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">INSERT</span> <span class=\"keyword\">INTO</span> products</span><br><span class=\"line\"><span class=\"keyword\">VALUES</span> (<span class=\"keyword\">default</span>,&quot;scooter&quot;,&quot;Small 2-wheel scooter&quot;),</span><br><span class=\"line\">       (<span class=\"keyword\">default</span>,&quot;car battery&quot;,&quot;12V car battery&quot;),</span><br><span class=\"line\">       (<span class=\"keyword\">default</span>,&quot;12-pack drill bits&quot;,&quot;12-pack of drill bits with sizes ranging from #40 to #3&quot;),</span><br><span class=\"line\">       (<span class=\"keyword\">default</span>,&quot;hammer&quot;,&quot;12oz carpenter&#x27;s hammer&quot;),</span><br><span class=\"line\">       (<span class=\"keyword\">default</span>,&quot;hammer&quot;,&quot;14oz carpenter&#x27;s hammer&quot;),</span><br><span class=\"line\">       (<span class=\"keyword\">default</span>,&quot;hammer&quot;,&quot;16oz carpenter&#x27;s hammer&quot;),</span><br><span class=\"line\">       (<span class=\"keyword\">default</span>,&quot;rocks&quot;,&quot;box of assorted rocks&quot;),</span><br><span class=\"line\">       (<span class=\"keyword\">default</span>,&quot;jacket&quot;,&quot;water resistent black wind breaker&quot;),</span><br><span class=\"line\">       (<span class=\"keyword\">default</span>,&quot;spare tire&quot;,&quot;24 inch spare tire&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">CREATE</span> <span class=\"keyword\">TABLE</span> orders (</span><br><span class=\"line\">  order_id <span class=\"type\">INTEGER</span> <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span> AUTO_INCREMENT <span class=\"keyword\">PRIMARY</span> KEY,</span><br><span class=\"line\">  order_date DATETIME <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  customer_name <span class=\"type\">VARCHAR</span>(<span class=\"number\">255</span>) <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  price <span class=\"type\">DECIMAL</span>(<span class=\"number\">10</span>, <span class=\"number\">5</span>) <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  product_id <span class=\"type\">INTEGER</span> <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  order_status <span class=\"type\">BOOLEAN</span> <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span> <span class=\"comment\">-- Whether order has been placed</span></span><br><span class=\"line\">) AUTO_INCREMENT <span class=\"operator\">=</span> <span class=\"number\">10001</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">INSERT</span> <span class=\"keyword\">INTO</span> orders</span><br><span class=\"line\"><span class=\"keyword\">VALUES</span> (<span class=\"keyword\">default</span>, <span class=\"string\">&#x27;2020-07-30 10:08:22&#x27;</span>, <span class=\"string\">&#x27;Jark&#x27;</span>, <span class=\"number\">50.50</span>, <span class=\"number\">102</span>, <span class=\"literal\">false</span>),</span><br><span class=\"line\">       (<span class=\"keyword\">default</span>, <span class=\"string\">&#x27;2020-07-30 10:11:09&#x27;</span>, <span class=\"string\">&#x27;Sally&#x27;</span>, <span class=\"number\">15.00</span>, <span class=\"number\">105</span>, <span class=\"literal\">false</span>),</span><br><span class=\"line\">       (<span class=\"keyword\">default</span>, <span class=\"string\">&#x27;2020-07-30 12:00:30&#x27;</span>, <span class=\"string\">&#x27;Edward&#x27;</span>, <span class=\"number\">25.25</span>, <span class=\"number\">106</span>, <span class=\"literal\">false</span>);</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>3、启动 Flink 集群和 Flink SQL CLI</p>\n<blockquote>\n<p>.&#x2F;bin&#x2F;start-cluster.sh<br>.&#x2F;bin&#x2F;sql-client.sh</p>\n</blockquote>\n</li>\n<li><p>4、在 Flink SQL CLI 中使用 Flink DDL 创建表</p>\n<blockquote>\n<p>首先，开启 checkpoint，每隔3秒做一次 checkpoint</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt;-- Flink SQL                   </span><br><span class=\"line\">&gt;Flink SQL&gt; SET execution.checkpointing.interval = 3s;</span><br></pre></td></tr></table></figure>\n\n<p>然后, 对于数据库中的表 <code>products</code>, <code>orders</code>, <code>shipments</code>， 使用 Flink SQL CLI 创建对应的表，用于同步这些底层数据库表的数据</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"> <span class=\"operator\">&gt;</span><span class=\"comment\">-- Flink SQL</span></span><br><span class=\"line\"> <span class=\"operator\">&gt;</span>Flink <span class=\"keyword\">SQL</span><span class=\"operator\">&gt;</span> <span class=\"keyword\">CREATE</span> <span class=\"keyword\">TABLE</span> products (</span><br><span class=\"line\">   id <span class=\"type\">INT</span>,</span><br><span class=\"line\">   name STRING,</span><br><span class=\"line\">   description STRING,</span><br><span class=\"line\">   <span class=\"keyword\">PRIMARY</span> KEY (id) <span class=\"keyword\">NOT</span> ENFORCED</span><br><span class=\"line\"> ) <span class=\"keyword\">WITH</span> (</span><br><span class=\"line\">   <span class=\"string\">&#x27;connector&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;mysql-cdc&#x27;</span>,</span><br><span class=\"line\">   <span class=\"string\">&#x27;hostname&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;localhost&#x27;</span>,</span><br><span class=\"line\">   <span class=\"string\">&#x27;port&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;3306&#x27;</span>,</span><br><span class=\"line\">   <span class=\"string\">&#x27;username&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;root&#x27;</span>,</span><br><span class=\"line\">   <span class=\"string\">&#x27;password&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;1234&#x27;</span>,</span><br><span class=\"line\">   <span class=\"string\">&#x27;database-name&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;mydb&#x27;</span>,</span><br><span class=\"line\">   <span class=\"string\">&#x27;table-name&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;products&#x27;</span></span><br><span class=\"line\"> );</span><br><span class=\"line\"></span><br><span class=\"line\"> <span class=\"operator\">&gt;</span>Flink <span class=\"keyword\">SQL</span><span class=\"operator\">&gt;</span> <span class=\"keyword\">CREATE</span> <span class=\"keyword\">TABLE</span> orders (</span><br><span class=\"line\">  order_id <span class=\"type\">INT</span>,</span><br><span class=\"line\">  order_date <span class=\"type\">TIMESTAMP</span>(<span class=\"number\">0</span>),</span><br><span class=\"line\">  customer_name STRING,</span><br><span class=\"line\">  price <span class=\"type\">DECIMAL</span>(<span class=\"number\">10</span>, <span class=\"number\">5</span>),</span><br><span class=\"line\">  product_id <span class=\"type\">INT</span>,</span><br><span class=\"line\">  order_status <span class=\"type\">BOOLEAN</span>,</span><br><span class=\"line\">  <span class=\"keyword\">PRIMARY</span> KEY (order_id) <span class=\"keyword\">NOT</span> ENFORCED</span><br><span class=\"line\">) <span class=\"keyword\">WITH</span> (</span><br><span class=\"line\">  <span class=\"string\">&#x27;connector&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;mysql-cdc&#x27;</span>,</span><br><span class=\"line\">  <span class=\"string\">&#x27;hostname&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;localhost&#x27;</span>,</span><br><span class=\"line\">  <span class=\"string\">&#x27;port&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;3306&#x27;</span>,</span><br><span class=\"line\">  <span class=\"string\">&#x27;username&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;root&#x27;</span>,</span><br><span class=\"line\">  <span class=\"string\">&#x27;password&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;1234&#x27;</span>,</span><br><span class=\"line\">  <span class=\"string\">&#x27;database-name&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;mydb&#x27;</span>,</span><br><span class=\"line\">  <span class=\"string\">&#x27;table-name&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;orders&#x27;</span></span><br><span class=\"line\">);</span><br></pre></td></tr></table></figure></blockquote>\n</li>\n</ul>\n<h1 id=\"SQL-Client\"><a href=\"#SQL-Client\" class=\"headerlink\" title=\"SQL Client\"></a>SQL Client</h1><ul>\n<li><p>CLI 为维护和可视化结果提供<strong>三种模式</strong>。</p>\n</li>\n<li><p><strong>表格模式</strong>（table mode）在内存中实体化结果，并将结果用规则的分页表格可视化展示出来。执行如下命令启用：</p>\n<figure class=\"highlight text\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SET &#x27;sql-client.execution.result-mode&#x27; = &#x27;table&#x27;;</span><br></pre></td></tr></table></figure>\n\n<p><strong>变更日志模式</strong>（changelog mode）不会实体化和可视化结果，而是由插入（<code>+</code>）和撤销（<code>-</code>）组成的持续查询产生结果流。</p>\n<figure class=\"highlight text\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SET &#x27;sql-client.execution.result-mode&#x27; = &#x27;changelog&#x27;;</span><br></pre></td></tr></table></figure>\n\n<p><strong>Tableau模式</strong>（tableau mode）更接近传统的数据库，会将执行的结果以制表的形式直接打在屏幕之上。具体显示的内容会取决于作业 执行模式的不同(<code>execution.type</code>)：</p>\n<figure class=\"highlight text\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SET &#x27;sql-client.execution.result-mode&#x27; = &#x27;tableau&#x27;;</span><br></pre></td></tr></table></figure></li>\n</ul>\n<h1 id=\"MySQL开启binlog\"><a href=\"#MySQL开启binlog\" class=\"headerlink\" title=\"MySQL开启binlog\"></a>MySQL开启binlog</h1><ul>\n<li><p>找到my.cnf文件</p>\n<blockquote>\n<p>mysql –help | grep ‘Default options’ -A 1</p>\n</blockquote>\n</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#第一种方式:</span></span><br><span class=\"line\"><span class=\"comment\">#开启binlog日志</span></span><br><span class=\"line\"><span class=\"string\">log_bin=ON</span></span><br><span class=\"line\"><span class=\"comment\">#binlog日志的基本文件名</span></span><br><span class=\"line\"><span class=\"string\">log_bin_basename=/var/lib/mysql/mysql-bin</span></span><br><span class=\"line\"><span class=\"comment\">#binlog文件的索引文件，管理所有binlog文件</span></span><br><span class=\"line\"><span class=\"string\">log_bin_index=/var/lib/mysql/mysql-bin.index</span></span><br><span class=\"line\"><span class=\"comment\">#配置serverid</span></span><br><span class=\"line\"><span class=\"string\">server-id=1</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#第二种方式:</span></span><br><span class=\"line\"><span class=\"comment\">#此一行等同于上面log_bin三行</span></span><br><span class=\"line\"><span class=\"string\">log-bin=/var/lib/mysql/mysql-bin</span></span><br><span class=\"line\"><span class=\"comment\">#配置serverid</span></span><br><span class=\"line\"><span class=\"string\">server-id=1</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Demo</span></span><br><span class=\"line\"><span class=\"string\">server-id=1</span></span><br><span class=\"line\"><span class=\"string\">log-bin=mysql-bin</span></span><br><span class=\"line\"><span class=\"string\">binlog_format=row</span></span><br><span class=\"line\"><span class=\"string\">binlog-do-db=mydb</span></span><br></pre></td></tr></table></figure>\n\n\n\n<h1 id=\"Code-Repo\"><a href=\"#Code-Repo\" class=\"headerlink\" title=\"Code Repo\"></a>Code Repo</h1><ul>\n<li><pre><code class=\"scala\">    // 从命令参数中读取hostname和port\n    val paramTool: ParameterTool = ParameterTool.fromArgs(args)\n    val hostname: String = paramTool.get(&quot;host&quot;)\n    val port: Int = paramTool.getInt(&quot;port&quot;)\n</code></pre>\n</li>\n</ul>\n"},{"title":"初识Doris","top_img":"linear-gradient(20deg, #0062be, #925696, #cc426e, #fb0347)","date":"2022-07-22T22:19:04.000Z","updated":"2022-07-22T22:19:04.000Z","cover":"https://tvax4.sinaimg.cn/large/0084aYsLgy1h3jum72m7kj31220e6jsc.jpg","description":null,"keywords":null,"_content":"\n>- MPP（ Massively Parallel Processing - 大规模并行处理）Based高性能、实时的分析型数据库。\n>\n>- 在**使用接口**方面，Doris 采用 MySQ L 协议，高度兼容 MySQL 语法，支持标准 SQL，用户可以通过各类客户端工具来访问 Doris，并支持与 BI 工具的无缝对接。\n>\n>- 在**存储引擎**方面，Doris 采用列式存储，按列进行数据的编码压缩和读取，能够实现极高的压缩比，同时减少大量非相关数据的扫描，从而更加有效利用 IO 和 CPU 资源。\n>\n>- 在**查询引擎**方面，Doris 采用 MPP 的模型，节点间和节点内都并行执行，也支持多个大表的分布式 Shuffle Join，从而能够更好应对复杂查询。\n>\n>  ![origin_img_v2_cee507bd-d6ed-4359-9e52-51e9b8458f8g](https://doris.apache.org/zh-CN/assets/images/origin_img_v2_cee507bd-d6ed-4359-9e52-51e9b8458f8g-cd4a2a172ec93222a40231fe1a8d4edd.png)\n>\n>- **Doris 查询引擎是向量化**的查询引擎，所有的内存结构能够按照列式布局，能够达到大幅减少虚函数调用、提升 Cache 命中率，高效利用 SIMD 指令的效果。在宽表聚合场景下性能是非向量化引擎的 5-10 倍。\n>\n>  ![origin_img_v2_ad65aae9-9ed0-463e-a34c-94e32b092a4g](https://doris.apache.org/zh-CN/assets/images/origin_img_v2_ad65aae9-9ed0-463e-a34c-94e32b092a4g-84273f42ae82408ff09c7af6c5b67022.png)\n>\n>- **Doris 采用了 Adaptive Query Execution 技术，** 可以根据 Runtime Statistics 来动态调整执行计划，比如通过 Runtime Filter 技术能够在运行时生成生成 Filter 推到 Probe 侧，并且能够将 Filter 自动穿透到 Probe 侧最底层的 Scan 节点，从而大幅减少 Probe 的数据量，加速 Join 性能。Doris 的 Runtime Filter 支持 In/Min/Max/Bloom Filter。\n>\n>- 在**优化器**方面 Doris 使用 CBO 和 RBO 结合的优化策略，RBO 支持常量折叠、子查询改写、谓词下推等，CBO 支持 Join Reorder。目前 CBO 还在持续优化中，主要集中在更加精准的统计信息收集和推导，更加精准的代价模型预估等方面。\n>\n>- **Doris 也支持强一致的物化视图**，物化视图的更新和选择都在系统内自动进行，不需要用户手动选择，从而大幅减少了物化视图维护的代价。\n>\n>- **Doris 也支持比较丰富的索引结构，来减少数据的扫描**\n\n------\n\n>- Doris 数据模型上目前分为三类: AGGREGATE KEY, UNIQUE KEY, DUPLICATE KEY。**三种模型中数据都是按KEY进行排序。**\n>\n>- AGGREGATE KEY\n>\n>  AGGREGATE KEY相同时，新旧记录进行聚合，目前支持的聚合函数有SUM, MIN, MAX, REPLACE。\n>\n>  AGGREGATE KEY模型可以提前聚合数据, 适合报表和多维分析业务。\n>\n>- UNIQUE KEY\n>\n>  UNIQUE KEY 相同时，新记录覆盖旧记录。目前 UNIQUE KEY 实现上和 AGGREGATE KEY 的 REPLACE 聚合方法一样，二者本质上相同。适用于有更新需求的分析业务。\n>\n>- DUPLICATE KEY\n>\n>  只指定排序列，相同的行不会合并。适用于数据无需提前聚合的分析业务。\n\n------\n\n>Doris**整体架构**如下图所示，Doris 架构非常简单，只有两类进程\n>\n>- **Frontend（FE）**，主要负责用户请求的接入、查询解析规划、元数据的管理、节点管理相关工作。\n>- **另一个是 Backend（BE）**，主要负责数据存储、查询计划的执行。\n>\n>这两类进程都是可以横向扩展的，单集群可以支持到数百台机器，数十 PB 的存储容量。并且这两类进程通过一致性协议来保证服务的高可用和数据的高可靠。这种高度集成的架构设计极大的降低了一款分布式系统的运维成本。\n>\n>![origin_img_v2_28d005e1-21d6-4801-956f-0c06373a7a9g](https://doris.apache.org/zh-CN/assets/images/origin_img_v2_28d005e1-21d6-4801-956f-0c06373a7a9g-11e2c3e5c6b6dc26b4f602697a1071a9.png)\n\n## 建表语句\n\n- Range Partition\n\n  ```sql\n  CREATE TABLE IF NOT EXISTS example_db.expamle_range_tbl\n  (\n   `user_id` LARGEINT NOT NULL COMMENT \"用户 id\",\n   `date` DATE NOT NULL COMMENT \"数据灌入日期时间\",\n   `timestamp` DATETIME NOT NULL COMMENT \"数据灌入的时间戳\",\n   `city` VARCHAR(20) COMMENT \"用户所在城市\",\n   `age` SMALLINT COMMENT \"用户年龄\",\n   `sex` TINYINT COMMENT \"用户性别\",\n   `last_visit_date` DATETIME REPLACE DEFAULT \"1970-01-01 \n  00:00:00\" COMMENT \"用户最后一次访问时间\",\n   `cost` BIGINT SUM DEFAULT \"0\" COMMENT \"用户总消费\",\n   `max_dwell_time` INT MAX DEFAULT \"0\" COMMENT \"用户最大停留时间\",\n   `min_dwell_time` INT MIN DEFAULT \"99999\" COMMENT \"用户最小停留时间\"\n  )\n  ENGINE=olap\n  AGGREGATE KEY(`user_id`, `date`, `timestamp`, `city`, `age`, `sex`)\n  PARTITION BY RANGE(`date`)\n  (\n   PARTITION `p201701` VALUES LESS THAN (\"2017-02-01\"),\n   PARTITION `p201702` VALUES LESS THAN (\"2017-03-01\"),\n   PARTITION `p201703` VALUES LESS THAN (\"2017-04-01\")\n  )\n  DISTRIBUTED BY HASH(`user_id`) BUCKETS 16\n  PROPERTIES\n  (\n   \"replication_num\" = \"3\",\n   \"storage_medium\" = \"SSD\",\n   \"storage_cooldown_time\" = \"2018-01-01 12:00:00\"\n  );\n  \n  ```\n\n- List Partition\n\n  ```sql\n  CREATE TABLE IF NOT EXISTS example_db.expamle_list_tbl\n  (\n   `user_id` LARGEINT NOT NULL COMMENT \"用户 id\",\n   `date` DATE NOT NULL COMMENT \"数据灌入日期时间\",\n   `timestamp` DATETIME NOT NULL COMMENT \"数据灌入的时间戳\",\n   `city` VARCHAR(20) COMMENT \"用户所在城市\",\n   `age` SMALLINT COMMENT \"用户年龄\",\n   `sex` TINYINT COMMENT \"用户性别\",\n   `last_visit_date` DATETIME REPLACE DEFAULT \"1970-01-01 \n  00:00:00\" COMMENT \"用户最后一次访问时间\",\n   `cost` BIGINT SUM DEFAULT \"0\" COMMENT \"用户总消费\",\n   `max_dwell_time` INT MAX DEFAULT \"0\" COMMENT \"用户最大停留时间\",\n   `min_dwell_time` INT MIN DEFAULT \"99999\" COMMENT \"用户最小停留时\n  间\"\n  )\n  ENGINE=olap\n  AGGREGATE KEY(`user_id`, `date`, `timestamp`, `city`, `age`, `sex`)\n  PARTITION BY LIST(`city`)\n  (\n   PARTITION `p_cn` VALUES IN (\"Beijing\", \"Shanghai\", \"Hong Kong\"),\n   PARTITION `p_usa` VALUES IN (\"New York\", \"San Francisco\"),\n   PARTITION `p_jp` VALUES IN (\"Tokyo\")\n  )\n  DISTRIBUTED BY HASH(`user_id`) BUCKETS 16\n  PROPERTIES\n  (\n   \"replication_num\" = \"3\",\n   \"storage_medium\" = \"SSD\",\n   \"storage_cooldown_time\" = \"2018-01-01 12:00:00\"\n  );\n  ```\n\n  \n\n## 数据模型\n\nDoris 的数据模型主要分为 3 类：Aggregate、Uniq、Duplicate\n\n### Aggregate 模型\n\n表中的列按照是否设置了 AggregationType，分为 Key（维度列）和 Value（指标列）。没有设置 AggregationType 的称为 Key，设置了 AggregationType 的称为 Value。\n当我们导入数据时，对于 Key 列相同的行会聚合成一行，而 Value 列会按照设置的AggregationType 进行聚合。AggregationType 目前有以下四种聚合方式：\n\n- ➢ SUM：求和，多行的 Value 进行累加。\n- ➢ REPLACE：替代，下一批数据中的 Value 会替换之前导入过的行中的 Value。\n     REPLACE_IF_NOT_NULL ：当遇到 null 值则不更新。\n- ➢ MAX：保留最大值。\n- ➢ MIN：保留最小值。\n\n数据的聚合，在 Doris 中有如下三个阶段发生：\n- （1）每一批次数据导入的 ETL 阶段。该阶段会在每一批次导入的数据内部进行聚合。\n- （2）底层 BE 进行数据 Compaction 的阶段。该阶段，BE 会对已导入的不同批次的数据进行进一步的聚合。\n- （3）数据查询阶段。在数据查询时，对于查询涉及到的数据，会进行对应的聚合。\n\n数据在不同时间，可能聚合的程度不一致。比如一批数据刚导入时，可能还未与之前已存在的数据进行聚合。但是对于用户而言，用户只能查询到聚合后的数据。即不同的聚合程度对于用户查询而言是透明的。用户需始终认为数据以最终的完成的聚合程度存在，而不应假设某些聚合还未发生。（可参阅聚合模型的局限性一节获得更多详情。）\n\n### Uniq 模型\n\n在某些多维分析场景下，用户更关注的是如何保证 Key 的唯一性，即如何获得 Primary  Key 唯一性约束。因此，我们引入了 Uniq 的数据模型。该模型本质上是聚合模型的一个特 例，也是一种简化的表结构表示方式。\n\nUniq 模型完全可以用聚合模型中的 REPLACE 方式替代。其内部的实现方式和数据存 储方式也完全一样。\n\n### Duplicate 模型\n\n在某些多维分析场景下，数据既没有主键，也没有聚合需求。Duplicate 数据模型可以 满足这类需求。数据完全按照导入文件中的数据进行存储，不会有任何聚合。即使两行数据 完全相同，也都会保留。 而在建表语句中指定的 `DUPLICATE KEY`，只是用来指明底层数 据按照那些列进行排序。\n\n### 数据模型的选择建议\n\n因为数据模型在建表时就已经确定，且无法修改。所以，选择一个合适的数据模型非常 重要。 \n\n（1）Aggregate 模型可以通过预聚合，极大地降低聚合查询时所需扫描的数据量和查询 的计算量，非常适合有固定模式的报表类查询场景。但是该模型对 count(*) 查询很不友好。 **同时因为固定了 Value 列上的聚合方式，在进行其他类型的聚合查询时，需要考虑语意正确 性。**\n\n（2）Uniq 模型针对需要唯一主键约束的场景，可以保证主键唯一性约束。**但是无法利 用 ROLLUP 等预聚合带来的查询优势（因为本质是 REPLACE，没有 SUM 这种聚合方式）。** \n\n（3）Duplicate 适合任意维度的 Ad-hoc 查询。虽然同样无法利用预聚合的特性，但是不 受聚合模型的约束，可以发挥列存模型的优势（只读取相关列，而不需要读取所有 Key 列）\n\n## Rollup\n\nROLLUP 在多维分析中是“上卷”的意思，即将数据按某种指定的粒度进行进一步聚 合。\n\n### 基本概念\n\n在 Doris 中，我们将用户通过建表语句创建出来的表称为 Base 表（Base Table）。Base  表中保存着按用户建表语句指定的方式存储的基础数据。 \n\n在 Base 表之上，我们可以创建任意多个 ROLLUP 表。这些 ROLLUP 的数据是基于 Base  表产生的，并且在物理上是独立存储的。 ROLLUP 表的基本作用，在于在 Base 表的基础上，获得更粗粒度的聚合数据\n\n###  Duplicate 模型中的 ROLLUP\n\n因为 Duplicate 模型没有聚合的语意。所以该模型中的 ROLLUP，已经失去了“上卷” 这一层含义。而仅仅是作为调整列顺序，以命中前缀索引的作用。下面详细介绍前缀索引， 以及如何使用 ROLLUP 改变前缀索引，以获得更好的查询效率。\n\n#### 前缀索引\n\n不同于传统的数据库设计，Doris 不支持在任意列上创建索引。Doris 这类 MPP 架构的 OLAP 数据库，通常都是通过提高并发，来处理大量数据的。 \n\n本质上，Doris 的数据存储在类似 SSTable（Sorted String Table）的数据结构中。该结构 是一种有序的数据结构，可以按照指定的列进行排序存储。在这种数据结构上，以排序列作 为条件进行查找，会非常的高效。 \n\n在 Aggregate、Uniq 和 Duplicate 三种数据模型中。底层的数据存储，是按照各自建表 语句中，AGGREGATE KEY、UNIQ KEY 和 DUPLICATE KEY 中指定的列进行排序存储 的。而**前缀索引，即在排序的基础上，实现的一种根据给定前缀列，快速查询数据的索引方 式。**\n\n#### ROLLUP 调整前缀索引\n\n因为建表时已经指定了列顺序，所以一个表只有一种前缀索引。这对于使用其他不能命 中前缀索引的列作为条件进行的查询来说，效率上可能无法满足需求。因此，我们可以通过 创建 ROLLUP 来人为的调整列顺序。举例说明。\n\n### ROLLUP 的几点说明\n\n⚫ ROLLUP 最根本的作用是提高某些查询的查询效率（无论是通过聚合来减少数据 量，还是修改列顺序以匹配前缀索引）。因此 ROLLUP 的含义已经超出了“上卷” 的范围。这也是为什么在源代码中，将其命名为 Materialized Index（物化索引）的 原因。\n\n⚫ ROLLUP 是附属于 Base 表的，可以看做是 Base 表的一种辅助数据结构。用户可以 在 Base 表的基础上，创建或删除 ROLLUP，但是不能在查询中显式的指定查询某 ROLLUP。是否命中 ROLLUP 完全由 Doris 系统自动决定。 \n\n⚫ ROLLUP 的数据是独立物理存储的。因此，创建的 ROLLUP 越多，占用的磁盘空 间也就越大。同时对导入速度也会有影响（导入的 ETL 阶段会自动产生所有 ROLLUP 的数据），但是不会降低查询效率（只会更好）。 \n\n⚫ ROLLUP 的数据更新与 Base 表是完全同步的。用户无需关心这个问题。\n\n⚫ ROLLUP 中列的聚合方式，与 Base 表完全相同。在创建 ROLLUP 无需指定，也不 能修改。 \n\n⚫ 查询能否命中 ROLLUP 的一个必要条件（非充分条件）是，查询所涉及的所有列 （包括 select list 和 where 中的查询条件列等）都存在于该 ROLLUP 的列中。否 则，查询只能命中 Base 表。 \n\n⚫ 某些类型的查询（如 count(*)）在任何条件下，都无法命中 ROLLUP。具体参见接 下来的聚合模型的局限性一节。\n\n⚫ 可以通过 EXPLAIN your_sql; 命令获得查询执行计划，在执行计划中，查看是否命 中 ROLLUP。\n\n⚫ 可以通过 DESC tbl_name ALL; 语句显示 Base 表和所有已创建完成的 ROLLUP。\n\n\n\n## 物化视图\n\n物化视图就是包含了查询结果的数据库对象，可能是对远程数据的本地 copy，也可能 是一个表或多表 join 后结果的行或列的子集，也可能是聚合后的结果。说白了，就是预先存 储查询结果的一种数据库对象。\n\n在 Doris 中的物化视图，就是查询结果预先存储起来的特殊的表。 \n\n物化视图的出现主要是为了满足用户，既能对原始明细数据的任意维度分析，也能快速 的对固定维度进行分析查询。\n\n### 优势\n\n⚫ 对于那些经常重复的使用相同的子查询结果的查询性能大幅提升。 \n\n⚫ Doris 自动维护物化视图的数据，无论是新的导入，还是删除操作都能保证 base 表 和物化视图表的数据一致性。无需任何额外的人工维护成本。 \n\n⚫ 查询时，会自动匹配到最优物化视图，并直接从物化视图中读取数据。 自动维护物化视图的数据会造成一些维护开销，会在后面的物化视图的局限性中展开说 明。\n\n### 物化视图 VS Rollup\n\n在没有物化视图功能之前，用户一般都是使用 Rollup 功能通过预聚合方式提升查询效 率的。但是 Rollup 具有一定的局限性，他不能基于明细模型做预聚合。 \n\n物化视图则在覆盖了 Rollup 的功能的同时，还能支持更丰富的聚合函数。所以物化视 图其实是 Rollup 的一个超集。 \n\n也就是说，之前 ALTER TABLE ADD ROLLUP 语法支持的功能现在均可以通过 CREATE MATERIALIZED VIEW 实现。\n\n### 物化视图原理\n\nDoris 系统提供了一整套对物化视图的 DDL 语法，包括创建，查看，删除。DDL 的语 法和 PostgreSQL, Oracle 都是一致的。但是 Doris 目前创建物化视图只能在单表操作，不支 持 join。\n","source":"_posts/bigdata/初识Doris.md","raw":"---\ntitle: 初识Doris\ntags:\n  - 'Doris'\ncategories:\n  - [bigdata,Doris]\ntop_img: 'linear-gradient(20deg, #0062be, #925696, #cc426e, #fb0347)'\ndate: 2022-07-23 06:19:04\nupdated: 2022-07-23 06:19:04\ncover:\ndescription:\nkeywords:\n---\n\n>- MPP（ Massively Parallel Processing - 大规模并行处理）Based高性能、实时的分析型数据库。\n>\n>- 在**使用接口**方面，Doris 采用 MySQ L 协议，高度兼容 MySQL 语法，支持标准 SQL，用户可以通过各类客户端工具来访问 Doris，并支持与 BI 工具的无缝对接。\n>\n>- 在**存储引擎**方面，Doris 采用列式存储，按列进行数据的编码压缩和读取，能够实现极高的压缩比，同时减少大量非相关数据的扫描，从而更加有效利用 IO 和 CPU 资源。\n>\n>- 在**查询引擎**方面，Doris 采用 MPP 的模型，节点间和节点内都并行执行，也支持多个大表的分布式 Shuffle Join，从而能够更好应对复杂查询。\n>\n>  ![origin_img_v2_cee507bd-d6ed-4359-9e52-51e9b8458f8g](https://doris.apache.org/zh-CN/assets/images/origin_img_v2_cee507bd-d6ed-4359-9e52-51e9b8458f8g-cd4a2a172ec93222a40231fe1a8d4edd.png)\n>\n>- **Doris 查询引擎是向量化**的查询引擎，所有的内存结构能够按照列式布局，能够达到大幅减少虚函数调用、提升 Cache 命中率，高效利用 SIMD 指令的效果。在宽表聚合场景下性能是非向量化引擎的 5-10 倍。\n>\n>  ![origin_img_v2_ad65aae9-9ed0-463e-a34c-94e32b092a4g](https://doris.apache.org/zh-CN/assets/images/origin_img_v2_ad65aae9-9ed0-463e-a34c-94e32b092a4g-84273f42ae82408ff09c7af6c5b67022.png)\n>\n>- **Doris 采用了 Adaptive Query Execution 技术，** 可以根据 Runtime Statistics 来动态调整执行计划，比如通过 Runtime Filter 技术能够在运行时生成生成 Filter 推到 Probe 侧，并且能够将 Filter 自动穿透到 Probe 侧最底层的 Scan 节点，从而大幅减少 Probe 的数据量，加速 Join 性能。Doris 的 Runtime Filter 支持 In/Min/Max/Bloom Filter。\n>\n>- 在**优化器**方面 Doris 使用 CBO 和 RBO 结合的优化策略，RBO 支持常量折叠、子查询改写、谓词下推等，CBO 支持 Join Reorder。目前 CBO 还在持续优化中，主要集中在更加精准的统计信息收集和推导，更加精准的代价模型预估等方面。\n>\n>- **Doris 也支持强一致的物化视图**，物化视图的更新和选择都在系统内自动进行，不需要用户手动选择，从而大幅减少了物化视图维护的代价。\n>\n>- **Doris 也支持比较丰富的索引结构，来减少数据的扫描**\n\n------\n\n>- Doris 数据模型上目前分为三类: AGGREGATE KEY, UNIQUE KEY, DUPLICATE KEY。**三种模型中数据都是按KEY进行排序。**\n>\n>- AGGREGATE KEY\n>\n>  AGGREGATE KEY相同时，新旧记录进行聚合，目前支持的聚合函数有SUM, MIN, MAX, REPLACE。\n>\n>  AGGREGATE KEY模型可以提前聚合数据, 适合报表和多维分析业务。\n>\n>- UNIQUE KEY\n>\n>  UNIQUE KEY 相同时，新记录覆盖旧记录。目前 UNIQUE KEY 实现上和 AGGREGATE KEY 的 REPLACE 聚合方法一样，二者本质上相同。适用于有更新需求的分析业务。\n>\n>- DUPLICATE KEY\n>\n>  只指定排序列，相同的行不会合并。适用于数据无需提前聚合的分析业务。\n\n------\n\n>Doris**整体架构**如下图所示，Doris 架构非常简单，只有两类进程\n>\n>- **Frontend（FE）**，主要负责用户请求的接入、查询解析规划、元数据的管理、节点管理相关工作。\n>- **另一个是 Backend（BE）**，主要负责数据存储、查询计划的执行。\n>\n>这两类进程都是可以横向扩展的，单集群可以支持到数百台机器，数十 PB 的存储容量。并且这两类进程通过一致性协议来保证服务的高可用和数据的高可靠。这种高度集成的架构设计极大的降低了一款分布式系统的运维成本。\n>\n>![origin_img_v2_28d005e1-21d6-4801-956f-0c06373a7a9g](https://doris.apache.org/zh-CN/assets/images/origin_img_v2_28d005e1-21d6-4801-956f-0c06373a7a9g-11e2c3e5c6b6dc26b4f602697a1071a9.png)\n\n## 建表语句\n\n- Range Partition\n\n  ```sql\n  CREATE TABLE IF NOT EXISTS example_db.expamle_range_tbl\n  (\n   `user_id` LARGEINT NOT NULL COMMENT \"用户 id\",\n   `date` DATE NOT NULL COMMENT \"数据灌入日期时间\",\n   `timestamp` DATETIME NOT NULL COMMENT \"数据灌入的时间戳\",\n   `city` VARCHAR(20) COMMENT \"用户所在城市\",\n   `age` SMALLINT COMMENT \"用户年龄\",\n   `sex` TINYINT COMMENT \"用户性别\",\n   `last_visit_date` DATETIME REPLACE DEFAULT \"1970-01-01 \n  00:00:00\" COMMENT \"用户最后一次访问时间\",\n   `cost` BIGINT SUM DEFAULT \"0\" COMMENT \"用户总消费\",\n   `max_dwell_time` INT MAX DEFAULT \"0\" COMMENT \"用户最大停留时间\",\n   `min_dwell_time` INT MIN DEFAULT \"99999\" COMMENT \"用户最小停留时间\"\n  )\n  ENGINE=olap\n  AGGREGATE KEY(`user_id`, `date`, `timestamp`, `city`, `age`, `sex`)\n  PARTITION BY RANGE(`date`)\n  (\n   PARTITION `p201701` VALUES LESS THAN (\"2017-02-01\"),\n   PARTITION `p201702` VALUES LESS THAN (\"2017-03-01\"),\n   PARTITION `p201703` VALUES LESS THAN (\"2017-04-01\")\n  )\n  DISTRIBUTED BY HASH(`user_id`) BUCKETS 16\n  PROPERTIES\n  (\n   \"replication_num\" = \"3\",\n   \"storage_medium\" = \"SSD\",\n   \"storage_cooldown_time\" = \"2018-01-01 12:00:00\"\n  );\n  \n  ```\n\n- List Partition\n\n  ```sql\n  CREATE TABLE IF NOT EXISTS example_db.expamle_list_tbl\n  (\n   `user_id` LARGEINT NOT NULL COMMENT \"用户 id\",\n   `date` DATE NOT NULL COMMENT \"数据灌入日期时间\",\n   `timestamp` DATETIME NOT NULL COMMENT \"数据灌入的时间戳\",\n   `city` VARCHAR(20) COMMENT \"用户所在城市\",\n   `age` SMALLINT COMMENT \"用户年龄\",\n   `sex` TINYINT COMMENT \"用户性别\",\n   `last_visit_date` DATETIME REPLACE DEFAULT \"1970-01-01 \n  00:00:00\" COMMENT \"用户最后一次访问时间\",\n   `cost` BIGINT SUM DEFAULT \"0\" COMMENT \"用户总消费\",\n   `max_dwell_time` INT MAX DEFAULT \"0\" COMMENT \"用户最大停留时间\",\n   `min_dwell_time` INT MIN DEFAULT \"99999\" COMMENT \"用户最小停留时\n  间\"\n  )\n  ENGINE=olap\n  AGGREGATE KEY(`user_id`, `date`, `timestamp`, `city`, `age`, `sex`)\n  PARTITION BY LIST(`city`)\n  (\n   PARTITION `p_cn` VALUES IN (\"Beijing\", \"Shanghai\", \"Hong Kong\"),\n   PARTITION `p_usa` VALUES IN (\"New York\", \"San Francisco\"),\n   PARTITION `p_jp` VALUES IN (\"Tokyo\")\n  )\n  DISTRIBUTED BY HASH(`user_id`) BUCKETS 16\n  PROPERTIES\n  (\n   \"replication_num\" = \"3\",\n   \"storage_medium\" = \"SSD\",\n   \"storage_cooldown_time\" = \"2018-01-01 12:00:00\"\n  );\n  ```\n\n  \n\n## 数据模型\n\nDoris 的数据模型主要分为 3 类：Aggregate、Uniq、Duplicate\n\n### Aggregate 模型\n\n表中的列按照是否设置了 AggregationType，分为 Key（维度列）和 Value（指标列）。没有设置 AggregationType 的称为 Key，设置了 AggregationType 的称为 Value。\n当我们导入数据时，对于 Key 列相同的行会聚合成一行，而 Value 列会按照设置的AggregationType 进行聚合。AggregationType 目前有以下四种聚合方式：\n\n- ➢ SUM：求和，多行的 Value 进行累加。\n- ➢ REPLACE：替代，下一批数据中的 Value 会替换之前导入过的行中的 Value。\n     REPLACE_IF_NOT_NULL ：当遇到 null 值则不更新。\n- ➢ MAX：保留最大值。\n- ➢ MIN：保留最小值。\n\n数据的聚合，在 Doris 中有如下三个阶段发生：\n- （1）每一批次数据导入的 ETL 阶段。该阶段会在每一批次导入的数据内部进行聚合。\n- （2）底层 BE 进行数据 Compaction 的阶段。该阶段，BE 会对已导入的不同批次的数据进行进一步的聚合。\n- （3）数据查询阶段。在数据查询时，对于查询涉及到的数据，会进行对应的聚合。\n\n数据在不同时间，可能聚合的程度不一致。比如一批数据刚导入时，可能还未与之前已存在的数据进行聚合。但是对于用户而言，用户只能查询到聚合后的数据。即不同的聚合程度对于用户查询而言是透明的。用户需始终认为数据以最终的完成的聚合程度存在，而不应假设某些聚合还未发生。（可参阅聚合模型的局限性一节获得更多详情。）\n\n### Uniq 模型\n\n在某些多维分析场景下，用户更关注的是如何保证 Key 的唯一性，即如何获得 Primary  Key 唯一性约束。因此，我们引入了 Uniq 的数据模型。该模型本质上是聚合模型的一个特 例，也是一种简化的表结构表示方式。\n\nUniq 模型完全可以用聚合模型中的 REPLACE 方式替代。其内部的实现方式和数据存 储方式也完全一样。\n\n### Duplicate 模型\n\n在某些多维分析场景下，数据既没有主键，也没有聚合需求。Duplicate 数据模型可以 满足这类需求。数据完全按照导入文件中的数据进行存储，不会有任何聚合。即使两行数据 完全相同，也都会保留。 而在建表语句中指定的 `DUPLICATE KEY`，只是用来指明底层数 据按照那些列进行排序。\n\n### 数据模型的选择建议\n\n因为数据模型在建表时就已经确定，且无法修改。所以，选择一个合适的数据模型非常 重要。 \n\n（1）Aggregate 模型可以通过预聚合，极大地降低聚合查询时所需扫描的数据量和查询 的计算量，非常适合有固定模式的报表类查询场景。但是该模型对 count(*) 查询很不友好。 **同时因为固定了 Value 列上的聚合方式，在进行其他类型的聚合查询时，需要考虑语意正确 性。**\n\n（2）Uniq 模型针对需要唯一主键约束的场景，可以保证主键唯一性约束。**但是无法利 用 ROLLUP 等预聚合带来的查询优势（因为本质是 REPLACE，没有 SUM 这种聚合方式）。** \n\n（3）Duplicate 适合任意维度的 Ad-hoc 查询。虽然同样无法利用预聚合的特性，但是不 受聚合模型的约束，可以发挥列存模型的优势（只读取相关列，而不需要读取所有 Key 列）\n\n## Rollup\n\nROLLUP 在多维分析中是“上卷”的意思，即将数据按某种指定的粒度进行进一步聚 合。\n\n### 基本概念\n\n在 Doris 中，我们将用户通过建表语句创建出来的表称为 Base 表（Base Table）。Base  表中保存着按用户建表语句指定的方式存储的基础数据。 \n\n在 Base 表之上，我们可以创建任意多个 ROLLUP 表。这些 ROLLUP 的数据是基于 Base  表产生的，并且在物理上是独立存储的。 ROLLUP 表的基本作用，在于在 Base 表的基础上，获得更粗粒度的聚合数据\n\n###  Duplicate 模型中的 ROLLUP\n\n因为 Duplicate 模型没有聚合的语意。所以该模型中的 ROLLUP，已经失去了“上卷” 这一层含义。而仅仅是作为调整列顺序，以命中前缀索引的作用。下面详细介绍前缀索引， 以及如何使用 ROLLUP 改变前缀索引，以获得更好的查询效率。\n\n#### 前缀索引\n\n不同于传统的数据库设计，Doris 不支持在任意列上创建索引。Doris 这类 MPP 架构的 OLAP 数据库，通常都是通过提高并发，来处理大量数据的。 \n\n本质上，Doris 的数据存储在类似 SSTable（Sorted String Table）的数据结构中。该结构 是一种有序的数据结构，可以按照指定的列进行排序存储。在这种数据结构上，以排序列作 为条件进行查找，会非常的高效。 \n\n在 Aggregate、Uniq 和 Duplicate 三种数据模型中。底层的数据存储，是按照各自建表 语句中，AGGREGATE KEY、UNIQ KEY 和 DUPLICATE KEY 中指定的列进行排序存储 的。而**前缀索引，即在排序的基础上，实现的一种根据给定前缀列，快速查询数据的索引方 式。**\n\n#### ROLLUP 调整前缀索引\n\n因为建表时已经指定了列顺序，所以一个表只有一种前缀索引。这对于使用其他不能命 中前缀索引的列作为条件进行的查询来说，效率上可能无法满足需求。因此，我们可以通过 创建 ROLLUP 来人为的调整列顺序。举例说明。\n\n### ROLLUP 的几点说明\n\n⚫ ROLLUP 最根本的作用是提高某些查询的查询效率（无论是通过聚合来减少数据 量，还是修改列顺序以匹配前缀索引）。因此 ROLLUP 的含义已经超出了“上卷” 的范围。这也是为什么在源代码中，将其命名为 Materialized Index（物化索引）的 原因。\n\n⚫ ROLLUP 是附属于 Base 表的，可以看做是 Base 表的一种辅助数据结构。用户可以 在 Base 表的基础上，创建或删除 ROLLUP，但是不能在查询中显式的指定查询某 ROLLUP。是否命中 ROLLUP 完全由 Doris 系统自动决定。 \n\n⚫ ROLLUP 的数据是独立物理存储的。因此，创建的 ROLLUP 越多，占用的磁盘空 间也就越大。同时对导入速度也会有影响（导入的 ETL 阶段会自动产生所有 ROLLUP 的数据），但是不会降低查询效率（只会更好）。 \n\n⚫ ROLLUP 的数据更新与 Base 表是完全同步的。用户无需关心这个问题。\n\n⚫ ROLLUP 中列的聚合方式，与 Base 表完全相同。在创建 ROLLUP 无需指定，也不 能修改。 \n\n⚫ 查询能否命中 ROLLUP 的一个必要条件（非充分条件）是，查询所涉及的所有列 （包括 select list 和 where 中的查询条件列等）都存在于该 ROLLUP 的列中。否 则，查询只能命中 Base 表。 \n\n⚫ 某些类型的查询（如 count(*)）在任何条件下，都无法命中 ROLLUP。具体参见接 下来的聚合模型的局限性一节。\n\n⚫ 可以通过 EXPLAIN your_sql; 命令获得查询执行计划，在执行计划中，查看是否命 中 ROLLUP。\n\n⚫ 可以通过 DESC tbl_name ALL; 语句显示 Base 表和所有已创建完成的 ROLLUP。\n\n\n\n## 物化视图\n\n物化视图就是包含了查询结果的数据库对象，可能是对远程数据的本地 copy，也可能 是一个表或多表 join 后结果的行或列的子集，也可能是聚合后的结果。说白了，就是预先存 储查询结果的一种数据库对象。\n\n在 Doris 中的物化视图，就是查询结果预先存储起来的特殊的表。 \n\n物化视图的出现主要是为了满足用户，既能对原始明细数据的任意维度分析，也能快速 的对固定维度进行分析查询。\n\n### 优势\n\n⚫ 对于那些经常重复的使用相同的子查询结果的查询性能大幅提升。 \n\n⚫ Doris 自动维护物化视图的数据，无论是新的导入，还是删除操作都能保证 base 表 和物化视图表的数据一致性。无需任何额外的人工维护成本。 \n\n⚫ 查询时，会自动匹配到最优物化视图，并直接从物化视图中读取数据。 自动维护物化视图的数据会造成一些维护开销，会在后面的物化视图的局限性中展开说 明。\n\n### 物化视图 VS Rollup\n\n在没有物化视图功能之前，用户一般都是使用 Rollup 功能通过预聚合方式提升查询效 率的。但是 Rollup 具有一定的局限性，他不能基于明细模型做预聚合。 \n\n物化视图则在覆盖了 Rollup 的功能的同时，还能支持更丰富的聚合函数。所以物化视 图其实是 Rollup 的一个超集。 \n\n也就是说，之前 ALTER TABLE ADD ROLLUP 语法支持的功能现在均可以通过 CREATE MATERIALIZED VIEW 实现。\n\n### 物化视图原理\n\nDoris 系统提供了一整套对物化视图的 DDL 语法，包括创建，查看，删除。DDL 的语 法和 PostgreSQL, Oracle 都是一致的。但是 Doris 目前创建物化视图只能在单表操作，不支 持 join。\n","slug":"bigdata/初识Doris","published":1,"comments":1,"layout":"post","photos":[],"link":"","_id":"cl9y38dsl001sfwui416a53so","content":"<blockquote>\n<ul>\n<li><p>MPP（ Massively Parallel Processing - 大规模并行处理）Based高性能、实时的分析型数据库。</p>\n</li>\n<li><p>在<strong>使用接口</strong>方面，Doris 采用 MySQ L 协议，高度兼容 MySQL 语法，支持标准 SQL，用户可以通过各类客户端工具来访问 Doris，并支持与 BI 工具的无缝对接。</p>\n</li>\n<li><p>在<strong>存储引擎</strong>方面，Doris 采用列式存储，按列进行数据的编码压缩和读取，能够实现极高的压缩比，同时减少大量非相关数据的扫描，从而更加有效利用 IO 和 CPU 资源。</p>\n</li>\n<li><p>在<strong>查询引擎</strong>方面，Doris 采用 MPP 的模型，节点间和节点内都并行执行，也支持多个大表的分布式 Shuffle Join，从而能够更好应对复杂查询。</p>\n</li>\n</ul>\n<p> <img src=\"https://doris.apache.org/zh-CN/assets/images/origin_img_v2_cee507bd-d6ed-4359-9e52-51e9b8458f8g-cd4a2a172ec93222a40231fe1a8d4edd.png\" alt=\"origin_img_v2_cee507bd-d6ed-4359-9e52-51e9b8458f8g\"></p>\n<ul>\n<li><strong>Doris 查询引擎是向量化</strong>的查询引擎，所有的内存结构能够按照列式布局，能够达到大幅减少虚函数调用、提升 Cache 命中率，高效利用 SIMD 指令的效果。在宽表聚合场景下性能是非向量化引擎的 5-10 倍。</li>\n</ul>\n<p> <img src=\"https://doris.apache.org/zh-CN/assets/images/origin_img_v2_ad65aae9-9ed0-463e-a34c-94e32b092a4g-84273f42ae82408ff09c7af6c5b67022.png\" alt=\"origin_img_v2_ad65aae9-9ed0-463e-a34c-94e32b092a4g\"></p>\n<ul>\n<li><p><strong>Doris 采用了 Adaptive Query Execution 技术，</strong> 可以根据 Runtime Statistics 来动态调整执行计划，比如通过 Runtime Filter 技术能够在运行时生成生成 Filter 推到 Probe 侧，并且能够将 Filter 自动穿透到 Probe 侧最底层的 Scan 节点，从而大幅减少 Probe 的数据量，加速 Join 性能。Doris 的 Runtime Filter 支持 In&#x2F;Min&#x2F;Max&#x2F;Bloom Filter。</p>\n</li>\n<li><p>在<strong>优化器</strong>方面 Doris 使用 CBO 和 RBO 结合的优化策略，RBO 支持常量折叠、子查询改写、谓词下推等，CBO 支持 Join Reorder。目前 CBO 还在持续优化中，主要集中在更加精准的统计信息收集和推导，更加精准的代价模型预估等方面。</p>\n</li>\n<li><p><strong>Doris 也支持强一致的物化视图</strong>，物化视图的更新和选择都在系统内自动进行，不需要用户手动选择，从而大幅减少了物化视图维护的代价。</p>\n</li>\n<li><p><strong>Doris 也支持比较丰富的索引结构，来减少数据的扫描</strong></p>\n</li>\n</ul>\n</blockquote>\n<hr>\n<blockquote>\n<ul>\n<li><p>Doris 数据模型上目前分为三类: AGGREGATE KEY, UNIQUE KEY, DUPLICATE KEY。<strong>三种模型中数据都是按KEY进行排序。</strong></p>\n</li>\n<li><p>AGGREGATE KEY</p>\n</li>\n</ul>\n<p> AGGREGATE KEY相同时，新旧记录进行聚合，目前支持的聚合函数有SUM, MIN, MAX, REPLACE。</p>\n<p> AGGREGATE KEY模型可以提前聚合数据, 适合报表和多维分析业务。</p>\n<ul>\n<li>UNIQUE KEY</li>\n</ul>\n<p> UNIQUE KEY 相同时，新记录覆盖旧记录。目前 UNIQUE KEY 实现上和 AGGREGATE KEY 的 REPLACE 聚合方法一样，二者本质上相同。适用于有更新需求的分析业务。</p>\n<ul>\n<li>DUPLICATE KEY</li>\n</ul>\n<p> 只指定排序列，相同的行不会合并。适用于数据无需提前聚合的分析业务。</p>\n</blockquote>\n<hr>\n<blockquote>\n<p>Doris<strong>整体架构</strong>如下图所示，Doris 架构非常简单，只有两类进程</p>\n<ul>\n<li><strong>Frontend（FE）</strong>，主要负责用户请求的接入、查询解析规划、元数据的管理、节点管理相关工作。</li>\n<li><strong>另一个是 Backend（BE）</strong>，主要负责数据存储、查询计划的执行。</li>\n</ul>\n<p>这两类进程都是可以横向扩展的，单集群可以支持到数百台机器，数十 PB 的存储容量。并且这两类进程通过一致性协议来保证服务的高可用和数据的高可靠。这种高度集成的架构设计极大的降低了一款分布式系统的运维成本。</p>\n<p><img src=\"https://doris.apache.org/zh-CN/assets/images/origin_img_v2_28d005e1-21d6-4801-956f-0c06373a7a9g-11e2c3e5c6b6dc26b4f602697a1071a9.png\" alt=\"origin_img_v2_28d005e1-21d6-4801-956f-0c06373a7a9g\"></p>\n</blockquote>\n<h2 id=\"建表语句\"><a href=\"#建表语句\" class=\"headerlink\" title=\"建表语句\"></a>建表语句</h2><ul>\n<li><p>Range Partition</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">CREATE</span> <span class=\"keyword\">TABLE</span> IF <span class=\"keyword\">NOT</span> <span class=\"keyword\">EXISTS</span> example_db.expamle_range_tbl</span><br><span class=\"line\">(</span><br><span class=\"line\"> `user_id` LARGEINT <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span> COMMENT &quot;用户 id&quot;,</span><br><span class=\"line\"> `<span class=\"type\">date</span>` <span class=\"type\">DATE</span> <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span> COMMENT &quot;数据灌入日期时间&quot;,</span><br><span class=\"line\"> `<span class=\"type\">timestamp</span>` DATETIME <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span> COMMENT &quot;数据灌入的时间戳&quot;,</span><br><span class=\"line\"> `city` <span class=\"type\">VARCHAR</span>(<span class=\"number\">20</span>) COMMENT &quot;用户所在城市&quot;,</span><br><span class=\"line\"> `age` <span class=\"type\">SMALLINT</span> COMMENT &quot;用户年龄&quot;,</span><br><span class=\"line\"> `sex` TINYINT COMMENT &quot;用户性别&quot;,</span><br><span class=\"line\"> `last_visit_date` DATETIME REPLACE <span class=\"keyword\">DEFAULT</span> &quot;1970-01-01 </span><br><span class=\"line\">00:00:00&quot; COMMENT &quot;用户最后一次访问时间&quot;,</span><br><span class=\"line\"> `cost` <span class=\"type\">BIGINT</span> SUM <span class=\"keyword\">DEFAULT</span> &quot;0&quot; COMMENT &quot;用户总消费&quot;,</span><br><span class=\"line\"> `max_dwell_time` <span class=\"type\">INT</span> MAX <span class=\"keyword\">DEFAULT</span> &quot;0&quot; COMMENT &quot;用户最大停留时间&quot;,</span><br><span class=\"line\"> `min_dwell_time` <span class=\"type\">INT</span> MIN <span class=\"keyword\">DEFAULT</span> &quot;99999&quot; COMMENT &quot;用户最小停留时间&quot;</span><br><span class=\"line\">)</span><br><span class=\"line\">ENGINE<span class=\"operator\">=</span>olap</span><br><span class=\"line\">AGGREGATE KEY(`user_id`, `<span class=\"type\">date</span>`, `<span class=\"type\">timestamp</span>`, `city`, `age`, `sex`)</span><br><span class=\"line\"><span class=\"keyword\">PARTITION</span> <span class=\"keyword\">BY</span> <span class=\"keyword\">RANGE</span>(`<span class=\"type\">date</span>`)</span><br><span class=\"line\">(</span><br><span class=\"line\"> <span class=\"keyword\">PARTITION</span> `p201701` <span class=\"keyword\">VALUES</span> LESS THAN (&quot;2017-02-01&quot;),</span><br><span class=\"line\"> <span class=\"keyword\">PARTITION</span> `p201702` <span class=\"keyword\">VALUES</span> LESS THAN (&quot;2017-03-01&quot;),</span><br><span class=\"line\"> <span class=\"keyword\">PARTITION</span> `p201703` <span class=\"keyword\">VALUES</span> LESS THAN (&quot;2017-04-01&quot;)</span><br><span class=\"line\">)</span><br><span class=\"line\">DISTRIBUTED <span class=\"keyword\">BY</span> HASH(`user_id`) BUCKETS <span class=\"number\">16</span></span><br><span class=\"line\">PROPERTIES</span><br><span class=\"line\">(</span><br><span class=\"line\"> &quot;replication_num&quot; <span class=\"operator\">=</span> &quot;3&quot;,</span><br><span class=\"line\"> &quot;storage_medium&quot; <span class=\"operator\">=</span> &quot;SSD&quot;,</span><br><span class=\"line\"> &quot;storage_cooldown_time&quot; <span class=\"operator\">=</span> &quot;2018-01-01 12:00:00&quot;</span><br><span class=\"line\">);</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>List Partition</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">CREATE</span> <span class=\"keyword\">TABLE</span> IF <span class=\"keyword\">NOT</span> <span class=\"keyword\">EXISTS</span> example_db.expamle_list_tbl</span><br><span class=\"line\">(</span><br><span class=\"line\"> `user_id` LARGEINT <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span> COMMENT &quot;用户 id&quot;,</span><br><span class=\"line\"> `<span class=\"type\">date</span>` <span class=\"type\">DATE</span> <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span> COMMENT &quot;数据灌入日期时间&quot;,</span><br><span class=\"line\"> `<span class=\"type\">timestamp</span>` DATETIME <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span> COMMENT &quot;数据灌入的时间戳&quot;,</span><br><span class=\"line\"> `city` <span class=\"type\">VARCHAR</span>(<span class=\"number\">20</span>) COMMENT &quot;用户所在城市&quot;,</span><br><span class=\"line\"> `age` <span class=\"type\">SMALLINT</span> COMMENT &quot;用户年龄&quot;,</span><br><span class=\"line\"> `sex` TINYINT COMMENT &quot;用户性别&quot;,</span><br><span class=\"line\"> `last_visit_date` DATETIME REPLACE <span class=\"keyword\">DEFAULT</span> &quot;1970-01-01 </span><br><span class=\"line\">00:00:00&quot; COMMENT &quot;用户最后一次访问时间&quot;,</span><br><span class=\"line\"> `cost` <span class=\"type\">BIGINT</span> SUM <span class=\"keyword\">DEFAULT</span> &quot;0&quot; COMMENT &quot;用户总消费&quot;,</span><br><span class=\"line\"> `max_dwell_time` <span class=\"type\">INT</span> MAX <span class=\"keyword\">DEFAULT</span> &quot;0&quot; COMMENT &quot;用户最大停留时间&quot;,</span><br><span class=\"line\"> `min_dwell_time` <span class=\"type\">INT</span> MIN <span class=\"keyword\">DEFAULT</span> &quot;99999&quot; COMMENT &quot;用户最小停留时</span><br><span class=\"line\">间&quot;</span><br><span class=\"line\">)</span><br><span class=\"line\">ENGINE<span class=\"operator\">=</span>olap</span><br><span class=\"line\">AGGREGATE KEY(`user_id`, `<span class=\"type\">date</span>`, `<span class=\"type\">timestamp</span>`, `city`, `age`, `sex`)</span><br><span class=\"line\"><span class=\"keyword\">PARTITION</span> <span class=\"keyword\">BY</span> LIST(`city`)</span><br><span class=\"line\">(</span><br><span class=\"line\"> <span class=\"keyword\">PARTITION</span> `p_cn` <span class=\"keyword\">VALUES</span> <span class=\"keyword\">IN</span> (&quot;Beijing&quot;, &quot;Shanghai&quot;, &quot;Hong Kong&quot;),</span><br><span class=\"line\"> <span class=\"keyword\">PARTITION</span> `p_usa` <span class=\"keyword\">VALUES</span> <span class=\"keyword\">IN</span> (&quot;New York&quot;, &quot;San Francisco&quot;),</span><br><span class=\"line\"> <span class=\"keyword\">PARTITION</span> `p_jp` <span class=\"keyword\">VALUES</span> <span class=\"keyword\">IN</span> (&quot;Tokyo&quot;)</span><br><span class=\"line\">)</span><br><span class=\"line\">DISTRIBUTED <span class=\"keyword\">BY</span> HASH(`user_id`) BUCKETS <span class=\"number\">16</span></span><br><span class=\"line\">PROPERTIES</span><br><span class=\"line\">(</span><br><span class=\"line\"> &quot;replication_num&quot; <span class=\"operator\">=</span> &quot;3&quot;,</span><br><span class=\"line\"> &quot;storage_medium&quot; <span class=\"operator\">=</span> &quot;SSD&quot;,</span><br><span class=\"line\"> &quot;storage_cooldown_time&quot; <span class=\"operator\">=</span> &quot;2018-01-01 12:00:00&quot;</span><br><span class=\"line\">);</span><br></pre></td></tr></table></figure></li>\n</ul>\n<h2 id=\"数据模型\"><a href=\"#数据模型\" class=\"headerlink\" title=\"数据模型\"></a>数据模型</h2><p>Doris 的数据模型主要分为 3 类：Aggregate、Uniq、Duplicate</p>\n<h3 id=\"Aggregate-模型\"><a href=\"#Aggregate-模型\" class=\"headerlink\" title=\"Aggregate 模型\"></a>Aggregate 模型</h3><p>表中的列按照是否设置了 AggregationType，分为 Key（维度列）和 Value（指标列）。没有设置 AggregationType 的称为 Key，设置了 AggregationType 的称为 Value。<br>当我们导入数据时，对于 Key 列相同的行会聚合成一行，而 Value 列会按照设置的AggregationType 进行聚合。AggregationType 目前有以下四种聚合方式：</p>\n<ul>\n<li>➢ SUM：求和，多行的 Value 进行累加。</li>\n<li>➢ REPLACE：替代，下一批数据中的 Value 会替换之前导入过的行中的 Value。<br>   REPLACE_IF_NOT_NULL ：当遇到 null 值则不更新。</li>\n<li>➢ MAX：保留最大值。</li>\n<li>➢ MIN：保留最小值。</li>\n</ul>\n<p>数据的聚合，在 Doris 中有如下三个阶段发生：</p>\n<ul>\n<li>（1）每一批次数据导入的 ETL 阶段。该阶段会在每一批次导入的数据内部进行聚合。</li>\n<li>（2）底层 BE 进行数据 Compaction 的阶段。该阶段，BE 会对已导入的不同批次的数据进行进一步的聚合。</li>\n<li>（3）数据查询阶段。在数据查询时，对于查询涉及到的数据，会进行对应的聚合。</li>\n</ul>\n<p>数据在不同时间，可能聚合的程度不一致。比如一批数据刚导入时，可能还未与之前已存在的数据进行聚合。但是对于用户而言，用户只能查询到聚合后的数据。即不同的聚合程度对于用户查询而言是透明的。用户需始终认为数据以最终的完成的聚合程度存在，而不应假设某些聚合还未发生。（可参阅聚合模型的局限性一节获得更多详情。）</p>\n<h3 id=\"Uniq-模型\"><a href=\"#Uniq-模型\" class=\"headerlink\" title=\"Uniq 模型\"></a>Uniq 模型</h3><p>在某些多维分析场景下，用户更关注的是如何保证 Key 的唯一性，即如何获得 Primary  Key 唯一性约束。因此，我们引入了 Uniq 的数据模型。该模型本质上是聚合模型的一个特 例，也是一种简化的表结构表示方式。</p>\n<p>Uniq 模型完全可以用聚合模型中的 REPLACE 方式替代。其内部的实现方式和数据存 储方式也完全一样。</p>\n<h3 id=\"Duplicate-模型\"><a href=\"#Duplicate-模型\" class=\"headerlink\" title=\"Duplicate 模型\"></a>Duplicate 模型</h3><p>在某些多维分析场景下，数据既没有主键，也没有聚合需求。Duplicate 数据模型可以 满足这类需求。数据完全按照导入文件中的数据进行存储，不会有任何聚合。即使两行数据 完全相同，也都会保留。 而在建表语句中指定的 <code>DUPLICATE KEY</code>，只是用来指明底层数 据按照那些列进行排序。</p>\n<h3 id=\"数据模型的选择建议\"><a href=\"#数据模型的选择建议\" class=\"headerlink\" title=\"数据模型的选择建议\"></a>数据模型的选择建议</h3><p>因为数据模型在建表时就已经确定，且无法修改。所以，选择一个合适的数据模型非常 重要。 </p>\n<p>（1）Aggregate 模型可以通过预聚合，极大地降低聚合查询时所需扫描的数据量和查询 的计算量，非常适合有固定模式的报表类查询场景。但是该模型对 count(*) 查询很不友好。 <strong>同时因为固定了 Value 列上的聚合方式，在进行其他类型的聚合查询时，需要考虑语意正确 性。</strong></p>\n<p>（2）Uniq 模型针对需要唯一主键约束的场景，可以保证主键唯一性约束。<strong>但是无法利 用 ROLLUP 等预聚合带来的查询优势（因为本质是 REPLACE，没有 SUM 这种聚合方式）。</strong> </p>\n<p>（3）Duplicate 适合任意维度的 Ad-hoc 查询。虽然同样无法利用预聚合的特性，但是不 受聚合模型的约束，可以发挥列存模型的优势（只读取相关列，而不需要读取所有 Key 列）</p>\n<h2 id=\"Rollup\"><a href=\"#Rollup\" class=\"headerlink\" title=\"Rollup\"></a>Rollup</h2><p>ROLLUP 在多维分析中是“上卷”的意思，即将数据按某种指定的粒度进行进一步聚 合。</p>\n<h3 id=\"基本概念\"><a href=\"#基本概念\" class=\"headerlink\" title=\"基本概念\"></a>基本概念</h3><p>在 Doris 中，我们将用户通过建表语句创建出来的表称为 Base 表（Base Table）。Base  表中保存着按用户建表语句指定的方式存储的基础数据。 </p>\n<p>在 Base 表之上，我们可以创建任意多个 ROLLUP 表。这些 ROLLUP 的数据是基于 Base  表产生的，并且在物理上是独立存储的。 ROLLUP 表的基本作用，在于在 Base 表的基础上，获得更粗粒度的聚合数据</p>\n<h3 id=\"Duplicate-模型中的-ROLLUP\"><a href=\"#Duplicate-模型中的-ROLLUP\" class=\"headerlink\" title=\"Duplicate 模型中的 ROLLUP\"></a>Duplicate 模型中的 ROLLUP</h3><p>因为 Duplicate 模型没有聚合的语意。所以该模型中的 ROLLUP，已经失去了“上卷” 这一层含义。而仅仅是作为调整列顺序，以命中前缀索引的作用。下面详细介绍前缀索引， 以及如何使用 ROLLUP 改变前缀索引，以获得更好的查询效率。</p>\n<h4 id=\"前缀索引\"><a href=\"#前缀索引\" class=\"headerlink\" title=\"前缀索引\"></a>前缀索引</h4><p>不同于传统的数据库设计，Doris 不支持在任意列上创建索引。Doris 这类 MPP 架构的 OLAP 数据库，通常都是通过提高并发，来处理大量数据的。 </p>\n<p>本质上，Doris 的数据存储在类似 SSTable（Sorted String Table）的数据结构中。该结构 是一种有序的数据结构，可以按照指定的列进行排序存储。在这种数据结构上，以排序列作 为条件进行查找，会非常的高效。 </p>\n<p>在 Aggregate、Uniq 和 Duplicate 三种数据模型中。底层的数据存储，是按照各自建表 语句中，AGGREGATE KEY、UNIQ KEY 和 DUPLICATE KEY 中指定的列进行排序存储 的。而<strong>前缀索引，即在排序的基础上，实现的一种根据给定前缀列，快速查询数据的索引方 式。</strong></p>\n<h4 id=\"ROLLUP-调整前缀索引\"><a href=\"#ROLLUP-调整前缀索引\" class=\"headerlink\" title=\"ROLLUP 调整前缀索引\"></a>ROLLUP 调整前缀索引</h4><p>因为建表时已经指定了列顺序，所以一个表只有一种前缀索引。这对于使用其他不能命 中前缀索引的列作为条件进行的查询来说，效率上可能无法满足需求。因此，我们可以通过 创建 ROLLUP 来人为的调整列顺序。举例说明。</p>\n<h3 id=\"ROLLUP-的几点说明\"><a href=\"#ROLLUP-的几点说明\" class=\"headerlink\" title=\"ROLLUP 的几点说明\"></a>ROLLUP 的几点说明</h3><p>⚫ ROLLUP 最根本的作用是提高某些查询的查询效率（无论是通过聚合来减少数据 量，还是修改列顺序以匹配前缀索引）。因此 ROLLUP 的含义已经超出了“上卷” 的范围。这也是为什么在源代码中，将其命名为 Materialized Index（物化索引）的 原因。</p>\n<p>⚫ ROLLUP 是附属于 Base 表的，可以看做是 Base 表的一种辅助数据结构。用户可以 在 Base 表的基础上，创建或删除 ROLLUP，但是不能在查询中显式的指定查询某 ROLLUP。是否命中 ROLLUP 完全由 Doris 系统自动决定。 </p>\n<p>⚫ ROLLUP 的数据是独立物理存储的。因此，创建的 ROLLUP 越多，占用的磁盘空 间也就越大。同时对导入速度也会有影响（导入的 ETL 阶段会自动产生所有 ROLLUP 的数据），但是不会降低查询效率（只会更好）。 </p>\n<p>⚫ ROLLUP 的数据更新与 Base 表是完全同步的。用户无需关心这个问题。</p>\n<p>⚫ ROLLUP 中列的聚合方式，与 Base 表完全相同。在创建 ROLLUP 无需指定，也不 能修改。 </p>\n<p>⚫ 查询能否命中 ROLLUP 的一个必要条件（非充分条件）是，查询所涉及的所有列 （包括 select list 和 where 中的查询条件列等）都存在于该 ROLLUP 的列中。否 则，查询只能命中 Base 表。 </p>\n<p>⚫ 某些类型的查询（如 count(*)）在任何条件下，都无法命中 ROLLUP。具体参见接 下来的聚合模型的局限性一节。</p>\n<p>⚫ 可以通过 EXPLAIN your_sql; 命令获得查询执行计划，在执行计划中，查看是否命 中 ROLLUP。</p>\n<p>⚫ 可以通过 DESC tbl_name ALL; 语句显示 Base 表和所有已创建完成的 ROLLUP。</p>\n<h2 id=\"物化视图\"><a href=\"#物化视图\" class=\"headerlink\" title=\"物化视图\"></a>物化视图</h2><p>物化视图就是包含了查询结果的数据库对象，可能是对远程数据的本地 copy，也可能 是一个表或多表 join 后结果的行或列的子集，也可能是聚合后的结果。说白了，就是预先存 储查询结果的一种数据库对象。</p>\n<p>在 Doris 中的物化视图，就是查询结果预先存储起来的特殊的表。 </p>\n<p>物化视图的出现主要是为了满足用户，既能对原始明细数据的任意维度分析，也能快速 的对固定维度进行分析查询。</p>\n<h3 id=\"优势\"><a href=\"#优势\" class=\"headerlink\" title=\"优势\"></a>优势</h3><p>⚫ 对于那些经常重复的使用相同的子查询结果的查询性能大幅提升。 </p>\n<p>⚫ Doris 自动维护物化视图的数据，无论是新的导入，还是删除操作都能保证 base 表 和物化视图表的数据一致性。无需任何额外的人工维护成本。 </p>\n<p>⚫ 查询时，会自动匹配到最优物化视图，并直接从物化视图中读取数据。 自动维护物化视图的数据会造成一些维护开销，会在后面的物化视图的局限性中展开说 明。</p>\n<h3 id=\"物化视图-VS-Rollup\"><a href=\"#物化视图-VS-Rollup\" class=\"headerlink\" title=\"物化视图 VS Rollup\"></a>物化视图 VS Rollup</h3><p>在没有物化视图功能之前，用户一般都是使用 Rollup 功能通过预聚合方式提升查询效 率的。但是 Rollup 具有一定的局限性，他不能基于明细模型做预聚合。 </p>\n<p>物化视图则在覆盖了 Rollup 的功能的同时，还能支持更丰富的聚合函数。所以物化视 图其实是 Rollup 的一个超集。 </p>\n<p>也就是说，之前 ALTER TABLE ADD ROLLUP 语法支持的功能现在均可以通过 CREATE MATERIALIZED VIEW 实现。</p>\n<h3 id=\"物化视图原理\"><a href=\"#物化视图原理\" class=\"headerlink\" title=\"物化视图原理\"></a>物化视图原理</h3><p>Doris 系统提供了一整套对物化视图的 DDL 语法，包括创建，查看，删除。DDL 的语 法和 PostgreSQL, Oracle 都是一致的。但是 Doris 目前创建物化视图只能在单表操作，不支 持 join。</p>\n","site":{"data":{"link":[{"class_name":"友情链接","class_desc":"那些人，那些事","link_list":[{"name":"张洪Heo","link":"https://blog.zhheo.com/","avatar":"https://npm.elemecdn.com/guli-heo/img/avatar2.png","descr":"分享设计与科技生活"},{"name":"瞬間の筆記","link":"https://hikki.site","descr":"喜欢的东西就努力去追求，万一成功了呢!","avatar":"https://cdn.jsdelivr.net/gh/0000rookie/imgs/202206120315.png"}]}]}},"excerpt":"","more":"<blockquote>\n<ul>\n<li><p>MPP（ Massively Parallel Processing - 大规模并行处理）Based高性能、实时的分析型数据库。</p>\n</li>\n<li><p>在<strong>使用接口</strong>方面，Doris 采用 MySQ L 协议，高度兼容 MySQL 语法，支持标准 SQL，用户可以通过各类客户端工具来访问 Doris，并支持与 BI 工具的无缝对接。</p>\n</li>\n<li><p>在<strong>存储引擎</strong>方面，Doris 采用列式存储，按列进行数据的编码压缩和读取，能够实现极高的压缩比，同时减少大量非相关数据的扫描，从而更加有效利用 IO 和 CPU 资源。</p>\n</li>\n<li><p>在<strong>查询引擎</strong>方面，Doris 采用 MPP 的模型，节点间和节点内都并行执行，也支持多个大表的分布式 Shuffle Join，从而能够更好应对复杂查询。</p>\n</li>\n</ul>\n<p> <img src=\"https://doris.apache.org/zh-CN/assets/images/origin_img_v2_cee507bd-d6ed-4359-9e52-51e9b8458f8g-cd4a2a172ec93222a40231fe1a8d4edd.png\" alt=\"origin_img_v2_cee507bd-d6ed-4359-9e52-51e9b8458f8g\"></p>\n<ul>\n<li><strong>Doris 查询引擎是向量化</strong>的查询引擎，所有的内存结构能够按照列式布局，能够达到大幅减少虚函数调用、提升 Cache 命中率，高效利用 SIMD 指令的效果。在宽表聚合场景下性能是非向量化引擎的 5-10 倍。</li>\n</ul>\n<p> <img src=\"https://doris.apache.org/zh-CN/assets/images/origin_img_v2_ad65aae9-9ed0-463e-a34c-94e32b092a4g-84273f42ae82408ff09c7af6c5b67022.png\" alt=\"origin_img_v2_ad65aae9-9ed0-463e-a34c-94e32b092a4g\"></p>\n<ul>\n<li><p><strong>Doris 采用了 Adaptive Query Execution 技术，</strong> 可以根据 Runtime Statistics 来动态调整执行计划，比如通过 Runtime Filter 技术能够在运行时生成生成 Filter 推到 Probe 侧，并且能够将 Filter 自动穿透到 Probe 侧最底层的 Scan 节点，从而大幅减少 Probe 的数据量，加速 Join 性能。Doris 的 Runtime Filter 支持 In&#x2F;Min&#x2F;Max&#x2F;Bloom Filter。</p>\n</li>\n<li><p>在<strong>优化器</strong>方面 Doris 使用 CBO 和 RBO 结合的优化策略，RBO 支持常量折叠、子查询改写、谓词下推等，CBO 支持 Join Reorder。目前 CBO 还在持续优化中，主要集中在更加精准的统计信息收集和推导，更加精准的代价模型预估等方面。</p>\n</li>\n<li><p><strong>Doris 也支持强一致的物化视图</strong>，物化视图的更新和选择都在系统内自动进行，不需要用户手动选择，从而大幅减少了物化视图维护的代价。</p>\n</li>\n<li><p><strong>Doris 也支持比较丰富的索引结构，来减少数据的扫描</strong></p>\n</li>\n</ul>\n</blockquote>\n<hr>\n<blockquote>\n<ul>\n<li><p>Doris 数据模型上目前分为三类: AGGREGATE KEY, UNIQUE KEY, DUPLICATE KEY。<strong>三种模型中数据都是按KEY进行排序。</strong></p>\n</li>\n<li><p>AGGREGATE KEY</p>\n</li>\n</ul>\n<p> AGGREGATE KEY相同时，新旧记录进行聚合，目前支持的聚合函数有SUM, MIN, MAX, REPLACE。</p>\n<p> AGGREGATE KEY模型可以提前聚合数据, 适合报表和多维分析业务。</p>\n<ul>\n<li>UNIQUE KEY</li>\n</ul>\n<p> UNIQUE KEY 相同时，新记录覆盖旧记录。目前 UNIQUE KEY 实现上和 AGGREGATE KEY 的 REPLACE 聚合方法一样，二者本质上相同。适用于有更新需求的分析业务。</p>\n<ul>\n<li>DUPLICATE KEY</li>\n</ul>\n<p> 只指定排序列，相同的行不会合并。适用于数据无需提前聚合的分析业务。</p>\n</blockquote>\n<hr>\n<blockquote>\n<p>Doris<strong>整体架构</strong>如下图所示，Doris 架构非常简单，只有两类进程</p>\n<ul>\n<li><strong>Frontend（FE）</strong>，主要负责用户请求的接入、查询解析规划、元数据的管理、节点管理相关工作。</li>\n<li><strong>另一个是 Backend（BE）</strong>，主要负责数据存储、查询计划的执行。</li>\n</ul>\n<p>这两类进程都是可以横向扩展的，单集群可以支持到数百台机器，数十 PB 的存储容量。并且这两类进程通过一致性协议来保证服务的高可用和数据的高可靠。这种高度集成的架构设计极大的降低了一款分布式系统的运维成本。</p>\n<p><img src=\"https://doris.apache.org/zh-CN/assets/images/origin_img_v2_28d005e1-21d6-4801-956f-0c06373a7a9g-11e2c3e5c6b6dc26b4f602697a1071a9.png\" alt=\"origin_img_v2_28d005e1-21d6-4801-956f-0c06373a7a9g\"></p>\n</blockquote>\n<h2 id=\"建表语句\"><a href=\"#建表语句\" class=\"headerlink\" title=\"建表语句\"></a>建表语句</h2><ul>\n<li><p>Range Partition</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">CREATE</span> <span class=\"keyword\">TABLE</span> IF <span class=\"keyword\">NOT</span> <span class=\"keyword\">EXISTS</span> example_db.expamle_range_tbl</span><br><span class=\"line\">(</span><br><span class=\"line\"> `user_id` LARGEINT <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span> COMMENT &quot;用户 id&quot;,</span><br><span class=\"line\"> `<span class=\"type\">date</span>` <span class=\"type\">DATE</span> <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span> COMMENT &quot;数据灌入日期时间&quot;,</span><br><span class=\"line\"> `<span class=\"type\">timestamp</span>` DATETIME <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span> COMMENT &quot;数据灌入的时间戳&quot;,</span><br><span class=\"line\"> `city` <span class=\"type\">VARCHAR</span>(<span class=\"number\">20</span>) COMMENT &quot;用户所在城市&quot;,</span><br><span class=\"line\"> `age` <span class=\"type\">SMALLINT</span> COMMENT &quot;用户年龄&quot;,</span><br><span class=\"line\"> `sex` TINYINT COMMENT &quot;用户性别&quot;,</span><br><span class=\"line\"> `last_visit_date` DATETIME REPLACE <span class=\"keyword\">DEFAULT</span> &quot;1970-01-01 </span><br><span class=\"line\">00:00:00&quot; COMMENT &quot;用户最后一次访问时间&quot;,</span><br><span class=\"line\"> `cost` <span class=\"type\">BIGINT</span> SUM <span class=\"keyword\">DEFAULT</span> &quot;0&quot; COMMENT &quot;用户总消费&quot;,</span><br><span class=\"line\"> `max_dwell_time` <span class=\"type\">INT</span> MAX <span class=\"keyword\">DEFAULT</span> &quot;0&quot; COMMENT &quot;用户最大停留时间&quot;,</span><br><span class=\"line\"> `min_dwell_time` <span class=\"type\">INT</span> MIN <span class=\"keyword\">DEFAULT</span> &quot;99999&quot; COMMENT &quot;用户最小停留时间&quot;</span><br><span class=\"line\">)</span><br><span class=\"line\">ENGINE<span class=\"operator\">=</span>olap</span><br><span class=\"line\">AGGREGATE KEY(`user_id`, `<span class=\"type\">date</span>`, `<span class=\"type\">timestamp</span>`, `city`, `age`, `sex`)</span><br><span class=\"line\"><span class=\"keyword\">PARTITION</span> <span class=\"keyword\">BY</span> <span class=\"keyword\">RANGE</span>(`<span class=\"type\">date</span>`)</span><br><span class=\"line\">(</span><br><span class=\"line\"> <span class=\"keyword\">PARTITION</span> `p201701` <span class=\"keyword\">VALUES</span> LESS THAN (&quot;2017-02-01&quot;),</span><br><span class=\"line\"> <span class=\"keyword\">PARTITION</span> `p201702` <span class=\"keyword\">VALUES</span> LESS THAN (&quot;2017-03-01&quot;),</span><br><span class=\"line\"> <span class=\"keyword\">PARTITION</span> `p201703` <span class=\"keyword\">VALUES</span> LESS THAN (&quot;2017-04-01&quot;)</span><br><span class=\"line\">)</span><br><span class=\"line\">DISTRIBUTED <span class=\"keyword\">BY</span> HASH(`user_id`) BUCKETS <span class=\"number\">16</span></span><br><span class=\"line\">PROPERTIES</span><br><span class=\"line\">(</span><br><span class=\"line\"> &quot;replication_num&quot; <span class=\"operator\">=</span> &quot;3&quot;,</span><br><span class=\"line\"> &quot;storage_medium&quot; <span class=\"operator\">=</span> &quot;SSD&quot;,</span><br><span class=\"line\"> &quot;storage_cooldown_time&quot; <span class=\"operator\">=</span> &quot;2018-01-01 12:00:00&quot;</span><br><span class=\"line\">);</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>List Partition</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">CREATE</span> <span class=\"keyword\">TABLE</span> IF <span class=\"keyword\">NOT</span> <span class=\"keyword\">EXISTS</span> example_db.expamle_list_tbl</span><br><span class=\"line\">(</span><br><span class=\"line\"> `user_id` LARGEINT <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span> COMMENT &quot;用户 id&quot;,</span><br><span class=\"line\"> `<span class=\"type\">date</span>` <span class=\"type\">DATE</span> <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span> COMMENT &quot;数据灌入日期时间&quot;,</span><br><span class=\"line\"> `<span class=\"type\">timestamp</span>` DATETIME <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span> COMMENT &quot;数据灌入的时间戳&quot;,</span><br><span class=\"line\"> `city` <span class=\"type\">VARCHAR</span>(<span class=\"number\">20</span>) COMMENT &quot;用户所在城市&quot;,</span><br><span class=\"line\"> `age` <span class=\"type\">SMALLINT</span> COMMENT &quot;用户年龄&quot;,</span><br><span class=\"line\"> `sex` TINYINT COMMENT &quot;用户性别&quot;,</span><br><span class=\"line\"> `last_visit_date` DATETIME REPLACE <span class=\"keyword\">DEFAULT</span> &quot;1970-01-01 </span><br><span class=\"line\">00:00:00&quot; COMMENT &quot;用户最后一次访问时间&quot;,</span><br><span class=\"line\"> `cost` <span class=\"type\">BIGINT</span> SUM <span class=\"keyword\">DEFAULT</span> &quot;0&quot; COMMENT &quot;用户总消费&quot;,</span><br><span class=\"line\"> `max_dwell_time` <span class=\"type\">INT</span> MAX <span class=\"keyword\">DEFAULT</span> &quot;0&quot; COMMENT &quot;用户最大停留时间&quot;,</span><br><span class=\"line\"> `min_dwell_time` <span class=\"type\">INT</span> MIN <span class=\"keyword\">DEFAULT</span> &quot;99999&quot; COMMENT &quot;用户最小停留时</span><br><span class=\"line\">间&quot;</span><br><span class=\"line\">)</span><br><span class=\"line\">ENGINE<span class=\"operator\">=</span>olap</span><br><span class=\"line\">AGGREGATE KEY(`user_id`, `<span class=\"type\">date</span>`, `<span class=\"type\">timestamp</span>`, `city`, `age`, `sex`)</span><br><span class=\"line\"><span class=\"keyword\">PARTITION</span> <span class=\"keyword\">BY</span> LIST(`city`)</span><br><span class=\"line\">(</span><br><span class=\"line\"> <span class=\"keyword\">PARTITION</span> `p_cn` <span class=\"keyword\">VALUES</span> <span class=\"keyword\">IN</span> (&quot;Beijing&quot;, &quot;Shanghai&quot;, &quot;Hong Kong&quot;),</span><br><span class=\"line\"> <span class=\"keyword\">PARTITION</span> `p_usa` <span class=\"keyword\">VALUES</span> <span class=\"keyword\">IN</span> (&quot;New York&quot;, &quot;San Francisco&quot;),</span><br><span class=\"line\"> <span class=\"keyword\">PARTITION</span> `p_jp` <span class=\"keyword\">VALUES</span> <span class=\"keyword\">IN</span> (&quot;Tokyo&quot;)</span><br><span class=\"line\">)</span><br><span class=\"line\">DISTRIBUTED <span class=\"keyword\">BY</span> HASH(`user_id`) BUCKETS <span class=\"number\">16</span></span><br><span class=\"line\">PROPERTIES</span><br><span class=\"line\">(</span><br><span class=\"line\"> &quot;replication_num&quot; <span class=\"operator\">=</span> &quot;3&quot;,</span><br><span class=\"line\"> &quot;storage_medium&quot; <span class=\"operator\">=</span> &quot;SSD&quot;,</span><br><span class=\"line\"> &quot;storage_cooldown_time&quot; <span class=\"operator\">=</span> &quot;2018-01-01 12:00:00&quot;</span><br><span class=\"line\">);</span><br></pre></td></tr></table></figure></li>\n</ul>\n<h2 id=\"数据模型\"><a href=\"#数据模型\" class=\"headerlink\" title=\"数据模型\"></a>数据模型</h2><p>Doris 的数据模型主要分为 3 类：Aggregate、Uniq、Duplicate</p>\n<h3 id=\"Aggregate-模型\"><a href=\"#Aggregate-模型\" class=\"headerlink\" title=\"Aggregate 模型\"></a>Aggregate 模型</h3><p>表中的列按照是否设置了 AggregationType，分为 Key（维度列）和 Value（指标列）。没有设置 AggregationType 的称为 Key，设置了 AggregationType 的称为 Value。<br>当我们导入数据时，对于 Key 列相同的行会聚合成一行，而 Value 列会按照设置的AggregationType 进行聚合。AggregationType 目前有以下四种聚合方式：</p>\n<ul>\n<li>➢ SUM：求和，多行的 Value 进行累加。</li>\n<li>➢ REPLACE：替代，下一批数据中的 Value 会替换之前导入过的行中的 Value。<br>   REPLACE_IF_NOT_NULL ：当遇到 null 值则不更新。</li>\n<li>➢ MAX：保留最大值。</li>\n<li>➢ MIN：保留最小值。</li>\n</ul>\n<p>数据的聚合，在 Doris 中有如下三个阶段发生：</p>\n<ul>\n<li>（1）每一批次数据导入的 ETL 阶段。该阶段会在每一批次导入的数据内部进行聚合。</li>\n<li>（2）底层 BE 进行数据 Compaction 的阶段。该阶段，BE 会对已导入的不同批次的数据进行进一步的聚合。</li>\n<li>（3）数据查询阶段。在数据查询时，对于查询涉及到的数据，会进行对应的聚合。</li>\n</ul>\n<p>数据在不同时间，可能聚合的程度不一致。比如一批数据刚导入时，可能还未与之前已存在的数据进行聚合。但是对于用户而言，用户只能查询到聚合后的数据。即不同的聚合程度对于用户查询而言是透明的。用户需始终认为数据以最终的完成的聚合程度存在，而不应假设某些聚合还未发生。（可参阅聚合模型的局限性一节获得更多详情。）</p>\n<h3 id=\"Uniq-模型\"><a href=\"#Uniq-模型\" class=\"headerlink\" title=\"Uniq 模型\"></a>Uniq 模型</h3><p>在某些多维分析场景下，用户更关注的是如何保证 Key 的唯一性，即如何获得 Primary  Key 唯一性约束。因此，我们引入了 Uniq 的数据模型。该模型本质上是聚合模型的一个特 例，也是一种简化的表结构表示方式。</p>\n<p>Uniq 模型完全可以用聚合模型中的 REPLACE 方式替代。其内部的实现方式和数据存 储方式也完全一样。</p>\n<h3 id=\"Duplicate-模型\"><a href=\"#Duplicate-模型\" class=\"headerlink\" title=\"Duplicate 模型\"></a>Duplicate 模型</h3><p>在某些多维分析场景下，数据既没有主键，也没有聚合需求。Duplicate 数据模型可以 满足这类需求。数据完全按照导入文件中的数据进行存储，不会有任何聚合。即使两行数据 完全相同，也都会保留。 而在建表语句中指定的 <code>DUPLICATE KEY</code>，只是用来指明底层数 据按照那些列进行排序。</p>\n<h3 id=\"数据模型的选择建议\"><a href=\"#数据模型的选择建议\" class=\"headerlink\" title=\"数据模型的选择建议\"></a>数据模型的选择建议</h3><p>因为数据模型在建表时就已经确定，且无法修改。所以，选择一个合适的数据模型非常 重要。 </p>\n<p>（1）Aggregate 模型可以通过预聚合，极大地降低聚合查询时所需扫描的数据量和查询 的计算量，非常适合有固定模式的报表类查询场景。但是该模型对 count(*) 查询很不友好。 <strong>同时因为固定了 Value 列上的聚合方式，在进行其他类型的聚合查询时，需要考虑语意正确 性。</strong></p>\n<p>（2）Uniq 模型针对需要唯一主键约束的场景，可以保证主键唯一性约束。<strong>但是无法利 用 ROLLUP 等预聚合带来的查询优势（因为本质是 REPLACE，没有 SUM 这种聚合方式）。</strong> </p>\n<p>（3）Duplicate 适合任意维度的 Ad-hoc 查询。虽然同样无法利用预聚合的特性，但是不 受聚合模型的约束，可以发挥列存模型的优势（只读取相关列，而不需要读取所有 Key 列）</p>\n<h2 id=\"Rollup\"><a href=\"#Rollup\" class=\"headerlink\" title=\"Rollup\"></a>Rollup</h2><p>ROLLUP 在多维分析中是“上卷”的意思，即将数据按某种指定的粒度进行进一步聚 合。</p>\n<h3 id=\"基本概念\"><a href=\"#基本概念\" class=\"headerlink\" title=\"基本概念\"></a>基本概念</h3><p>在 Doris 中，我们将用户通过建表语句创建出来的表称为 Base 表（Base Table）。Base  表中保存着按用户建表语句指定的方式存储的基础数据。 </p>\n<p>在 Base 表之上，我们可以创建任意多个 ROLLUP 表。这些 ROLLUP 的数据是基于 Base  表产生的，并且在物理上是独立存储的。 ROLLUP 表的基本作用，在于在 Base 表的基础上，获得更粗粒度的聚合数据</p>\n<h3 id=\"Duplicate-模型中的-ROLLUP\"><a href=\"#Duplicate-模型中的-ROLLUP\" class=\"headerlink\" title=\"Duplicate 模型中的 ROLLUP\"></a>Duplicate 模型中的 ROLLUP</h3><p>因为 Duplicate 模型没有聚合的语意。所以该模型中的 ROLLUP，已经失去了“上卷” 这一层含义。而仅仅是作为调整列顺序，以命中前缀索引的作用。下面详细介绍前缀索引， 以及如何使用 ROLLUP 改变前缀索引，以获得更好的查询效率。</p>\n<h4 id=\"前缀索引\"><a href=\"#前缀索引\" class=\"headerlink\" title=\"前缀索引\"></a>前缀索引</h4><p>不同于传统的数据库设计，Doris 不支持在任意列上创建索引。Doris 这类 MPP 架构的 OLAP 数据库，通常都是通过提高并发，来处理大量数据的。 </p>\n<p>本质上，Doris 的数据存储在类似 SSTable（Sorted String Table）的数据结构中。该结构 是一种有序的数据结构，可以按照指定的列进行排序存储。在这种数据结构上，以排序列作 为条件进行查找，会非常的高效。 </p>\n<p>在 Aggregate、Uniq 和 Duplicate 三种数据模型中。底层的数据存储，是按照各自建表 语句中，AGGREGATE KEY、UNIQ KEY 和 DUPLICATE KEY 中指定的列进行排序存储 的。而<strong>前缀索引，即在排序的基础上，实现的一种根据给定前缀列，快速查询数据的索引方 式。</strong></p>\n<h4 id=\"ROLLUP-调整前缀索引\"><a href=\"#ROLLUP-调整前缀索引\" class=\"headerlink\" title=\"ROLLUP 调整前缀索引\"></a>ROLLUP 调整前缀索引</h4><p>因为建表时已经指定了列顺序，所以一个表只有一种前缀索引。这对于使用其他不能命 中前缀索引的列作为条件进行的查询来说，效率上可能无法满足需求。因此，我们可以通过 创建 ROLLUP 来人为的调整列顺序。举例说明。</p>\n<h3 id=\"ROLLUP-的几点说明\"><a href=\"#ROLLUP-的几点说明\" class=\"headerlink\" title=\"ROLLUP 的几点说明\"></a>ROLLUP 的几点说明</h3><p>⚫ ROLLUP 最根本的作用是提高某些查询的查询效率（无论是通过聚合来减少数据 量，还是修改列顺序以匹配前缀索引）。因此 ROLLUP 的含义已经超出了“上卷” 的范围。这也是为什么在源代码中，将其命名为 Materialized Index（物化索引）的 原因。</p>\n<p>⚫ ROLLUP 是附属于 Base 表的，可以看做是 Base 表的一种辅助数据结构。用户可以 在 Base 表的基础上，创建或删除 ROLLUP，但是不能在查询中显式的指定查询某 ROLLUP。是否命中 ROLLUP 完全由 Doris 系统自动决定。 </p>\n<p>⚫ ROLLUP 的数据是独立物理存储的。因此，创建的 ROLLUP 越多，占用的磁盘空 间也就越大。同时对导入速度也会有影响（导入的 ETL 阶段会自动产生所有 ROLLUP 的数据），但是不会降低查询效率（只会更好）。 </p>\n<p>⚫ ROLLUP 的数据更新与 Base 表是完全同步的。用户无需关心这个问题。</p>\n<p>⚫ ROLLUP 中列的聚合方式，与 Base 表完全相同。在创建 ROLLUP 无需指定，也不 能修改。 </p>\n<p>⚫ 查询能否命中 ROLLUP 的一个必要条件（非充分条件）是，查询所涉及的所有列 （包括 select list 和 where 中的查询条件列等）都存在于该 ROLLUP 的列中。否 则，查询只能命中 Base 表。 </p>\n<p>⚫ 某些类型的查询（如 count(*)）在任何条件下，都无法命中 ROLLUP。具体参见接 下来的聚合模型的局限性一节。</p>\n<p>⚫ 可以通过 EXPLAIN your_sql; 命令获得查询执行计划，在执行计划中，查看是否命 中 ROLLUP。</p>\n<p>⚫ 可以通过 DESC tbl_name ALL; 语句显示 Base 表和所有已创建完成的 ROLLUP。</p>\n<h2 id=\"物化视图\"><a href=\"#物化视图\" class=\"headerlink\" title=\"物化视图\"></a>物化视图</h2><p>物化视图就是包含了查询结果的数据库对象，可能是对远程数据的本地 copy，也可能 是一个表或多表 join 后结果的行或列的子集，也可能是聚合后的结果。说白了，就是预先存 储查询结果的一种数据库对象。</p>\n<p>在 Doris 中的物化视图，就是查询结果预先存储起来的特殊的表。 </p>\n<p>物化视图的出现主要是为了满足用户，既能对原始明细数据的任意维度分析，也能快速 的对固定维度进行分析查询。</p>\n<h3 id=\"优势\"><a href=\"#优势\" class=\"headerlink\" title=\"优势\"></a>优势</h3><p>⚫ 对于那些经常重复的使用相同的子查询结果的查询性能大幅提升。 </p>\n<p>⚫ Doris 自动维护物化视图的数据，无论是新的导入，还是删除操作都能保证 base 表 和物化视图表的数据一致性。无需任何额外的人工维护成本。 </p>\n<p>⚫ 查询时，会自动匹配到最优物化视图，并直接从物化视图中读取数据。 自动维护物化视图的数据会造成一些维护开销，会在后面的物化视图的局限性中展开说 明。</p>\n<h3 id=\"物化视图-VS-Rollup\"><a href=\"#物化视图-VS-Rollup\" class=\"headerlink\" title=\"物化视图 VS Rollup\"></a>物化视图 VS Rollup</h3><p>在没有物化视图功能之前，用户一般都是使用 Rollup 功能通过预聚合方式提升查询效 率的。但是 Rollup 具有一定的局限性，他不能基于明细模型做预聚合。 </p>\n<p>物化视图则在覆盖了 Rollup 的功能的同时，还能支持更丰富的聚合函数。所以物化视 图其实是 Rollup 的一个超集。 </p>\n<p>也就是说，之前 ALTER TABLE ADD ROLLUP 语法支持的功能现在均可以通过 CREATE MATERIALIZED VIEW 实现。</p>\n<h3 id=\"物化视图原理\"><a href=\"#物化视图原理\" class=\"headerlink\" title=\"物化视图原理\"></a>物化视图原理</h3><p>Doris 系统提供了一整套对物化视图的 DDL 语法，包括创建，查看，删除。DDL 的语 法和 PostgreSQL, Oracle 都是一致的。但是 Doris 目前创建物化视图只能在单表操作，不支 持 join。</p>\n"},{"title":"Flink Cluster With YARN","top_img":"linear-gradient(20deg, #0062be, #925696, #cc426e, #fb0347)","date":"2022-08-08T11:54:07.000Z","updated":"2022-08-08T11:54:07.000Z","cover":"https://tva3.sinaimg.cn/large/0084aYsLgy1h22161jezaj30xc0f0dh1.jpg","description":null,"keywords":null,"_content":"\n>在YARN部署模式中，有三种部署方式：\n>\n>- in Application Mode\n>- in Session Mode\n>- in a Per-Job Mode (deprecated)\n\n# YARN模式\n\n独立（Standalone）模式由 Flink 自身提供资源，无需其他框架，这种方式降低了和其他第三方资源框架的耦合性，独立性非常强。但我们知道，Flink 是大数据计算框架，不是资源调度框架，这并不是它的强项；所以还是应该让专业的框架做专业的事，和其他资源调度框架集成更靠谱。而在目前大数据生态中，国内应用最为广泛的资源管理平台就是 YARN 了。所以接下来我们就将学习，在强大的 YARN 平台上 Flink 是如何集成部署的。\n\n整体来说，YARN 上部署的过程是：客户端把 Flink 应用提交给 Yarn 的ResourceManager, Yarn 的 ResourceManager 会向 Yarn 的 NodeManager 申请容器。在这些容器上，Flink 会部署JobManager 和 TaskManager 的实例，从而启动集群。Flink 会根据运行在 JobManger 上的作业所需要的 Slot 数量动态分配TaskManager 资源。\n\n ![image.png](https://cdn.nlark.com/yuque/0/2022/png/2500465/1659960821751-9ec31d52-d839-445c-8aa4-e6f9af4d2ca8.png)\n\n## 相关准备和配置\n\n在 Flink1.8.0 之前的版本，想要以 YARN 模式部署 Flink 任务时，需要 Flink 是有 Hadoop 支持的。从 Flink 1.8 版本开始，不再提供基于 Hadoop 编译的安装包，若需要Hadoop 的环境支持，需要自行在官网下载 Hadoop 相关版本的组件flink-shaded-hadoop-2-uber-2.7.5-10.0.jar， 并将该组件上传至 Flink 的 lib 目录下。在 Flink 1.11.0 版本之后，增加了很多重要新特性，其中就包括增加了对Hadoop3.0.0 以及更高版本Hadoop 的支持，不再提供“flink-shaded-hadoop-*” jar 包，而是通过配置环境变量完成与 YARN 集群的对接。\n\n在将 Flink 任务部署至 YARN 集群之前，需要确认集群是否安装有Hadoop，保证 Hadoop\n\n版本至少在 2.2 以上，并且集群中安装有 HDFS 服务。具体配置步骤如下：\n\n（1）下载并解压安装包，并将解压后的安装包重命名为flink-1.13.0-yarn，本节的相关操作都将默认在此安装路径下执行。\n\n（2）配置环境变量，增加环境变量配置如下：\n\n```sh\n$ sudo vim /etc/profile.d/my_env.sh \nHADOOP_HOME=/opt/module/hadoop-2.7.5\nexport PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin\nexport HADOOP_CONF_DIR=${HADOOP_HOME}/etc/hadoop\nexport HADOOP_CLASSPATH=`hadoop classpath`\n```\n这里必须保证设置了环境变量HADOOP_CLASSPATH。\n\n（3）启动Hadoop 集群，包括 HDFS 和 YARN\n（4）进入 conf 目录，修改 flink-conf.yaml 文件，修改以下配置，若在提交命令中不特定指明，这些配置将作为默认配置。\n```\n$ cd /opt/module/flink-1.13.0-yarn/conf/\n$ vim flink-conf.yaml \njobmanager.memory.process.size: 1600m \ntaskmanager.memory.process.size: 1728m \ntaskmanager.numberOfTaskSlots: 8\nparallelism.default: 1\n```\n\n## 应用模式部署\n\n应用模式同样非常简单，与单作业模式类似，直接执行 flink run-application 命令即可。\n\n（1)执行命令提交作业。\n\n```sh\n$ bin/flink run-application -t yarn-application -c com.atguigu.wc.StreamWordCount\nFlinkTutorial-1.0-SNAPSHOT.jar\n```\n\n（2）在命令行中查看或取消作业。\n\n```shell\n$./bin/flink list -t yarn-application -Dyarn.application.id=application_XXXX_YY\n$./bin/flink cancel\t-t\tyarn-application -Dyarn.application.id=application_XXXX_YY <jobId>\n```\n\n（3） 也可以通过yarn.provided.lib.dirs 配置选项指定位置，将 jar 上传到远程。\n\n```sh\n$ ./bin/flink run-application -t yarn-application -Dyarn.provided.lib.dirs=\"hdfs://myhdfs/my-remote-flink-dist-dir\" \nhdfs://myhdfs/jars/my-application.jar\n```\n\n\n这种方式下 jar 可以预先上传到 HDFS，而不需要单独发送到集群，这就使得作业提交更加轻量了。\n\n## 高可用\n\nYARN 模式的高可用和独立模式（Standalone）的高可用原理不一样。\n\nStandalone 模式中, 同时启动多个 JobManager, 一个为“领导者”（leader），其他为“后备”（standby）, 当 leader 挂了, 其他的才会有一个成为 leader。\n\n而 YARN 的高可用是只启动一个 Jobmanager, 当这个 Jobmanager 挂了之后, YARN 会再次启动一个, 所以其实是利用的 YARN 的重试次数来实现的高可用。\n\n（1） 在 yarn-site.xml 中配置。\n\n```xml\n<property>\n<name>yarn.resourcemanager.am.max-attempts</name>\n<value>4</value>\n<description>\nThe maximum number of application master execution attempts.\n</description>\n</property>\n```\n\n注意: 配置完不要忘记分发, 和重启 YARN。\n\n（2） 在 flink-conf.yaml 中配置。\n\n```yaml\nyarn.application-attempts: 3 \nhigh-availability: zookeeper\nhigh-availability.storageDir: hdfs://hadoop102:9820/flink/yarn/ha \nhigh-availability.zookeeper.quorum: hadoop102:2181,hadoop103:2181,hadoop104:2181\nhigh-availability.zookeeper.path.root: /flink-yarn\n```\n\n（3） 启动 yarn-session。\n\n（4） 杀死 JobManager, 查看复活情况。\n\n注意: yarn-site.xml 中配置的是 JobManager 重启次数的上限, flink-conf.xml 中的次数应该小于这个值。\n","source":"_posts/bigdata/搭建Flink集群.md","raw":"---\ntitle: Flink Cluster With YARN\ntags:\n  - 'Flink'\ncategories:\n  - [bigdata,Flink]\ntop_img: 'linear-gradient(20deg, #0062be, #925696, #cc426e, #fb0347)'\ndate: 2022-08-08 19:54:07\nupdated: 2022-08-08 19:54:07\ncover:\ndescription:\nkeywords:\n---\n\n>在YARN部署模式中，有三种部署方式：\n>\n>- in Application Mode\n>- in Session Mode\n>- in a Per-Job Mode (deprecated)\n\n# YARN模式\n\n独立（Standalone）模式由 Flink 自身提供资源，无需其他框架，这种方式降低了和其他第三方资源框架的耦合性，独立性非常强。但我们知道，Flink 是大数据计算框架，不是资源调度框架，这并不是它的强项；所以还是应该让专业的框架做专业的事，和其他资源调度框架集成更靠谱。而在目前大数据生态中，国内应用最为广泛的资源管理平台就是 YARN 了。所以接下来我们就将学习，在强大的 YARN 平台上 Flink 是如何集成部署的。\n\n整体来说，YARN 上部署的过程是：客户端把 Flink 应用提交给 Yarn 的ResourceManager, Yarn 的 ResourceManager 会向 Yarn 的 NodeManager 申请容器。在这些容器上，Flink 会部署JobManager 和 TaskManager 的实例，从而启动集群。Flink 会根据运行在 JobManger 上的作业所需要的 Slot 数量动态分配TaskManager 资源。\n\n ![image.png](https://cdn.nlark.com/yuque/0/2022/png/2500465/1659960821751-9ec31d52-d839-445c-8aa4-e6f9af4d2ca8.png)\n\n## 相关准备和配置\n\n在 Flink1.8.0 之前的版本，想要以 YARN 模式部署 Flink 任务时，需要 Flink 是有 Hadoop 支持的。从 Flink 1.8 版本开始，不再提供基于 Hadoop 编译的安装包，若需要Hadoop 的环境支持，需要自行在官网下载 Hadoop 相关版本的组件flink-shaded-hadoop-2-uber-2.7.5-10.0.jar， 并将该组件上传至 Flink 的 lib 目录下。在 Flink 1.11.0 版本之后，增加了很多重要新特性，其中就包括增加了对Hadoop3.0.0 以及更高版本Hadoop 的支持，不再提供“flink-shaded-hadoop-*” jar 包，而是通过配置环境变量完成与 YARN 集群的对接。\n\n在将 Flink 任务部署至 YARN 集群之前，需要确认集群是否安装有Hadoop，保证 Hadoop\n\n版本至少在 2.2 以上，并且集群中安装有 HDFS 服务。具体配置步骤如下：\n\n（1）下载并解压安装包，并将解压后的安装包重命名为flink-1.13.0-yarn，本节的相关操作都将默认在此安装路径下执行。\n\n（2）配置环境变量，增加环境变量配置如下：\n\n```sh\n$ sudo vim /etc/profile.d/my_env.sh \nHADOOP_HOME=/opt/module/hadoop-2.7.5\nexport PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin\nexport HADOOP_CONF_DIR=${HADOOP_HOME}/etc/hadoop\nexport HADOOP_CLASSPATH=`hadoop classpath`\n```\n这里必须保证设置了环境变量HADOOP_CLASSPATH。\n\n（3）启动Hadoop 集群，包括 HDFS 和 YARN\n（4）进入 conf 目录，修改 flink-conf.yaml 文件，修改以下配置，若在提交命令中不特定指明，这些配置将作为默认配置。\n```\n$ cd /opt/module/flink-1.13.0-yarn/conf/\n$ vim flink-conf.yaml \njobmanager.memory.process.size: 1600m \ntaskmanager.memory.process.size: 1728m \ntaskmanager.numberOfTaskSlots: 8\nparallelism.default: 1\n```\n\n## 应用模式部署\n\n应用模式同样非常简单，与单作业模式类似，直接执行 flink run-application 命令即可。\n\n（1)执行命令提交作业。\n\n```sh\n$ bin/flink run-application -t yarn-application -c com.atguigu.wc.StreamWordCount\nFlinkTutorial-1.0-SNAPSHOT.jar\n```\n\n（2）在命令行中查看或取消作业。\n\n```shell\n$./bin/flink list -t yarn-application -Dyarn.application.id=application_XXXX_YY\n$./bin/flink cancel\t-t\tyarn-application -Dyarn.application.id=application_XXXX_YY <jobId>\n```\n\n（3） 也可以通过yarn.provided.lib.dirs 配置选项指定位置，将 jar 上传到远程。\n\n```sh\n$ ./bin/flink run-application -t yarn-application -Dyarn.provided.lib.dirs=\"hdfs://myhdfs/my-remote-flink-dist-dir\" \nhdfs://myhdfs/jars/my-application.jar\n```\n\n\n这种方式下 jar 可以预先上传到 HDFS，而不需要单独发送到集群，这就使得作业提交更加轻量了。\n\n## 高可用\n\nYARN 模式的高可用和独立模式（Standalone）的高可用原理不一样。\n\nStandalone 模式中, 同时启动多个 JobManager, 一个为“领导者”（leader），其他为“后备”（standby）, 当 leader 挂了, 其他的才会有一个成为 leader。\n\n而 YARN 的高可用是只启动一个 Jobmanager, 当这个 Jobmanager 挂了之后, YARN 会再次启动一个, 所以其实是利用的 YARN 的重试次数来实现的高可用。\n\n（1） 在 yarn-site.xml 中配置。\n\n```xml\n<property>\n<name>yarn.resourcemanager.am.max-attempts</name>\n<value>4</value>\n<description>\nThe maximum number of application master execution attempts.\n</description>\n</property>\n```\n\n注意: 配置完不要忘记分发, 和重启 YARN。\n\n（2） 在 flink-conf.yaml 中配置。\n\n```yaml\nyarn.application-attempts: 3 \nhigh-availability: zookeeper\nhigh-availability.storageDir: hdfs://hadoop102:9820/flink/yarn/ha \nhigh-availability.zookeeper.quorum: hadoop102:2181,hadoop103:2181,hadoop104:2181\nhigh-availability.zookeeper.path.root: /flink-yarn\n```\n\n（3） 启动 yarn-session。\n\n（4） 杀死 JobManager, 查看复活情况。\n\n注意: yarn-site.xml 中配置的是 JobManager 重启次数的上限, flink-conf.xml 中的次数应该小于这个值。\n","slug":"bigdata/搭建Flink集群","published":1,"comments":1,"layout":"post","photos":[],"link":"","_id":"cl9y38dsn001wfwuigta4aut2","content":"<blockquote>\n<p>在YARN部署模式中，有三种部署方式：</p>\n<ul>\n<li>in Application Mode</li>\n<li>in Session Mode</li>\n<li>in a Per-Job Mode (deprecated)</li>\n</ul>\n</blockquote>\n<h1 id=\"YARN模式\"><a href=\"#YARN模式\" class=\"headerlink\" title=\"YARN模式\"></a>YARN模式</h1><p>独立（Standalone）模式由 Flink 自身提供资源，无需其他框架，这种方式降低了和其他第三方资源框架的耦合性，独立性非常强。但我们知道，Flink 是大数据计算框架，不是资源调度框架，这并不是它的强项；所以还是应该让专业的框架做专业的事，和其他资源调度框架集成更靠谱。而在目前大数据生态中，国内应用最为广泛的资源管理平台就是 YARN 了。所以接下来我们就将学习，在强大的 YARN 平台上 Flink 是如何集成部署的。</p>\n<p>整体来说，YARN 上部署的过程是：客户端把 Flink 应用提交给 Yarn 的ResourceManager, Yarn 的 ResourceManager 会向 Yarn 的 NodeManager 申请容器。在这些容器上，Flink 会部署JobManager 和 TaskManager 的实例，从而启动集群。Flink 会根据运行在 JobManger 上的作业所需要的 Slot 数量动态分配TaskManager 资源。</p>\n<p> <img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1659960821751-9ec31d52-d839-445c-8aa4-e6f9af4d2ca8.png\" alt=\"image.png\"></p>\n<h2 id=\"相关准备和配置\"><a href=\"#相关准备和配置\" class=\"headerlink\" title=\"相关准备和配置\"></a>相关准备和配置</h2><p>在 Flink1.8.0 之前的版本，想要以 YARN 模式部署 Flink 任务时，需要 Flink 是有 Hadoop 支持的。从 Flink 1.8 版本开始，不再提供基于 Hadoop 编译的安装包，若需要Hadoop 的环境支持，需要自行在官网下载 Hadoop 相关版本的组件flink-shaded-hadoop-2-uber-2.7.5-10.0.jar， 并将该组件上传至 Flink 的 lib 目录下。在 Flink 1.11.0 版本之后，增加了很多重要新特性，其中就包括增加了对Hadoop3.0.0 以及更高版本Hadoop 的支持，不再提供“flink-shaded-hadoop-*” jar 包，而是通过配置环境变量完成与 YARN 集群的对接。</p>\n<p>在将 Flink 任务部署至 YARN 集群之前，需要确认集群是否安装有Hadoop，保证 Hadoop</p>\n<p>版本至少在 2.2 以上，并且集群中安装有 HDFS 服务。具体配置步骤如下：</p>\n<p>（1）下载并解压安装包，并将解压后的安装包重命名为flink-1.13.0-yarn，本节的相关操作都将默认在此安装路径下执行。</p>\n<p>（2）配置环境变量，增加环境变量配置如下：</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo vim /etc/profile.d/my_env.sh </span><br><span class=\"line\">HADOOP_HOME=/opt/module/hadoop-2.7.5</span><br><span class=\"line\"><span class=\"built_in\">export</span> PATH=<span class=\"variable\">$PATH</span>:<span class=\"variable\">$HADOOP_HOME</span>/bin:<span class=\"variable\">$HADOOP_HOME</span>/sbin</span><br><span class=\"line\"><span class=\"built_in\">export</span> HADOOP_CONF_DIR=<span class=\"variable\">$&#123;HADOOP_HOME&#125;</span>/etc/hadoop</span><br><span class=\"line\"><span class=\"built_in\">export</span> HADOOP_CLASSPATH=`hadoop classpath`</span><br></pre></td></tr></table></figure>\n<p>这里必须保证设置了环境变量HADOOP_CLASSPATH。</p>\n<p>（3）启动Hadoop 集群，包括 HDFS 和 YARN<br>（4）进入 conf 目录，修改 flink-conf.yaml 文件，修改以下配置，若在提交命令中不特定指明，这些配置将作为默认配置。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ cd /opt/module/flink-1.13.0-yarn/conf/</span><br><span class=\"line\">$ vim flink-conf.yaml </span><br><span class=\"line\">jobmanager.memory.process.size: 1600m </span><br><span class=\"line\">taskmanager.memory.process.size: 1728m </span><br><span class=\"line\">taskmanager.numberOfTaskSlots: 8</span><br><span class=\"line\">parallelism.default: 1</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"应用模式部署\"><a href=\"#应用模式部署\" class=\"headerlink\" title=\"应用模式部署\"></a>应用模式部署</h2><p>应用模式同样非常简单，与单作业模式类似，直接执行 flink run-application 命令即可。</p>\n<p>（1)执行命令提交作业。</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ bin/flink run-application -t yarn-application -c com.atguigu.wc.StreamWordCount</span><br><span class=\"line\">FlinkTutorial-1.0-SNAPSHOT.jar</span><br></pre></td></tr></table></figure>\n\n<p>（2）在命令行中查看或取消作业。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\">$</span><span class=\"language-bash\">./bin/flink list -t yarn-application -Dyarn.application.id=application_XXXX_YY</span></span><br><span class=\"line\"><span class=\"meta prompt_\">$</span><span class=\"language-bash\">./bin/flink cancel\t-t\tyarn-application -Dyarn.application.id=application_XXXX_YY &lt;jobId&gt;</span></span><br></pre></td></tr></table></figure>\n\n<p>（3） 也可以通过yarn.provided.lib.dirs 配置选项指定位置，将 jar 上传到远程。</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ./bin/flink run-application -t yarn-application -Dyarn.provided.lib.dirs=<span class=\"string\">&quot;hdfs://myhdfs/my-remote-flink-dist-dir&quot;</span> </span><br><span class=\"line\">hdfs://myhdfs/jars/my-application.jar</span><br></pre></td></tr></table></figure>\n\n\n<p>这种方式下 jar 可以预先上传到 HDFS，而不需要单独发送到集群，这就使得作业提交更加轻量了。</p>\n<h2 id=\"高可用\"><a href=\"#高可用\" class=\"headerlink\" title=\"高可用\"></a>高可用</h2><p>YARN 模式的高可用和独立模式（Standalone）的高可用原理不一样。</p>\n<p>Standalone 模式中, 同时启动多个 JobManager, 一个为“领导者”（leader），其他为“后备”（standby）, 当 leader 挂了, 其他的才会有一个成为 leader。</p>\n<p>而 YARN 的高可用是只启动一个 Jobmanager, 当这个 Jobmanager 挂了之后, YARN 会再次启动一个, 所以其实是利用的 YARN 的重试次数来实现的高可用。</p>\n<p>（1） 在 yarn-site.xml 中配置。</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>yarn.resourcemanager.am.max-attempts<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>4<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">description</span>&gt;</span></span><br><span class=\"line\">The maximum number of application master execution attempts.</span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">description</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n\n<p>注意: 配置完不要忘记分发, 和重启 YARN。</p>\n<p>（2） 在 flink-conf.yaml 中配置。</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">yarn.application-attempts:</span> <span class=\"number\">3</span> </span><br><span class=\"line\"><span class=\"attr\">high-availability:</span> <span class=\"string\">zookeeper</span></span><br><span class=\"line\"><span class=\"attr\">high-availability.storageDir:</span> <span class=\"string\">hdfs://hadoop102:9820/flink/yarn/ha</span> </span><br><span class=\"line\"><span class=\"attr\">high-availability.zookeeper.quorum:</span> <span class=\"string\">hadoop102:2181,hadoop103:2181,hadoop104:2181</span></span><br><span class=\"line\"><span class=\"attr\">high-availability.zookeeper.path.root:</span> <span class=\"string\">/flink-yarn</span></span><br></pre></td></tr></table></figure>\n\n<p>（3） 启动 yarn-session。</p>\n<p>（4） 杀死 JobManager, 查看复活情况。</p>\n<p>注意: yarn-site.xml 中配置的是 JobManager 重启次数的上限, flink-conf.xml 中的次数应该小于这个值。</p>\n","site":{"data":{"link":[{"class_name":"友情链接","class_desc":"那些人，那些事","link_list":[{"name":"张洪Heo","link":"https://blog.zhheo.com/","avatar":"https://npm.elemecdn.com/guli-heo/img/avatar2.png","descr":"分享设计与科技生活"},{"name":"瞬間の筆記","link":"https://hikki.site","descr":"喜欢的东西就努力去追求，万一成功了呢!","avatar":"https://cdn.jsdelivr.net/gh/0000rookie/imgs/202206120315.png"}]}]}},"excerpt":"","more":"<blockquote>\n<p>在YARN部署模式中，有三种部署方式：</p>\n<ul>\n<li>in Application Mode</li>\n<li>in Session Mode</li>\n<li>in a Per-Job Mode (deprecated)</li>\n</ul>\n</blockquote>\n<h1 id=\"YARN模式\"><a href=\"#YARN模式\" class=\"headerlink\" title=\"YARN模式\"></a>YARN模式</h1><p>独立（Standalone）模式由 Flink 自身提供资源，无需其他框架，这种方式降低了和其他第三方资源框架的耦合性，独立性非常强。但我们知道，Flink 是大数据计算框架，不是资源调度框架，这并不是它的强项；所以还是应该让专业的框架做专业的事，和其他资源调度框架集成更靠谱。而在目前大数据生态中，国内应用最为广泛的资源管理平台就是 YARN 了。所以接下来我们就将学习，在强大的 YARN 平台上 Flink 是如何集成部署的。</p>\n<p>整体来说，YARN 上部署的过程是：客户端把 Flink 应用提交给 Yarn 的ResourceManager, Yarn 的 ResourceManager 会向 Yarn 的 NodeManager 申请容器。在这些容器上，Flink 会部署JobManager 和 TaskManager 的实例，从而启动集群。Flink 会根据运行在 JobManger 上的作业所需要的 Slot 数量动态分配TaskManager 资源。</p>\n<p> <img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1659960821751-9ec31d52-d839-445c-8aa4-e6f9af4d2ca8.png\" alt=\"image.png\"></p>\n<h2 id=\"相关准备和配置\"><a href=\"#相关准备和配置\" class=\"headerlink\" title=\"相关准备和配置\"></a>相关准备和配置</h2><p>在 Flink1.8.0 之前的版本，想要以 YARN 模式部署 Flink 任务时，需要 Flink 是有 Hadoop 支持的。从 Flink 1.8 版本开始，不再提供基于 Hadoop 编译的安装包，若需要Hadoop 的环境支持，需要自行在官网下载 Hadoop 相关版本的组件flink-shaded-hadoop-2-uber-2.7.5-10.0.jar， 并将该组件上传至 Flink 的 lib 目录下。在 Flink 1.11.0 版本之后，增加了很多重要新特性，其中就包括增加了对Hadoop3.0.0 以及更高版本Hadoop 的支持，不再提供“flink-shaded-hadoop-*” jar 包，而是通过配置环境变量完成与 YARN 集群的对接。</p>\n<p>在将 Flink 任务部署至 YARN 集群之前，需要确认集群是否安装有Hadoop，保证 Hadoop</p>\n<p>版本至少在 2.2 以上，并且集群中安装有 HDFS 服务。具体配置步骤如下：</p>\n<p>（1）下载并解压安装包，并将解压后的安装包重命名为flink-1.13.0-yarn，本节的相关操作都将默认在此安装路径下执行。</p>\n<p>（2）配置环境变量，增加环境变量配置如下：</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo vim /etc/profile.d/my_env.sh </span><br><span class=\"line\">HADOOP_HOME=/opt/module/hadoop-2.7.5</span><br><span class=\"line\"><span class=\"built_in\">export</span> PATH=<span class=\"variable\">$PATH</span>:<span class=\"variable\">$HADOOP_HOME</span>/bin:<span class=\"variable\">$HADOOP_HOME</span>/sbin</span><br><span class=\"line\"><span class=\"built_in\">export</span> HADOOP_CONF_DIR=<span class=\"variable\">$&#123;HADOOP_HOME&#125;</span>/etc/hadoop</span><br><span class=\"line\"><span class=\"built_in\">export</span> HADOOP_CLASSPATH=`hadoop classpath`</span><br></pre></td></tr></table></figure>\n<p>这里必须保证设置了环境变量HADOOP_CLASSPATH。</p>\n<p>（3）启动Hadoop 集群，包括 HDFS 和 YARN<br>（4）进入 conf 目录，修改 flink-conf.yaml 文件，修改以下配置，若在提交命令中不特定指明，这些配置将作为默认配置。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ cd /opt/module/flink-1.13.0-yarn/conf/</span><br><span class=\"line\">$ vim flink-conf.yaml </span><br><span class=\"line\">jobmanager.memory.process.size: 1600m </span><br><span class=\"line\">taskmanager.memory.process.size: 1728m </span><br><span class=\"line\">taskmanager.numberOfTaskSlots: 8</span><br><span class=\"line\">parallelism.default: 1</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"应用模式部署\"><a href=\"#应用模式部署\" class=\"headerlink\" title=\"应用模式部署\"></a>应用模式部署</h2><p>应用模式同样非常简单，与单作业模式类似，直接执行 flink run-application 命令即可。</p>\n<p>（1)执行命令提交作业。</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ bin/flink run-application -t yarn-application -c com.atguigu.wc.StreamWordCount</span><br><span class=\"line\">FlinkTutorial-1.0-SNAPSHOT.jar</span><br></pre></td></tr></table></figure>\n\n<p>（2）在命令行中查看或取消作业。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\">$</span><span class=\"language-bash\">./bin/flink list -t yarn-application -Dyarn.application.id=application_XXXX_YY</span></span><br><span class=\"line\"><span class=\"meta prompt_\">$</span><span class=\"language-bash\">./bin/flink cancel\t-t\tyarn-application -Dyarn.application.id=application_XXXX_YY &lt;jobId&gt;</span></span><br></pre></td></tr></table></figure>\n\n<p>（3） 也可以通过yarn.provided.lib.dirs 配置选项指定位置，将 jar 上传到远程。</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ./bin/flink run-application -t yarn-application -Dyarn.provided.lib.dirs=<span class=\"string\">&quot;hdfs://myhdfs/my-remote-flink-dist-dir&quot;</span> </span><br><span class=\"line\">hdfs://myhdfs/jars/my-application.jar</span><br></pre></td></tr></table></figure>\n\n\n<p>这种方式下 jar 可以预先上传到 HDFS，而不需要单独发送到集群，这就使得作业提交更加轻量了。</p>\n<h2 id=\"高可用\"><a href=\"#高可用\" class=\"headerlink\" title=\"高可用\"></a>高可用</h2><p>YARN 模式的高可用和独立模式（Standalone）的高可用原理不一样。</p>\n<p>Standalone 模式中, 同时启动多个 JobManager, 一个为“领导者”（leader），其他为“后备”（standby）, 当 leader 挂了, 其他的才会有一个成为 leader。</p>\n<p>而 YARN 的高可用是只启动一个 Jobmanager, 当这个 Jobmanager 挂了之后, YARN 会再次启动一个, 所以其实是利用的 YARN 的重试次数来实现的高可用。</p>\n<p>（1） 在 yarn-site.xml 中配置。</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>yarn.resourcemanager.am.max-attempts<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>4<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">description</span>&gt;</span></span><br><span class=\"line\">The maximum number of application master execution attempts.</span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">description</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n\n<p>注意: 配置完不要忘记分发, 和重启 YARN。</p>\n<p>（2） 在 flink-conf.yaml 中配置。</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">yarn.application-attempts:</span> <span class=\"number\">3</span> </span><br><span class=\"line\"><span class=\"attr\">high-availability:</span> <span class=\"string\">zookeeper</span></span><br><span class=\"line\"><span class=\"attr\">high-availability.storageDir:</span> <span class=\"string\">hdfs://hadoop102:9820/flink/yarn/ha</span> </span><br><span class=\"line\"><span class=\"attr\">high-availability.zookeeper.quorum:</span> <span class=\"string\">hadoop102:2181,hadoop103:2181,hadoop104:2181</span></span><br><span class=\"line\"><span class=\"attr\">high-availability.zookeeper.path.root:</span> <span class=\"string\">/flink-yarn</span></span><br></pre></td></tr></table></figure>\n\n<p>（3） 启动 yarn-session。</p>\n<p>（4） 杀死 JobManager, 查看复活情况。</p>\n<p>注意: yarn-site.xml 中配置的是 JobManager 重启次数的上限, flink-conf.xml 中的次数应该小于这个值。</p>\n"},{"title":"测试Flink Doris Connector","top_img":"linear-gradient(20deg, #0062be, #925696, #cc426e, #fb0347)","date":"2022-08-06T09:57:25.000Z","updated":"2022-08-06T09:57:25.000Z","cover":"https://tvax3.sinaimg.cn/large/0084aYsLly1grnkfb3zyvj31hc0tndku.jpg","description":null,"keywords":null,"_content":"\n> 利用Flink Doris Connector将Kafka中的数据实时导入到Doris\n>\n> 该Connector支持Flink SQL和DataStream API\n>\n> **注意：**\n>\n> 1. 修改和删除只支持在 Unique Key 模型上\n> 2. 目前的删除是支持 Flink CDC 的方式接入数据实现自动删除，如果是其他数据接入的方式删除需要自己实现。Flink CDC 的数据删除使用方式参照本文档最后一节\n\n\n\n### Maven\n\n```xml\n<dependency>\n    <groupId>org.apache.flink</groupId>\n    <artifactId>flink-java</artifactId>\n    <version>${flink.version}</version>\n    <scope>provided</scope>\n</dependency>\n<dependency>\n    <groupId>org.apache.flink</groupId>\n    <artifactId>flink-streaming-java_${scala.version}</artifactId>\n    <version>${flink.version}</version>\n    <scope>provided</scope>\n</dependency>\n<dependency>\n    <groupId>org.apache.flink</groupId>\n    <artifactId>flink-clients_${scala.version}</artifactId>\n    <version>${flink.version}</version>\n    <scope>provided</scope>\n</dependency>\n<!-- flink table -->\n<dependency>\n    <groupId>org.apache.flink</groupId>\n    <artifactId>flink-table-planner_${scala.version}</artifactId>\n    <version>${flink.version}</version>\n    <scope>provided</scope>\n</dependency>\n\n<!-- flink-doris-connector -->\n<dependency>\n  <groupId>org.apache.doris</groupId>\n  <artifactId>flink-doris-connector-1.14_2.12</artifactId>\n  <version>1.1.0</version>\n</dependency>  \n```\n\n\n\n### 参数配置\n\nFlink Doris Connector Sink 的内部实现是通过 `Stream Load` 服务向 Doris 写入数据, 同时也支持 `Stream Load` 请求参数的配置设置，具体参数可参考[这里](https://doris.apache.org/zh-CN/docs/data-operate/import/import-way/stream-load-manual)，配置方法如下：\n\n- SQL 使用 `WITH` 参数 `sink.properties.` 配置\n- DataStream 使用方法`DorisExecutionOptions.builder().setStreamLoadProp(Properties)`配置\n\n\n\n### 示例\n\n```scala\npackage cn.jxau.yuan\n\n\nimport cn.jxau.yuan.common.Config\nimport org.apache.doris.flink.cfg.{DorisExecutionOptions, DorisOptions, DorisReadOptions}\nimport org.apache.doris.flink.sink.DorisSink\nimport org.apache.doris.flink.sink.writer.SimpleStringSerializer\nimport org.apache.flink.api.common.eventtime.WatermarkStrategy\nimport org.apache.flink.api.common.serialization.SimpleStringSchema\nimport org.apache.flink.connector.kafka.source.KafkaSource\nimport org.apache.flink.connector.kafka.source.enumerator.initializer.OffsetsInitializer\nimport org.apache.flink.streaming.api.environment.CheckpointConfig\nimport org.apache.flink.streaming.api.scala._\n\nimport java.util.Properties\n\n\nobject KafkaConnectTest {\n\n  def main(args: Array[String]): Unit = {\n    val env: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment\n    env.enableCheckpointing(10000)\n    env.getCheckpointConfig.setExternalizedCheckpointCleanup(CheckpointConfig.ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION)\n\n\n    val kafkaSource: KafkaSource[String] = KafkaSource.builder[String]\n      .setBootstrapServers(Config.broker)\n      .setTopics(\"input-topic\")\n      .setGroupId(\"my-group\")\n      .setStartingOffsets(OffsetsInitializer.earliest)\n      .setValueOnlyDeserializer(new SimpleStringSchema)\n      .build\n\n    env.fromSource(kafkaSource, WatermarkStrategy.noWatermarks[String](), \"Kafka Source\")\n      .sinkTo(buildDorisSink())\n\n    env.execute()\n  }\n\n  def buildDorisSink(): DorisSink[String]  = {\n    //sink config\n    val builder: DorisSink.Builder[String] = DorisSink.builder();\n    val dorisBuilder: DorisOptions.Builder = DorisOptions.builder();\n    dorisBuilder.setFenodes(\"127.0.0.1:8030\")\n      .setTableIdentifier(\"db.table\")\n      .setUsername(\"root\")\n      .setPassword(\"password\");\n\n\n    val pro: Properties = new Properties();\n    //json data format\n    pro.setProperty(\"format\", \"json\");\n    pro.setProperty(\"read_json_by_line\", \"true\");\n\n\n    val executionOptions: DorisExecutionOptions  = DorisExecutionOptions.builder()\n      .setLabelPrefix(\"label-doris\") //streamload label prefix,\n      .setStreamLoadProp(pro)\n      .build()\n\n    builder.setDorisReadOptions(DorisReadOptions.builder().build())\n      .setDorisExecutionOptions(executionOptions)\n      .setSerializer(new SimpleStringSerializer()) //serialize according to string\n      .setDorisOptions(dorisBuilder.build())\n      .build()\n  }\n}\n\n```\n\n## Flink Table && SQL Maven\n\n我们想要在代码中使用Table API，必须引入相关的依赖。\n\n```xml\n<dependency>\n    <groupId>org.apache.flink</groupId>\n    <artifactId>flink-table-api-java-bridge_${scala.binary.version}</artifactId>\n    <version>${flink.version}</version>\n</dependency>\n\n```\n\n这里的依赖是一个 Java 的“桥接器”（bridge），主要就是负责 Table API 和下层 DataStream API 的连接支持，按照不同的语言分为 Java 版和 Scala 版。\n\n如果我们希望在本地的集成开发环境（IDE）里运行 Table API 和 SQL，还需要引入以下依赖：\n\n```xml\n<dependency>\n    <groupId>org.apache.flink</groupId>\n    <artifactId>flink-table-planner-blink_${scala.binary.version}</artifactId>\n    <version>${flink.version}</version>\n    </dependency>\n    <dependency>\n    <groupId>org.apache.flink</groupId>\n    <artifactId>flink-streaming-scala_${scala.binary.version}</artifactId>\n    <version>${flink.version}</version>\n</dependency>\n```\n\n这里主要添加的依赖是一个“计划器”（planner），它是 Table API 的核心组件，负责提供运行时环境，并生成程序的执行计划。这里我们用到的是新版的 blink planner。由于 Flink 安装包的 lib 目录下会自带planner，所以在生产集群环境中提交的作业不需要打包这个赖。而在Table API 的内部实现上，部分相关的代码是用 Scala 实现的，所以还需要额外添加一个 Scala 版流处理的相关依赖。\n另外，如果想实现自定义的数据格式来做序列化，可以引入下面的依赖：\n\n```xml\n<dependency>\n    <groupId>org.apache.flink</groupId>\n    <artifactId>flink-table-common</artifactId>\n    <version>${flink.version}</version>\n</dependency>\n```\n\n","source":"_posts/bigdata/测试Flink-Doris-Connector.md","raw":"---\ntitle: 测试Flink Doris Connector\ntags:\n  - 'Doris'\ncategories:\n  - [bigdata,Doris]\ntop_img: 'linear-gradient(20deg, #0062be, #925696, #cc426e, #fb0347)'\ndate: 2022-08-06 17:57:25\nupdated: 2022-08-06 17:57:25\ncover:\ndescription:\nkeywords:\n---\n\n> 利用Flink Doris Connector将Kafka中的数据实时导入到Doris\n>\n> 该Connector支持Flink SQL和DataStream API\n>\n> **注意：**\n>\n> 1. 修改和删除只支持在 Unique Key 模型上\n> 2. 目前的删除是支持 Flink CDC 的方式接入数据实现自动删除，如果是其他数据接入的方式删除需要自己实现。Flink CDC 的数据删除使用方式参照本文档最后一节\n\n\n\n### Maven\n\n```xml\n<dependency>\n    <groupId>org.apache.flink</groupId>\n    <artifactId>flink-java</artifactId>\n    <version>${flink.version}</version>\n    <scope>provided</scope>\n</dependency>\n<dependency>\n    <groupId>org.apache.flink</groupId>\n    <artifactId>flink-streaming-java_${scala.version}</artifactId>\n    <version>${flink.version}</version>\n    <scope>provided</scope>\n</dependency>\n<dependency>\n    <groupId>org.apache.flink</groupId>\n    <artifactId>flink-clients_${scala.version}</artifactId>\n    <version>${flink.version}</version>\n    <scope>provided</scope>\n</dependency>\n<!-- flink table -->\n<dependency>\n    <groupId>org.apache.flink</groupId>\n    <artifactId>flink-table-planner_${scala.version}</artifactId>\n    <version>${flink.version}</version>\n    <scope>provided</scope>\n</dependency>\n\n<!-- flink-doris-connector -->\n<dependency>\n  <groupId>org.apache.doris</groupId>\n  <artifactId>flink-doris-connector-1.14_2.12</artifactId>\n  <version>1.1.0</version>\n</dependency>  \n```\n\n\n\n### 参数配置\n\nFlink Doris Connector Sink 的内部实现是通过 `Stream Load` 服务向 Doris 写入数据, 同时也支持 `Stream Load` 请求参数的配置设置，具体参数可参考[这里](https://doris.apache.org/zh-CN/docs/data-operate/import/import-way/stream-load-manual)，配置方法如下：\n\n- SQL 使用 `WITH` 参数 `sink.properties.` 配置\n- DataStream 使用方法`DorisExecutionOptions.builder().setStreamLoadProp(Properties)`配置\n\n\n\n### 示例\n\n```scala\npackage cn.jxau.yuan\n\n\nimport cn.jxau.yuan.common.Config\nimport org.apache.doris.flink.cfg.{DorisExecutionOptions, DorisOptions, DorisReadOptions}\nimport org.apache.doris.flink.sink.DorisSink\nimport org.apache.doris.flink.sink.writer.SimpleStringSerializer\nimport org.apache.flink.api.common.eventtime.WatermarkStrategy\nimport org.apache.flink.api.common.serialization.SimpleStringSchema\nimport org.apache.flink.connector.kafka.source.KafkaSource\nimport org.apache.flink.connector.kafka.source.enumerator.initializer.OffsetsInitializer\nimport org.apache.flink.streaming.api.environment.CheckpointConfig\nimport org.apache.flink.streaming.api.scala._\n\nimport java.util.Properties\n\n\nobject KafkaConnectTest {\n\n  def main(args: Array[String]): Unit = {\n    val env: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment\n    env.enableCheckpointing(10000)\n    env.getCheckpointConfig.setExternalizedCheckpointCleanup(CheckpointConfig.ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION)\n\n\n    val kafkaSource: KafkaSource[String] = KafkaSource.builder[String]\n      .setBootstrapServers(Config.broker)\n      .setTopics(\"input-topic\")\n      .setGroupId(\"my-group\")\n      .setStartingOffsets(OffsetsInitializer.earliest)\n      .setValueOnlyDeserializer(new SimpleStringSchema)\n      .build\n\n    env.fromSource(kafkaSource, WatermarkStrategy.noWatermarks[String](), \"Kafka Source\")\n      .sinkTo(buildDorisSink())\n\n    env.execute()\n  }\n\n  def buildDorisSink(): DorisSink[String]  = {\n    //sink config\n    val builder: DorisSink.Builder[String] = DorisSink.builder();\n    val dorisBuilder: DorisOptions.Builder = DorisOptions.builder();\n    dorisBuilder.setFenodes(\"127.0.0.1:8030\")\n      .setTableIdentifier(\"db.table\")\n      .setUsername(\"root\")\n      .setPassword(\"password\");\n\n\n    val pro: Properties = new Properties();\n    //json data format\n    pro.setProperty(\"format\", \"json\");\n    pro.setProperty(\"read_json_by_line\", \"true\");\n\n\n    val executionOptions: DorisExecutionOptions  = DorisExecutionOptions.builder()\n      .setLabelPrefix(\"label-doris\") //streamload label prefix,\n      .setStreamLoadProp(pro)\n      .build()\n\n    builder.setDorisReadOptions(DorisReadOptions.builder().build())\n      .setDorisExecutionOptions(executionOptions)\n      .setSerializer(new SimpleStringSerializer()) //serialize according to string\n      .setDorisOptions(dorisBuilder.build())\n      .build()\n  }\n}\n\n```\n\n## Flink Table && SQL Maven\n\n我们想要在代码中使用Table API，必须引入相关的依赖。\n\n```xml\n<dependency>\n    <groupId>org.apache.flink</groupId>\n    <artifactId>flink-table-api-java-bridge_${scala.binary.version}</artifactId>\n    <version>${flink.version}</version>\n</dependency>\n\n```\n\n这里的依赖是一个 Java 的“桥接器”（bridge），主要就是负责 Table API 和下层 DataStream API 的连接支持，按照不同的语言分为 Java 版和 Scala 版。\n\n如果我们希望在本地的集成开发环境（IDE）里运行 Table API 和 SQL，还需要引入以下依赖：\n\n```xml\n<dependency>\n    <groupId>org.apache.flink</groupId>\n    <artifactId>flink-table-planner-blink_${scala.binary.version}</artifactId>\n    <version>${flink.version}</version>\n    </dependency>\n    <dependency>\n    <groupId>org.apache.flink</groupId>\n    <artifactId>flink-streaming-scala_${scala.binary.version}</artifactId>\n    <version>${flink.version}</version>\n</dependency>\n```\n\n这里主要添加的依赖是一个“计划器”（planner），它是 Table API 的核心组件，负责提供运行时环境，并生成程序的执行计划。这里我们用到的是新版的 blink planner。由于 Flink 安装包的 lib 目录下会自带planner，所以在生产集群环境中提交的作业不需要打包这个赖。而在Table API 的内部实现上，部分相关的代码是用 Scala 实现的，所以还需要额外添加一个 Scala 版流处理的相关依赖。\n另外，如果想实现自定义的数据格式来做序列化，可以引入下面的依赖：\n\n```xml\n<dependency>\n    <groupId>org.apache.flink</groupId>\n    <artifactId>flink-table-common</artifactId>\n    <version>${flink.version}</version>\n</dependency>\n```\n\n","slug":"bigdata/测试Flink-Doris-Connector","published":1,"comments":1,"layout":"post","photos":[],"link":"","_id":"cl9y38dso0020fwui2i26b3ll","content":"<blockquote>\n<p>利用Flink Doris Connector将Kafka中的数据实时导入到Doris</p>\n<p>该Connector支持Flink SQL和DataStream API</p>\n<p><strong>注意：</strong></p>\n<ol>\n<li>修改和删除只支持在 Unique Key 模型上</li>\n<li>目前的删除是支持 Flink CDC 的方式接入数据实现自动删除，如果是其他数据接入的方式删除需要自己实现。Flink CDC 的数据删除使用方式参照本文档最后一节</li>\n</ol>\n</blockquote>\n<h3 id=\"Maven\"><a href=\"#Maven\" class=\"headerlink\" title=\"Maven\"></a>Maven</h3><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.flink<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>flink-java<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>$&#123;flink.version&#125;<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">scope</span>&gt;</span>provided<span class=\"tag\">&lt;/<span class=\"name\">scope</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.flink<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>flink-streaming-java_$&#123;scala.version&#125;<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>$&#123;flink.version&#125;<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">scope</span>&gt;</span>provided<span class=\"tag\">&lt;/<span class=\"name\">scope</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.flink<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>flink-clients_$&#123;scala.version&#125;<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>$&#123;flink.version&#125;<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">scope</span>&gt;</span>provided<span class=\"tag\">&lt;/<span class=\"name\">scope</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\"><span class=\"comment\">&lt;!-- flink table --&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.flink<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>flink-table-planner_$&#123;scala.version&#125;<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>$&#123;flink.version&#125;<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">scope</span>&gt;</span>provided<span class=\"tag\">&lt;/<span class=\"name\">scope</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">&lt;!-- flink-doris-connector --&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.doris<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>flink-doris-connector-1.14_2.12<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>1.1.0<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span>  </span><br></pre></td></tr></table></figure>\n\n\n\n<h3 id=\"参数配置\"><a href=\"#参数配置\" class=\"headerlink\" title=\"参数配置\"></a>参数配置</h3><p>Flink Doris Connector Sink 的内部实现是通过 <code>Stream Load</code> 服务向 Doris 写入数据, 同时也支持 <code>Stream Load</code> 请求参数的配置设置，具体参数可参考<a href=\"https://doris.apache.org/zh-CN/docs/data-operate/import/import-way/stream-load-manual\">这里</a>，配置方法如下：</p>\n<ul>\n<li>SQL 使用 <code>WITH</code> 参数 <code>sink.properties.</code> 配置</li>\n<li>DataStream 使用方法<code>DorisExecutionOptions.builder().setStreamLoadProp(Properties)</code>配置</li>\n</ul>\n<h3 id=\"示例\"><a href=\"#示例\" class=\"headerlink\" title=\"示例\"></a>示例</h3><figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> cn.jxau.yuan</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> cn.jxau.yuan.common.<span class=\"type\">Config</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.doris.flink.cfg.&#123;<span class=\"type\">DorisExecutionOptions</span>, <span class=\"type\">DorisOptions</span>, <span class=\"type\">DorisReadOptions</span>&#125;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.doris.flink.sink.<span class=\"type\">DorisSink</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.doris.flink.sink.writer.<span class=\"type\">SimpleStringSerializer</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.flink.api.common.eventtime.<span class=\"type\">WatermarkStrategy</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.flink.api.common.serialization.<span class=\"type\">SimpleStringSchema</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.flink.connector.kafka.source.<span class=\"type\">KafkaSource</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.flink.connector.kafka.source.enumerator.initializer.<span class=\"type\">OffsetsInitializer</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.flink.streaming.api.environment.<span class=\"type\">CheckpointConfig</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.flink.streaming.api.scala._</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> java.util.<span class=\"type\">Properties</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">object</span> <span class=\"title\">KafkaConnectTest</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">main</span></span>(args: <span class=\"type\">Array</span>[<span class=\"type\">String</span>]): <span class=\"type\">Unit</span> = &#123;</span><br><span class=\"line\">    <span class=\"keyword\">val</span> env: <span class=\"type\">StreamExecutionEnvironment</span> = <span class=\"type\">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class=\"line\">    env.enableCheckpointing(<span class=\"number\">10000</span>)</span><br><span class=\"line\">    env.getCheckpointConfig.setExternalizedCheckpointCleanup(<span class=\"type\">CheckpointConfig</span>.<span class=\"type\">ExternalizedCheckpointCleanup</span>.<span class=\"type\">RETAIN_ON_CANCELLATION</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">val</span> kafkaSource: <span class=\"type\">KafkaSource</span>[<span class=\"type\">String</span>] = <span class=\"type\">KafkaSource</span>.builder[<span class=\"type\">String</span>]</span><br><span class=\"line\">      .setBootstrapServers(<span class=\"type\">Config</span>.broker)</span><br><span class=\"line\">      .setTopics(<span class=\"string\">&quot;input-topic&quot;</span>)</span><br><span class=\"line\">      .setGroupId(<span class=\"string\">&quot;my-group&quot;</span>)</span><br><span class=\"line\">      .setStartingOffsets(<span class=\"type\">OffsetsInitializer</span>.earliest)</span><br><span class=\"line\">      .setValueOnlyDeserializer(<span class=\"keyword\">new</span> <span class=\"type\">SimpleStringSchema</span>)</span><br><span class=\"line\">      .build</span><br><span class=\"line\"></span><br><span class=\"line\">    env.fromSource(kafkaSource, <span class=\"type\">WatermarkStrategy</span>.noWatermarks[<span class=\"type\">String</span>](), <span class=\"string\">&quot;Kafka Source&quot;</span>)</span><br><span class=\"line\">      .sinkTo(buildDorisSink())</span><br><span class=\"line\"></span><br><span class=\"line\">    env.execute()</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">buildDorisSink</span></span>(): <span class=\"type\">DorisSink</span>[<span class=\"type\">String</span>]  = &#123;</span><br><span class=\"line\">    <span class=\"comment\">//sink config</span></span><br><span class=\"line\">    <span class=\"keyword\">val</span> builder: <span class=\"type\">DorisSink</span>.<span class=\"type\">Builder</span>[<span class=\"type\">String</span>] = <span class=\"type\">DorisSink</span>.builder();</span><br><span class=\"line\">    <span class=\"keyword\">val</span> dorisBuilder: <span class=\"type\">DorisOptions</span>.<span class=\"type\">Builder</span> = <span class=\"type\">DorisOptions</span>.builder();</span><br><span class=\"line\">    dorisBuilder.setFenodes(<span class=\"string\">&quot;127.0.0.1:8030&quot;</span>)</span><br><span class=\"line\">      .setTableIdentifier(<span class=\"string\">&quot;db.table&quot;</span>)</span><br><span class=\"line\">      .setUsername(<span class=\"string\">&quot;root&quot;</span>)</span><br><span class=\"line\">      .setPassword(<span class=\"string\">&quot;password&quot;</span>);</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">val</span> pro: <span class=\"type\">Properties</span> = <span class=\"keyword\">new</span> <span class=\"type\">Properties</span>();</span><br><span class=\"line\">    <span class=\"comment\">//json data format</span></span><br><span class=\"line\">    pro.setProperty(<span class=\"string\">&quot;format&quot;</span>, <span class=\"string\">&quot;json&quot;</span>);</span><br><span class=\"line\">    pro.setProperty(<span class=\"string\">&quot;read_json_by_line&quot;</span>, <span class=\"string\">&quot;true&quot;</span>);</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">val</span> executionOptions: <span class=\"type\">DorisExecutionOptions</span>  = <span class=\"type\">DorisExecutionOptions</span>.builder()</span><br><span class=\"line\">      .setLabelPrefix(<span class=\"string\">&quot;label-doris&quot;</span>) <span class=\"comment\">//streamload label prefix,</span></span><br><span class=\"line\">      .setStreamLoadProp(pro)</span><br><span class=\"line\">      .build()</span><br><span class=\"line\"></span><br><span class=\"line\">    builder.setDorisReadOptions(<span class=\"type\">DorisReadOptions</span>.builder().build())</span><br><span class=\"line\">      .setDorisExecutionOptions(executionOptions)</span><br><span class=\"line\">      .setSerializer(<span class=\"keyword\">new</span> <span class=\"type\">SimpleStringSerializer</span>()) <span class=\"comment\">//serialize according to string</span></span><br><span class=\"line\">      .setDorisOptions(dorisBuilder.build())</span><br><span class=\"line\">      .build()</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Flink-Table-amp-amp-SQL-Maven\"><a href=\"#Flink-Table-amp-amp-SQL-Maven\" class=\"headerlink\" title=\"Flink Table &amp;&amp; SQL Maven\"></a>Flink Table &amp;&amp; SQL Maven</h2><p>我们想要在代码中使用Table API，必须引入相关的依赖。</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.flink<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>flink-table-api-java-bridge_$&#123;scala.binary.version&#125;<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>$&#123;flink.version&#125;<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>这里的依赖是一个 Java 的“桥接器”（bridge），主要就是负责 Table API 和下层 DataStream API 的连接支持，按照不同的语言分为 Java 版和 Scala 版。</p>\n<p>如果我们希望在本地的集成开发环境（IDE）里运行 Table API 和 SQL，还需要引入以下依赖：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.flink<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>flink-table-planner-blink_$&#123;scala.binary.version&#125;<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>$&#123;flink.version&#125;<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.flink<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>flink-streaming-scala_$&#123;scala.binary.version&#125;<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>$&#123;flink.version&#125;<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>\n\n<p>这里主要添加的依赖是一个“计划器”（planner），它是 Table API 的核心组件，负责提供运行时环境，并生成程序的执行计划。这里我们用到的是新版的 blink planner。由于 Flink 安装包的 lib 目录下会自带planner，所以在生产集群环境中提交的作业不需要打包这个赖。而在Table API 的内部实现上，部分相关的代码是用 Scala 实现的，所以还需要额外添加一个 Scala 版流处理的相关依赖。<br>另外，如果想实现自定义的数据格式来做序列化，可以引入下面的依赖：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.flink<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>flink-table-common<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>$&#123;flink.version&#125;<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>\n\n","site":{"data":{"link":[{"class_name":"友情链接","class_desc":"那些人，那些事","link_list":[{"name":"张洪Heo","link":"https://blog.zhheo.com/","avatar":"https://npm.elemecdn.com/guli-heo/img/avatar2.png","descr":"分享设计与科技生活"},{"name":"瞬間の筆記","link":"https://hikki.site","descr":"喜欢的东西就努力去追求，万一成功了呢!","avatar":"https://cdn.jsdelivr.net/gh/0000rookie/imgs/202206120315.png"}]}]}},"excerpt":"","more":"<blockquote>\n<p>利用Flink Doris Connector将Kafka中的数据实时导入到Doris</p>\n<p>该Connector支持Flink SQL和DataStream API</p>\n<p><strong>注意：</strong></p>\n<ol>\n<li>修改和删除只支持在 Unique Key 模型上</li>\n<li>目前的删除是支持 Flink CDC 的方式接入数据实现自动删除，如果是其他数据接入的方式删除需要自己实现。Flink CDC 的数据删除使用方式参照本文档最后一节</li>\n</ol>\n</blockquote>\n<h3 id=\"Maven\"><a href=\"#Maven\" class=\"headerlink\" title=\"Maven\"></a>Maven</h3><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.flink<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>flink-java<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>$&#123;flink.version&#125;<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">scope</span>&gt;</span>provided<span class=\"tag\">&lt;/<span class=\"name\">scope</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.flink<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>flink-streaming-java_$&#123;scala.version&#125;<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>$&#123;flink.version&#125;<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">scope</span>&gt;</span>provided<span class=\"tag\">&lt;/<span class=\"name\">scope</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.flink<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>flink-clients_$&#123;scala.version&#125;<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>$&#123;flink.version&#125;<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">scope</span>&gt;</span>provided<span class=\"tag\">&lt;/<span class=\"name\">scope</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\"><span class=\"comment\">&lt;!-- flink table --&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.flink<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>flink-table-planner_$&#123;scala.version&#125;<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>$&#123;flink.version&#125;<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">scope</span>&gt;</span>provided<span class=\"tag\">&lt;/<span class=\"name\">scope</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">&lt;!-- flink-doris-connector --&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.doris<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>flink-doris-connector-1.14_2.12<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>1.1.0<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span>  </span><br></pre></td></tr></table></figure>\n\n\n\n<h3 id=\"参数配置\"><a href=\"#参数配置\" class=\"headerlink\" title=\"参数配置\"></a>参数配置</h3><p>Flink Doris Connector Sink 的内部实现是通过 <code>Stream Load</code> 服务向 Doris 写入数据, 同时也支持 <code>Stream Load</code> 请求参数的配置设置，具体参数可参考<a href=\"https://doris.apache.org/zh-CN/docs/data-operate/import/import-way/stream-load-manual\">这里</a>，配置方法如下：</p>\n<ul>\n<li>SQL 使用 <code>WITH</code> 参数 <code>sink.properties.</code> 配置</li>\n<li>DataStream 使用方法<code>DorisExecutionOptions.builder().setStreamLoadProp(Properties)</code>配置</li>\n</ul>\n<h3 id=\"示例\"><a href=\"#示例\" class=\"headerlink\" title=\"示例\"></a>示例</h3><figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> cn.jxau.yuan</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> cn.jxau.yuan.common.<span class=\"type\">Config</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.doris.flink.cfg.&#123;<span class=\"type\">DorisExecutionOptions</span>, <span class=\"type\">DorisOptions</span>, <span class=\"type\">DorisReadOptions</span>&#125;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.doris.flink.sink.<span class=\"type\">DorisSink</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.doris.flink.sink.writer.<span class=\"type\">SimpleStringSerializer</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.flink.api.common.eventtime.<span class=\"type\">WatermarkStrategy</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.flink.api.common.serialization.<span class=\"type\">SimpleStringSchema</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.flink.connector.kafka.source.<span class=\"type\">KafkaSource</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.flink.connector.kafka.source.enumerator.initializer.<span class=\"type\">OffsetsInitializer</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.flink.streaming.api.environment.<span class=\"type\">CheckpointConfig</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.flink.streaming.api.scala._</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> java.util.<span class=\"type\">Properties</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">object</span> <span class=\"title\">KafkaConnectTest</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">main</span></span>(args: <span class=\"type\">Array</span>[<span class=\"type\">String</span>]): <span class=\"type\">Unit</span> = &#123;</span><br><span class=\"line\">    <span class=\"keyword\">val</span> env: <span class=\"type\">StreamExecutionEnvironment</span> = <span class=\"type\">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class=\"line\">    env.enableCheckpointing(<span class=\"number\">10000</span>)</span><br><span class=\"line\">    env.getCheckpointConfig.setExternalizedCheckpointCleanup(<span class=\"type\">CheckpointConfig</span>.<span class=\"type\">ExternalizedCheckpointCleanup</span>.<span class=\"type\">RETAIN_ON_CANCELLATION</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">val</span> kafkaSource: <span class=\"type\">KafkaSource</span>[<span class=\"type\">String</span>] = <span class=\"type\">KafkaSource</span>.builder[<span class=\"type\">String</span>]</span><br><span class=\"line\">      .setBootstrapServers(<span class=\"type\">Config</span>.broker)</span><br><span class=\"line\">      .setTopics(<span class=\"string\">&quot;input-topic&quot;</span>)</span><br><span class=\"line\">      .setGroupId(<span class=\"string\">&quot;my-group&quot;</span>)</span><br><span class=\"line\">      .setStartingOffsets(<span class=\"type\">OffsetsInitializer</span>.earliest)</span><br><span class=\"line\">      .setValueOnlyDeserializer(<span class=\"keyword\">new</span> <span class=\"type\">SimpleStringSchema</span>)</span><br><span class=\"line\">      .build</span><br><span class=\"line\"></span><br><span class=\"line\">    env.fromSource(kafkaSource, <span class=\"type\">WatermarkStrategy</span>.noWatermarks[<span class=\"type\">String</span>](), <span class=\"string\">&quot;Kafka Source&quot;</span>)</span><br><span class=\"line\">      .sinkTo(buildDorisSink())</span><br><span class=\"line\"></span><br><span class=\"line\">    env.execute()</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">buildDorisSink</span></span>(): <span class=\"type\">DorisSink</span>[<span class=\"type\">String</span>]  = &#123;</span><br><span class=\"line\">    <span class=\"comment\">//sink config</span></span><br><span class=\"line\">    <span class=\"keyword\">val</span> builder: <span class=\"type\">DorisSink</span>.<span class=\"type\">Builder</span>[<span class=\"type\">String</span>] = <span class=\"type\">DorisSink</span>.builder();</span><br><span class=\"line\">    <span class=\"keyword\">val</span> dorisBuilder: <span class=\"type\">DorisOptions</span>.<span class=\"type\">Builder</span> = <span class=\"type\">DorisOptions</span>.builder();</span><br><span class=\"line\">    dorisBuilder.setFenodes(<span class=\"string\">&quot;127.0.0.1:8030&quot;</span>)</span><br><span class=\"line\">      .setTableIdentifier(<span class=\"string\">&quot;db.table&quot;</span>)</span><br><span class=\"line\">      .setUsername(<span class=\"string\">&quot;root&quot;</span>)</span><br><span class=\"line\">      .setPassword(<span class=\"string\">&quot;password&quot;</span>);</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">val</span> pro: <span class=\"type\">Properties</span> = <span class=\"keyword\">new</span> <span class=\"type\">Properties</span>();</span><br><span class=\"line\">    <span class=\"comment\">//json data format</span></span><br><span class=\"line\">    pro.setProperty(<span class=\"string\">&quot;format&quot;</span>, <span class=\"string\">&quot;json&quot;</span>);</span><br><span class=\"line\">    pro.setProperty(<span class=\"string\">&quot;read_json_by_line&quot;</span>, <span class=\"string\">&quot;true&quot;</span>);</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">val</span> executionOptions: <span class=\"type\">DorisExecutionOptions</span>  = <span class=\"type\">DorisExecutionOptions</span>.builder()</span><br><span class=\"line\">      .setLabelPrefix(<span class=\"string\">&quot;label-doris&quot;</span>) <span class=\"comment\">//streamload label prefix,</span></span><br><span class=\"line\">      .setStreamLoadProp(pro)</span><br><span class=\"line\">      .build()</span><br><span class=\"line\"></span><br><span class=\"line\">    builder.setDorisReadOptions(<span class=\"type\">DorisReadOptions</span>.builder().build())</span><br><span class=\"line\">      .setDorisExecutionOptions(executionOptions)</span><br><span class=\"line\">      .setSerializer(<span class=\"keyword\">new</span> <span class=\"type\">SimpleStringSerializer</span>()) <span class=\"comment\">//serialize according to string</span></span><br><span class=\"line\">      .setDorisOptions(dorisBuilder.build())</span><br><span class=\"line\">      .build()</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Flink-Table-amp-amp-SQL-Maven\"><a href=\"#Flink-Table-amp-amp-SQL-Maven\" class=\"headerlink\" title=\"Flink Table &amp;&amp; SQL Maven\"></a>Flink Table &amp;&amp; SQL Maven</h2><p>我们想要在代码中使用Table API，必须引入相关的依赖。</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.flink<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>flink-table-api-java-bridge_$&#123;scala.binary.version&#125;<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>$&#123;flink.version&#125;<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>这里的依赖是一个 Java 的“桥接器”（bridge），主要就是负责 Table API 和下层 DataStream API 的连接支持，按照不同的语言分为 Java 版和 Scala 版。</p>\n<p>如果我们希望在本地的集成开发环境（IDE）里运行 Table API 和 SQL，还需要引入以下依赖：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.flink<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>flink-table-planner-blink_$&#123;scala.binary.version&#125;<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>$&#123;flink.version&#125;<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.flink<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>flink-streaming-scala_$&#123;scala.binary.version&#125;<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>$&#123;flink.version&#125;<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>\n\n<p>这里主要添加的依赖是一个“计划器”（planner），它是 Table API 的核心组件，负责提供运行时环境，并生成程序的执行计划。这里我们用到的是新版的 blink planner。由于 Flink 安装包的 lib 目录下会自带planner，所以在生产集群环境中提交的作业不需要打包这个赖。而在Table API 的内部实现上，部分相关的代码是用 Scala 实现的，所以还需要额外添加一个 Scala 版流处理的相关依赖。<br>另外，如果想实现自定义的数据格式来做序列化，可以引入下面的依赖：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.flink<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>flink-table-common<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>$&#123;flink.version&#125;<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>\n\n"},{"title":"初入用户画像","top_img":"linear-gradient(20deg, #0062be, #925696, #cc426e, #fb0347)","date":"2022-07-16T09:18:03.000Z","updated":"2022-07-16T09:18:03.000Z","cover":"https://zfh-tuchuang.oss-cn-shanghai.aliyuncs.com/img/site-backgound.jpg","description":null,"keywords":null,"_content":"\n# ![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657964933349-cdb78ce8-c129-4bcb-a488-1f7893d60951.png)\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657968667409-a69d4ea1-0109-4256-b82c-0c0c9a1140a8.png)\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657968859817-eeae0216-172c-4263-ad92-dd54bc9a3e49.png)\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657970317537-eeb1a873-b622-4295-bb77-bf647ac8bf82.png)\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657969697929-6449077d-1147-45a9-85ab-e6ba911ed237.png)\n\n# 用户画像\n\n- 应用场景\n\n1. 1. 精准营销\n   2. 数据化运营\n   3. 推荐系统\n   4. 广告投放\n   5. 产品布局\n   6. 行业报告\n   7. 场景间的共性\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657964826208-f018b6ec-15cb-45ce-8f61-022a18c56ff0.png)\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657964865703-6839d76a-6684-4520-92aa-284db00a5c53.png)\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657965034189-2ce05463-eb5e-4269-998e-c23d98c9036e.png)\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657965062495-0b7a89f8-5185-4590-a1c8-9f2aa58295d1.png)\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657965084978-3bedec8e-2263-4404-ba1b-70715b55fa4d.png)\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657965117870-d6391669-0922-41fe-953d-4aa57785c0bd.png)\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657965147545-19b2219e-f017-4dfe-8454-59928015904d.png)\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657965165090-939ae364-e19c-455c-8121-04eb94795607.png)\n\n## 平台用户画像（用户群体画像）\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657963821022-c48933fc-dafd-4c9b-9db9-af85fc84aa53.png)\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657963862801-930ad384-d3d7-4110-804c-441e0b754ebf.png)\n\n\n\n统计整个平台的用户画像，更了解我们的用户\n\n- 性别比例\n- 年龄分布\n- 城市分布\n- 手机系统、型号分布\n\n## 用户个体画像\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657967347237-aff38b75-fbdb-4698-a17f-33990ea130b4.png)\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657967925952-df8b9a9b-edd8-47af-8a56-732e346a1219.png)\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657967976515-4e605319-54b0-430b-83f2-da4655cf61ec.png)\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657967057844-1e450af9-5466-4149-97da-f4993b741519.png)\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657968173261-a3d676b1-db1b-4d40-b4f1-ae6a6b91fa63.png)\n\n\n\n### 标签的存储\n\n- 用户画像标签表\n\n- - 1、存储到HBase - 根据UserID查询标签，用于个性化广告、推荐系统\n\n> 列族：user、item（商品标签列族）\n>\n> RowKey：userID\n>\n> Cloumn：标签名 + 标签值\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657966057558-60b2c61b-2513-42d1-8e2f-2fde427d9e9d.png)\n\n- - 2、存储到Elasticsearch - 倒排索引，根据标签，圈定人群\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657966542279-5879e05c-cf3a-4f15-9718-842c02cb729b.png)\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657970155892-d692d44c-4ba7-4087-9e64-a218d6a07f54.png)\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657966569582-646027f7-ed6d-46d6-9567-b66e083d3a89.png)\n\n- 标签信息表（标签**元数据**）- 存储到MySQL\n\n> TagId,\tTagName,\tTagDesc\n>\n> 384\t\t男\t\t\t用户的性别为男性\n>\n> 385\t\t女\t\t\t用户的性别为女性\n","source":"_posts/bigdata/用户画像介绍.md","raw":"---\ntitle: 初入用户画像\ntags:\n  - '用户画像'\ncategories:\n  - [bigdata,User-Profile]\ntop_img: 'linear-gradient(20deg, #0062be, #925696, #cc426e, #fb0347)'\ndate: 2022-07-16 17:18:03\nupdated: 2022-07-16 17:18:03\ncover:\ndescription:\nkeywords:\n---\n\n# ![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657964933349-cdb78ce8-c129-4bcb-a488-1f7893d60951.png)\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657968667409-a69d4ea1-0109-4256-b82c-0c0c9a1140a8.png)\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657968859817-eeae0216-172c-4263-ad92-dd54bc9a3e49.png)\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657970317537-eeb1a873-b622-4295-bb77-bf647ac8bf82.png)\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657969697929-6449077d-1147-45a9-85ab-e6ba911ed237.png)\n\n# 用户画像\n\n- 应用场景\n\n1. 1. 精准营销\n   2. 数据化运营\n   3. 推荐系统\n   4. 广告投放\n   5. 产品布局\n   6. 行业报告\n   7. 场景间的共性\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657964826208-f018b6ec-15cb-45ce-8f61-022a18c56ff0.png)\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657964865703-6839d76a-6684-4520-92aa-284db00a5c53.png)\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657965034189-2ce05463-eb5e-4269-998e-c23d98c9036e.png)\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657965062495-0b7a89f8-5185-4590-a1c8-9f2aa58295d1.png)\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657965084978-3bedec8e-2263-4404-ba1b-70715b55fa4d.png)\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657965117870-d6391669-0922-41fe-953d-4aa57785c0bd.png)\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657965147545-19b2219e-f017-4dfe-8454-59928015904d.png)\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657965165090-939ae364-e19c-455c-8121-04eb94795607.png)\n\n## 平台用户画像（用户群体画像）\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657963821022-c48933fc-dafd-4c9b-9db9-af85fc84aa53.png)\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657963862801-930ad384-d3d7-4110-804c-441e0b754ebf.png)\n\n\n\n统计整个平台的用户画像，更了解我们的用户\n\n- 性别比例\n- 年龄分布\n- 城市分布\n- 手机系统、型号分布\n\n## 用户个体画像\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657967347237-aff38b75-fbdb-4698-a17f-33990ea130b4.png)\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657967925952-df8b9a9b-edd8-47af-8a56-732e346a1219.png)\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657967976515-4e605319-54b0-430b-83f2-da4655cf61ec.png)\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657967057844-1e450af9-5466-4149-97da-f4993b741519.png)\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657968173261-a3d676b1-db1b-4d40-b4f1-ae6a6b91fa63.png)\n\n\n\n### 标签的存储\n\n- 用户画像标签表\n\n- - 1、存储到HBase - 根据UserID查询标签，用于个性化广告、推荐系统\n\n> 列族：user、item（商品标签列族）\n>\n> RowKey：userID\n>\n> Cloumn：标签名 + 标签值\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657966057558-60b2c61b-2513-42d1-8e2f-2fde427d9e9d.png)\n\n- - 2、存储到Elasticsearch - 倒排索引，根据标签，圈定人群\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657966542279-5879e05c-cf3a-4f15-9718-842c02cb729b.png)\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657970155892-d692d44c-4ba7-4087-9e64-a218d6a07f54.png)\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1657966569582-646027f7-ed6d-46d6-9567-b66e083d3a89.png)\n\n- 标签信息表（标签**元数据**）- 存储到MySQL\n\n> TagId,\tTagName,\tTagDesc\n>\n> 384\t\t男\t\t\t用户的性别为男性\n>\n> 385\t\t女\t\t\t用户的性别为女性\n","slug":"bigdata/用户画像介绍","published":1,"comments":1,"layout":"post","photos":[],"link":"","_id":"cl9y38dsp0022fwuiam7u0ub1","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657964933349-cdb78ce8-c129-4bcb-a488-1f7893d60951.png\" alt=\"img\"></h1><p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657968667409-a69d4ea1-0109-4256-b82c-0c0c9a1140a8.png\" alt=\"img\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657968859817-eeae0216-172c-4263-ad92-dd54bc9a3e49.png\" alt=\"img\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657970317537-eeb1a873-b622-4295-bb77-bf647ac8bf82.png\" alt=\"img\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657969697929-6449077d-1147-45a9-85ab-e6ba911ed237.png\" alt=\"img\"></p>\n<h1 id=\"用户画像\"><a href=\"#用户画像\" class=\"headerlink\" title=\"用户画像\"></a>用户画像</h1><ul>\n<li>应用场景</li>\n</ul>\n<ol>\n<li><ol>\n<li>精准营销</li>\n<li>数据化运营</li>\n<li>推荐系统</li>\n<li>广告投放</li>\n<li>产品布局</li>\n<li>行业报告</li>\n<li>场景间的共性</li>\n</ol>\n</li>\n</ol>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657964826208-f018b6ec-15cb-45ce-8f61-022a18c56ff0.png\" alt=\"img\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657964865703-6839d76a-6684-4520-92aa-284db00a5c53.png\" alt=\"img\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657965034189-2ce05463-eb5e-4269-998e-c23d98c9036e.png\" alt=\"img\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657965062495-0b7a89f8-5185-4590-a1c8-9f2aa58295d1.png\" alt=\"img\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657965084978-3bedec8e-2263-4404-ba1b-70715b55fa4d.png\" alt=\"img\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657965117870-d6391669-0922-41fe-953d-4aa57785c0bd.png\" alt=\"img\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657965147545-19b2219e-f017-4dfe-8454-59928015904d.png\" alt=\"img\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657965165090-939ae364-e19c-455c-8121-04eb94795607.png\" alt=\"img\"></p>\n<h2 id=\"平台用户画像（用户群体画像）\"><a href=\"#平台用户画像（用户群体画像）\" class=\"headerlink\" title=\"平台用户画像（用户群体画像）\"></a>平台用户画像（用户群体画像）</h2><p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657963821022-c48933fc-dafd-4c9b-9db9-af85fc84aa53.png\" alt=\"img\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657963862801-930ad384-d3d7-4110-804c-441e0b754ebf.png\" alt=\"img\"></p>\n<p>统计整个平台的用户画像，更了解我们的用户</p>\n<ul>\n<li>性别比例</li>\n<li>年龄分布</li>\n<li>城市分布</li>\n<li>手机系统、型号分布</li>\n</ul>\n<h2 id=\"用户个体画像\"><a href=\"#用户个体画像\" class=\"headerlink\" title=\"用户个体画像\"></a>用户个体画像</h2><p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657967347237-aff38b75-fbdb-4698-a17f-33990ea130b4.png\" alt=\"img\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657967925952-df8b9a9b-edd8-47af-8a56-732e346a1219.png\" alt=\"img\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657967976515-4e605319-54b0-430b-83f2-da4655cf61ec.png\" alt=\"img\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657967057844-1e450af9-5466-4149-97da-f4993b741519.png\" alt=\"img\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657968173261-a3d676b1-db1b-4d40-b4f1-ae6a6b91fa63.png\" alt=\"img\"></p>\n<h3 id=\"标签的存储\"><a href=\"#标签的存储\" class=\"headerlink\" title=\"标签的存储\"></a>标签的存储</h3><ul>\n<li><p>用户画像标签表</p>\n</li>\n<li><ul>\n<li>1、存储到HBase - 根据UserID查询标签，用于个性化广告、推荐系统</li>\n</ul>\n</li>\n</ul>\n<blockquote>\n<p>列族：user、item（商品标签列族）</p>\n<p>RowKey：userID</p>\n<p>Cloumn：标签名 + 标签值</p>\n</blockquote>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657966057558-60b2c61b-2513-42d1-8e2f-2fde427d9e9d.png\" alt=\"img\"></p>\n<ul>\n<li><ul>\n<li>2、存储到Elasticsearch - 倒排索引，根据标签，圈定人群</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657966542279-5879e05c-cf3a-4f15-9718-842c02cb729b.png\" alt=\"img\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657970155892-d692d44c-4ba7-4087-9e64-a218d6a07f54.png\" alt=\"img\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657966569582-646027f7-ed6d-46d6-9567-b66e083d3a89.png\" alt=\"img\"></p>\n<ul>\n<li>标签信息表（标签<strong>元数据</strong>）- 存储到MySQL</li>\n</ul>\n<blockquote>\n<p>TagId,\tTagName,\tTagDesc</p>\n<p>384\t\t男\t\t\t用户的性别为男性</p>\n<p>385\t\t女\t\t\t用户的性别为女性</p>\n</blockquote>\n","site":{"data":{"link":[{"class_name":"友情链接","class_desc":"那些人，那些事","link_list":[{"name":"张洪Heo","link":"https://blog.zhheo.com/","avatar":"https://npm.elemecdn.com/guli-heo/img/avatar2.png","descr":"分享设计与科技生活"},{"name":"瞬間の筆記","link":"https://hikki.site","descr":"喜欢的东西就努力去追求，万一成功了呢!","avatar":"https://cdn.jsdelivr.net/gh/0000rookie/imgs/202206120315.png"}]}]}},"excerpt":"","more":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657964933349-cdb78ce8-c129-4bcb-a488-1f7893d60951.png\" alt=\"img\"></h1><p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657968667409-a69d4ea1-0109-4256-b82c-0c0c9a1140a8.png\" alt=\"img\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657968859817-eeae0216-172c-4263-ad92-dd54bc9a3e49.png\" alt=\"img\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657970317537-eeb1a873-b622-4295-bb77-bf647ac8bf82.png\" alt=\"img\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657969697929-6449077d-1147-45a9-85ab-e6ba911ed237.png\" alt=\"img\"></p>\n<h1 id=\"用户画像\"><a href=\"#用户画像\" class=\"headerlink\" title=\"用户画像\"></a>用户画像</h1><ul>\n<li>应用场景</li>\n</ul>\n<ol>\n<li><ol>\n<li>精准营销</li>\n<li>数据化运营</li>\n<li>推荐系统</li>\n<li>广告投放</li>\n<li>产品布局</li>\n<li>行业报告</li>\n<li>场景间的共性</li>\n</ol>\n</li>\n</ol>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657964826208-f018b6ec-15cb-45ce-8f61-022a18c56ff0.png\" alt=\"img\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657964865703-6839d76a-6684-4520-92aa-284db00a5c53.png\" alt=\"img\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657965034189-2ce05463-eb5e-4269-998e-c23d98c9036e.png\" alt=\"img\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657965062495-0b7a89f8-5185-4590-a1c8-9f2aa58295d1.png\" alt=\"img\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657965084978-3bedec8e-2263-4404-ba1b-70715b55fa4d.png\" alt=\"img\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657965117870-d6391669-0922-41fe-953d-4aa57785c0bd.png\" alt=\"img\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657965147545-19b2219e-f017-4dfe-8454-59928015904d.png\" alt=\"img\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657965165090-939ae364-e19c-455c-8121-04eb94795607.png\" alt=\"img\"></p>\n<h2 id=\"平台用户画像（用户群体画像）\"><a href=\"#平台用户画像（用户群体画像）\" class=\"headerlink\" title=\"平台用户画像（用户群体画像）\"></a>平台用户画像（用户群体画像）</h2><p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657963821022-c48933fc-dafd-4c9b-9db9-af85fc84aa53.png\" alt=\"img\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657963862801-930ad384-d3d7-4110-804c-441e0b754ebf.png\" alt=\"img\"></p>\n<p>统计整个平台的用户画像，更了解我们的用户</p>\n<ul>\n<li>性别比例</li>\n<li>年龄分布</li>\n<li>城市分布</li>\n<li>手机系统、型号分布</li>\n</ul>\n<h2 id=\"用户个体画像\"><a href=\"#用户个体画像\" class=\"headerlink\" title=\"用户个体画像\"></a>用户个体画像</h2><p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657967347237-aff38b75-fbdb-4698-a17f-33990ea130b4.png\" alt=\"img\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657967925952-df8b9a9b-edd8-47af-8a56-732e346a1219.png\" alt=\"img\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657967976515-4e605319-54b0-430b-83f2-da4655cf61ec.png\" alt=\"img\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657967057844-1e450af9-5466-4149-97da-f4993b741519.png\" alt=\"img\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657968173261-a3d676b1-db1b-4d40-b4f1-ae6a6b91fa63.png\" alt=\"img\"></p>\n<h3 id=\"标签的存储\"><a href=\"#标签的存储\" class=\"headerlink\" title=\"标签的存储\"></a>标签的存储</h3><ul>\n<li><p>用户画像标签表</p>\n</li>\n<li><ul>\n<li>1、存储到HBase - 根据UserID查询标签，用于个性化广告、推荐系统</li>\n</ul>\n</li>\n</ul>\n<blockquote>\n<p>列族：user、item（商品标签列族）</p>\n<p>RowKey：userID</p>\n<p>Cloumn：标签名 + 标签值</p>\n</blockquote>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657966057558-60b2c61b-2513-42d1-8e2f-2fde427d9e9d.png\" alt=\"img\"></p>\n<ul>\n<li><ul>\n<li>2、存储到Elasticsearch - 倒排索引，根据标签，圈定人群</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657966542279-5879e05c-cf3a-4f15-9718-842c02cb729b.png\" alt=\"img\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657970155892-d692d44c-4ba7-4087-9e64-a218d6a07f54.png\" alt=\"img\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1657966569582-646027f7-ed6d-46d6-9567-b66e083d3a89.png\" alt=\"img\"></p>\n<ul>\n<li>标签信息表（标签<strong>元数据</strong>）- 存储到MySQL</li>\n</ul>\n<blockquote>\n<p>TagId,\tTagName,\tTagDesc</p>\n<p>384\t\t男\t\t\t用户的性别为男性</p>\n<p>385\t\t女\t\t\t用户的性别为女性</p>\n</blockquote>\n"},{"title":"通过Flink-SQL，将Kafka中的Oracle-CDC-Log同步到Doris","top_img":"linear-gradient(20deg, #0062be, #925696, #cc426e, #fb0347)","date":"2022-08-14T15:14:56.000Z","updated":"2022-08-14T15:14:56.000Z","cover":"https://zfh-tuchuang.oss-cn-shanghai.aliyuncs.com/img/site-backgound.jpg","description":null,"keywords":null,"_content":"\n## 前言\n- Oracle的binlog日志已经由DBA通过OGG同步到Kafka中了，因此用不到Flink CDC\n- 同步到Kafka中的JSON样式\n  ```json\n  {\n  \"before\": {\n    \"id\": 111,\n    \"name\": \"scooter\",\n    \"description\": \"Big 2-wheel scooter\",\n    \"weight\": 5.18\n  },\n  \"after\": {\n    \"id\": 111,\n    \"name\": \"scooter\",\n    \"description\": \"Big 2-wheel scooter\",\n    \"weight\": 5.15\n  },\n  \"op_type\": \"U\",\n  \"op_ts\": \"2020-05-13 15:40:06.000000\",\n  \"current_ts\": \"2020-05-13 15:40:07.000000\",\n  \"primary_keys\": [\n    \"id\"\n  ],\n  \"pos\": \"00000000000000000000143\",\n  \"table\": \"PRODUCTS\"\n  }\n  ```\n\n## Flink SQL\n> 需要下载以下Jar包，放在{flink_home}/lib/下\n> flink-sql-connector-kafka_2.12-1.14.5.jar\n> flink-json-1.15.1.jar\n> flink-doris-connector-1.14_2.12-1.1.0.jar\n\n- 开启CheckPoint：`SET 'execution.checkpointing.interval' = '10min';`\n\n- 创建Kafka数据源表，设置`'format' = 'ogg-json'`，只有`org.apache.flink.flink-json-1.15.1`中以上才支持ogg-json fromat\n```sql\nCREATE TABLE topic_products (\n  id INT,\n  name STRING,\n  description STRING,\n  weight DECIMAL(10, 2)\n) WITH (\n  'connector' = 'kafka',\n  'topic' = 'products_ogg_1',\n  'properties.bootstrap.servers' = '172.30.160.5:9092',\n  'properties.group.id' = 'testGroup',\n  'format' = 'ogg-json',\n  'scan.startup.mode' = 'earliest-offset',\n  'ogg-json.ignore-parse-errors' = 'true'\n);\n```\n\n- 创建Doris-Sink表\n```sql\nCREATE TABLE doris_sink (\nid INT,\nname STRING,\ndescription STRING,\nweight DECIMAL(10, 2)\n)\nWITH (\n  'connector' = 'doris',\n  'fenodes' = '172.30.160.5:8030',\n  'table.identifier' = 'test.product',\n  'username' = 'root',\n  'password' = '',\n  'sink.properties.format' = 'json',\n  'sink.properties.read_json_by_line' = 'true',\n  'sink.enable-delete' = 'true',\n  'sink.label-prefix' = 'doris_label'\n);\n```\n\n- 执行`INSERT into doris_sink select * from topic_products;`语句，写入Doris\n\n## Code Repo\n\n> 1. **bin/sql-client.sh embedded -i init_file -f file -s yarn-session** \n> 2. Execute SQL Files \n\n```sql\n-- Define available catalogs\n\nCREATE CATALOG MyCatalog\n  WITH (\n    'type' = 'hive'\n  );\n\nUSE CATALOG MyCatalog;\n\n-- Define available database\n\nCREATE DATABASE MyDatabase;\n\nUSE MyDatabase;\n\n-- Define TABLE\n\nCREATE TABLE MyTable(\n  MyField1 INT,\n  MyField2 STRING\n) WITH (\n  'connector' = 'filesystem',\n  'path' = '/path/to/something',\n  'format' = 'csv'\n);\n\n-- Define VIEW\n\nCREATE VIEW MyCustomView AS SELECT MyField2 FROM MyTable;\n\n-- Define user-defined functions here.\n\nCREATE FUNCTION foo.bar.AggregateUDF AS myUDF;\n\n-- Properties that change the fundamental execution behavior of a table program.\n\nSET 'execution.runtime-mode' = 'streaming'; -- execution mode either 'batch' or 'streaming'\nSET 'sql-client.execution.result-mode' = 'table'; -- available values: 'table', 'changelog' and 'tableau'\nSET 'sql-client.execution.max-table-result.rows' = '10000'; -- optional: maximum number of maintained rows\nSET 'parallelism.default' = '1'; -- optional: Flink's parallelism (1 by default)\nSET 'pipeline.auto-watermark-interval' = '200'; --optional: interval for periodic watermarks\nSET 'pipeline.max-parallelism' = '10'; -- optional: Flink's maximum parallelism\nSET 'table.exec.state.ttl' = '1000'; -- optional: table program's idle state time\nSET 'restart-strategy' = 'fixed-delay';\n\n-- Configuration options for adjusting and tuning table programs.\n\nSET 'table.optimizer.join-reorder-enabled' = 'true';\nSET 'table.exec.spill-compression.enabled' = 'true';\nSET 'table.exec.spill-compression.block-size' = '128kb';\n```\n\n\n\n```sql\nCREATE TEMPORARY TABLE users (\n  user_id BIGINT,\n  user_name STRING,\n  user_level STRING,\n  region STRING,\n  PRIMARY KEY (user_id) NOT ENFORCED\n) WITH (\n  'connector' = 'upsert-kafka',\n  'topic' = 'users',\n  'properties.bootstrap.servers' = '...',\n  'key.format' = 'csv',\n  'value.format' = 'avro'\n);\n\n-- set sync mode\nSET 'table.dml-sync' = 'true';\n\n-- set the job name\nSET 'pipeline.name' = 'SqlJob';\n\n-- set the queue that the job submit to\nSET 'yarn.application.queue' = 'root';\n\n-- set the job parallelism\nSET 'parallelism.default' = '100';\n\n-- restore from the specific savepoint path\nSET 'execution.savepoint.path' = '/tmp/flink-savepoints/savepoint-cca7bc-bb1e257f0dab';\n\nINSERT INTO pageviews_enriched\nSELECT *\nFROM pageviews AS p\nLEFT JOIN users FOR SYSTEM_TIME AS OF p.proctime AS u\nON p.user_id = u.user_id;\n```\n\n","source":"_posts/bigdata/通过Flink-SQL，将Kafka中的Oracle-CDC-Log同步到Doris.md","raw":"---\ntitle: 通过Flink-SQL，将Kafka中的Oracle-CDC-Log同步到Doris\ntags:\n  - 'Flink'\ncategories:\n  - [bigdata,Flink]\ntop_img: 'linear-gradient(20deg, #0062be, #925696, #cc426e, #fb0347)'\ndate: 2022-08-14 23:14:56\nupdated: 2022-08-14 23:14:56\ncover:\ndescription:\nkeywords:\n---\n\n## 前言\n- Oracle的binlog日志已经由DBA通过OGG同步到Kafka中了，因此用不到Flink CDC\n- 同步到Kafka中的JSON样式\n  ```json\n  {\n  \"before\": {\n    \"id\": 111,\n    \"name\": \"scooter\",\n    \"description\": \"Big 2-wheel scooter\",\n    \"weight\": 5.18\n  },\n  \"after\": {\n    \"id\": 111,\n    \"name\": \"scooter\",\n    \"description\": \"Big 2-wheel scooter\",\n    \"weight\": 5.15\n  },\n  \"op_type\": \"U\",\n  \"op_ts\": \"2020-05-13 15:40:06.000000\",\n  \"current_ts\": \"2020-05-13 15:40:07.000000\",\n  \"primary_keys\": [\n    \"id\"\n  ],\n  \"pos\": \"00000000000000000000143\",\n  \"table\": \"PRODUCTS\"\n  }\n  ```\n\n## Flink SQL\n> 需要下载以下Jar包，放在{flink_home}/lib/下\n> flink-sql-connector-kafka_2.12-1.14.5.jar\n> flink-json-1.15.1.jar\n> flink-doris-connector-1.14_2.12-1.1.0.jar\n\n- 开启CheckPoint：`SET 'execution.checkpointing.interval' = '10min';`\n\n- 创建Kafka数据源表，设置`'format' = 'ogg-json'`，只有`org.apache.flink.flink-json-1.15.1`中以上才支持ogg-json fromat\n```sql\nCREATE TABLE topic_products (\n  id INT,\n  name STRING,\n  description STRING,\n  weight DECIMAL(10, 2)\n) WITH (\n  'connector' = 'kafka',\n  'topic' = 'products_ogg_1',\n  'properties.bootstrap.servers' = '172.30.160.5:9092',\n  'properties.group.id' = 'testGroup',\n  'format' = 'ogg-json',\n  'scan.startup.mode' = 'earliest-offset',\n  'ogg-json.ignore-parse-errors' = 'true'\n);\n```\n\n- 创建Doris-Sink表\n```sql\nCREATE TABLE doris_sink (\nid INT,\nname STRING,\ndescription STRING,\nweight DECIMAL(10, 2)\n)\nWITH (\n  'connector' = 'doris',\n  'fenodes' = '172.30.160.5:8030',\n  'table.identifier' = 'test.product',\n  'username' = 'root',\n  'password' = '',\n  'sink.properties.format' = 'json',\n  'sink.properties.read_json_by_line' = 'true',\n  'sink.enable-delete' = 'true',\n  'sink.label-prefix' = 'doris_label'\n);\n```\n\n- 执行`INSERT into doris_sink select * from topic_products;`语句，写入Doris\n\n## Code Repo\n\n> 1. **bin/sql-client.sh embedded -i init_file -f file -s yarn-session** \n> 2. Execute SQL Files \n\n```sql\n-- Define available catalogs\n\nCREATE CATALOG MyCatalog\n  WITH (\n    'type' = 'hive'\n  );\n\nUSE CATALOG MyCatalog;\n\n-- Define available database\n\nCREATE DATABASE MyDatabase;\n\nUSE MyDatabase;\n\n-- Define TABLE\n\nCREATE TABLE MyTable(\n  MyField1 INT,\n  MyField2 STRING\n) WITH (\n  'connector' = 'filesystem',\n  'path' = '/path/to/something',\n  'format' = 'csv'\n);\n\n-- Define VIEW\n\nCREATE VIEW MyCustomView AS SELECT MyField2 FROM MyTable;\n\n-- Define user-defined functions here.\n\nCREATE FUNCTION foo.bar.AggregateUDF AS myUDF;\n\n-- Properties that change the fundamental execution behavior of a table program.\n\nSET 'execution.runtime-mode' = 'streaming'; -- execution mode either 'batch' or 'streaming'\nSET 'sql-client.execution.result-mode' = 'table'; -- available values: 'table', 'changelog' and 'tableau'\nSET 'sql-client.execution.max-table-result.rows' = '10000'; -- optional: maximum number of maintained rows\nSET 'parallelism.default' = '1'; -- optional: Flink's parallelism (1 by default)\nSET 'pipeline.auto-watermark-interval' = '200'; --optional: interval for periodic watermarks\nSET 'pipeline.max-parallelism' = '10'; -- optional: Flink's maximum parallelism\nSET 'table.exec.state.ttl' = '1000'; -- optional: table program's idle state time\nSET 'restart-strategy' = 'fixed-delay';\n\n-- Configuration options for adjusting and tuning table programs.\n\nSET 'table.optimizer.join-reorder-enabled' = 'true';\nSET 'table.exec.spill-compression.enabled' = 'true';\nSET 'table.exec.spill-compression.block-size' = '128kb';\n```\n\n\n\n```sql\nCREATE TEMPORARY TABLE users (\n  user_id BIGINT,\n  user_name STRING,\n  user_level STRING,\n  region STRING,\n  PRIMARY KEY (user_id) NOT ENFORCED\n) WITH (\n  'connector' = 'upsert-kafka',\n  'topic' = 'users',\n  'properties.bootstrap.servers' = '...',\n  'key.format' = 'csv',\n  'value.format' = 'avro'\n);\n\n-- set sync mode\nSET 'table.dml-sync' = 'true';\n\n-- set the job name\nSET 'pipeline.name' = 'SqlJob';\n\n-- set the queue that the job submit to\nSET 'yarn.application.queue' = 'root';\n\n-- set the job parallelism\nSET 'parallelism.default' = '100';\n\n-- restore from the specific savepoint path\nSET 'execution.savepoint.path' = '/tmp/flink-savepoints/savepoint-cca7bc-bb1e257f0dab';\n\nINSERT INTO pageviews_enriched\nSELECT *\nFROM pageviews AS p\nLEFT JOIN users FOR SYSTEM_TIME AS OF p.proctime AS u\nON p.user_id = u.user_id;\n```\n\n","slug":"bigdata/通过Flink-SQL，将Kafka中的Oracle-CDC-Log同步到Doris","published":1,"comments":1,"layout":"post","photos":[],"link":"","_id":"cl9y38dsq0025fwui0szl7rra","content":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><ul>\n<li>Oracle的binlog日志已经由DBA通过OGG同步到Kafka中了，因此用不到Flink CDC</li>\n<li>同步到Kafka中的JSON样式<figure class=\"highlight json\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"punctuation\">&#123;</span></span><br><span class=\"line\"><span class=\"attr\">&quot;before&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">  <span class=\"attr\">&quot;id&quot;</span><span class=\"punctuation\">:</span> <span class=\"number\">111</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">  <span class=\"attr\">&quot;name&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;scooter&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">  <span class=\"attr\">&quot;description&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;Big 2-wheel scooter&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">  <span class=\"attr\">&quot;weight&quot;</span><span class=\"punctuation\">:</span> <span class=\"number\">5.18</span></span><br><span class=\"line\"><span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\"><span class=\"attr\">&quot;after&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">  <span class=\"attr\">&quot;id&quot;</span><span class=\"punctuation\">:</span> <span class=\"number\">111</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">  <span class=\"attr\">&quot;name&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;scooter&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">  <span class=\"attr\">&quot;description&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;Big 2-wheel scooter&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">  <span class=\"attr\">&quot;weight&quot;</span><span class=\"punctuation\">:</span> <span class=\"number\">5.15</span></span><br><span class=\"line\"><span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\"><span class=\"attr\">&quot;op_type&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;U&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\"><span class=\"attr\">&quot;op_ts&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;2020-05-13 15:40:06.000000&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\"><span class=\"attr\">&quot;current_ts&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;2020-05-13 15:40:07.000000&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\"><span class=\"attr\">&quot;primary_keys&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">[</span></span><br><span class=\"line\">  <span class=\"string\">&quot;id&quot;</span></span><br><span class=\"line\"><span class=\"punctuation\">]</span><span class=\"punctuation\">,</span></span><br><span class=\"line\"><span class=\"attr\">&quot;pos&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;00000000000000000000143&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\"><span class=\"attr\">&quot;table&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;PRODUCTS&quot;</span></span><br><span class=\"line\"><span class=\"punctuation\">&#125;</span></span><br></pre></td></tr></table></figure></li>\n</ul>\n<h2 id=\"Flink-SQL\"><a href=\"#Flink-SQL\" class=\"headerlink\" title=\"Flink SQL\"></a>Flink SQL</h2><blockquote>\n<p>需要下载以下Jar包，放在{flink_home}&#x2F;lib&#x2F;下<br>flink-sql-connector-kafka_2.12-1.14.5.jar<br>flink-json-1.15.1.jar<br>flink-doris-connector-1.14_2.12-1.1.0.jar</p>\n</blockquote>\n<ul>\n<li><p>开启CheckPoint：<code>SET &#39;execution.checkpointing.interval&#39; = &#39;10min&#39;;</code></p>\n</li>\n<li><p>创建Kafka数据源表，设置<code>&#39;format&#39; = &#39;ogg-json&#39;</code>，只有<code>org.apache.flink.flink-json-1.15.1</code>中以上才支持ogg-json fromat</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">CREATE</span> <span class=\"keyword\">TABLE</span> topic_products (</span><br><span class=\"line\">  id <span class=\"type\">INT</span>,</span><br><span class=\"line\">  name STRING,</span><br><span class=\"line\">  description STRING,</span><br><span class=\"line\">  weight <span class=\"type\">DECIMAL</span>(<span class=\"number\">10</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\">) <span class=\"keyword\">WITH</span> (</span><br><span class=\"line\">  <span class=\"string\">&#x27;connector&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;kafka&#x27;</span>,</span><br><span class=\"line\">  <span class=\"string\">&#x27;topic&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;products_ogg_1&#x27;</span>,</span><br><span class=\"line\">  <span class=\"string\">&#x27;properties.bootstrap.servers&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;172.30.160.5:9092&#x27;</span>,</span><br><span class=\"line\">  <span class=\"string\">&#x27;properties.group.id&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;testGroup&#x27;</span>,</span><br><span class=\"line\">  <span class=\"string\">&#x27;format&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;ogg-json&#x27;</span>,</span><br><span class=\"line\">  <span class=\"string\">&#x27;scan.startup.mode&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;earliest-offset&#x27;</span>,</span><br><span class=\"line\">  <span class=\"string\">&#x27;ogg-json.ignore-parse-errors&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;true&#x27;</span></span><br><span class=\"line\">);</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>创建Doris-Sink表</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">CREATE</span> <span class=\"keyword\">TABLE</span> doris_sink (</span><br><span class=\"line\">id <span class=\"type\">INT</span>,</span><br><span class=\"line\">name STRING,</span><br><span class=\"line\">description STRING,</span><br><span class=\"line\">weight <span class=\"type\">DECIMAL</span>(<span class=\"number\">10</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\">)</span><br><span class=\"line\"><span class=\"keyword\">WITH</span> (</span><br><span class=\"line\">  <span class=\"string\">&#x27;connector&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;doris&#x27;</span>,</span><br><span class=\"line\">  <span class=\"string\">&#x27;fenodes&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;172.30.160.5:8030&#x27;</span>,</span><br><span class=\"line\">  <span class=\"string\">&#x27;table.identifier&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;test.product&#x27;</span>,</span><br><span class=\"line\">  <span class=\"string\">&#x27;username&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;root&#x27;</span>,</span><br><span class=\"line\">  <span class=\"string\">&#x27;password&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;&#x27;</span>,</span><br><span class=\"line\">  <span class=\"string\">&#x27;sink.properties.format&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;json&#x27;</span>,</span><br><span class=\"line\">  <span class=\"string\">&#x27;sink.properties.read_json_by_line&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;true&#x27;</span>,</span><br><span class=\"line\">  <span class=\"string\">&#x27;sink.enable-delete&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;true&#x27;</span>,</span><br><span class=\"line\">  <span class=\"string\">&#x27;sink.label-prefix&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;doris_label&#x27;</span></span><br><span class=\"line\">);</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>执行<code>INSERT into doris_sink select * from topic_products;</code>语句，写入Doris</p>\n</li>\n</ul>\n<h2 id=\"Code-Repo\"><a href=\"#Code-Repo\" class=\"headerlink\" title=\"Code Repo\"></a>Code Repo</h2><blockquote>\n<ol>\n<li><strong>bin&#x2F;sql-client.sh embedded -i init_file -f file -s yarn-session</strong> </li>\n<li>Execute SQL Files</li>\n</ol>\n</blockquote>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">-- Define available catalogs</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">CREATE</span> CATALOG MyCatalog</span><br><span class=\"line\">  <span class=\"keyword\">WITH</span> (</span><br><span class=\"line\">    <span class=\"string\">&#x27;type&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;hive&#x27;</span></span><br><span class=\"line\">  );</span><br><span class=\"line\"></span><br><span class=\"line\">USE CATALOG MyCatalog;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">-- Define available database</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">CREATE</span> DATABASE MyDatabase;</span><br><span class=\"line\"></span><br><span class=\"line\">USE MyDatabase;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">-- Define TABLE</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">CREATE</span> <span class=\"keyword\">TABLE</span> MyTable(</span><br><span class=\"line\">  MyField1 <span class=\"type\">INT</span>,</span><br><span class=\"line\">  MyField2 STRING</span><br><span class=\"line\">) <span class=\"keyword\">WITH</span> (</span><br><span class=\"line\">  <span class=\"string\">&#x27;connector&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;filesystem&#x27;</span>,</span><br><span class=\"line\">  <span class=\"string\">&#x27;path&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;/path/to/something&#x27;</span>,</span><br><span class=\"line\">  <span class=\"string\">&#x27;format&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;csv&#x27;</span></span><br><span class=\"line\">);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">-- Define VIEW</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">CREATE</span> <span class=\"keyword\">VIEW</span> MyCustomView <span class=\"keyword\">AS</span> <span class=\"keyword\">SELECT</span> MyField2 <span class=\"keyword\">FROM</span> MyTable;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">-- Define user-defined functions here.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">CREATE</span> <span class=\"keyword\">FUNCTION</span> foo.bar.AggregateUDF <span class=\"keyword\">AS</span> myUDF;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">-- Properties that change the fundamental execution behavior of a table program.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">SET</span> <span class=\"string\">&#x27;execution.runtime-mode&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;streaming&#x27;</span>; <span class=\"comment\">-- execution mode either &#x27;batch&#x27; or &#x27;streaming&#x27;</span></span><br><span class=\"line\"><span class=\"keyword\">SET</span> <span class=\"string\">&#x27;sql-client.execution.result-mode&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;table&#x27;</span>; <span class=\"comment\">-- available values: &#x27;table&#x27;, &#x27;changelog&#x27; and &#x27;tableau&#x27;</span></span><br><span class=\"line\"><span class=\"keyword\">SET</span> <span class=\"string\">&#x27;sql-client.execution.max-table-result.rows&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;10000&#x27;</span>; <span class=\"comment\">-- optional: maximum number of maintained rows</span></span><br><span class=\"line\"><span class=\"keyword\">SET</span> <span class=\"string\">&#x27;parallelism.default&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;1&#x27;</span>; <span class=\"comment\">-- optional: Flink&#x27;s parallelism (1 by default)</span></span><br><span class=\"line\"><span class=\"keyword\">SET</span> <span class=\"string\">&#x27;pipeline.auto-watermark-interval&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;200&#x27;</span>; <span class=\"comment\">--optional: interval for periodic watermarks</span></span><br><span class=\"line\"><span class=\"keyword\">SET</span> <span class=\"string\">&#x27;pipeline.max-parallelism&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;10&#x27;</span>; <span class=\"comment\">-- optional: Flink&#x27;s maximum parallelism</span></span><br><span class=\"line\"><span class=\"keyword\">SET</span> <span class=\"string\">&#x27;table.exec.state.ttl&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;1000&#x27;</span>; <span class=\"comment\">-- optional: table program&#x27;s idle state time</span></span><br><span class=\"line\"><span class=\"keyword\">SET</span> <span class=\"string\">&#x27;restart-strategy&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;fixed-delay&#x27;</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">-- Configuration options for adjusting and tuning table programs.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">SET</span> <span class=\"string\">&#x27;table.optimizer.join-reorder-enabled&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;true&#x27;</span>;</span><br><span class=\"line\"><span class=\"keyword\">SET</span> <span class=\"string\">&#x27;table.exec.spill-compression.enabled&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;true&#x27;</span>;</span><br><span class=\"line\"><span class=\"keyword\">SET</span> <span class=\"string\">&#x27;table.exec.spill-compression.block-size&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;128kb&#x27;</span>;</span><br></pre></td></tr></table></figure>\n\n\n\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">CREATE</span> TEMPORARY <span class=\"keyword\">TABLE</span> users (</span><br><span class=\"line\">  user_id <span class=\"type\">BIGINT</span>,</span><br><span class=\"line\">  user_name STRING,</span><br><span class=\"line\">  user_level STRING,</span><br><span class=\"line\">  region STRING,</span><br><span class=\"line\">  <span class=\"keyword\">PRIMARY</span> KEY (user_id) <span class=\"keyword\">NOT</span> ENFORCED</span><br><span class=\"line\">) <span class=\"keyword\">WITH</span> (</span><br><span class=\"line\">  <span class=\"string\">&#x27;connector&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;upsert-kafka&#x27;</span>,</span><br><span class=\"line\">  <span class=\"string\">&#x27;topic&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;users&#x27;</span>,</span><br><span class=\"line\">  <span class=\"string\">&#x27;properties.bootstrap.servers&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;...&#x27;</span>,</span><br><span class=\"line\">  <span class=\"string\">&#x27;key.format&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;csv&#x27;</span>,</span><br><span class=\"line\">  <span class=\"string\">&#x27;value.format&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;avro&#x27;</span></span><br><span class=\"line\">);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">-- set sync mode</span></span><br><span class=\"line\"><span class=\"keyword\">SET</span> <span class=\"string\">&#x27;table.dml-sync&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;true&#x27;</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">-- set the job name</span></span><br><span class=\"line\"><span class=\"keyword\">SET</span> <span class=\"string\">&#x27;pipeline.name&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;SqlJob&#x27;</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">-- set the queue that the job submit to</span></span><br><span class=\"line\"><span class=\"keyword\">SET</span> <span class=\"string\">&#x27;yarn.application.queue&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;root&#x27;</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">-- set the job parallelism</span></span><br><span class=\"line\"><span class=\"keyword\">SET</span> <span class=\"string\">&#x27;parallelism.default&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;100&#x27;</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">-- restore from the specific savepoint path</span></span><br><span class=\"line\"><span class=\"keyword\">SET</span> <span class=\"string\">&#x27;execution.savepoint.path&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;/tmp/flink-savepoints/savepoint-cca7bc-bb1e257f0dab&#x27;</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">INSERT</span> <span class=\"keyword\">INTO</span> pageviews_enriched</span><br><span class=\"line\"><span class=\"keyword\">SELECT</span> <span class=\"operator\">*</span></span><br><span class=\"line\"><span class=\"keyword\">FROM</span> pageviews <span class=\"keyword\">AS</span> p</span><br><span class=\"line\"><span class=\"keyword\">LEFT</span> <span class=\"keyword\">JOIN</span> users <span class=\"keyword\">FOR</span> <span class=\"built_in\">SYSTEM_TIME</span> <span class=\"keyword\">AS</span> <span class=\"keyword\">OF</span> p.proctime <span class=\"keyword\">AS</span> u</span><br><span class=\"line\"><span class=\"keyword\">ON</span> p.user_id <span class=\"operator\">=</span> u.user_id;</span><br></pre></td></tr></table></figure>\n\n","site":{"data":{"link":[{"class_name":"友情链接","class_desc":"那些人，那些事","link_list":[{"name":"张洪Heo","link":"https://blog.zhheo.com/","avatar":"https://npm.elemecdn.com/guli-heo/img/avatar2.png","descr":"分享设计与科技生活"},{"name":"瞬間の筆記","link":"https://hikki.site","descr":"喜欢的东西就努力去追求，万一成功了呢!","avatar":"https://cdn.jsdelivr.net/gh/0000rookie/imgs/202206120315.png"}]}]}},"excerpt":"","more":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><ul>\n<li>Oracle的binlog日志已经由DBA通过OGG同步到Kafka中了，因此用不到Flink CDC</li>\n<li>同步到Kafka中的JSON样式<figure class=\"highlight json\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"punctuation\">&#123;</span></span><br><span class=\"line\"><span class=\"attr\">&quot;before&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">  <span class=\"attr\">&quot;id&quot;</span><span class=\"punctuation\">:</span> <span class=\"number\">111</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">  <span class=\"attr\">&quot;name&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;scooter&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">  <span class=\"attr\">&quot;description&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;Big 2-wheel scooter&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">  <span class=\"attr\">&quot;weight&quot;</span><span class=\"punctuation\">:</span> <span class=\"number\">5.18</span></span><br><span class=\"line\"><span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\"><span class=\"attr\">&quot;after&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">  <span class=\"attr\">&quot;id&quot;</span><span class=\"punctuation\">:</span> <span class=\"number\">111</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">  <span class=\"attr\">&quot;name&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;scooter&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">  <span class=\"attr\">&quot;description&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;Big 2-wheel scooter&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">  <span class=\"attr\">&quot;weight&quot;</span><span class=\"punctuation\">:</span> <span class=\"number\">5.15</span></span><br><span class=\"line\"><span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\"><span class=\"attr\">&quot;op_type&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;U&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\"><span class=\"attr\">&quot;op_ts&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;2020-05-13 15:40:06.000000&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\"><span class=\"attr\">&quot;current_ts&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;2020-05-13 15:40:07.000000&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\"><span class=\"attr\">&quot;primary_keys&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">[</span></span><br><span class=\"line\">  <span class=\"string\">&quot;id&quot;</span></span><br><span class=\"line\"><span class=\"punctuation\">]</span><span class=\"punctuation\">,</span></span><br><span class=\"line\"><span class=\"attr\">&quot;pos&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;00000000000000000000143&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\"><span class=\"attr\">&quot;table&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;PRODUCTS&quot;</span></span><br><span class=\"line\"><span class=\"punctuation\">&#125;</span></span><br></pre></td></tr></table></figure></li>\n</ul>\n<h2 id=\"Flink-SQL\"><a href=\"#Flink-SQL\" class=\"headerlink\" title=\"Flink SQL\"></a>Flink SQL</h2><blockquote>\n<p>需要下载以下Jar包，放在{flink_home}&#x2F;lib&#x2F;下<br>flink-sql-connector-kafka_2.12-1.14.5.jar<br>flink-json-1.15.1.jar<br>flink-doris-connector-1.14_2.12-1.1.0.jar</p>\n</blockquote>\n<ul>\n<li><p>开启CheckPoint：<code>SET &#39;execution.checkpointing.interval&#39; = &#39;10min&#39;;</code></p>\n</li>\n<li><p>创建Kafka数据源表，设置<code>&#39;format&#39; = &#39;ogg-json&#39;</code>，只有<code>org.apache.flink.flink-json-1.15.1</code>中以上才支持ogg-json fromat</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">CREATE</span> <span class=\"keyword\">TABLE</span> topic_products (</span><br><span class=\"line\">  id <span class=\"type\">INT</span>,</span><br><span class=\"line\">  name STRING,</span><br><span class=\"line\">  description STRING,</span><br><span class=\"line\">  weight <span class=\"type\">DECIMAL</span>(<span class=\"number\">10</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\">) <span class=\"keyword\">WITH</span> (</span><br><span class=\"line\">  <span class=\"string\">&#x27;connector&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;kafka&#x27;</span>,</span><br><span class=\"line\">  <span class=\"string\">&#x27;topic&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;products_ogg_1&#x27;</span>,</span><br><span class=\"line\">  <span class=\"string\">&#x27;properties.bootstrap.servers&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;172.30.160.5:9092&#x27;</span>,</span><br><span class=\"line\">  <span class=\"string\">&#x27;properties.group.id&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;testGroup&#x27;</span>,</span><br><span class=\"line\">  <span class=\"string\">&#x27;format&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;ogg-json&#x27;</span>,</span><br><span class=\"line\">  <span class=\"string\">&#x27;scan.startup.mode&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;earliest-offset&#x27;</span>,</span><br><span class=\"line\">  <span class=\"string\">&#x27;ogg-json.ignore-parse-errors&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;true&#x27;</span></span><br><span class=\"line\">);</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>创建Doris-Sink表</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">CREATE</span> <span class=\"keyword\">TABLE</span> doris_sink (</span><br><span class=\"line\">id <span class=\"type\">INT</span>,</span><br><span class=\"line\">name STRING,</span><br><span class=\"line\">description STRING,</span><br><span class=\"line\">weight <span class=\"type\">DECIMAL</span>(<span class=\"number\">10</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\">)</span><br><span class=\"line\"><span class=\"keyword\">WITH</span> (</span><br><span class=\"line\">  <span class=\"string\">&#x27;connector&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;doris&#x27;</span>,</span><br><span class=\"line\">  <span class=\"string\">&#x27;fenodes&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;172.30.160.5:8030&#x27;</span>,</span><br><span class=\"line\">  <span class=\"string\">&#x27;table.identifier&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;test.product&#x27;</span>,</span><br><span class=\"line\">  <span class=\"string\">&#x27;username&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;root&#x27;</span>,</span><br><span class=\"line\">  <span class=\"string\">&#x27;password&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;&#x27;</span>,</span><br><span class=\"line\">  <span class=\"string\">&#x27;sink.properties.format&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;json&#x27;</span>,</span><br><span class=\"line\">  <span class=\"string\">&#x27;sink.properties.read_json_by_line&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;true&#x27;</span>,</span><br><span class=\"line\">  <span class=\"string\">&#x27;sink.enable-delete&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;true&#x27;</span>,</span><br><span class=\"line\">  <span class=\"string\">&#x27;sink.label-prefix&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;doris_label&#x27;</span></span><br><span class=\"line\">);</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>执行<code>INSERT into doris_sink select * from topic_products;</code>语句，写入Doris</p>\n</li>\n</ul>\n<h2 id=\"Code-Repo\"><a href=\"#Code-Repo\" class=\"headerlink\" title=\"Code Repo\"></a>Code Repo</h2><blockquote>\n<ol>\n<li><strong>bin&#x2F;sql-client.sh embedded -i init_file -f file -s yarn-session</strong> </li>\n<li>Execute SQL Files</li>\n</ol>\n</blockquote>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">-- Define available catalogs</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">CREATE</span> CATALOG MyCatalog</span><br><span class=\"line\">  <span class=\"keyword\">WITH</span> (</span><br><span class=\"line\">    <span class=\"string\">&#x27;type&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;hive&#x27;</span></span><br><span class=\"line\">  );</span><br><span class=\"line\"></span><br><span class=\"line\">USE CATALOG MyCatalog;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">-- Define available database</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">CREATE</span> DATABASE MyDatabase;</span><br><span class=\"line\"></span><br><span class=\"line\">USE MyDatabase;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">-- Define TABLE</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">CREATE</span> <span class=\"keyword\">TABLE</span> MyTable(</span><br><span class=\"line\">  MyField1 <span class=\"type\">INT</span>,</span><br><span class=\"line\">  MyField2 STRING</span><br><span class=\"line\">) <span class=\"keyword\">WITH</span> (</span><br><span class=\"line\">  <span class=\"string\">&#x27;connector&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;filesystem&#x27;</span>,</span><br><span class=\"line\">  <span class=\"string\">&#x27;path&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;/path/to/something&#x27;</span>,</span><br><span class=\"line\">  <span class=\"string\">&#x27;format&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;csv&#x27;</span></span><br><span class=\"line\">);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">-- Define VIEW</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">CREATE</span> <span class=\"keyword\">VIEW</span> MyCustomView <span class=\"keyword\">AS</span> <span class=\"keyword\">SELECT</span> MyField2 <span class=\"keyword\">FROM</span> MyTable;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">-- Define user-defined functions here.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">CREATE</span> <span class=\"keyword\">FUNCTION</span> foo.bar.AggregateUDF <span class=\"keyword\">AS</span> myUDF;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">-- Properties that change the fundamental execution behavior of a table program.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">SET</span> <span class=\"string\">&#x27;execution.runtime-mode&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;streaming&#x27;</span>; <span class=\"comment\">-- execution mode either &#x27;batch&#x27; or &#x27;streaming&#x27;</span></span><br><span class=\"line\"><span class=\"keyword\">SET</span> <span class=\"string\">&#x27;sql-client.execution.result-mode&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;table&#x27;</span>; <span class=\"comment\">-- available values: &#x27;table&#x27;, &#x27;changelog&#x27; and &#x27;tableau&#x27;</span></span><br><span class=\"line\"><span class=\"keyword\">SET</span> <span class=\"string\">&#x27;sql-client.execution.max-table-result.rows&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;10000&#x27;</span>; <span class=\"comment\">-- optional: maximum number of maintained rows</span></span><br><span class=\"line\"><span class=\"keyword\">SET</span> <span class=\"string\">&#x27;parallelism.default&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;1&#x27;</span>; <span class=\"comment\">-- optional: Flink&#x27;s parallelism (1 by default)</span></span><br><span class=\"line\"><span class=\"keyword\">SET</span> <span class=\"string\">&#x27;pipeline.auto-watermark-interval&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;200&#x27;</span>; <span class=\"comment\">--optional: interval for periodic watermarks</span></span><br><span class=\"line\"><span class=\"keyword\">SET</span> <span class=\"string\">&#x27;pipeline.max-parallelism&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;10&#x27;</span>; <span class=\"comment\">-- optional: Flink&#x27;s maximum parallelism</span></span><br><span class=\"line\"><span class=\"keyword\">SET</span> <span class=\"string\">&#x27;table.exec.state.ttl&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;1000&#x27;</span>; <span class=\"comment\">-- optional: table program&#x27;s idle state time</span></span><br><span class=\"line\"><span class=\"keyword\">SET</span> <span class=\"string\">&#x27;restart-strategy&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;fixed-delay&#x27;</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">-- Configuration options for adjusting and tuning table programs.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">SET</span> <span class=\"string\">&#x27;table.optimizer.join-reorder-enabled&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;true&#x27;</span>;</span><br><span class=\"line\"><span class=\"keyword\">SET</span> <span class=\"string\">&#x27;table.exec.spill-compression.enabled&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;true&#x27;</span>;</span><br><span class=\"line\"><span class=\"keyword\">SET</span> <span class=\"string\">&#x27;table.exec.spill-compression.block-size&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;128kb&#x27;</span>;</span><br></pre></td></tr></table></figure>\n\n\n\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">CREATE</span> TEMPORARY <span class=\"keyword\">TABLE</span> users (</span><br><span class=\"line\">  user_id <span class=\"type\">BIGINT</span>,</span><br><span class=\"line\">  user_name STRING,</span><br><span class=\"line\">  user_level STRING,</span><br><span class=\"line\">  region STRING,</span><br><span class=\"line\">  <span class=\"keyword\">PRIMARY</span> KEY (user_id) <span class=\"keyword\">NOT</span> ENFORCED</span><br><span class=\"line\">) <span class=\"keyword\">WITH</span> (</span><br><span class=\"line\">  <span class=\"string\">&#x27;connector&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;upsert-kafka&#x27;</span>,</span><br><span class=\"line\">  <span class=\"string\">&#x27;topic&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;users&#x27;</span>,</span><br><span class=\"line\">  <span class=\"string\">&#x27;properties.bootstrap.servers&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;...&#x27;</span>,</span><br><span class=\"line\">  <span class=\"string\">&#x27;key.format&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;csv&#x27;</span>,</span><br><span class=\"line\">  <span class=\"string\">&#x27;value.format&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;avro&#x27;</span></span><br><span class=\"line\">);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">-- set sync mode</span></span><br><span class=\"line\"><span class=\"keyword\">SET</span> <span class=\"string\">&#x27;table.dml-sync&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;true&#x27;</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">-- set the job name</span></span><br><span class=\"line\"><span class=\"keyword\">SET</span> <span class=\"string\">&#x27;pipeline.name&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;SqlJob&#x27;</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">-- set the queue that the job submit to</span></span><br><span class=\"line\"><span class=\"keyword\">SET</span> <span class=\"string\">&#x27;yarn.application.queue&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;root&#x27;</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">-- set the job parallelism</span></span><br><span class=\"line\"><span class=\"keyword\">SET</span> <span class=\"string\">&#x27;parallelism.default&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;100&#x27;</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">-- restore from the specific savepoint path</span></span><br><span class=\"line\"><span class=\"keyword\">SET</span> <span class=\"string\">&#x27;execution.savepoint.path&#x27;</span> <span class=\"operator\">=</span> <span class=\"string\">&#x27;/tmp/flink-savepoints/savepoint-cca7bc-bb1e257f0dab&#x27;</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">INSERT</span> <span class=\"keyword\">INTO</span> pageviews_enriched</span><br><span class=\"line\"><span class=\"keyword\">SELECT</span> <span class=\"operator\">*</span></span><br><span class=\"line\"><span class=\"keyword\">FROM</span> pageviews <span class=\"keyword\">AS</span> p</span><br><span class=\"line\"><span class=\"keyword\">LEFT</span> <span class=\"keyword\">JOIN</span> users <span class=\"keyword\">FOR</span> <span class=\"built_in\">SYSTEM_TIME</span> <span class=\"keyword\">AS</span> <span class=\"keyword\">OF</span> p.proctime <span class=\"keyword\">AS</span> u</span><br><span class=\"line\"><span class=\"keyword\">ON</span> p.user_id <span class=\"operator\">=</span> u.user_id;</span><br></pre></td></tr></table></figure>\n\n"},{"title":"配置hadoop-snappy那些事","date":"2022-11-01T09:46:42.000Z","updated":"2022-11-01T09:46:42.000Z","cover":"https://tvax4.sinaimg.cn/large/0084aYsLgy1h3jum72m7kj31220e6jsc.jpg","top_img":null,"description":null,"keywords":null,"_content":"\n## 前言\n\n在Apache Hadoop3.x社区二进制发行版中已经包含hadoop-snappy，同时Centos7已经自带snappy本地库。因此Hadoop3.x+Centos7无需配置snappy本地库。可运行`hadoop checknative -a`检查snappy本地库是否可用。\n\n> 看了网上繁琐的Hadoop Snappy配置过程，配置了半天，才发现是白费功夫。原来是Hive的一个Bug。\n\n## Hive3.1.2中orc文件snappy压缩的Bug\n\n### Bug描述\n\n- 创建一个Hive表，存储为orc文件，同时启用snappy压缩。\n\n  ```hive\n  CREATE TABLE `default`.`user_orc` (\n    `tid` INT,\n    `userid` STRING\n  )\n  STORED AS orc\n  TBLPROPERTIES (\n    \"orc.compress\"=\"SNAPPY\"\n  );\n  ```\n  \n- Insert overwrite进一些数据\n\n  ```hive\n  insert overwrite table user_orc select * from user_1;\n  ```\n\n- 会在HDFS生成/user/hadoop/warehouse/user_orc/000000_0文件，文件没有带有.orc后缀\n\n- 使用`hive --orcfiledump /user/hadoop/warehouse/user_orc/000000_0`查看该orc文件信息，发现Compression: ZLIB，即默认的ZLIB压缩算法，snappy压缩算法没有生效。\n\n### 解决\n\n- 1、设置`set hive.exec.orc.default.compress=snappy;`参数，可暂时解决。\n- 2、升级到hive-3.1.3，貌似已经修复该问题。","source":"_posts/bigdata/配置hadoop-snappy那些事.md","raw":"---\ntitle: 配置hadoop-snappy那些事\ntags:\n  - ''\ncategories:\n  - []\ndate: 2022-11-01 17:46:42\nupdated: 2022-11-01 17:46:42\ncover:\ntop_img:\ndescription:\nkeywords:\n---\n\n## 前言\n\n在Apache Hadoop3.x社区二进制发行版中已经包含hadoop-snappy，同时Centos7已经自带snappy本地库。因此Hadoop3.x+Centos7无需配置snappy本地库。可运行`hadoop checknative -a`检查snappy本地库是否可用。\n\n> 看了网上繁琐的Hadoop Snappy配置过程，配置了半天，才发现是白费功夫。原来是Hive的一个Bug。\n\n## Hive3.1.2中orc文件snappy压缩的Bug\n\n### Bug描述\n\n- 创建一个Hive表，存储为orc文件，同时启用snappy压缩。\n\n  ```hive\n  CREATE TABLE `default`.`user_orc` (\n    `tid` INT,\n    `userid` STRING\n  )\n  STORED AS orc\n  TBLPROPERTIES (\n    \"orc.compress\"=\"SNAPPY\"\n  );\n  ```\n  \n- Insert overwrite进一些数据\n\n  ```hive\n  insert overwrite table user_orc select * from user_1;\n  ```\n\n- 会在HDFS生成/user/hadoop/warehouse/user_orc/000000_0文件，文件没有带有.orc后缀\n\n- 使用`hive --orcfiledump /user/hadoop/warehouse/user_orc/000000_0`查看该orc文件信息，发现Compression: ZLIB，即默认的ZLIB压缩算法，snappy压缩算法没有生效。\n\n### 解决\n\n- 1、设置`set hive.exec.orc.default.compress=snappy;`参数，可暂时解决。\n- 2、升级到hive-3.1.3，貌似已经修复该问题。","slug":"bigdata/配置hadoop-snappy那些事","published":1,"comments":1,"layout":"post","photos":[],"link":"","_id":"cl9y38dsr0027fwuigur63fnr","content":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>在Apache Hadoop3.x社区二进制发行版中已经包含hadoop-snappy，同时Centos7已经自带snappy本地库。因此Hadoop3.x+Centos7无需配置snappy本地库。可运行<code>hadoop checknative -a</code>检查snappy本地库是否可用。</p>\n<blockquote>\n<p>看了网上繁琐的Hadoop Snappy配置过程，配置了半天，才发现是白费功夫。原来是Hive的一个Bug。</p>\n</blockquote>\n<h2 id=\"Hive3-1-2中orc文件snappy压缩的Bug\"><a href=\"#Hive3-1-2中orc文件snappy压缩的Bug\" class=\"headerlink\" title=\"Hive3.1.2中orc文件snappy压缩的Bug\"></a>Hive3.1.2中orc文件snappy压缩的Bug</h2><h3 id=\"Bug描述\"><a href=\"#Bug描述\" class=\"headerlink\" title=\"Bug描述\"></a>Bug描述</h3><ul>\n<li><p>创建一个Hive表，存储为orc文件，同时启用snappy压缩。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CREATE TABLE `default`.`user_orc` (</span><br><span class=\"line\">  `tid` INT,</span><br><span class=\"line\">  `userid` STRING</span><br><span class=\"line\">)</span><br><span class=\"line\">STORED AS orc</span><br><span class=\"line\">TBLPROPERTIES (</span><br><span class=\"line\">  &quot;orc.compress&quot;=&quot;SNAPPY&quot;</span><br><span class=\"line\">);</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>Insert overwrite进一些数据</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">insert overwrite table user_orc select * from user_1;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>会在HDFS生成&#x2F;user&#x2F;hadoop&#x2F;warehouse&#x2F;user_orc&#x2F;000000_0文件，文件没有带有.orc后缀</p>\n</li>\n<li><p>使用<code>hive --orcfiledump /user/hadoop/warehouse/user_orc/000000_0</code>查看该orc文件信息，发现Compression: ZLIB，即默认的ZLIB压缩算法，snappy压缩算法没有生效。</p>\n</li>\n</ul>\n<h3 id=\"解决\"><a href=\"#解决\" class=\"headerlink\" title=\"解决\"></a>解决</h3><ul>\n<li>1、设置<code>set hive.exec.orc.default.compress=snappy;</code>参数，可暂时解决。</li>\n<li>2、升级到hive-3.1.3，貌似已经修复该问题。</li>\n</ul>\n","site":{"data":{"link":[{"class_name":"友情链接","class_desc":"那些人，那些事","link_list":[{"name":"张洪Heo","link":"https://blog.zhheo.com/","avatar":"https://npm.elemecdn.com/guli-heo/img/avatar2.png","descr":"分享设计与科技生活"},{"name":"瞬間の筆記","link":"https://hikki.site","descr":"喜欢的东西就努力去追求，万一成功了呢!","avatar":"https://cdn.jsdelivr.net/gh/0000rookie/imgs/202206120315.png"}]}]}},"excerpt":"","more":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>在Apache Hadoop3.x社区二进制发行版中已经包含hadoop-snappy，同时Centos7已经自带snappy本地库。因此Hadoop3.x+Centos7无需配置snappy本地库。可运行<code>hadoop checknative -a</code>检查snappy本地库是否可用。</p>\n<blockquote>\n<p>看了网上繁琐的Hadoop Snappy配置过程，配置了半天，才发现是白费功夫。原来是Hive的一个Bug。</p>\n</blockquote>\n<h2 id=\"Hive3-1-2中orc文件snappy压缩的Bug\"><a href=\"#Hive3-1-2中orc文件snappy压缩的Bug\" class=\"headerlink\" title=\"Hive3.1.2中orc文件snappy压缩的Bug\"></a>Hive3.1.2中orc文件snappy压缩的Bug</h2><h3 id=\"Bug描述\"><a href=\"#Bug描述\" class=\"headerlink\" title=\"Bug描述\"></a>Bug描述</h3><ul>\n<li><p>创建一个Hive表，存储为orc文件，同时启用snappy压缩。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CREATE TABLE `default`.`user_orc` (</span><br><span class=\"line\">  `tid` INT,</span><br><span class=\"line\">  `userid` STRING</span><br><span class=\"line\">)</span><br><span class=\"line\">STORED AS orc</span><br><span class=\"line\">TBLPROPERTIES (</span><br><span class=\"line\">  &quot;orc.compress&quot;=&quot;SNAPPY&quot;</span><br><span class=\"line\">);</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>Insert overwrite进一些数据</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">insert overwrite table user_orc select * from user_1;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>会在HDFS生成&#x2F;user&#x2F;hadoop&#x2F;warehouse&#x2F;user_orc&#x2F;000000_0文件，文件没有带有.orc后缀</p>\n</li>\n<li><p>使用<code>hive --orcfiledump /user/hadoop/warehouse/user_orc/000000_0</code>查看该orc文件信息，发现Compression: ZLIB，即默认的ZLIB压缩算法，snappy压缩算法没有生效。</p>\n</li>\n</ul>\n<h3 id=\"解决\"><a href=\"#解决\" class=\"headerlink\" title=\"解决\"></a>解决</h3><ul>\n<li>1、设置<code>set hive.exec.orc.default.compress=snappy;</code>参数，可暂时解决。</li>\n<li>2、升级到hive-3.1.3，貌似已经修复该问题。</li>\n</ul>\n"},{"title":"从SS-Table到LSM-Tree","top_img":null,"date":"2022-09-11T03:45:16.000Z","updated":"2022-09-11T03:45:16.000Z","cover":"https://tvax4.sinaimg.cn/large/0084aYsLgy1h3jum72m7kj31220e6jsc.jpg","description":null,"keywords":null,"_content":"\n## SS-Table\n\n- SSTable 最早出自 Google 的 Bigtable 论文\n\n  >An SSTable provides a persistent, ordered immutable map from keys to values, where both keys and values are arbitrary byte strings. Operations are provided to look up the value associated with a specified key, and to iterate over all key/value pairs in a specified key range. Internally, each SSTable contains a sequence of blocks (typically each block is 64KB in size, but this is configurable). A block index (stored at the end of the SSTable) is used to locate blocks; the index is loaded into memory when the SSTable is opened. A lookup can be performed with a single disk seek: we first find the appropriate block by performing a binary search in the in-memory index, and then reading the appropriate block from disk. Optionally, an SSTable can be completely mapped into memory, which allows us to perform lookups and scans without touching disk.\n  >\n  >\n  >\n  >通过以上描述，我们可以把 SSTable 抽象为以下结构，每个 SSTable 包含了很多按照 key 排序的 key-value 对，key 和 value 都是任意的字节数组。SSTable 可以方便的支持基于 key 的查找和范围扫描。SSTable 会把数据分成块进行存储，并在 SSTable 文件尾部保存块索引(Block Index), 块索引记录每个块结束的 key 及对应的offset。块索引一般会在 SSTable 打开的时候载入内存。每次读取 SSTable 的时候，在内存中找到对应的块，再进行一次磁盘访问，读取到块中的数据。当然，把 SSTable 大小限定在可以加载进内存的大小，每次直接加载进内存访问也是一种方法。\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1662868513341-45eab64f-2958-447b-8fc5-328a4942dfa1.png)\n\n> SSTable本身是个简单而有用的数据结构, 而往往由于工业界对于它的overload, 导致大家的误解\n> 它本身就像他的名字一样, 就是a set of sorted key-value pairs\n> 如下图左, 当文件比较大的时候, 也可以建立key:offset的index, 用于快速分段定位, 但这个是可选的.\n>\n> 这个结构和普通的key-value pairs的区别, **可以support range query和random r/w**\n\n## SSTables and Log Structured Merge Trees\n\n仅仅SSTable数据结构本身仍然无法support高效的range query和random r/w的场景\n还需要一整套的机制来完成从memory sort, flush to disk, compaction以及快速读取……这样的一个完成的机制和架构称为,\"[The Log-Structured Merge-Tree](http://nosqlsummer.org/paper/lsm-tree)\" (**LSM Tree**)\n名字很形象, 首先是基于log的, 不断产生SSTable结构的log文件, 并且是需要不断merge以提高效率的\n\n下图很好的描绘了LSM Tree的结构和大部分操作\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1662868915058-01727c5c-f5e9-402b-8737-41408cc5323d.png)\n\n![img](https://cdn.nlark.com/yuque/0/2022/webp/2500465/1662868956879-bb12a4e1-38b5-47c0-a25e-4d0d8f8ce788.webp)\n\n> - 写操作：Tablet 把响应的操作写入操作日志（tablet log），然后将具体的内容写入内存中 MemTable\n> - 读操作：读操作需要同时读 Memtable 和 SSTable，将结果合并返回。Memtable 和 SSTable 都是按照 key 有序的，可以快速的进行类似归并排序的合并。\n> - Minor Compaction：随着写请求的不断增多，Memtable 在内存中的空间不断增大，当 Memtable 的大小达到一定阈值时，Memtable 被 dump 到 GFS 中成为不可变的 SSTable。\n> - Merging Compaction：随着 Memtable 不断的变为 SSTable，SSTable 也不断增多，意味着读操作需要读取的 SSTable 也越来越多，为了限制 SSTable 的个数，Tablet Server 会在后台将多个 SSTable 合并为一个\n> - Major Compaction：Major Compaction 是一种特殊的 Merging Compaction，只把所有的 SSTable 合并为一个 SSTable，在 非 Major Compaction 产生的 SSTable 中可能包含已经删除的数据，Major Compaction 的过程会将这些数据真正的剔除掉，避免这些数据浪费存储空间。\n\nLSM Tree 的索引机制和 B+ Tree 的索引机制是明显不同的，B+ Tree 为所有的数据维护了一个索引，LSM Tree 则是为每个 磁盘文件维护了一个 Index。\n\n\n\n## 列行存储\n\n![image.png](https://cdn.nlark.com/yuque/0/2022/png/2500465/1662869279366-ddf2ea3e-ed85-4708-854f-7306682043b4.png)\n\n![image.png](https://cdn.nlark.com/yuque/0/2022/png/2500465/1662869286634-2e3183d7-1ce6-410d-95c2-68a26db82e60.png)\n\n>在Doris中，数据从 MemTable 刷写到磁盘的过程分为两个阶段，第一阶段是将 MemTable 中的行存结构在内存中转换为列存结构，并为每一列生成对应的索引结构；第二阶段是将转换后的列存结构写入磁盘，生成 Segment 文件。\n\n## 参考\n\n- https://www.igvita.com/2012/02/06/sstable-and-log-structured-storage-leveldb/\n","source":"_posts/data-structure/从SS-Table到LSM-Tree.md","raw":"---\ntitle: 从SS-Table到LSM-Tree\ntags:\n  - 'LSM-Tree'\ncategories:\n  - [data-structure]\ntop_img: \ndate: 2022-09-11 11:45:16\nupdated: 2022-09-11 11:45:16\ncover:\ndescription:\nkeywords:\n---\n\n## SS-Table\n\n- SSTable 最早出自 Google 的 Bigtable 论文\n\n  >An SSTable provides a persistent, ordered immutable map from keys to values, where both keys and values are arbitrary byte strings. Operations are provided to look up the value associated with a specified key, and to iterate over all key/value pairs in a specified key range. Internally, each SSTable contains a sequence of blocks (typically each block is 64KB in size, but this is configurable). A block index (stored at the end of the SSTable) is used to locate blocks; the index is loaded into memory when the SSTable is opened. A lookup can be performed with a single disk seek: we first find the appropriate block by performing a binary search in the in-memory index, and then reading the appropriate block from disk. Optionally, an SSTable can be completely mapped into memory, which allows us to perform lookups and scans without touching disk.\n  >\n  >\n  >\n  >通过以上描述，我们可以把 SSTable 抽象为以下结构，每个 SSTable 包含了很多按照 key 排序的 key-value 对，key 和 value 都是任意的字节数组。SSTable 可以方便的支持基于 key 的查找和范围扫描。SSTable 会把数据分成块进行存储，并在 SSTable 文件尾部保存块索引(Block Index), 块索引记录每个块结束的 key 及对应的offset。块索引一般会在 SSTable 打开的时候载入内存。每次读取 SSTable 的时候，在内存中找到对应的块，再进行一次磁盘访问，读取到块中的数据。当然，把 SSTable 大小限定在可以加载进内存的大小，每次直接加载进内存访问也是一种方法。\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1662868513341-45eab64f-2958-447b-8fc5-328a4942dfa1.png)\n\n> SSTable本身是个简单而有用的数据结构, 而往往由于工业界对于它的overload, 导致大家的误解\n> 它本身就像他的名字一样, 就是a set of sorted key-value pairs\n> 如下图左, 当文件比较大的时候, 也可以建立key:offset的index, 用于快速分段定位, 但这个是可选的.\n>\n> 这个结构和普通的key-value pairs的区别, **可以support range query和random r/w**\n\n## SSTables and Log Structured Merge Trees\n\n仅仅SSTable数据结构本身仍然无法support高效的range query和random r/w的场景\n还需要一整套的机制来完成从memory sort, flush to disk, compaction以及快速读取……这样的一个完成的机制和架构称为,\"[The Log-Structured Merge-Tree](http://nosqlsummer.org/paper/lsm-tree)\" (**LSM Tree**)\n名字很形象, 首先是基于log的, 不断产生SSTable结构的log文件, 并且是需要不断merge以提高效率的\n\n下图很好的描绘了LSM Tree的结构和大部分操作\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1662868915058-01727c5c-f5e9-402b-8737-41408cc5323d.png)\n\n![img](https://cdn.nlark.com/yuque/0/2022/webp/2500465/1662868956879-bb12a4e1-38b5-47c0-a25e-4d0d8f8ce788.webp)\n\n> - 写操作：Tablet 把响应的操作写入操作日志（tablet log），然后将具体的内容写入内存中 MemTable\n> - 读操作：读操作需要同时读 Memtable 和 SSTable，将结果合并返回。Memtable 和 SSTable 都是按照 key 有序的，可以快速的进行类似归并排序的合并。\n> - Minor Compaction：随着写请求的不断增多，Memtable 在内存中的空间不断增大，当 Memtable 的大小达到一定阈值时，Memtable 被 dump 到 GFS 中成为不可变的 SSTable。\n> - Merging Compaction：随着 Memtable 不断的变为 SSTable，SSTable 也不断增多，意味着读操作需要读取的 SSTable 也越来越多，为了限制 SSTable 的个数，Tablet Server 会在后台将多个 SSTable 合并为一个\n> - Major Compaction：Major Compaction 是一种特殊的 Merging Compaction，只把所有的 SSTable 合并为一个 SSTable，在 非 Major Compaction 产生的 SSTable 中可能包含已经删除的数据，Major Compaction 的过程会将这些数据真正的剔除掉，避免这些数据浪费存储空间。\n\nLSM Tree 的索引机制和 B+ Tree 的索引机制是明显不同的，B+ Tree 为所有的数据维护了一个索引，LSM Tree 则是为每个 磁盘文件维护了一个 Index。\n\n\n\n## 列行存储\n\n![image.png](https://cdn.nlark.com/yuque/0/2022/png/2500465/1662869279366-ddf2ea3e-ed85-4708-854f-7306682043b4.png)\n\n![image.png](https://cdn.nlark.com/yuque/0/2022/png/2500465/1662869286634-2e3183d7-1ce6-410d-95c2-68a26db82e60.png)\n\n>在Doris中，数据从 MemTable 刷写到磁盘的过程分为两个阶段，第一阶段是将 MemTable 中的行存结构在内存中转换为列存结构，并为每一列生成对应的索引结构；第二阶段是将转换后的列存结构写入磁盘，生成 Segment 文件。\n\n## 参考\n\n- https://www.igvita.com/2012/02/06/sstable-and-log-structured-storage-leveldb/\n","slug":"data-structure/从SS-Table到LSM-Tree","published":1,"comments":1,"layout":"post","photos":[],"link":"","_id":"cl9y38dss002afwuidni0cozt","content":"<h2 id=\"SS-Table\"><a href=\"#SS-Table\" class=\"headerlink\" title=\"SS-Table\"></a>SS-Table</h2><ul>\n<li><p>SSTable 最早出自 Google 的 Bigtable 论文</p>\n<blockquote>\n<p>An SSTable provides a persistent, ordered immutable map from keys to values, where both keys and values are arbitrary byte strings. Operations are provided to look up the value associated with a specified key, and to iterate over all key&#x2F;value pairs in a specified key range. Internally, each SSTable contains a sequence of blocks (typically each block is 64KB in size, but this is configurable). A block index (stored at the end of the SSTable) is used to locate blocks; the index is loaded into memory when the SSTable is opened. A lookup can be performed with a single disk seek: we first find the appropriate block by performing a binary search in the in-memory index, and then reading the appropriate block from disk. Optionally, an SSTable can be completely mapped into memory, which allows us to perform lookups and scans without touching disk.</p>\n<p>通过以上描述，我们可以把 SSTable 抽象为以下结构，每个 SSTable 包含了很多按照 key 排序的 key-value 对，key 和 value 都是任意的字节数组。SSTable 可以方便的支持基于 key 的查找和范围扫描。SSTable 会把数据分成块进行存储，并在 SSTable 文件尾部保存块索引(Block Index), 块索引记录每个块结束的 key 及对应的offset。块索引一般会在 SSTable 打开的时候载入内存。每次读取 SSTable 的时候，在内存中找到对应的块，再进行一次磁盘访问，读取到块中的数据。当然，把 SSTable 大小限定在可以加载进内存的大小，每次直接加载进内存访问也是一种方法。</p>\n</blockquote>\n</li>\n</ul>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1662868513341-45eab64f-2958-447b-8fc5-328a4942dfa1.png\" alt=\"img\"></p>\n<blockquote>\n<p>SSTable本身是个简单而有用的数据结构, 而往往由于工业界对于它的overload, 导致大家的误解<br>它本身就像他的名字一样, 就是a set of sorted key-value pairs<br>如下图左, 当文件比较大的时候, 也可以建立key:offset的index, 用于快速分段定位, 但这个是可选的.</p>\n<p>这个结构和普通的key-value pairs的区别, <strong>可以support range query和random r&#x2F;w</strong></p>\n</blockquote>\n<h2 id=\"SSTables-and-Log-Structured-Merge-Trees\"><a href=\"#SSTables-and-Log-Structured-Merge-Trees\" class=\"headerlink\" title=\"SSTables and Log Structured Merge Trees\"></a>SSTables and Log Structured Merge Trees</h2><p>仅仅SSTable数据结构本身仍然无法support高效的range query和random r&#x2F;w的场景<br>还需要一整套的机制来完成从memory sort, flush to disk, compaction以及快速读取……这样的一个完成的机制和架构称为,”<a href=\"http://nosqlsummer.org/paper/lsm-tree\">The Log-Structured Merge-Tree</a>“ (<strong>LSM Tree</strong>)<br>名字很形象, 首先是基于log的, 不断产生SSTable结构的log文件, 并且是需要不断merge以提高效率的</p>\n<p>下图很好的描绘了LSM Tree的结构和大部分操作</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1662868915058-01727c5c-f5e9-402b-8737-41408cc5323d.png\" alt=\"img\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/webp/2500465/1662868956879-bb12a4e1-38b5-47c0-a25e-4d0d8f8ce788.webp\" alt=\"img\"></p>\n<blockquote>\n<ul>\n<li>写操作：Tablet 把响应的操作写入操作日志（tablet log），然后将具体的内容写入内存中 MemTable</li>\n<li>读操作：读操作需要同时读 Memtable 和 SSTable，将结果合并返回。Memtable 和 SSTable 都是按照 key 有序的，可以快速的进行类似归并排序的合并。</li>\n<li>Minor Compaction：随着写请求的不断增多，Memtable 在内存中的空间不断增大，当 Memtable 的大小达到一定阈值时，Memtable 被 dump 到 GFS 中成为不可变的 SSTable。</li>\n<li>Merging Compaction：随着 Memtable 不断的变为 SSTable，SSTable 也不断增多，意味着读操作需要读取的 SSTable 也越来越多，为了限制 SSTable 的个数，Tablet Server 会在后台将多个 SSTable 合并为一个</li>\n<li>Major Compaction：Major Compaction 是一种特殊的 Merging Compaction，只把所有的 SSTable 合并为一个 SSTable，在 非 Major Compaction 产生的 SSTable 中可能包含已经删除的数据，Major Compaction 的过程会将这些数据真正的剔除掉，避免这些数据浪费存储空间。</li>\n</ul>\n</blockquote>\n<p>LSM Tree 的索引机制和 B+ Tree 的索引机制是明显不同的，B+ Tree 为所有的数据维护了一个索引，LSM Tree 则是为每个 磁盘文件维护了一个 Index。</p>\n<h2 id=\"列行存储\"><a href=\"#列行存储\" class=\"headerlink\" title=\"列行存储\"></a>列行存储</h2><p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1662869279366-ddf2ea3e-ed85-4708-854f-7306682043b4.png\" alt=\"image.png\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1662869286634-2e3183d7-1ce6-410d-95c2-68a26db82e60.png\" alt=\"image.png\"></p>\n<blockquote>\n<p>在Doris中，数据从 MemTable 刷写到磁盘的过程分为两个阶段，第一阶段是将 MemTable 中的行存结构在内存中转换为列存结构，并为每一列生成对应的索引结构；第二阶段是将转换后的列存结构写入磁盘，生成 Segment 文件。</p>\n</blockquote>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><ul>\n<li><a href=\"https://www.igvita.com/2012/02/06/sstable-and-log-structured-storage-leveldb/\">https://www.igvita.com/2012/02/06/sstable-and-log-structured-storage-leveldb/</a></li>\n</ul>\n","site":{"data":{"link":[{"class_name":"友情链接","class_desc":"那些人，那些事","link_list":[{"name":"张洪Heo","link":"https://blog.zhheo.com/","avatar":"https://npm.elemecdn.com/guli-heo/img/avatar2.png","descr":"分享设计与科技生活"},{"name":"瞬間の筆記","link":"https://hikki.site","descr":"喜欢的东西就努力去追求，万一成功了呢!","avatar":"https://cdn.jsdelivr.net/gh/0000rookie/imgs/202206120315.png"}]}]}},"excerpt":"","more":"<h2 id=\"SS-Table\"><a href=\"#SS-Table\" class=\"headerlink\" title=\"SS-Table\"></a>SS-Table</h2><ul>\n<li><p>SSTable 最早出自 Google 的 Bigtable 论文</p>\n<blockquote>\n<p>An SSTable provides a persistent, ordered immutable map from keys to values, where both keys and values are arbitrary byte strings. Operations are provided to look up the value associated with a specified key, and to iterate over all key&#x2F;value pairs in a specified key range. Internally, each SSTable contains a sequence of blocks (typically each block is 64KB in size, but this is configurable). A block index (stored at the end of the SSTable) is used to locate blocks; the index is loaded into memory when the SSTable is opened. A lookup can be performed with a single disk seek: we first find the appropriate block by performing a binary search in the in-memory index, and then reading the appropriate block from disk. Optionally, an SSTable can be completely mapped into memory, which allows us to perform lookups and scans without touching disk.</p>\n<p>通过以上描述，我们可以把 SSTable 抽象为以下结构，每个 SSTable 包含了很多按照 key 排序的 key-value 对，key 和 value 都是任意的字节数组。SSTable 可以方便的支持基于 key 的查找和范围扫描。SSTable 会把数据分成块进行存储，并在 SSTable 文件尾部保存块索引(Block Index), 块索引记录每个块结束的 key 及对应的offset。块索引一般会在 SSTable 打开的时候载入内存。每次读取 SSTable 的时候，在内存中找到对应的块，再进行一次磁盘访问，读取到块中的数据。当然，把 SSTable 大小限定在可以加载进内存的大小，每次直接加载进内存访问也是一种方法。</p>\n</blockquote>\n</li>\n</ul>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1662868513341-45eab64f-2958-447b-8fc5-328a4942dfa1.png\" alt=\"img\"></p>\n<blockquote>\n<p>SSTable本身是个简单而有用的数据结构, 而往往由于工业界对于它的overload, 导致大家的误解<br>它本身就像他的名字一样, 就是a set of sorted key-value pairs<br>如下图左, 当文件比较大的时候, 也可以建立key:offset的index, 用于快速分段定位, 但这个是可选的.</p>\n<p>这个结构和普通的key-value pairs的区别, <strong>可以support range query和random r&#x2F;w</strong></p>\n</blockquote>\n<h2 id=\"SSTables-and-Log-Structured-Merge-Trees\"><a href=\"#SSTables-and-Log-Structured-Merge-Trees\" class=\"headerlink\" title=\"SSTables and Log Structured Merge Trees\"></a>SSTables and Log Structured Merge Trees</h2><p>仅仅SSTable数据结构本身仍然无法support高效的range query和random r&#x2F;w的场景<br>还需要一整套的机制来完成从memory sort, flush to disk, compaction以及快速读取……这样的一个完成的机制和架构称为,”<a href=\"http://nosqlsummer.org/paper/lsm-tree\">The Log-Structured Merge-Tree</a>“ (<strong>LSM Tree</strong>)<br>名字很形象, 首先是基于log的, 不断产生SSTable结构的log文件, 并且是需要不断merge以提高效率的</p>\n<p>下图很好的描绘了LSM Tree的结构和大部分操作</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1662868915058-01727c5c-f5e9-402b-8737-41408cc5323d.png\" alt=\"img\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/webp/2500465/1662868956879-bb12a4e1-38b5-47c0-a25e-4d0d8f8ce788.webp\" alt=\"img\"></p>\n<blockquote>\n<ul>\n<li>写操作：Tablet 把响应的操作写入操作日志（tablet log），然后将具体的内容写入内存中 MemTable</li>\n<li>读操作：读操作需要同时读 Memtable 和 SSTable，将结果合并返回。Memtable 和 SSTable 都是按照 key 有序的，可以快速的进行类似归并排序的合并。</li>\n<li>Minor Compaction：随着写请求的不断增多，Memtable 在内存中的空间不断增大，当 Memtable 的大小达到一定阈值时，Memtable 被 dump 到 GFS 中成为不可变的 SSTable。</li>\n<li>Merging Compaction：随着 Memtable 不断的变为 SSTable，SSTable 也不断增多，意味着读操作需要读取的 SSTable 也越来越多，为了限制 SSTable 的个数，Tablet Server 会在后台将多个 SSTable 合并为一个</li>\n<li>Major Compaction：Major Compaction 是一种特殊的 Merging Compaction，只把所有的 SSTable 合并为一个 SSTable，在 非 Major Compaction 产生的 SSTable 中可能包含已经删除的数据，Major Compaction 的过程会将这些数据真正的剔除掉，避免这些数据浪费存储空间。</li>\n</ul>\n</blockquote>\n<p>LSM Tree 的索引机制和 B+ Tree 的索引机制是明显不同的，B+ Tree 为所有的数据维护了一个索引，LSM Tree 则是为每个 磁盘文件维护了一个 Index。</p>\n<h2 id=\"列行存储\"><a href=\"#列行存储\" class=\"headerlink\" title=\"列行存储\"></a>列行存储</h2><p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1662869279366-ddf2ea3e-ed85-4708-854f-7306682043b4.png\" alt=\"image.png\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1662869286634-2e3183d7-1ce6-410d-95c2-68a26db82e60.png\" alt=\"image.png\"></p>\n<blockquote>\n<p>在Doris中，数据从 MemTable 刷写到磁盘的过程分为两个阶段，第一阶段是将 MemTable 中的行存结构在内存中转换为列存结构，并为每一列生成对应的索引结构；第二阶段是将转换后的列存结构写入磁盘，生成 Segment 文件。</p>\n</blockquote>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><ul>\n<li><a href=\"https://www.igvita.com/2012/02/06/sstable-and-log-structured-storage-leveldb/\">https://www.igvita.com/2012/02/06/sstable-and-log-structured-storage-leveldb/</a></li>\n</ul>\n"},{"title":"hexo不显示语雀图床CDN图片的解决办法","top_img":null,"date":"2022-07-02T03:22:17.000Z","updated":"2022-07-02T03:22:17.000Z","cover":"https://tvax3.sinaimg.cn/large/0084aYsLly1gnhmxy0hdlj31hc0u0gpt.jpg","description":null,"keywords":null,"_content":"\n# 前言\n\n在语雀中写了一点东西，于是想着一起发到hexo上面，本地Typora显示完全没有问题，但是打开博客一看，图片全挂了！！！\n\n于是复制图片链接到浏览器上，竟然是直接下载，什么情况，直接懵逼。又试了试正常显示的图片，是在浏览器打开的。Google了半天，原来是语雀的防盗链搞得。\n\n\n\n# 解决方法\n\n\n\n### 1、在Hexo的.md文件加上`<meta name=\"referrer\" content=\"no-referrer\" />`\n\n- 可以在post模板中直接加上,就像下面这样，每次`hexo new post`创建都会自动加上，就不用每次都添加了。\n\n``` markdown\n---\ntitle: \ntags:\n  - ''\ncategories:\n  - []\ntop_img: \ndate: \nupdated: \ncover:\ndescription:\nkeywords:\n---\n  \n<meta name=\"referrer\" content=\"no-referrer\" />\n```\n\n\n\n### 2、以`<img src=\"xxxx\" referrerpolicy=\"no-referrer\">`的形式插入图片\n\n- 太麻烦了,每次都要设置`referrerpolicy=\"no-referrer\"`\n\n\n\n### 3、在html模版的头信息中添加`<meta name=\"referrer\" content=\"no-referrer\" />`\n\n#### 1、butterfly主题\n\n在hexo-theme-butterfly/layout/includes目录下的head.pug文件中添加`meta(name=\"referrer\" content=\"no-referrer\")`\n\n```typescript\nmeta(charset='UTF-8')\nmeta(http-equiv=\"X-UA-Compatible\" content=\"IE=edge\")\nmeta(name=\"viewport\" content=\"width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no\")\ntitle= tabTitle\nif pageKeywords\n  meta(name=\"keywords\" content=pageKeywords)\nmeta(name=\"author\" content=pageAuthor)\nmeta(name=\"copyright\" content=pageCopyright)\nmeta(name =\"format-detection\" content=\"telephone=no\")\nmeta(name=\"theme-color\" content=themeColor)\n\nmeta(name=\"referrer\" content=\"no-referrer\")\n```\n\n\n\n# 参考资料\n\n- https://github.com/x-cold/yuque-hexo/issues/41\n\n","source":"_posts/hexo/hexo不显示语雀图床CDN图片的解决办法.md","raw":"---\ntitle: hexo不显示语雀图床CDN图片的解决办法\ntags:\n  - 'hexo'\ncategories:\n  - [hexo]\ntop_img: \ndate: 2022-07-02 11:22:17\nupdated: 2022-07-02 11:22:17\ncover:\ndescription:\nkeywords:\n---\n\n# 前言\n\n在语雀中写了一点东西，于是想着一起发到hexo上面，本地Typora显示完全没有问题，但是打开博客一看，图片全挂了！！！\n\n于是复制图片链接到浏览器上，竟然是直接下载，什么情况，直接懵逼。又试了试正常显示的图片，是在浏览器打开的。Google了半天，原来是语雀的防盗链搞得。\n\n\n\n# 解决方法\n\n\n\n### 1、在Hexo的.md文件加上`<meta name=\"referrer\" content=\"no-referrer\" />`\n\n- 可以在post模板中直接加上,就像下面这样，每次`hexo new post`创建都会自动加上，就不用每次都添加了。\n\n``` markdown\n---\ntitle: \ntags:\n  - ''\ncategories:\n  - []\ntop_img: \ndate: \nupdated: \ncover:\ndescription:\nkeywords:\n---\n  \n<meta name=\"referrer\" content=\"no-referrer\" />\n```\n\n\n\n### 2、以`<img src=\"xxxx\" referrerpolicy=\"no-referrer\">`的形式插入图片\n\n- 太麻烦了,每次都要设置`referrerpolicy=\"no-referrer\"`\n\n\n\n### 3、在html模版的头信息中添加`<meta name=\"referrer\" content=\"no-referrer\" />`\n\n#### 1、butterfly主题\n\n在hexo-theme-butterfly/layout/includes目录下的head.pug文件中添加`meta(name=\"referrer\" content=\"no-referrer\")`\n\n```typescript\nmeta(charset='UTF-8')\nmeta(http-equiv=\"X-UA-Compatible\" content=\"IE=edge\")\nmeta(name=\"viewport\" content=\"width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no\")\ntitle= tabTitle\nif pageKeywords\n  meta(name=\"keywords\" content=pageKeywords)\nmeta(name=\"author\" content=pageAuthor)\nmeta(name=\"copyright\" content=pageCopyright)\nmeta(name =\"format-detection\" content=\"telephone=no\")\nmeta(name=\"theme-color\" content=themeColor)\n\nmeta(name=\"referrer\" content=\"no-referrer\")\n```\n\n\n\n# 参考资料\n\n- https://github.com/x-cold/yuque-hexo/issues/41\n\n","slug":"hexo/hexo不显示语雀图床CDN图片的解决办法","published":1,"comments":1,"layout":"post","photos":[],"link":"","_id":"cl9y38dst002dfwuiabw17p2u","content":"<h1 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h1><p>在语雀中写了一点东西，于是想着一起发到hexo上面，本地Typora显示完全没有问题，但是打开博客一看，图片全挂了！！！</p>\n<p>于是复制图片链接到浏览器上，竟然是直接下载，什么情况，直接懵逼。又试了试正常显示的图片，是在浏览器打开的。Google了半天，原来是语雀的防盗链搞得。</p>\n<h1 id=\"解决方法\"><a href=\"#解决方法\" class=\"headerlink\" title=\"解决方法\"></a>解决方法</h1><h3 id=\"1、在Hexo的-md文件加上-lt-meta-name-quot-referrer-quot-content-quot-no-referrer-quot-gt\"><a href=\"#1、在Hexo的-md文件加上-lt-meta-name-quot-referrer-quot-content-quot-no-referrer-quot-gt\" class=\"headerlink\" title=\"1、在Hexo的.md文件加上&lt;meta name=&quot;referrer&quot; content=&quot;no-referrer&quot; /&gt;\"></a>1、在Hexo的.md文件加上<code>&lt;meta name=&quot;referrer&quot; content=&quot;no-referrer&quot; /&gt;</code></h3><ul>\n<li>可以在post模板中直接加上,就像下面这样，每次<code>hexo new post</code>创建都会自动加上，就不用每次都添加了。</li>\n</ul>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">---</span><br><span class=\"line\">title: </span><br><span class=\"line\">tags:</span><br><span class=\"line\"><span class=\"bullet\">  -</span> &#x27;&#x27;</span><br><span class=\"line\">categories:</span><br><span class=\"line\"><span class=\"bullet\">  -</span> []</span><br><span class=\"line\">top<span class=\"emphasis\">_img: </span></span><br><span class=\"line\"><span class=\"emphasis\">date: </span></span><br><span class=\"line\"><span class=\"emphasis\">updated: </span></span><br><span class=\"line\"><span class=\"emphasis\">cover:</span></span><br><span class=\"line\"><span class=\"emphasis\">description:</span></span><br><span class=\"line\"><span class=\"emphasis\">keywords:</span></span><br><span class=\"line\"><span class=\"emphasis\">---</span></span><br><span class=\"line\"><span class=\"emphasis\">  </span></span><br><span class=\"line\"><span class=\"emphasis\"><span class=\"language-xml\"><span class=\"tag\">&lt;<span class=\"name\">meta</span> <span class=\"attr\">name</span>=<span class=\"string\">&quot;referrer&quot;</span> <span class=\"attr\">content</span>=<span class=\"string\">&quot;no-referrer&quot;</span> /&gt;</span></span></span></span><br></pre></td></tr></table></figure>\n\n\n\n<h3 id=\"2、以-lt-img-src-quot-xxxx-quot-referrerpolicy-quot-no-referrer-quot-gt-的形式插入图片\"><a href=\"#2、以-lt-img-src-quot-xxxx-quot-referrerpolicy-quot-no-referrer-quot-gt-的形式插入图片\" class=\"headerlink\" title=\"2、以&lt;img src=&quot;xxxx&quot; referrerpolicy=&quot;no-referrer&quot;&gt;的形式插入图片\"></a>2、以<code>&lt;img src=&quot;xxxx&quot; referrerpolicy=&quot;no-referrer&quot;&gt;</code>的形式插入图片</h3><ul>\n<li>太麻烦了,每次都要设置<code>referrerpolicy=&quot;no-referrer&quot;</code></li>\n</ul>\n<h3 id=\"3、在html模版的头信息中添加-lt-meta-name-quot-referrer-quot-content-quot-no-referrer-quot-gt\"><a href=\"#3、在html模版的头信息中添加-lt-meta-name-quot-referrer-quot-content-quot-no-referrer-quot-gt\" class=\"headerlink\" title=\"3、在html模版的头信息中添加&lt;meta name=&quot;referrer&quot; content=&quot;no-referrer&quot; /&gt;\"></a>3、在html模版的头信息中添加<code>&lt;meta name=&quot;referrer&quot; content=&quot;no-referrer&quot; /&gt;</code></h3><h4 id=\"1、butterfly主题\"><a href=\"#1、butterfly主题\" class=\"headerlink\" title=\"1、butterfly主题\"></a>1、butterfly主题</h4><p>在hexo-theme-butterfly&#x2F;layout&#x2F;includes目录下的head.pug文件中添加<code>meta(name=&quot;referrer&quot; content=&quot;no-referrer&quot;)</code></p>\n<figure class=\"highlight typescript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"title function_\">meta</span>(charset=<span class=\"string\">&#x27;UTF-8&#x27;</span>)</span><br><span class=\"line\"><span class=\"title function_\">meta</span>(http-equiv=<span class=\"string\">&quot;X-UA-Compatible&quot;</span> content=<span class=\"string\">&quot;IE=edge&quot;</span>)</span><br><span class=\"line\"><span class=\"title function_\">meta</span>(name=<span class=\"string\">&quot;viewport&quot;</span> content=<span class=\"string\">&quot;width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot;</span>)</span><br><span class=\"line\">title= tabTitle</span><br><span class=\"line\"><span class=\"keyword\">if</span> pageKeywords</span><br><span class=\"line\">  <span class=\"title function_\">meta</span>(name=<span class=\"string\">&quot;keywords&quot;</span> content=pageKeywords)</span><br><span class=\"line\"><span class=\"title function_\">meta</span>(name=<span class=\"string\">&quot;author&quot;</span> content=pageAuthor)</span><br><span class=\"line\"><span class=\"title function_\">meta</span>(name=<span class=\"string\">&quot;copyright&quot;</span> content=pageCopyright)</span><br><span class=\"line\"><span class=\"title function_\">meta</span>(name =<span class=\"string\">&quot;format-detection&quot;</span> content=<span class=\"string\">&quot;telephone=no&quot;</span>)</span><br><span class=\"line\"><span class=\"title function_\">meta</span>(name=<span class=\"string\">&quot;theme-color&quot;</span> content=themeColor)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"title function_\">meta</span>(name=<span class=\"string\">&quot;referrer&quot;</span> content=<span class=\"string\">&quot;no-referrer&quot;</span>)</span><br></pre></td></tr></table></figure>\n\n\n\n<h1 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h1><ul>\n<li><a href=\"https://github.com/x-cold/yuque-hexo/issues/41\">https://github.com/x-cold/yuque-hexo/issues/41</a></li>\n</ul>\n","site":{"data":{"link":[{"class_name":"友情链接","class_desc":"那些人，那些事","link_list":[{"name":"张洪Heo","link":"https://blog.zhheo.com/","avatar":"https://npm.elemecdn.com/guli-heo/img/avatar2.png","descr":"分享设计与科技生活"},{"name":"瞬間の筆記","link":"https://hikki.site","descr":"喜欢的东西就努力去追求，万一成功了呢!","avatar":"https://cdn.jsdelivr.net/gh/0000rookie/imgs/202206120315.png"}]}]}},"excerpt":"","more":"<h1 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h1><p>在语雀中写了一点东西，于是想着一起发到hexo上面，本地Typora显示完全没有问题，但是打开博客一看，图片全挂了！！！</p>\n<p>于是复制图片链接到浏览器上，竟然是直接下载，什么情况，直接懵逼。又试了试正常显示的图片，是在浏览器打开的。Google了半天，原来是语雀的防盗链搞得。</p>\n<h1 id=\"解决方法\"><a href=\"#解决方法\" class=\"headerlink\" title=\"解决方法\"></a>解决方法</h1><h3 id=\"1、在Hexo的-md文件加上-lt-meta-name-quot-referrer-quot-content-quot-no-referrer-quot-gt\"><a href=\"#1、在Hexo的-md文件加上-lt-meta-name-quot-referrer-quot-content-quot-no-referrer-quot-gt\" class=\"headerlink\" title=\"1、在Hexo的.md文件加上&lt;meta name=&quot;referrer&quot; content=&quot;no-referrer&quot; /&gt;\"></a>1、在Hexo的.md文件加上<code>&lt;meta name=&quot;referrer&quot; content=&quot;no-referrer&quot; /&gt;</code></h3><ul>\n<li>可以在post模板中直接加上,就像下面这样，每次<code>hexo new post</code>创建都会自动加上，就不用每次都添加了。</li>\n</ul>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">---</span><br><span class=\"line\">title: </span><br><span class=\"line\">tags:</span><br><span class=\"line\"><span class=\"bullet\">  -</span> &#x27;&#x27;</span><br><span class=\"line\">categories:</span><br><span class=\"line\"><span class=\"bullet\">  -</span> []</span><br><span class=\"line\">top<span class=\"emphasis\">_img: </span></span><br><span class=\"line\"><span class=\"emphasis\">date: </span></span><br><span class=\"line\"><span class=\"emphasis\">updated: </span></span><br><span class=\"line\"><span class=\"emphasis\">cover:</span></span><br><span class=\"line\"><span class=\"emphasis\">description:</span></span><br><span class=\"line\"><span class=\"emphasis\">keywords:</span></span><br><span class=\"line\"><span class=\"emphasis\">---</span></span><br><span class=\"line\"><span class=\"emphasis\">  </span></span><br><span class=\"line\"><span class=\"emphasis\"><span class=\"language-xml\"><span class=\"tag\">&lt;<span class=\"name\">meta</span> <span class=\"attr\">name</span>=<span class=\"string\">&quot;referrer&quot;</span> <span class=\"attr\">content</span>=<span class=\"string\">&quot;no-referrer&quot;</span> /&gt;</span></span></span></span><br></pre></td></tr></table></figure>\n\n\n\n<h3 id=\"2、以-lt-img-src-quot-xxxx-quot-referrerpolicy-quot-no-referrer-quot-gt-的形式插入图片\"><a href=\"#2、以-lt-img-src-quot-xxxx-quot-referrerpolicy-quot-no-referrer-quot-gt-的形式插入图片\" class=\"headerlink\" title=\"2、以&lt;img src=&quot;xxxx&quot; referrerpolicy=&quot;no-referrer&quot;&gt;的形式插入图片\"></a>2、以<code>&lt;img src=&quot;xxxx&quot; referrerpolicy=&quot;no-referrer&quot;&gt;</code>的形式插入图片</h3><ul>\n<li>太麻烦了,每次都要设置<code>referrerpolicy=&quot;no-referrer&quot;</code></li>\n</ul>\n<h3 id=\"3、在html模版的头信息中添加-lt-meta-name-quot-referrer-quot-content-quot-no-referrer-quot-gt\"><a href=\"#3、在html模版的头信息中添加-lt-meta-name-quot-referrer-quot-content-quot-no-referrer-quot-gt\" class=\"headerlink\" title=\"3、在html模版的头信息中添加&lt;meta name=&quot;referrer&quot; content=&quot;no-referrer&quot; /&gt;\"></a>3、在html模版的头信息中添加<code>&lt;meta name=&quot;referrer&quot; content=&quot;no-referrer&quot; /&gt;</code></h3><h4 id=\"1、butterfly主题\"><a href=\"#1、butterfly主题\" class=\"headerlink\" title=\"1、butterfly主题\"></a>1、butterfly主题</h4><p>在hexo-theme-butterfly&#x2F;layout&#x2F;includes目录下的head.pug文件中添加<code>meta(name=&quot;referrer&quot; content=&quot;no-referrer&quot;)</code></p>\n<figure class=\"highlight typescript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"title function_\">meta</span>(charset=<span class=\"string\">&#x27;UTF-8&#x27;</span>)</span><br><span class=\"line\"><span class=\"title function_\">meta</span>(http-equiv=<span class=\"string\">&quot;X-UA-Compatible&quot;</span> content=<span class=\"string\">&quot;IE=edge&quot;</span>)</span><br><span class=\"line\"><span class=\"title function_\">meta</span>(name=<span class=\"string\">&quot;viewport&quot;</span> content=<span class=\"string\">&quot;width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot;</span>)</span><br><span class=\"line\">title= tabTitle</span><br><span class=\"line\"><span class=\"keyword\">if</span> pageKeywords</span><br><span class=\"line\">  <span class=\"title function_\">meta</span>(name=<span class=\"string\">&quot;keywords&quot;</span> content=pageKeywords)</span><br><span class=\"line\"><span class=\"title function_\">meta</span>(name=<span class=\"string\">&quot;author&quot;</span> content=pageAuthor)</span><br><span class=\"line\"><span class=\"title function_\">meta</span>(name=<span class=\"string\">&quot;copyright&quot;</span> content=pageCopyright)</span><br><span class=\"line\"><span class=\"title function_\">meta</span>(name =<span class=\"string\">&quot;format-detection&quot;</span> content=<span class=\"string\">&quot;telephone=no&quot;</span>)</span><br><span class=\"line\"><span class=\"title function_\">meta</span>(name=<span class=\"string\">&quot;theme-color&quot;</span> content=themeColor)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"title function_\">meta</span>(name=<span class=\"string\">&quot;referrer&quot;</span> content=<span class=\"string\">&quot;no-referrer&quot;</span>)</span><br></pre></td></tr></table></figure>\n\n\n\n<h1 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h1><ul>\n<li><a href=\"https://github.com/x-cold/yuque-hexo/issues/41\">https://github.com/x-cold/yuque-hexo/issues/41</a></li>\n</ul>\n"},{"title":"从github恢复备份hexo博客By hexo-git-backup","top_img":"linear-gradient(20deg, #0062be, #925696, #cc426e, #fb0347)","date":"2022-06-29T05:54:12.000Z","updated":"2022-06-29T05:54:12.000Z","cover":"https://tvax3.sinaimg.cn/large/0084aYsLly1grnkfb3zyvj31hc0tndku.jpg","description":null,"keywords":null,"_content":"\n\n\n​\t\t利用hexo + github pages构建静态博客网站，hexo发布到github上的内容是渲染过后的文件。而我们自己写的markdown文件并没有推送到github上面，因此如果发生电脑挂掉、磁盘挂掉等意外，我们的.md源文件以及我们的博客配置文件就会丢失。丢失后要想还原回去，就需要费好大力气了。\n\n​\t\t因此我们需要备份源数据，并且最好每次部署博客的时候，就自动进行备份，而不需要再手动去备份。\n\n\n\n## 利用hexo-git-backup插件备份源文件\n\n- 1、安装hexo-git-backup插件\n\n  ```\n  $ npm install hexo-git-backup --save\n  ```\n\n- 2、配置插件，同步源数据到github仓库\n\n  **强烈建议：备份到博客所在的同一个git仓库的不同分支，方便管理，下面是备份到hexo分支**\n\n  > 编辑hexo的配置文件_config.yml，添加需要备份到仓库\n\n  ```yml\n  # 备份插件：hexo-git-backup\n  backup:\n      type: git\n      repository:\n         github: git@github.com:xxxxx.git,hexo\n  ```\n\n- 3、hexo根目录执行hexo b命令，即可完成备份\n\n\n\n##  每次更新博客后，自动进行备份\n\n- 使用windows的同学，强烈建议(￣▽￣)\"开启linux子系统WSL，在WSL中部署Hexo：https://poxiao.tk/2022/06/WSL%E4%B8%AD%E7%9A%84%E9%AA%9A%E6%93%8D%E4%BD%9C/\n\n### 利用shell alias，部署后自动备份\n\n- 编辑zsh的配置文件~/.zshrc，添加别名alias：\n\n```shell\nalias hd=\"hexo clean && hexo g && hexo d && hexo b\"\n```\n\n- 每次要更新博客进行部署的时候，直接执行`hd`命令，就会自动完成部署和备份的工作。\n\n  \n\n  \n","source":"_posts/hexo/从github恢复备份hexo博客hexo-git-backup.md","raw":"---\ntitle: 从github恢复备份hexo博客By hexo-git-backup\ntags:\n  - 'hexo'\ncategories:\n  - [hexo]\ntop_img: 'linear-gradient(20deg, #0062be, #925696, #cc426e, #fb0347)'\ndate: 2022-06-29 13:54:12\nupdated: 2022-06-29 13:54:12\ncover:\ndescription:\nkeywords:\n---\n\n\n\n​\t\t利用hexo + github pages构建静态博客网站，hexo发布到github上的内容是渲染过后的文件。而我们自己写的markdown文件并没有推送到github上面，因此如果发生电脑挂掉、磁盘挂掉等意外，我们的.md源文件以及我们的博客配置文件就会丢失。丢失后要想还原回去，就需要费好大力气了。\n\n​\t\t因此我们需要备份源数据，并且最好每次部署博客的时候，就自动进行备份，而不需要再手动去备份。\n\n\n\n## 利用hexo-git-backup插件备份源文件\n\n- 1、安装hexo-git-backup插件\n\n  ```\n  $ npm install hexo-git-backup --save\n  ```\n\n- 2、配置插件，同步源数据到github仓库\n\n  **强烈建议：备份到博客所在的同一个git仓库的不同分支，方便管理，下面是备份到hexo分支**\n\n  > 编辑hexo的配置文件_config.yml，添加需要备份到仓库\n\n  ```yml\n  # 备份插件：hexo-git-backup\n  backup:\n      type: git\n      repository:\n         github: git@github.com:xxxxx.git,hexo\n  ```\n\n- 3、hexo根目录执行hexo b命令，即可完成备份\n\n\n\n##  每次更新博客后，自动进行备份\n\n- 使用windows的同学，强烈建议(￣▽￣)\"开启linux子系统WSL，在WSL中部署Hexo：https://poxiao.tk/2022/06/WSL%E4%B8%AD%E7%9A%84%E9%AA%9A%E6%93%8D%E4%BD%9C/\n\n### 利用shell alias，部署后自动备份\n\n- 编辑zsh的配置文件~/.zshrc，添加别名alias：\n\n```shell\nalias hd=\"hexo clean && hexo g && hexo d && hexo b\"\n```\n\n- 每次要更新博客进行部署的时候，直接执行`hd`命令，就会自动完成部署和备份的工作。\n\n  \n\n  \n","slug":"hexo/从github恢复备份hexo博客hexo-git-backup","published":1,"comments":1,"layout":"post","photos":[],"link":"","_id":"cl9y38dsv002ifwui5f684xp3","content":"<p>​\t\t利用hexo + github pages构建静态博客网站，hexo发布到github上的内容是渲染过后的文件。而我们自己写的markdown文件并没有推送到github上面，因此如果发生电脑挂掉、磁盘挂掉等意外，我们的.md源文件以及我们的博客配置文件就会丢失。丢失后要想还原回去，就需要费好大力气了。</p>\n<p>​\t\t因此我们需要备份源数据，并且最好每次部署博客的时候，就自动进行备份，而不需要再手动去备份。</p>\n<h2 id=\"利用hexo-git-backup插件备份源文件\"><a href=\"#利用hexo-git-backup插件备份源文件\" class=\"headerlink\" title=\"利用hexo-git-backup插件备份源文件\"></a>利用hexo-git-backup插件备份源文件</h2><ul>\n<li><p>1、安装hexo-git-backup插件</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ npm install hexo-git-backup --save</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>2、配置插件，同步源数据到github仓库</p>\n<p><strong>强烈建议：备份到博客所在的同一个git仓库的不同分支，方便管理，下面是备份到hexo分支</strong></p>\n<blockquote>\n<p>编辑hexo的配置文件_config.yml，添加需要备份到仓库</p>\n</blockquote>\n<figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 备份插件：hexo-git-backup</span></span><br><span class=\"line\"><span class=\"attr\">backup:</span></span><br><span class=\"line\">    <span class=\"attr\">type:</span> <span class=\"string\">git</span></span><br><span class=\"line\">    <span class=\"attr\">repository:</span></span><br><span class=\"line\">       <span class=\"attr\">github:</span> <span class=\"string\">git@github.com:xxxxx.git,hexo</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>3、hexo根目录执行hexo b命令，即可完成备份</p>\n</li>\n</ul>\n<h2 id=\"每次更新博客后，自动进行备份\"><a href=\"#每次更新博客后，自动进行备份\" class=\"headerlink\" title=\"每次更新博客后，自动进行备份\"></a>每次更新博客后，自动进行备份</h2><ul>\n<li>使用windows的同学，强烈建议(￣▽￣)”开启linux子系统WSL，在WSL中部署Hexo：<a href=\"https://poxiao.tk/2022/06/WSL%E4%B8%AD%E7%9A%84%E9%AA%9A%E6%93%8D%E4%BD%9C/\">https://poxiao.tk/2022/06/WSL%E4%B8%AD%E7%9A%84%E9%AA%9A%E6%93%8D%E4%BD%9C/</a></li>\n</ul>\n<h3 id=\"利用shell-alias，部署后自动备份\"><a href=\"#利用shell-alias，部署后自动备份\" class=\"headerlink\" title=\"利用shell alias，部署后自动备份\"></a>利用shell alias，部署后自动备份</h3><ul>\n<li>编辑zsh的配置文件~&#x2F;.zshrc，添加别名alias：</li>\n</ul>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">alias hd=&quot;hexo clean &amp;&amp; hexo g &amp;&amp; hexo d &amp;&amp; hexo b&quot;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>每次要更新博客进行部署的时候，直接执行<code>hd</code>命令，就会自动完成部署和备份的工作。</li>\n</ul>\n","site":{"data":{"link":[{"class_name":"友情链接","class_desc":"那些人，那些事","link_list":[{"name":"张洪Heo","link":"https://blog.zhheo.com/","avatar":"https://npm.elemecdn.com/guli-heo/img/avatar2.png","descr":"分享设计与科技生活"},{"name":"瞬間の筆記","link":"https://hikki.site","descr":"喜欢的东西就努力去追求，万一成功了呢!","avatar":"https://cdn.jsdelivr.net/gh/0000rookie/imgs/202206120315.png"}]}]}},"excerpt":"","more":"<p>​\t\t利用hexo + github pages构建静态博客网站，hexo发布到github上的内容是渲染过后的文件。而我们自己写的markdown文件并没有推送到github上面，因此如果发生电脑挂掉、磁盘挂掉等意外，我们的.md源文件以及我们的博客配置文件就会丢失。丢失后要想还原回去，就需要费好大力气了。</p>\n<p>​\t\t因此我们需要备份源数据，并且最好每次部署博客的时候，就自动进行备份，而不需要再手动去备份。</p>\n<h2 id=\"利用hexo-git-backup插件备份源文件\"><a href=\"#利用hexo-git-backup插件备份源文件\" class=\"headerlink\" title=\"利用hexo-git-backup插件备份源文件\"></a>利用hexo-git-backup插件备份源文件</h2><ul>\n<li><p>1、安装hexo-git-backup插件</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ npm install hexo-git-backup --save</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>2、配置插件，同步源数据到github仓库</p>\n<p><strong>强烈建议：备份到博客所在的同一个git仓库的不同分支，方便管理，下面是备份到hexo分支</strong></p>\n<blockquote>\n<p>编辑hexo的配置文件_config.yml，添加需要备份到仓库</p>\n</blockquote>\n<figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 备份插件：hexo-git-backup</span></span><br><span class=\"line\"><span class=\"attr\">backup:</span></span><br><span class=\"line\">    <span class=\"attr\">type:</span> <span class=\"string\">git</span></span><br><span class=\"line\">    <span class=\"attr\">repository:</span></span><br><span class=\"line\">       <span class=\"attr\">github:</span> <span class=\"string\">git@github.com:xxxxx.git,hexo</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>3、hexo根目录执行hexo b命令，即可完成备份</p>\n</li>\n</ul>\n<h2 id=\"每次更新博客后，自动进行备份\"><a href=\"#每次更新博客后，自动进行备份\" class=\"headerlink\" title=\"每次更新博客后，自动进行备份\"></a>每次更新博客后，自动进行备份</h2><ul>\n<li>使用windows的同学，强烈建议(￣▽￣)”开启linux子系统WSL，在WSL中部署Hexo：<a href=\"https://poxiao.tk/2022/06/WSL%E4%B8%AD%E7%9A%84%E9%AA%9A%E6%93%8D%E4%BD%9C/\">https://poxiao.tk/2022/06/WSL%E4%B8%AD%E7%9A%84%E9%AA%9A%E6%93%8D%E4%BD%9C/</a></li>\n</ul>\n<h3 id=\"利用shell-alias，部署后自动备份\"><a href=\"#利用shell-alias，部署后自动备份\" class=\"headerlink\" title=\"利用shell alias，部署后自动备份\"></a>利用shell alias，部署后自动备份</h3><ul>\n<li>编辑zsh的配置文件~&#x2F;.zshrc，添加别名alias：</li>\n</ul>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">alias hd=&quot;hexo clean &amp;&amp; hexo g &amp;&amp; hexo d &amp;&amp; hexo b&quot;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>每次要更新博客进行部署的时候，直接执行<code>hd</code>命令，就会自动完成部署和备份的工作。</li>\n</ul>\n"},{"title":"thrift-从入门到放弃","top_img":"linear-gradient(20deg, #0062be, #925696, #cc426e, #fb0347)","date":"2022-08-31T13:07:13.000Z","updated":"2022-08-31T13:07:13.000Z","cover":"https://tvax4.sinaimg.cn/large/0084aYsLgy1h3jum72m7kj31220e6jsc.jpg","description":null,"keywords":null,"_content":"\n## Thrift-Java-Maven使用指北\n\n- 1、下载安装Thrift，配置Thrift环境变量\n\n- 2、Maven中引入libthrift依赖\n\n  ```xml\n  <dependency>\n     <groupId>org.apache.thrift</groupId>\n     <artifactId>libthrift</artifactId>\n     <version>0.14.1</version>\n  </dependency>\n  ```\n\n- 3、引入Maven插件maven-thrift-plugin\n\n  ```xml\n  <build>\n        <plugins>\n           <plugin>\n              <groupId>org.apache.thrift.tools</groupId>\n              <artifactId>maven-thrift-plugin</artifactId>\n              <version>0.1.11</version>\n              <configuration>\n                 <!--指定Thrift编译文件的目录和位置，设定环境变量便可不用指定-->\n                 <thriftExecutable>./thrift/thrift.exe</thriftExecutable>\n                 <!--指定待编译的  IDL文件目录，默认为src/main/thrift-->\n                 <thriftSourceRoot>src/main/resources/thrift</thriftSourceRoot>\n                 <!--在0.1.10版本后的plugin需要添加的参数-->\n                 <generator>java</generator> \n                 <!--指定编译输出目录-->\n                 <outputDirectory>src/main/java</outputDirectory>\n              </configuration>\n           </plugin>\n        </plugins>\n     </build>\n  ```\n\n  >  然后通过执行plugin 的compile指令即可将文件直接编译转化为java类，注意有些版本需要添加<generator>java</generator>，否则可能会报错：[ERROR] thrift failed error: [FAILURE:generation:1] Error: unknown option java:hashcode。\n  >\n  > \n  >\n  > 同时，如果我们像上面一样指定了编译输出目录为项目目录，会覆盖原有目录下的文件，所以可以保持默认配置，输出至target目录下，然后复制到我们想要的package下。\n\n## FQA\n\n- 执行mvn clean install编译失败\n\n  > [ERROR] thrift failed error: [FAILURE:generation:1] Error: unknown option java:hashcode\n  >\n  > [ERROR] Failed to execute goal org.apache.thrift.tools:maven-thrift-plugin:0.1.11:compile (thrift-sources) on project HelloService: thrift did n\n  > ot exit cleanly. Review output for more information. -> [Help 1]\n\n  Maven插件maven-thrift-plugin配置中添加`<generator>java</generator>`\n\n  ```xml\n  \t\t<plugin>\n              <groupId>org.apache.thrift.tools</groupId>\n              <artifactId>maven-thrift-plugin</artifactId>\n              <version>0.1.11</version>\n              <configuration>\n                 <!--指定Thrift编译文件的目录和位置，设定环境变量便可不用指定-->\n                 <thriftExecutable>./thrift/thrift.exe</thriftExecutable>\n                 <!--指定待编译的  IDL文件目录，默认为src/main/thrift-->\n                 <thriftSourceRoot>src/main/resources/thrift</thriftSourceRoot>\n                 <!--在0.1.10版本后的plugin需要添加的参数-->\n                 <generator>java</generator> \n                 <!--指定编译输出目录-->\n                 <outputDirectory>src/main/java</outputDirectory>\n              </configuration>\n           </plugin>\n  ```\n\n  \n\n- Thrift生成的java文件，无法被import引用，原因是Thrift生成的java文件路径不对\n\n  >1、<outputDirectory></outputDirectory>配置为<outputDirectory>src/main/java</outputDirectory>\n  >\n  >2、将生成的目录在IDEA中指定为源文件目录：\n  >\n  >![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1661953198633-ec36aeea-e0ef-4398-beaa-cbefdef85f3d.png)\n","source":"_posts/rpc/thrift-从入门到放弃.md","raw":"---\ntitle: thrift-从入门到放弃\ntags:\n  - 'thrift'\ncategories:\n  - [RPC,thrift]\ntop_img: 'linear-gradient(20deg, #0062be, #925696, #cc426e, #fb0347)'\ndate: 2022-08-31 21:07:13\nupdated: 2022-08-31 21:07:13\ncover:\ndescription:\nkeywords:\n---\n\n## Thrift-Java-Maven使用指北\n\n- 1、下载安装Thrift，配置Thrift环境变量\n\n- 2、Maven中引入libthrift依赖\n\n  ```xml\n  <dependency>\n     <groupId>org.apache.thrift</groupId>\n     <artifactId>libthrift</artifactId>\n     <version>0.14.1</version>\n  </dependency>\n  ```\n\n- 3、引入Maven插件maven-thrift-plugin\n\n  ```xml\n  <build>\n        <plugins>\n           <plugin>\n              <groupId>org.apache.thrift.tools</groupId>\n              <artifactId>maven-thrift-plugin</artifactId>\n              <version>0.1.11</version>\n              <configuration>\n                 <!--指定Thrift编译文件的目录和位置，设定环境变量便可不用指定-->\n                 <thriftExecutable>./thrift/thrift.exe</thriftExecutable>\n                 <!--指定待编译的  IDL文件目录，默认为src/main/thrift-->\n                 <thriftSourceRoot>src/main/resources/thrift</thriftSourceRoot>\n                 <!--在0.1.10版本后的plugin需要添加的参数-->\n                 <generator>java</generator> \n                 <!--指定编译输出目录-->\n                 <outputDirectory>src/main/java</outputDirectory>\n              </configuration>\n           </plugin>\n        </plugins>\n     </build>\n  ```\n\n  >  然后通过执行plugin 的compile指令即可将文件直接编译转化为java类，注意有些版本需要添加<generator>java</generator>，否则可能会报错：[ERROR] thrift failed error: [FAILURE:generation:1] Error: unknown option java:hashcode。\n  >\n  > \n  >\n  > 同时，如果我们像上面一样指定了编译输出目录为项目目录，会覆盖原有目录下的文件，所以可以保持默认配置，输出至target目录下，然后复制到我们想要的package下。\n\n## FQA\n\n- 执行mvn clean install编译失败\n\n  > [ERROR] thrift failed error: [FAILURE:generation:1] Error: unknown option java:hashcode\n  >\n  > [ERROR] Failed to execute goal org.apache.thrift.tools:maven-thrift-plugin:0.1.11:compile (thrift-sources) on project HelloService: thrift did n\n  > ot exit cleanly. Review output for more information. -> [Help 1]\n\n  Maven插件maven-thrift-plugin配置中添加`<generator>java</generator>`\n\n  ```xml\n  \t\t<plugin>\n              <groupId>org.apache.thrift.tools</groupId>\n              <artifactId>maven-thrift-plugin</artifactId>\n              <version>0.1.11</version>\n              <configuration>\n                 <!--指定Thrift编译文件的目录和位置，设定环境变量便可不用指定-->\n                 <thriftExecutable>./thrift/thrift.exe</thriftExecutable>\n                 <!--指定待编译的  IDL文件目录，默认为src/main/thrift-->\n                 <thriftSourceRoot>src/main/resources/thrift</thriftSourceRoot>\n                 <!--在0.1.10版本后的plugin需要添加的参数-->\n                 <generator>java</generator> \n                 <!--指定编译输出目录-->\n                 <outputDirectory>src/main/java</outputDirectory>\n              </configuration>\n           </plugin>\n  ```\n\n  \n\n- Thrift生成的java文件，无法被import引用，原因是Thrift生成的java文件路径不对\n\n  >1、<outputDirectory></outputDirectory>配置为<outputDirectory>src/main/java</outputDirectory>\n  >\n  >2、将生成的目录在IDEA中指定为源文件目录：\n  >\n  >![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1661953198633-ec36aeea-e0ef-4398-beaa-cbefdef85f3d.png)\n","slug":"rpc/thrift-从入门到放弃","published":1,"comments":1,"layout":"post","photos":[],"link":"","_id":"cl9y38dsw002lfwuibj480wcd","content":"<h2 id=\"Thrift-Java-Maven使用指北\"><a href=\"#Thrift-Java-Maven使用指北\" class=\"headerlink\" title=\"Thrift-Java-Maven使用指北\"></a>Thrift-Java-Maven使用指北</h2><ul>\n<li><p>1、下载安装Thrift，配置Thrift环境变量</p>\n</li>\n<li><p>2、Maven中引入libthrift依赖</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.thrift<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>libthrift<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>0.14.1<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>3、引入Maven插件maven-thrift-plugin</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">build</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">plugins</span>&gt;</span></span><br><span class=\"line\">         <span class=\"tag\">&lt;<span class=\"name\">plugin</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.thrift.tools<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-thrift-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>0.1.11<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">               <span class=\"comment\">&lt;!--指定Thrift编译文件的目录和位置，设定环境变量便可不用指定--&gt;</span></span><br><span class=\"line\">               <span class=\"tag\">&lt;<span class=\"name\">thriftExecutable</span>&gt;</span>./thrift/thrift.exe<span class=\"tag\">&lt;/<span class=\"name\">thriftExecutable</span>&gt;</span></span><br><span class=\"line\">               <span class=\"comment\">&lt;!--指定待编译的  IDL文件目录，默认为src/main/thrift--&gt;</span></span><br><span class=\"line\">               <span class=\"tag\">&lt;<span class=\"name\">thriftSourceRoot</span>&gt;</span>src/main/resources/thrift<span class=\"tag\">&lt;/<span class=\"name\">thriftSourceRoot</span>&gt;</span></span><br><span class=\"line\">               <span class=\"comment\">&lt;!--在0.1.10版本后的plugin需要添加的参数--&gt;</span></span><br><span class=\"line\">               <span class=\"tag\">&lt;<span class=\"name\">generator</span>&gt;</span>java<span class=\"tag\">&lt;/<span class=\"name\">generator</span>&gt;</span> </span><br><span class=\"line\">               <span class=\"comment\">&lt;!--指定编译输出目录--&gt;</span></span><br><span class=\"line\">               <span class=\"tag\">&lt;<span class=\"name\">outputDirectory</span>&gt;</span>src/main/java<span class=\"tag\">&lt;/<span class=\"name\">outputDirectory</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">         <span class=\"tag\">&lt;/<span class=\"name\">plugin</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;/<span class=\"name\">plugins</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;/<span class=\"name\">build</span>&gt;</span></span><br></pre></td></tr></table></figure>\n\n<blockquote>\n<p> 然后通过执行plugin 的compile指令即可将文件直接编译转化为java类，注意有些版本需要添加<generator>java</generator>，否则可能会报错：[ERROR] thrift failed error: [FAILURE:generation:1] Error: unknown option java:hashcode。</p>\n<p>同时，如果我们像上面一样指定了编译输出目录为项目目录，会覆盖原有目录下的文件，所以可以保持默认配置，输出至target目录下，然后复制到我们想要的package下。</p>\n</blockquote>\n</li>\n</ul>\n<h2 id=\"FQA\"><a href=\"#FQA\" class=\"headerlink\" title=\"FQA\"></a>FQA</h2><ul>\n<li><p>执行mvn clean install编译失败</p>\n<blockquote>\n<p>[ERROR] thrift failed error: [FAILURE:generation:1] Error: unknown option java:hashcode</p>\n<p>[ERROR] Failed to execute goal org.apache.thrift.tools:maven-thrift-plugin:0.1.11:compile (thrift-sources) on project HelloService: thrift did n<br>ot exit cleanly. Review output for more information. -&gt; [Help 1]</p>\n</blockquote>\n<p>Maven插件maven-thrift-plugin配置中添加<code>&lt;generator&gt;java&lt;/generator&gt;</code></p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">plugin</span>&gt;</span></span><br><span class=\"line\">          <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.thrift.tools<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">          <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-thrift-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">          <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>0.1.11<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">          <span class=\"tag\">&lt;<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">             <span class=\"comment\">&lt;!--指定Thrift编译文件的目录和位置，设定环境变量便可不用指定--&gt;</span></span><br><span class=\"line\">             <span class=\"tag\">&lt;<span class=\"name\">thriftExecutable</span>&gt;</span>./thrift/thrift.exe<span class=\"tag\">&lt;/<span class=\"name\">thriftExecutable</span>&gt;</span></span><br><span class=\"line\">             <span class=\"comment\">&lt;!--指定待编译的  IDL文件目录，默认为src/main/thrift--&gt;</span></span><br><span class=\"line\">             <span class=\"tag\">&lt;<span class=\"name\">thriftSourceRoot</span>&gt;</span>src/main/resources/thrift<span class=\"tag\">&lt;/<span class=\"name\">thriftSourceRoot</span>&gt;</span></span><br><span class=\"line\">             <span class=\"comment\">&lt;!--在0.1.10版本后的plugin需要添加的参数--&gt;</span></span><br><span class=\"line\">             <span class=\"tag\">&lt;<span class=\"name\">generator</span>&gt;</span>java<span class=\"tag\">&lt;/<span class=\"name\">generator</span>&gt;</span> </span><br><span class=\"line\">             <span class=\"comment\">&lt;!--指定编译输出目录--&gt;</span></span><br><span class=\"line\">             <span class=\"tag\">&lt;<span class=\"name\">outputDirectory</span>&gt;</span>src/main/java<span class=\"tag\">&lt;/<span class=\"name\">outputDirectory</span>&gt;</span></span><br><span class=\"line\">          <span class=\"tag\">&lt;/<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">       <span class=\"tag\">&lt;/<span class=\"name\">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure>\n\n\n</li>\n<li><p>Thrift生成的java文件，无法被import引用，原因是Thrift生成的java文件路径不对</p>\n<blockquote>\n<p>1、<outputDirectory></outputDirectory>配置为<outputDirectory>src&#x2F;main&#x2F;java</outputDirectory></p>\n<p>2、将生成的目录在IDEA中指定为源文件目录：</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1661953198633-ec36aeea-e0ef-4398-beaa-cbefdef85f3d.png\" alt=\"img\"></p>\n</blockquote>\n</li>\n</ul>\n","site":{"data":{"link":[{"class_name":"友情链接","class_desc":"那些人，那些事","link_list":[{"name":"张洪Heo","link":"https://blog.zhheo.com/","avatar":"https://npm.elemecdn.com/guli-heo/img/avatar2.png","descr":"分享设计与科技生活"},{"name":"瞬間の筆記","link":"https://hikki.site","descr":"喜欢的东西就努力去追求，万一成功了呢!","avatar":"https://cdn.jsdelivr.net/gh/0000rookie/imgs/202206120315.png"}]}]}},"excerpt":"","more":"<h2 id=\"Thrift-Java-Maven使用指北\"><a href=\"#Thrift-Java-Maven使用指北\" class=\"headerlink\" title=\"Thrift-Java-Maven使用指北\"></a>Thrift-Java-Maven使用指北</h2><ul>\n<li><p>1、下载安装Thrift，配置Thrift环境变量</p>\n</li>\n<li><p>2、Maven中引入libthrift依赖</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.thrift<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>libthrift<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>0.14.1<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>3、引入Maven插件maven-thrift-plugin</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">build</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">plugins</span>&gt;</span></span><br><span class=\"line\">         <span class=\"tag\">&lt;<span class=\"name\">plugin</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.thrift.tools<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-thrift-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>0.1.11<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">               <span class=\"comment\">&lt;!--指定Thrift编译文件的目录和位置，设定环境变量便可不用指定--&gt;</span></span><br><span class=\"line\">               <span class=\"tag\">&lt;<span class=\"name\">thriftExecutable</span>&gt;</span>./thrift/thrift.exe<span class=\"tag\">&lt;/<span class=\"name\">thriftExecutable</span>&gt;</span></span><br><span class=\"line\">               <span class=\"comment\">&lt;!--指定待编译的  IDL文件目录，默认为src/main/thrift--&gt;</span></span><br><span class=\"line\">               <span class=\"tag\">&lt;<span class=\"name\">thriftSourceRoot</span>&gt;</span>src/main/resources/thrift<span class=\"tag\">&lt;/<span class=\"name\">thriftSourceRoot</span>&gt;</span></span><br><span class=\"line\">               <span class=\"comment\">&lt;!--在0.1.10版本后的plugin需要添加的参数--&gt;</span></span><br><span class=\"line\">               <span class=\"tag\">&lt;<span class=\"name\">generator</span>&gt;</span>java<span class=\"tag\">&lt;/<span class=\"name\">generator</span>&gt;</span> </span><br><span class=\"line\">               <span class=\"comment\">&lt;!--指定编译输出目录--&gt;</span></span><br><span class=\"line\">               <span class=\"tag\">&lt;<span class=\"name\">outputDirectory</span>&gt;</span>src/main/java<span class=\"tag\">&lt;/<span class=\"name\">outputDirectory</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">         <span class=\"tag\">&lt;/<span class=\"name\">plugin</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;/<span class=\"name\">plugins</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;/<span class=\"name\">build</span>&gt;</span></span><br></pre></td></tr></table></figure>\n\n<blockquote>\n<p> 然后通过执行plugin 的compile指令即可将文件直接编译转化为java类，注意有些版本需要添加<generator>java</generator>，否则可能会报错：[ERROR] thrift failed error: [FAILURE:generation:1] Error: unknown option java:hashcode。</p>\n<p>同时，如果我们像上面一样指定了编译输出目录为项目目录，会覆盖原有目录下的文件，所以可以保持默认配置，输出至target目录下，然后复制到我们想要的package下。</p>\n</blockquote>\n</li>\n</ul>\n<h2 id=\"FQA\"><a href=\"#FQA\" class=\"headerlink\" title=\"FQA\"></a>FQA</h2><ul>\n<li><p>执行mvn clean install编译失败</p>\n<blockquote>\n<p>[ERROR] thrift failed error: [FAILURE:generation:1] Error: unknown option java:hashcode</p>\n<p>[ERROR] Failed to execute goal org.apache.thrift.tools:maven-thrift-plugin:0.1.11:compile (thrift-sources) on project HelloService: thrift did n<br>ot exit cleanly. Review output for more information. -&gt; [Help 1]</p>\n</blockquote>\n<p>Maven插件maven-thrift-plugin配置中添加<code>&lt;generator&gt;java&lt;/generator&gt;</code></p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">plugin</span>&gt;</span></span><br><span class=\"line\">          <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.thrift.tools<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">          <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-thrift-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">          <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>0.1.11<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">          <span class=\"tag\">&lt;<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">             <span class=\"comment\">&lt;!--指定Thrift编译文件的目录和位置，设定环境变量便可不用指定--&gt;</span></span><br><span class=\"line\">             <span class=\"tag\">&lt;<span class=\"name\">thriftExecutable</span>&gt;</span>./thrift/thrift.exe<span class=\"tag\">&lt;/<span class=\"name\">thriftExecutable</span>&gt;</span></span><br><span class=\"line\">             <span class=\"comment\">&lt;!--指定待编译的  IDL文件目录，默认为src/main/thrift--&gt;</span></span><br><span class=\"line\">             <span class=\"tag\">&lt;<span class=\"name\">thriftSourceRoot</span>&gt;</span>src/main/resources/thrift<span class=\"tag\">&lt;/<span class=\"name\">thriftSourceRoot</span>&gt;</span></span><br><span class=\"line\">             <span class=\"comment\">&lt;!--在0.1.10版本后的plugin需要添加的参数--&gt;</span></span><br><span class=\"line\">             <span class=\"tag\">&lt;<span class=\"name\">generator</span>&gt;</span>java<span class=\"tag\">&lt;/<span class=\"name\">generator</span>&gt;</span> </span><br><span class=\"line\">             <span class=\"comment\">&lt;!--指定编译输出目录--&gt;</span></span><br><span class=\"line\">             <span class=\"tag\">&lt;<span class=\"name\">outputDirectory</span>&gt;</span>src/main/java<span class=\"tag\">&lt;/<span class=\"name\">outputDirectory</span>&gt;</span></span><br><span class=\"line\">          <span class=\"tag\">&lt;/<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">       <span class=\"tag\">&lt;/<span class=\"name\">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure>\n\n\n</li>\n<li><p>Thrift生成的java文件，无法被import引用，原因是Thrift生成的java文件路径不对</p>\n<blockquote>\n<p>1、<outputDirectory></outputDirectory>配置为<outputDirectory>src&#x2F;main&#x2F;java</outputDirectory></p>\n<p>2、将生成的目录在IDEA中指定为源文件目录：</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1661953198633-ec36aeea-e0ef-4398-beaa-cbefdef85f3d.png\" alt=\"img\"></p>\n</blockquote>\n</li>\n</ul>\n"},{"title":"Linux系统编程-文件与I/O","date":"2022-10-09T05:47:56.000Z","updated":"2022-10-09T05:47:56.000Z","cover":"https://tvax3.sinaimg.cn/large/0084aYsLly1gnhmxy0hdlj31hc0u0gpt.jpg","top_img":null,"description":null,"keywords":null,"_content":"\n##  read/write\n\n读常规文件是不会阻塞的，不管读多少字节，`read`一定会在有限的时间内返回。从终端设备或网络读则不一定，如果从终端输入的数据没有换行符，调用`read`读终端设备就会阻塞，如果网络上没有接收到数据包，调用`read`从网络读就会阻塞，至于会阻塞多长时间也是不确定的，如果一直没有数据到达就一直阻塞在那里。同样，写常规文件是不会阻塞的，而向终端设备或网络写则不一定。\n\n现在明确一下阻塞（Block）这个概念。当进程调用一个阻塞的系统函数时，该进程被置于睡眠（Sleep）状态，这时内核调度其它进程运行，直到该进程等待的事件发生了（比如网络上接收到数据包，或者调用`sleep`指定的睡眠时间到了）它才有可能继续运行。与睡眠状态相对的是运行（Running）状态，在Linux内核中，处于运行状态的进程分为两种情况：\n\n- 正在被调度执行。CPU处于该进程的上下文环境中，程序计数器（`eip`）里保存着该进程的指令地址，通用寄存器里保存着该进程运算过程的中间结果，正在执行该进程的指令，正在读写该进程的地址空间。\n- 就绪状态。该进程不需要等待什么事件发生，随时都可以执行，但CPU暂时还在执行另一个进程，所以该进程在一个就绪队列中等待被内核调度。系统中可能同时有多个就绪的进程，那么该调度谁执行呢？内核的调度算法是基于优先级和时间片的，而且会根据每个进程的运行情况动态调整它的优先级和时间片，让每个进程都能比较公平地得到机会执行，同时要兼顾用户体验，不能让和用户交互的进程响应太慢。\n\n## mmap函数系统调用\n\n`mmap`可以把磁盘文件的一部分直接映射到内存，这样文件中的位置直接就有对应的内存地址，对文件的读写可以直接用指针来做而不需要`read`/`write`函数。\n\n> mmap, munmap - map or unmap files or devices into memory\n>\n> void *mmap(void *addr, size_t length, int prot, int flags, int fd, off_t offset);\n> int munmap(void *addr, size_t length);\n>\n> mmap() creates a new mapping in the virtual address space of the calling process.  The starting address for the new mapping is specified in addr.  The length argument specifies the length of the mapping (which must be greater than 0).\n\n```c\n#include <stdlib.h>\n#include <sys/mman.h>\n#include <fcntl.h>\n\nint main(void)\n{\n        int *p;\n        int fd = open(\"hello\", O_RDWR);\n        if (fd < 0) {\n                perror(\"open hello\");\n                exit(1);\n        }\n\n          // 6：文件映射到内存的长度\n          // PROT_WRITE：映射的这段内存可写\n          // MAP_SHARED：多个进程对同一个文件的映射是共享的，一个进程对映射的内存做了修改，另一个进程也会看到这种变化。\n          // fd：文件描述符\n          // 0：offset\n        p = mmap(NULL, 6, PROT_WRITE, MAP_SHARED, fd, 0);\n        if (p == MAP_FAILED) {\n                perror(\"mmap\");\n                exit(1);\n        }\n        close(fd);\n\n      char *char_point = (char *)p;\n      //p[0] = 0x30313233;\n      // 修改第一个字符为i\n      char_point[0] = 'i';\n\n      // 解除内存映射\n      munmap(p, 6);\n      return 0;\n}\n```\n\n修改后，mmap不会立即将更新同步到文件，可以用msync函数将更新刷到内存。\n\n>  msync - synchronize a file with a memory map \n>\n> int msync(void *addr, size_t length, int flags);\n>\n> msync() flushes changes made to the in-core copy of a file that was mapped into memory using mmap(2) back to the filesystem.  Without use of this call, there is no guarantee that changes are written back before munmap(2) is called.  To be more precise,  the  part  of the file that corresponds to the memory area starting at addr and having length length is updated.\n","source":"_posts/os/文件与IO.md","raw":"---\ntitle: Linux系统编程-文件与I/O\ntags:\n  - 'os'\ncategories:\n  - ['os']\ndate: 2022-10-09 13:47:56\nupdated: 2022-10-09 13:47:56\ncover:\ntop_img:\ndescription:\nkeywords:\n---\n\n##  read/write\n\n读常规文件是不会阻塞的，不管读多少字节，`read`一定会在有限的时间内返回。从终端设备或网络读则不一定，如果从终端输入的数据没有换行符，调用`read`读终端设备就会阻塞，如果网络上没有接收到数据包，调用`read`从网络读就会阻塞，至于会阻塞多长时间也是不确定的，如果一直没有数据到达就一直阻塞在那里。同样，写常规文件是不会阻塞的，而向终端设备或网络写则不一定。\n\n现在明确一下阻塞（Block）这个概念。当进程调用一个阻塞的系统函数时，该进程被置于睡眠（Sleep）状态，这时内核调度其它进程运行，直到该进程等待的事件发生了（比如网络上接收到数据包，或者调用`sleep`指定的睡眠时间到了）它才有可能继续运行。与睡眠状态相对的是运行（Running）状态，在Linux内核中，处于运行状态的进程分为两种情况：\n\n- 正在被调度执行。CPU处于该进程的上下文环境中，程序计数器（`eip`）里保存着该进程的指令地址，通用寄存器里保存着该进程运算过程的中间结果，正在执行该进程的指令，正在读写该进程的地址空间。\n- 就绪状态。该进程不需要等待什么事件发生，随时都可以执行，但CPU暂时还在执行另一个进程，所以该进程在一个就绪队列中等待被内核调度。系统中可能同时有多个就绪的进程，那么该调度谁执行呢？内核的调度算法是基于优先级和时间片的，而且会根据每个进程的运行情况动态调整它的优先级和时间片，让每个进程都能比较公平地得到机会执行，同时要兼顾用户体验，不能让和用户交互的进程响应太慢。\n\n## mmap函数系统调用\n\n`mmap`可以把磁盘文件的一部分直接映射到内存，这样文件中的位置直接就有对应的内存地址，对文件的读写可以直接用指针来做而不需要`read`/`write`函数。\n\n> mmap, munmap - map or unmap files or devices into memory\n>\n> void *mmap(void *addr, size_t length, int prot, int flags, int fd, off_t offset);\n> int munmap(void *addr, size_t length);\n>\n> mmap() creates a new mapping in the virtual address space of the calling process.  The starting address for the new mapping is specified in addr.  The length argument specifies the length of the mapping (which must be greater than 0).\n\n```c\n#include <stdlib.h>\n#include <sys/mman.h>\n#include <fcntl.h>\n\nint main(void)\n{\n        int *p;\n        int fd = open(\"hello\", O_RDWR);\n        if (fd < 0) {\n                perror(\"open hello\");\n                exit(1);\n        }\n\n          // 6：文件映射到内存的长度\n          // PROT_WRITE：映射的这段内存可写\n          // MAP_SHARED：多个进程对同一个文件的映射是共享的，一个进程对映射的内存做了修改，另一个进程也会看到这种变化。\n          // fd：文件描述符\n          // 0：offset\n        p = mmap(NULL, 6, PROT_WRITE, MAP_SHARED, fd, 0);\n        if (p == MAP_FAILED) {\n                perror(\"mmap\");\n                exit(1);\n        }\n        close(fd);\n\n      char *char_point = (char *)p;\n      //p[0] = 0x30313233;\n      // 修改第一个字符为i\n      char_point[0] = 'i';\n\n      // 解除内存映射\n      munmap(p, 6);\n      return 0;\n}\n```\n\n修改后，mmap不会立即将更新同步到文件，可以用msync函数将更新刷到内存。\n\n>  msync - synchronize a file with a memory map \n>\n> int msync(void *addr, size_t length, int flags);\n>\n> msync() flushes changes made to the in-core copy of a file that was mapped into memory using mmap(2) back to the filesystem.  Without use of this call, there is no guarantee that changes are written back before munmap(2) is called.  To be more precise,  the  part  of the file that corresponds to the memory area starting at addr and having length length is updated.\n","slug":"os/文件与IO","published":1,"comments":1,"layout":"post","photos":[],"link":"","_id":"cl9y38dt0002qfwuieoeodxzt","content":"<h2 id=\"read-x2F-write\"><a href=\"#read-x2F-write\" class=\"headerlink\" title=\"read&#x2F;write\"></a>read&#x2F;write</h2><p>读常规文件是不会阻塞的，不管读多少字节，<code>read</code>一定会在有限的时间内返回。从终端设备或网络读则不一定，如果从终端输入的数据没有换行符，调用<code>read</code>读终端设备就会阻塞，如果网络上没有接收到数据包，调用<code>read</code>从网络读就会阻塞，至于会阻塞多长时间也是不确定的，如果一直没有数据到达就一直阻塞在那里。同样，写常规文件是不会阻塞的，而向终端设备或网络写则不一定。</p>\n<p>现在明确一下阻塞（Block）这个概念。当进程调用一个阻塞的系统函数时，该进程被置于睡眠（Sleep）状态，这时内核调度其它进程运行，直到该进程等待的事件发生了（比如网络上接收到数据包，或者调用<code>sleep</code>指定的睡眠时间到了）它才有可能继续运行。与睡眠状态相对的是运行（Running）状态，在Linux内核中，处于运行状态的进程分为两种情况：</p>\n<ul>\n<li>正在被调度执行。CPU处于该进程的上下文环境中，程序计数器（<code>eip</code>）里保存着该进程的指令地址，通用寄存器里保存着该进程运算过程的中间结果，正在执行该进程的指令，正在读写该进程的地址空间。</li>\n<li>就绪状态。该进程不需要等待什么事件发生，随时都可以执行，但CPU暂时还在执行另一个进程，所以该进程在一个就绪队列中等待被内核调度。系统中可能同时有多个就绪的进程，那么该调度谁执行呢？内核的调度算法是基于优先级和时间片的，而且会根据每个进程的运行情况动态调整它的优先级和时间片，让每个进程都能比较公平地得到机会执行，同时要兼顾用户体验，不能让和用户交互的进程响应太慢。</li>\n</ul>\n<h2 id=\"mmap函数系统调用\"><a href=\"#mmap函数系统调用\" class=\"headerlink\" title=\"mmap函数系统调用\"></a>mmap函数系统调用</h2><p><code>mmap</code>可以把磁盘文件的一部分直接映射到内存，这样文件中的位置直接就有对应的内存地址，对文件的读写可以直接用指针来做而不需要<code>read</code>&#x2F;<code>write</code>函数。</p>\n<blockquote>\n<p>mmap, munmap - map or unmap files or devices into memory</p>\n<p>void *mmap(void *addr, size_t length, int prot, int flags, int fd, off_t offset);<br>int munmap(void *addr, size_t length);</p>\n<p>mmap() creates a new mapping in the virtual address space of the calling process.  The starting address for the new mapping is specified in addr.  The length argument specifies the length of the mapping (which must be greater than 0).</p>\n</blockquote>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;stdlib.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;sys/mman.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;fcntl.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">main</span><span class=\"params\">(<span class=\"type\">void</span>)</span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">        <span class=\"type\">int</span> *p;</span><br><span class=\"line\">        <span class=\"type\">int</span> fd = open(<span class=\"string\">&quot;hello&quot;</span>, O_RDWR);</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (fd &lt; <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">                perror(<span class=\"string\">&quot;open hello&quot;</span>);</span><br><span class=\"line\">                <span class=\"built_in\">exit</span>(<span class=\"number\">1</span>);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">          <span class=\"comment\">// 6：文件映射到内存的长度</span></span><br><span class=\"line\">          <span class=\"comment\">// PROT_WRITE：映射的这段内存可写</span></span><br><span class=\"line\">          <span class=\"comment\">// MAP_SHARED：多个进程对同一个文件的映射是共享的，一个进程对映射的内存做了修改，另一个进程也会看到这种变化。</span></span><br><span class=\"line\">          <span class=\"comment\">// fd：文件描述符</span></span><br><span class=\"line\">          <span class=\"comment\">// 0：offset</span></span><br><span class=\"line\">        p = mmap(<span class=\"literal\">NULL</span>, <span class=\"number\">6</span>, PROT_WRITE, MAP_SHARED, fd, <span class=\"number\">0</span>);</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (p == MAP_FAILED) &#123;</span><br><span class=\"line\">                perror(<span class=\"string\">&quot;mmap&quot;</span>);</span><br><span class=\"line\">                <span class=\"built_in\">exit</span>(<span class=\"number\">1</span>);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        close(fd);</span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"type\">char</span> *char_point = (<span class=\"type\">char</span> *)p;</span><br><span class=\"line\">      <span class=\"comment\">//p[0] = 0x30313233;</span></span><br><span class=\"line\">      <span class=\"comment\">// 修改第一个字符为i</span></span><br><span class=\"line\">      char_point[<span class=\"number\">0</span>] = <span class=\"string\">&#x27;i&#x27;</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"comment\">// 解除内存映射</span></span><br><span class=\"line\">      munmap(p, <span class=\"number\">6</span>);</span><br><span class=\"line\">      <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>修改后，mmap不会立即将更新同步到文件，可以用msync函数将更新刷到内存。</p>\n<blockquote>\n<p> msync - synchronize a file with a memory map </p>\n<p>int msync(void *addr, size_t length, int flags);</p>\n<p>msync() flushes changes made to the in-core copy of a file that was mapped into memory using mmap(2) back to the filesystem.  Without use of this call, there is no guarantee that changes are written back before munmap(2) is called.  To be more precise,  the  part  of the file that corresponds to the memory area starting at addr and having length length is updated.</p>\n</blockquote>\n","site":{"data":{"link":[{"class_name":"友情链接","class_desc":"那些人，那些事","link_list":[{"name":"张洪Heo","link":"https://blog.zhheo.com/","avatar":"https://npm.elemecdn.com/guli-heo/img/avatar2.png","descr":"分享设计与科技生活"},{"name":"瞬間の筆記","link":"https://hikki.site","descr":"喜欢的东西就努力去追求，万一成功了呢!","avatar":"https://cdn.jsdelivr.net/gh/0000rookie/imgs/202206120315.png"}]}]}},"excerpt":"","more":"<h2 id=\"read-x2F-write\"><a href=\"#read-x2F-write\" class=\"headerlink\" title=\"read&#x2F;write\"></a>read&#x2F;write</h2><p>读常规文件是不会阻塞的，不管读多少字节，<code>read</code>一定会在有限的时间内返回。从终端设备或网络读则不一定，如果从终端输入的数据没有换行符，调用<code>read</code>读终端设备就会阻塞，如果网络上没有接收到数据包，调用<code>read</code>从网络读就会阻塞，至于会阻塞多长时间也是不确定的，如果一直没有数据到达就一直阻塞在那里。同样，写常规文件是不会阻塞的，而向终端设备或网络写则不一定。</p>\n<p>现在明确一下阻塞（Block）这个概念。当进程调用一个阻塞的系统函数时，该进程被置于睡眠（Sleep）状态，这时内核调度其它进程运行，直到该进程等待的事件发生了（比如网络上接收到数据包，或者调用<code>sleep</code>指定的睡眠时间到了）它才有可能继续运行。与睡眠状态相对的是运行（Running）状态，在Linux内核中，处于运行状态的进程分为两种情况：</p>\n<ul>\n<li>正在被调度执行。CPU处于该进程的上下文环境中，程序计数器（<code>eip</code>）里保存着该进程的指令地址，通用寄存器里保存着该进程运算过程的中间结果，正在执行该进程的指令，正在读写该进程的地址空间。</li>\n<li>就绪状态。该进程不需要等待什么事件发生，随时都可以执行，但CPU暂时还在执行另一个进程，所以该进程在一个就绪队列中等待被内核调度。系统中可能同时有多个就绪的进程，那么该调度谁执行呢？内核的调度算法是基于优先级和时间片的，而且会根据每个进程的运行情况动态调整它的优先级和时间片，让每个进程都能比较公平地得到机会执行，同时要兼顾用户体验，不能让和用户交互的进程响应太慢。</li>\n</ul>\n<h2 id=\"mmap函数系统调用\"><a href=\"#mmap函数系统调用\" class=\"headerlink\" title=\"mmap函数系统调用\"></a>mmap函数系统调用</h2><p><code>mmap</code>可以把磁盘文件的一部分直接映射到内存，这样文件中的位置直接就有对应的内存地址，对文件的读写可以直接用指针来做而不需要<code>read</code>&#x2F;<code>write</code>函数。</p>\n<blockquote>\n<p>mmap, munmap - map or unmap files or devices into memory</p>\n<p>void *mmap(void *addr, size_t length, int prot, int flags, int fd, off_t offset);<br>int munmap(void *addr, size_t length);</p>\n<p>mmap() creates a new mapping in the virtual address space of the calling process.  The starting address for the new mapping is specified in addr.  The length argument specifies the length of the mapping (which must be greater than 0).</p>\n</blockquote>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;stdlib.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;sys/mman.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;fcntl.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">main</span><span class=\"params\">(<span class=\"type\">void</span>)</span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">        <span class=\"type\">int</span> *p;</span><br><span class=\"line\">        <span class=\"type\">int</span> fd = open(<span class=\"string\">&quot;hello&quot;</span>, O_RDWR);</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (fd &lt; <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">                perror(<span class=\"string\">&quot;open hello&quot;</span>);</span><br><span class=\"line\">                <span class=\"built_in\">exit</span>(<span class=\"number\">1</span>);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">          <span class=\"comment\">// 6：文件映射到内存的长度</span></span><br><span class=\"line\">          <span class=\"comment\">// PROT_WRITE：映射的这段内存可写</span></span><br><span class=\"line\">          <span class=\"comment\">// MAP_SHARED：多个进程对同一个文件的映射是共享的，一个进程对映射的内存做了修改，另一个进程也会看到这种变化。</span></span><br><span class=\"line\">          <span class=\"comment\">// fd：文件描述符</span></span><br><span class=\"line\">          <span class=\"comment\">// 0：offset</span></span><br><span class=\"line\">        p = mmap(<span class=\"literal\">NULL</span>, <span class=\"number\">6</span>, PROT_WRITE, MAP_SHARED, fd, <span class=\"number\">0</span>);</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (p == MAP_FAILED) &#123;</span><br><span class=\"line\">                perror(<span class=\"string\">&quot;mmap&quot;</span>);</span><br><span class=\"line\">                <span class=\"built_in\">exit</span>(<span class=\"number\">1</span>);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        close(fd);</span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"type\">char</span> *char_point = (<span class=\"type\">char</span> *)p;</span><br><span class=\"line\">      <span class=\"comment\">//p[0] = 0x30313233;</span></span><br><span class=\"line\">      <span class=\"comment\">// 修改第一个字符为i</span></span><br><span class=\"line\">      char_point[<span class=\"number\">0</span>] = <span class=\"string\">&#x27;i&#x27;</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"comment\">// 解除内存映射</span></span><br><span class=\"line\">      munmap(p, <span class=\"number\">6</span>);</span><br><span class=\"line\">      <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>修改后，mmap不会立即将更新同步到文件，可以用msync函数将更新刷到内存。</p>\n<blockquote>\n<p> msync - synchronize a file with a memory map </p>\n<p>int msync(void *addr, size_t length, int flags);</p>\n<p>msync() flushes changes made to the in-core copy of a file that was mapped into memory using mmap(2) back to the filesystem.  Without use of this call, there is no guarantee that changes are written back before munmap(2) is called.  To be more precise,  the  part  of the file that corresponds to the memory area starting at addr and having length length is updated.</p>\n</blockquote>\n"},{"title":"虚拟内存-从入门到跑路","date":"2022-10-08T10:41:38.000Z","updated":"2022-10-08T10:41:38.000Z","cover":"https://tvax4.sinaimg.cn/large/0084aYsLgy1h3jum72m7kj31220e6jsc.jpg","top_img":null,"description":null,"keywords":null,"_content":"\n>#### 虚拟内存可以提高系统的稳定性和安全性，主要通过以下两点：\n>\n> - 1、控制物理内存的访问权限。\n>\n>   例如，Text Segment被只读保护起来，防止被错误的指令意外改写，内核地址空间也被保护起来，防止在用户模式下执行错误的指令意外改写内核数据。这样，执行错误指令或恶意代码的破坏能力受到了限制，顶多使当前进程因段错误终止，而不会影响整个系统的稳定性。\n>\n> - 2、让每个进程有独立的地址空间。\n>\n>   所谓独立的地址空间是指，不同进程中的同一个VA被MMU映射到不同的PA，并且在某一个进程中访问任何地址都不可能访问到另外一个进程的数据，这样使得任何一个进程由于执行错误指令或恶意代码导致的非法内存访问都不会意外改写其它进程的数据，不会影响其它进程的运行，从而保证整个系统的稳定性。\n>\n>#### 虚拟内存 + 共享库可以大大节省内存。\n>\n> 比如`libc`共享库，系统中几乎所有的进程都映射`libc`到自己的进程地址空间，而`libc`的只读部分在物理内存中只需要存在一份，就可以被所有进程共享，这就是“共享库”这个名称的由来了。    \n>\n>#### 虚拟内存方便给分配和释放内存带来方便，物理地址不连续的几块内存可以映射成虚拟地址连续的一块内存。\n>\n>#### 虚拟内存带来了交换分区。这样就提高了系统中可分配的内存总量，可以运行更多进程。\n>\n>比如要用`malloc`分配一块很大的内存空间，虽然有足够多的空闲物理内存，却没有足够大的*连续*空闲内存，这时就可以分配多个不连续的物理页面而映射到连续的虚拟地址范围。\n\n## What-什么是虚拟内存\n\n> **虚拟内存**是计算机系统内存管理的一种技术。它使得应用程序认为它拥有连续可用的内存（一个连续完整的地址空间），而实际上[物理内存](https://zh.m.wikipedia.org/wiki/物理内存)通常被分隔成多个[内存碎片](https://zh.m.wikipedia.org/wiki/碎片化)，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。与没有使用虚拟内存技术的系统相比，使用这种技术使得大型程序的编写变得更容易，对真正的物理内存（例如[RAM](https://zh.m.wikipedia.org/wiki/隨機存取記憶體)）的使用也更有效率。此外，虚拟内存技术可以使多个[进程](https://zh.m.wikipedia.org/wiki/行程)共享同一个[运行库](https://zh.m.wikipedia.org/wiki/函式庫)，并通过分割不同进程的内存空间来提高系统的安全性。\n>\n> 注意：**虚拟内存**不只是“用磁盘空间来扩展物理内存”的意思——这只是扩充[内存级别](https://zh.m.wikipedia.org/wiki/記憶體階層)以使其包含[硬盘驱动器](https://zh.m.wikipedia.org/wiki/硬盘驱动器)而已。把内存扩展到磁盘只是使用虚拟内存技术的一个结果，它的作用也可以通过[覆盖](https://zh.m.wikipedia.org/wiki/覆盖_(编程))或者把处于不活动状态的程序以及它们的数据全部交换到磁盘上等方式来实现。对虚拟内存的定义是基于对[地址空间](https://zh.m.wikipedia.org/wiki/地址空间)的重定义的，即把地址空间定义为“连续的虚拟内存地址”，以借此“欺骗”程序，使它们以为自己正在使用一大块的“连续”地址。\n>\n> 那些需要快速存取或者相应时间非常稳定的[嵌入式](https://zh.m.wikipedia.org/wiki/嵌入式)系统，以及其他的具有特殊应用的计算机系统，可能会为了避免让[运算结果的可预测性](https://zh.m.wikipedia.org/wiki/确定性算法)降低，而选择不使用虚拟内存。\n\n## How\n\n> 虚拟内存技术是现代[计算机系统结构](https://zh.m.wikipedia.org/wiki/计算机系统结构)中不可分割的一部分。现代所有用于一般应用的[操作系统](https://zh.m.wikipedia.org/wiki/操作系统)都对普通的应用程序使用虚拟内存技术，例如文字处理软件，电子制表软件，多媒体播放器等等。大部分架构通过[CPU](https://zh.m.wikipedia.org/wiki/CPU)中独立的硬件**内存管理单元**（英语：**memory management unit**，缩写为**MMU**），有时称作**分页内存管理单元**（英语：**paged memory management unit**，缩写为**PMMU**)来辅助实现这一功能。\n\n- 操作系统利用体系结构提供的VA到PA的转换机制实现虚拟内存管理。\n\n  用`ps`命令查看当前终端下的进程，得知`bash`进程的id是27613，然后用`cat /proc/27613/maps`命令查看它的虚拟地址空间。`/proc`目录中的文件并不是真正的磁盘文件，而是由内核虚拟出来的文件系统，当前系统中运行的每个进程在`/proc`下都有一个子目录，目录名就是进程的id，查看目录下的文件可以得到该进程的相关信息。\n\n  ```shell\n  root@DESKTOP-KD33OT8:/home/demo# cat /proc/27613/maps\n  5589e9d2b000-5589e9d42000 r--p 00000000 08:10 225588                     /usr/bin/zsh\n  5589e9d42000-5589e9dd7000 r-xp 00017000 08:10 225588                     /usr/bin/zsh\n  5589e9dd7000-5589e9df9000 r--p 000ac000 08:10 225588                     /usr/bin/zsh\n  5589e9dfa000-5589e9dfc000 r--p 000ce000 08:10 225588                     /usr/bin/zsh\n  5589e9dfc000-5589e9e02000 rw-p 000d0000 08:10 225588                     /usr/bin/zsh\n  5589e9e02000-5589e9e16000 rw-p 00000000 00:00 0\n  5589eac55000-5589eb1af000 rw-p 00000000 00:00 0                          [heap]\n  7f90adfc6000-7f90adfc9000 r--p 00000000 08:10 225599                     /usr/lib/x86_64-linux-gnu/zsh/5.8/zsh/computil.so\n  7f90adfc9000-7f90adfd6000 r-xp 00003000 08:10 225599                     /usr/lib/x86_64-linux-gnu/zsh/5.8/zsh/computil.so\n  7f90adfd6000-7f90adfd8000 r--p 00010000 08:10 225599                     /usr/lib/x86_64-linux-gnu/zsh/5.8/zsh/computil.so\n  7f90adfd8000-7f90adfd9000 r--p 00011000 08:10 225599                     /usr/lib/x86_64-linux-gnu/zsh/5.8/zsh/computil.so\n  7f90adfd9000-7f90adfda000 rw-p 00012000 08:10 225599                     /usr/lib/x86_64-linux-gnu/zsh/5.8/zsh/computil.so\n  7f90adfda000-7f90ae25a000 r--s 00000000 08:10 225058                     /usr/share/zsh/functions/Completion/Unix.zwc\n  7f90ae265000-7f90ae28a000 r--s 00000000 08:10 225225                     /usr/share/zsh/functions/Completion/Zsh.zwc\n  7f90ae299000-7f90ae2b2000 r--s 00000000 08:10 225469                     /usr/share/zsh/functions/Zle.zwc\n  7f90ae2b6000-7f90ae2da000 rw-p 00000000 00:00 0\n  7f90ae325000-7f90ae331000 rw-p 00000000 00:00 0\n  7f90ae331000-7f90ae37d000 rw-p 00000000 00:00 0\n  7f90ae37d000-7f90ae381000 r--p 00000000 08:10 225596                     /usr/lib/x86_64-linux-gnu/zsh/5.8/zsh/compctl.so\n  7f90ae381000-7f90ae38d000 r-xp 00004000 08:10 225596                     /usr/lib/x86_64-linux-gnu/zsh/5.8/zsh/compctl.so\n  7f90ae38d000-7f90ae38f000 r--p 00010000 08:10 225596                     /usr/lib/x86_64-linux-gnu/zsh/5.8/zsh/compctl.so\n  7f90ae38f000-7f90ae390000 r--p 00011000 08:10 225596                     /usr/lib/x86_64-linux-gnu/zsh/5.8/zsh/compctl.so\n  7f90ae390000-7f90ae391000 rw-p 00012000 08:10 225596                     /usr/lib/x86_64-linux-gnu/zsh/5.8/zsh/compctl.so\n  7f90aecf3000-7f90aecf5000 rw-p 00000000 00:00 0\n  7f90aecf5000-7f90aecf6000 r--p 00000000 08:10 2985                       /usr/lib/locale/C.UTF-8/LC_TELEPHONE\n  7f90aecf6000-7f90aecf7000 r--p 00000000 08:10 2978                       /usr/lib/locale/C.UTF-8/LC_MEASUREMENT\n  7f90aecf7000-7f90aecfe000 r--s 00000000 08:10 264854                     /usr/lib/x86_64-linux-gnu/gconv/gconv-modules.cache\n  7f90aecfe000-7f90aecff000 r--p 00000000 08:10 38549                      /usr/lib/x86_64-linux-gnu/ld-2.31.so\n  7f90aecff000-7f90aed22000 r-xp 00001000 08:10 38549                      /usr/lib/x86_64-linux-gnu/ld-2.31.so\n  7f90aed22000-7f90aed2a000 r--p 00024000 08:10 38549                      /usr/lib/x86_64-linux-gnu/ld-2.31.so\n  7f90aed2a000-7f90aed2b000 r--p 00000000 08:10 2977                       /usr/lib/locale/C.UTF-8/LC_IDENTIFICATION\n  7f90aed2b000-7f90aed2c000 r--p 0002c000 08:10 38549                      /usr/lib/x86_64-linux-gnu/ld-2.31.so\n  7f90aed2c000-7f90aed2d000 rw-p 0002d000 08:10 38549                      /usr/lib/x86_64-linux-gnu/ld-2.31.so\n  7f90aed2d000-7f90aed2e000 rw-p 00000000 00:00 0\n  7ffeb1e2d000-7ffeb1e7c000 rw-p 00000000 00:00 0                          [stack]\n  7ffeb1f0c000-7ffeb1f10000 r--p 00000000 00:00 0                          [vvar]\n  7ffeb1f10000-7ffeb1f11000 r-xp 00000000 00:00 0                          [vdso]\n  ```\n  \n  \n\n## Why-为什么需要虚拟内存\n\n### 第一，虚拟内存管理可以控制物理内存的访问权限。\n\n**物理内存本身是不限制访问的，任何地址都可以读写，而操作系统要求不同的页面具有不同的访问权限，这是利用CPU模式和MMU的内存保护机制实现的。**例如，Text Segment被只读保护起来，防止被错误的指令意外改写，内核地址空间也被保护起来，防止在用户模式下执行错误的指令意外改写内核数据。这样，执行错误指令或恶意代码的破坏能力受到了限制，顶多使当前进程因段错误终止，而不会影响整个系统的稳定性。\n\n### 第二，虚拟内存管理最主要的作用是让每个进程有独立的地址空间。\n\n**所谓独立的地址空间是指，不同进程中的同一个VA被MMU映射到不同的PA，并且在某一个进程中访问任何地址都不可能访问到另外一个进程的数据，这样使得任何一个进程由于执行错误指令或恶意代码导致的非法内存访问都不会意外改写其它进程的数据，不会影响其它进程的运行，从而保证整个系统的稳定性。**另一方面，每个进程都认为自己独占整个虚拟地址空间，这样链接器和加载器的实现会比较容易，不必考虑各进程的地址范围是否冲突。\n\n继续前面的实验，再打开一个终端窗口，看一下这个新的`bash`进程的地址空间，可以发现和先前的`bash`进程地址空间的布局差不多：\n\n```shell\n$ ps\n  PID TTY          TIME CMD\n30697 pts/1    00:00:00 bash\n30749 pts/1    00:00:00 ps\n$ cat /proc/30697/maps\n08048000-080f4000 r-xp 00000000 08:15 688142     /bin/bash\n080f4000-080f9000 rw-p 000ac000 08:15 688142     /bin/bash\n080f9000-080fe000 rw-p 080f9000 00:00 0 \n082d7000-084f9000 rw-p 082d7000 00:00 0          [heap]\nb7cf1000-b7cfb000 r-xp 00000000 08:15 581665     /lib/tls/i686/cmov/libnss_files-2.8.90.so\nb7cfb000-b7cfc000 r--p 00009000 08:15 581665     /lib/tls/i686/cmov/libnss_files-2.8.90.so\nb7cfc000-b7cfd000 rw-p 0000a000 08:15 581665     /lib/tls/i686/cmov/libnss_files-2.8.90.so\n...\nb7e5e000-b7fb6000 r-xp 00000000 08:15 581656     /lib/tls/i686/cmov/libc-2.8.90.so\nb7fb6000-b7fb8000 r--p 00158000 08:15 581656     /lib/tls/i686/cmov/libc-2.8.90.so\nb7fb8000-b7fb9000 rw-p 0015a000 08:15 581656     /lib/tls/i686/cmov/libc-2.8.90.so\n...\nb8006000-b8020000 r-xp 00000000 08:15 565466     /lib/ld-2.8.90.so\nb8020000-b8021000 r-xp b8020000 00:00 0          [vdso]\nb8021000-b8022000 r--p 0001a000 08:15 565466     /lib/ld-2.8.90.so\nb8022000-b8023000 rw-p 0001b000 08:15 565466     /lib/ld-2.8.90.so\nbff0e000-bff23000 rw-p bffeb000 00:00 0          [stack]\n```\n\n该进程也占用了0x0000 0000-0xbfff ffff的地址空间，Text Segment也是0x0804 8000-0x080f 4000，Data Segment也是0x080f 4000-0x080f 9000，和先前的进程一模一样，因为这些地址是在编译链接时写进`/bin/bash`这个可执行文件的，两个进程都加载它。这两个进程在同一个系统中同时运行着，它们的Data Segment占用相同的VA，但是两个进程各自干各自的事情，显然Data Segment中的数据应该是不同的，相同的VA怎么会有不同的数据呢？因为它们被映射到不同的PA。如下图所示。\n\n**图 20.5. 进程地址空间是独立的**\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1665229505062-380026ae-9136-4837-ac8c-28e7d794a3d6.png)\n\n从图中还可以看到，两个进程都是`bash`进程，Text Segment是一样的，并且Text Segment是只读的，不会被改写，因此操作系统会安排两个进程的Text Segment共享相同的物理页面。由于每个进程都有自己的一套VA到PA的映射表，整个地址空间中的任何VA都在每个进程自己的映射表中查找相应的PA，因此不可能访问到其它进程的地址，也就没有可能意外改写其它进程的数据。\n\n另外，注意到两个进程的共享库加载地址并不相同，共享库的加载地址是在运行时决定的，而不是写在`/bin/bash`这个可执行文件中。但即使如此，也不影响两个进程共享相同物理页面中的共享库，当然，只有只读的部分是共享的，可读可写的部分不共享。\n\n**使用共享库可以大大节省内存。比如`libc`，系统中几乎所有的进程都映射`libc`到自己的进程地址空间，而`libc`的只读部分在物理内存中只需要存在一份，就可以被所有进程共享，这就是“共享库”这个名称的由来了。**\n\n现在我们也可以理解为什么共享库必须是位置无关代码了。比如`libc`，不同的进程虽然共享`libc`所在的物理页面，但这些物理页面被映射到各进程的虚拟地址空间时却位于不同的地址，所以要求`libc`的代码不管加载到什么地址都能正确执行。\n\n### 第三，VA到PA的映射会给分配和释放内存带来方便，物理地址不连续的几块内存可以映射成虚拟地址连续的一块内存。\n\n比如要用`malloc`分配一块很大的内存空间，虽然有足够多的空闲物理内存，却没有足够大的*连续*空闲内存，这时就可以分配多个不连续的物理页面而映射到连续的虚拟地址范围。如下图所示。\n\n**图 20.6. 不连续的PA可以映射为连续的VA**\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1665229512867-30829a8c-dc36-47c3-a300-9afec24b0b0a.png)\n\n### 四，一个系统如果同时运行着很多进程，为各进程分配的内存之和可能会大于实际可用的物理内存，虚拟内存管理使得这种情况下各进程仍然能够正常运行。\n\n因为各进程分配的只不过是虚拟内存的页面，这些页面的数据可以映射到物理页面，也可以临时保存到磁盘上而不占用物理页面，在磁盘上临时保存虚拟内存页面的可能是一个磁盘分区，也可能是一个磁盘文件，称为**交换设备（Swap Device）**。当物理内存不够用时，将一些不常用的物理页面中的数据临时保存到交换设备，然后这个物理页面就认为是空闲的了，可以重新分配给进程使用，这个过程称为**换出（Page out）**。如果进程要用到被换出的页面，就从交换设备再加载回物理内存，这称为**换入（Page in）**。换出和换入操作统称为换页（Paging），因此：\n\n**系统中可分配的内存总量 = 物理内存的大小 + 交换设备的大小**\n\n如下图所示。第一张图是换出，将物理页面中的数据保存到磁盘，并解除地址映射，释放物理页面。第二张图是换入，从空闲的物理页面中分配一个，将磁盘暂存的页面加载回内存，并建立地址映射。\n\n\n\n**图 20.7. 换页**\n\n![image.png](https://cdn.nlark.com/yuque/0/2022/png/2500465/1665229520142-3901c155-5c01-4e50-b706-6f68f98236c6.png)\n\n\n\n","source":"_posts/os/虚拟内存.md","raw":"---\ntitle: 虚拟内存-从入门到跑路\ntags:\n  - 'os'\ncategories:\n  - [os]\ndate: 2022-10-08 18:41:38\nupdated: 2022-10-08 18:41:38\ncover:\ntop_img:\ndescription:\nkeywords:\n---\n\n>#### 虚拟内存可以提高系统的稳定性和安全性，主要通过以下两点：\n>\n> - 1、控制物理内存的访问权限。\n>\n>   例如，Text Segment被只读保护起来，防止被错误的指令意外改写，内核地址空间也被保护起来，防止在用户模式下执行错误的指令意外改写内核数据。这样，执行错误指令或恶意代码的破坏能力受到了限制，顶多使当前进程因段错误终止，而不会影响整个系统的稳定性。\n>\n> - 2、让每个进程有独立的地址空间。\n>\n>   所谓独立的地址空间是指，不同进程中的同一个VA被MMU映射到不同的PA，并且在某一个进程中访问任何地址都不可能访问到另外一个进程的数据，这样使得任何一个进程由于执行错误指令或恶意代码导致的非法内存访问都不会意外改写其它进程的数据，不会影响其它进程的运行，从而保证整个系统的稳定性。\n>\n>#### 虚拟内存 + 共享库可以大大节省内存。\n>\n> 比如`libc`共享库，系统中几乎所有的进程都映射`libc`到自己的进程地址空间，而`libc`的只读部分在物理内存中只需要存在一份，就可以被所有进程共享，这就是“共享库”这个名称的由来了。    \n>\n>#### 虚拟内存方便给分配和释放内存带来方便，物理地址不连续的几块内存可以映射成虚拟地址连续的一块内存。\n>\n>#### 虚拟内存带来了交换分区。这样就提高了系统中可分配的内存总量，可以运行更多进程。\n>\n>比如要用`malloc`分配一块很大的内存空间，虽然有足够多的空闲物理内存，却没有足够大的*连续*空闲内存，这时就可以分配多个不连续的物理页面而映射到连续的虚拟地址范围。\n\n## What-什么是虚拟内存\n\n> **虚拟内存**是计算机系统内存管理的一种技术。它使得应用程序认为它拥有连续可用的内存（一个连续完整的地址空间），而实际上[物理内存](https://zh.m.wikipedia.org/wiki/物理内存)通常被分隔成多个[内存碎片](https://zh.m.wikipedia.org/wiki/碎片化)，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。与没有使用虚拟内存技术的系统相比，使用这种技术使得大型程序的编写变得更容易，对真正的物理内存（例如[RAM](https://zh.m.wikipedia.org/wiki/隨機存取記憶體)）的使用也更有效率。此外，虚拟内存技术可以使多个[进程](https://zh.m.wikipedia.org/wiki/行程)共享同一个[运行库](https://zh.m.wikipedia.org/wiki/函式庫)，并通过分割不同进程的内存空间来提高系统的安全性。\n>\n> 注意：**虚拟内存**不只是“用磁盘空间来扩展物理内存”的意思——这只是扩充[内存级别](https://zh.m.wikipedia.org/wiki/記憶體階層)以使其包含[硬盘驱动器](https://zh.m.wikipedia.org/wiki/硬盘驱动器)而已。把内存扩展到磁盘只是使用虚拟内存技术的一个结果，它的作用也可以通过[覆盖](https://zh.m.wikipedia.org/wiki/覆盖_(编程))或者把处于不活动状态的程序以及它们的数据全部交换到磁盘上等方式来实现。对虚拟内存的定义是基于对[地址空间](https://zh.m.wikipedia.org/wiki/地址空间)的重定义的，即把地址空间定义为“连续的虚拟内存地址”，以借此“欺骗”程序，使它们以为自己正在使用一大块的“连续”地址。\n>\n> 那些需要快速存取或者相应时间非常稳定的[嵌入式](https://zh.m.wikipedia.org/wiki/嵌入式)系统，以及其他的具有特殊应用的计算机系统，可能会为了避免让[运算结果的可预测性](https://zh.m.wikipedia.org/wiki/确定性算法)降低，而选择不使用虚拟内存。\n\n## How\n\n> 虚拟内存技术是现代[计算机系统结构](https://zh.m.wikipedia.org/wiki/计算机系统结构)中不可分割的一部分。现代所有用于一般应用的[操作系统](https://zh.m.wikipedia.org/wiki/操作系统)都对普通的应用程序使用虚拟内存技术，例如文字处理软件，电子制表软件，多媒体播放器等等。大部分架构通过[CPU](https://zh.m.wikipedia.org/wiki/CPU)中独立的硬件**内存管理单元**（英语：**memory management unit**，缩写为**MMU**），有时称作**分页内存管理单元**（英语：**paged memory management unit**，缩写为**PMMU**)来辅助实现这一功能。\n\n- 操作系统利用体系结构提供的VA到PA的转换机制实现虚拟内存管理。\n\n  用`ps`命令查看当前终端下的进程，得知`bash`进程的id是27613，然后用`cat /proc/27613/maps`命令查看它的虚拟地址空间。`/proc`目录中的文件并不是真正的磁盘文件，而是由内核虚拟出来的文件系统，当前系统中运行的每个进程在`/proc`下都有一个子目录，目录名就是进程的id，查看目录下的文件可以得到该进程的相关信息。\n\n  ```shell\n  root@DESKTOP-KD33OT8:/home/demo# cat /proc/27613/maps\n  5589e9d2b000-5589e9d42000 r--p 00000000 08:10 225588                     /usr/bin/zsh\n  5589e9d42000-5589e9dd7000 r-xp 00017000 08:10 225588                     /usr/bin/zsh\n  5589e9dd7000-5589e9df9000 r--p 000ac000 08:10 225588                     /usr/bin/zsh\n  5589e9dfa000-5589e9dfc000 r--p 000ce000 08:10 225588                     /usr/bin/zsh\n  5589e9dfc000-5589e9e02000 rw-p 000d0000 08:10 225588                     /usr/bin/zsh\n  5589e9e02000-5589e9e16000 rw-p 00000000 00:00 0\n  5589eac55000-5589eb1af000 rw-p 00000000 00:00 0                          [heap]\n  7f90adfc6000-7f90adfc9000 r--p 00000000 08:10 225599                     /usr/lib/x86_64-linux-gnu/zsh/5.8/zsh/computil.so\n  7f90adfc9000-7f90adfd6000 r-xp 00003000 08:10 225599                     /usr/lib/x86_64-linux-gnu/zsh/5.8/zsh/computil.so\n  7f90adfd6000-7f90adfd8000 r--p 00010000 08:10 225599                     /usr/lib/x86_64-linux-gnu/zsh/5.8/zsh/computil.so\n  7f90adfd8000-7f90adfd9000 r--p 00011000 08:10 225599                     /usr/lib/x86_64-linux-gnu/zsh/5.8/zsh/computil.so\n  7f90adfd9000-7f90adfda000 rw-p 00012000 08:10 225599                     /usr/lib/x86_64-linux-gnu/zsh/5.8/zsh/computil.so\n  7f90adfda000-7f90ae25a000 r--s 00000000 08:10 225058                     /usr/share/zsh/functions/Completion/Unix.zwc\n  7f90ae265000-7f90ae28a000 r--s 00000000 08:10 225225                     /usr/share/zsh/functions/Completion/Zsh.zwc\n  7f90ae299000-7f90ae2b2000 r--s 00000000 08:10 225469                     /usr/share/zsh/functions/Zle.zwc\n  7f90ae2b6000-7f90ae2da000 rw-p 00000000 00:00 0\n  7f90ae325000-7f90ae331000 rw-p 00000000 00:00 0\n  7f90ae331000-7f90ae37d000 rw-p 00000000 00:00 0\n  7f90ae37d000-7f90ae381000 r--p 00000000 08:10 225596                     /usr/lib/x86_64-linux-gnu/zsh/5.8/zsh/compctl.so\n  7f90ae381000-7f90ae38d000 r-xp 00004000 08:10 225596                     /usr/lib/x86_64-linux-gnu/zsh/5.8/zsh/compctl.so\n  7f90ae38d000-7f90ae38f000 r--p 00010000 08:10 225596                     /usr/lib/x86_64-linux-gnu/zsh/5.8/zsh/compctl.so\n  7f90ae38f000-7f90ae390000 r--p 00011000 08:10 225596                     /usr/lib/x86_64-linux-gnu/zsh/5.8/zsh/compctl.so\n  7f90ae390000-7f90ae391000 rw-p 00012000 08:10 225596                     /usr/lib/x86_64-linux-gnu/zsh/5.8/zsh/compctl.so\n  7f90aecf3000-7f90aecf5000 rw-p 00000000 00:00 0\n  7f90aecf5000-7f90aecf6000 r--p 00000000 08:10 2985                       /usr/lib/locale/C.UTF-8/LC_TELEPHONE\n  7f90aecf6000-7f90aecf7000 r--p 00000000 08:10 2978                       /usr/lib/locale/C.UTF-8/LC_MEASUREMENT\n  7f90aecf7000-7f90aecfe000 r--s 00000000 08:10 264854                     /usr/lib/x86_64-linux-gnu/gconv/gconv-modules.cache\n  7f90aecfe000-7f90aecff000 r--p 00000000 08:10 38549                      /usr/lib/x86_64-linux-gnu/ld-2.31.so\n  7f90aecff000-7f90aed22000 r-xp 00001000 08:10 38549                      /usr/lib/x86_64-linux-gnu/ld-2.31.so\n  7f90aed22000-7f90aed2a000 r--p 00024000 08:10 38549                      /usr/lib/x86_64-linux-gnu/ld-2.31.so\n  7f90aed2a000-7f90aed2b000 r--p 00000000 08:10 2977                       /usr/lib/locale/C.UTF-8/LC_IDENTIFICATION\n  7f90aed2b000-7f90aed2c000 r--p 0002c000 08:10 38549                      /usr/lib/x86_64-linux-gnu/ld-2.31.so\n  7f90aed2c000-7f90aed2d000 rw-p 0002d000 08:10 38549                      /usr/lib/x86_64-linux-gnu/ld-2.31.so\n  7f90aed2d000-7f90aed2e000 rw-p 00000000 00:00 0\n  7ffeb1e2d000-7ffeb1e7c000 rw-p 00000000 00:00 0                          [stack]\n  7ffeb1f0c000-7ffeb1f10000 r--p 00000000 00:00 0                          [vvar]\n  7ffeb1f10000-7ffeb1f11000 r-xp 00000000 00:00 0                          [vdso]\n  ```\n  \n  \n\n## Why-为什么需要虚拟内存\n\n### 第一，虚拟内存管理可以控制物理内存的访问权限。\n\n**物理内存本身是不限制访问的，任何地址都可以读写，而操作系统要求不同的页面具有不同的访问权限，这是利用CPU模式和MMU的内存保护机制实现的。**例如，Text Segment被只读保护起来，防止被错误的指令意外改写，内核地址空间也被保护起来，防止在用户模式下执行错误的指令意外改写内核数据。这样，执行错误指令或恶意代码的破坏能力受到了限制，顶多使当前进程因段错误终止，而不会影响整个系统的稳定性。\n\n### 第二，虚拟内存管理最主要的作用是让每个进程有独立的地址空间。\n\n**所谓独立的地址空间是指，不同进程中的同一个VA被MMU映射到不同的PA，并且在某一个进程中访问任何地址都不可能访问到另外一个进程的数据，这样使得任何一个进程由于执行错误指令或恶意代码导致的非法内存访问都不会意外改写其它进程的数据，不会影响其它进程的运行，从而保证整个系统的稳定性。**另一方面，每个进程都认为自己独占整个虚拟地址空间，这样链接器和加载器的实现会比较容易，不必考虑各进程的地址范围是否冲突。\n\n继续前面的实验，再打开一个终端窗口，看一下这个新的`bash`进程的地址空间，可以发现和先前的`bash`进程地址空间的布局差不多：\n\n```shell\n$ ps\n  PID TTY          TIME CMD\n30697 pts/1    00:00:00 bash\n30749 pts/1    00:00:00 ps\n$ cat /proc/30697/maps\n08048000-080f4000 r-xp 00000000 08:15 688142     /bin/bash\n080f4000-080f9000 rw-p 000ac000 08:15 688142     /bin/bash\n080f9000-080fe000 rw-p 080f9000 00:00 0 \n082d7000-084f9000 rw-p 082d7000 00:00 0          [heap]\nb7cf1000-b7cfb000 r-xp 00000000 08:15 581665     /lib/tls/i686/cmov/libnss_files-2.8.90.so\nb7cfb000-b7cfc000 r--p 00009000 08:15 581665     /lib/tls/i686/cmov/libnss_files-2.8.90.so\nb7cfc000-b7cfd000 rw-p 0000a000 08:15 581665     /lib/tls/i686/cmov/libnss_files-2.8.90.so\n...\nb7e5e000-b7fb6000 r-xp 00000000 08:15 581656     /lib/tls/i686/cmov/libc-2.8.90.so\nb7fb6000-b7fb8000 r--p 00158000 08:15 581656     /lib/tls/i686/cmov/libc-2.8.90.so\nb7fb8000-b7fb9000 rw-p 0015a000 08:15 581656     /lib/tls/i686/cmov/libc-2.8.90.so\n...\nb8006000-b8020000 r-xp 00000000 08:15 565466     /lib/ld-2.8.90.so\nb8020000-b8021000 r-xp b8020000 00:00 0          [vdso]\nb8021000-b8022000 r--p 0001a000 08:15 565466     /lib/ld-2.8.90.so\nb8022000-b8023000 rw-p 0001b000 08:15 565466     /lib/ld-2.8.90.so\nbff0e000-bff23000 rw-p bffeb000 00:00 0          [stack]\n```\n\n该进程也占用了0x0000 0000-0xbfff ffff的地址空间，Text Segment也是0x0804 8000-0x080f 4000，Data Segment也是0x080f 4000-0x080f 9000，和先前的进程一模一样，因为这些地址是在编译链接时写进`/bin/bash`这个可执行文件的，两个进程都加载它。这两个进程在同一个系统中同时运行着，它们的Data Segment占用相同的VA，但是两个进程各自干各自的事情，显然Data Segment中的数据应该是不同的，相同的VA怎么会有不同的数据呢？因为它们被映射到不同的PA。如下图所示。\n\n**图 20.5. 进程地址空间是独立的**\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1665229505062-380026ae-9136-4837-ac8c-28e7d794a3d6.png)\n\n从图中还可以看到，两个进程都是`bash`进程，Text Segment是一样的，并且Text Segment是只读的，不会被改写，因此操作系统会安排两个进程的Text Segment共享相同的物理页面。由于每个进程都有自己的一套VA到PA的映射表，整个地址空间中的任何VA都在每个进程自己的映射表中查找相应的PA，因此不可能访问到其它进程的地址，也就没有可能意外改写其它进程的数据。\n\n另外，注意到两个进程的共享库加载地址并不相同，共享库的加载地址是在运行时决定的，而不是写在`/bin/bash`这个可执行文件中。但即使如此，也不影响两个进程共享相同物理页面中的共享库，当然，只有只读的部分是共享的，可读可写的部分不共享。\n\n**使用共享库可以大大节省内存。比如`libc`，系统中几乎所有的进程都映射`libc`到自己的进程地址空间，而`libc`的只读部分在物理内存中只需要存在一份，就可以被所有进程共享，这就是“共享库”这个名称的由来了。**\n\n现在我们也可以理解为什么共享库必须是位置无关代码了。比如`libc`，不同的进程虽然共享`libc`所在的物理页面，但这些物理页面被映射到各进程的虚拟地址空间时却位于不同的地址，所以要求`libc`的代码不管加载到什么地址都能正确执行。\n\n### 第三，VA到PA的映射会给分配和释放内存带来方便，物理地址不连续的几块内存可以映射成虚拟地址连续的一块内存。\n\n比如要用`malloc`分配一块很大的内存空间，虽然有足够多的空闲物理内存，却没有足够大的*连续*空闲内存，这时就可以分配多个不连续的物理页面而映射到连续的虚拟地址范围。如下图所示。\n\n**图 20.6. 不连续的PA可以映射为连续的VA**\n\n![img](https://cdn.nlark.com/yuque/0/2022/png/2500465/1665229512867-30829a8c-dc36-47c3-a300-9afec24b0b0a.png)\n\n### 四，一个系统如果同时运行着很多进程，为各进程分配的内存之和可能会大于实际可用的物理内存，虚拟内存管理使得这种情况下各进程仍然能够正常运行。\n\n因为各进程分配的只不过是虚拟内存的页面，这些页面的数据可以映射到物理页面，也可以临时保存到磁盘上而不占用物理页面，在磁盘上临时保存虚拟内存页面的可能是一个磁盘分区，也可能是一个磁盘文件，称为**交换设备（Swap Device）**。当物理内存不够用时，将一些不常用的物理页面中的数据临时保存到交换设备，然后这个物理页面就认为是空闲的了，可以重新分配给进程使用，这个过程称为**换出（Page out）**。如果进程要用到被换出的页面，就从交换设备再加载回物理内存，这称为**换入（Page in）**。换出和换入操作统称为换页（Paging），因此：\n\n**系统中可分配的内存总量 = 物理内存的大小 + 交换设备的大小**\n\n如下图所示。第一张图是换出，将物理页面中的数据保存到磁盘，并解除地址映射，释放物理页面。第二张图是换入，从空闲的物理页面中分配一个，将磁盘暂存的页面加载回内存，并建立地址映射。\n\n\n\n**图 20.7. 换页**\n\n![image.png](https://cdn.nlark.com/yuque/0/2022/png/2500465/1665229520142-3901c155-5c01-4e50-b706-6f68f98236c6.png)\n\n\n\n","slug":"os/虚拟内存","published":1,"comments":1,"layout":"post","photos":[],"link":"","_id":"cl9y38dtr005tfwuidykid4jv","content":"<blockquote>\n<h4 id=\"虚拟内存可以提高系统的稳定性和安全性，主要通过以下两点：\"><a href=\"#虚拟内存可以提高系统的稳定性和安全性，主要通过以下两点：\" class=\"headerlink\" title=\"虚拟内存可以提高系统的稳定性和安全性，主要通过以下两点：\"></a>虚拟内存可以提高系统的稳定性和安全性，主要通过以下两点：</h4><ul>\n<li><p>1、控制物理内存的访问权限。</p>\n<p>例如，Text Segment被只读保护起来，防止被错误的指令意外改写，内核地址空间也被保护起来，防止在用户模式下执行错误的指令意外改写内核数据。这样，执行错误指令或恶意代码的破坏能力受到了限制，顶多使当前进程因段错误终止，而不会影响整个系统的稳定性。</p>\n</li>\n<li><p>2、让每个进程有独立的地址空间。</p>\n<p>所谓独立的地址空间是指，不同进程中的同一个VA被MMU映射到不同的PA，并且在某一个进程中访问任何地址都不可能访问到另外一个进程的数据，这样使得任何一个进程由于执行错误指令或恶意代码导致的非法内存访问都不会意外改写其它进程的数据，不会影响其它进程的运行，从而保证整个系统的稳定性。</p>\n</li>\n</ul>\n<h4 id=\"虚拟内存-共享库可以大大节省内存。\"><a href=\"#虚拟内存-共享库可以大大节省内存。\" class=\"headerlink\" title=\"虚拟内存 + 共享库可以大大节省内存。\"></a>虚拟内存 + 共享库可以大大节省内存。</h4><p>比如<code>libc</code>共享库，系统中几乎所有的进程都映射<code>libc</code>到自己的进程地址空间，而<code>libc</code>的只读部分在物理内存中只需要存在一份，就可以被所有进程共享，这就是“共享库”这个名称的由来了。    </p>\n<h4 id=\"虚拟内存方便给分配和释放内存带来方便，物理地址不连续的几块内存可以映射成虚拟地址连续的一块内存。\"><a href=\"#虚拟内存方便给分配和释放内存带来方便，物理地址不连续的几块内存可以映射成虚拟地址连续的一块内存。\" class=\"headerlink\" title=\"虚拟内存方便给分配和释放内存带来方便，物理地址不连续的几块内存可以映射成虚拟地址连续的一块内存。\"></a>虚拟内存方便给分配和释放内存带来方便，物理地址不连续的几块内存可以映射成虚拟地址连续的一块内存。</h4><h4 id=\"虚拟内存带来了交换分区。这样就提高了系统中可分配的内存总量，可以运行更多进程。\"><a href=\"#虚拟内存带来了交换分区。这样就提高了系统中可分配的内存总量，可以运行更多进程。\" class=\"headerlink\" title=\"虚拟内存带来了交换分区。这样就提高了系统中可分配的内存总量，可以运行更多进程。\"></a>虚拟内存带来了交换分区。这样就提高了系统中可分配的内存总量，可以运行更多进程。</h4><p>比如要用<code>malloc</code>分配一块很大的内存空间，虽然有足够多的空闲物理内存，却没有足够大的<em>连续</em>空闲内存，这时就可以分配多个不连续的物理页面而映射到连续的虚拟地址范围。</p>\n</blockquote>\n<h2 id=\"What-什么是虚拟内存\"><a href=\"#What-什么是虚拟内存\" class=\"headerlink\" title=\"What-什么是虚拟内存\"></a>What-什么是虚拟内存</h2><blockquote>\n<p><strong>虚拟内存</strong>是计算机系统内存管理的一种技术。它使得应用程序认为它拥有连续可用的内存（一个连续完整的地址空间），而实际上<a href=\"https://zh.m.wikipedia.org/wiki/%E7%89%A9%E7%90%86%E5%86%85%E5%AD%98\">物理内存</a>通常被分隔成多个<a href=\"https://zh.m.wikipedia.org/wiki/%E7%A2%8E%E7%89%87%E5%8C%96\">内存碎片</a>，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。与没有使用虚拟内存技术的系统相比，使用这种技术使得大型程序的编写变得更容易，对真正的物理内存（例如<a href=\"https://zh.m.wikipedia.org/wiki/%E9%9A%A8%E6%A9%9F%E5%AD%98%E5%8F%96%E8%A8%98%E6%86%B6%E9%AB%94\">RAM</a>）的使用也更有效率。此外，虚拟内存技术可以使多个<a href=\"https://zh.m.wikipedia.org/wiki/%E8%A1%8C%E7%A8%8B\">进程</a>共享同一个<a href=\"https://zh.m.wikipedia.org/wiki/%E5%87%BD%E5%BC%8F%E5%BA%AB\">运行库</a>，并通过分割不同进程的内存空间来提高系统的安全性。</p>\n<p>注意：<strong>虚拟内存</strong>不只是“用磁盘空间来扩展物理内存”的意思——这只是扩充<a href=\"https://zh.m.wikipedia.org/wiki/%E8%A8%98%E6%86%B6%E9%AB%94%E9%9A%8E%E5%B1%A4\">内存级别</a>以使其包含<a href=\"https://zh.m.wikipedia.org/wiki/%E7%A1%AC%E7%9B%98%E9%A9%B1%E5%8A%A8%E5%99%A8\">硬盘驱动器</a>而已。把内存扩展到磁盘只是使用虚拟内存技术的一个结果，它的作用也可以通过<a href=\"https://zh.m.wikipedia.org/wiki/%E8%A6%86%E7%9B%96_(%E7%BC%96%E7%A8%8B)\">覆盖</a>或者把处于不活动状态的程序以及它们的数据全部交换到磁盘上等方式来实现。对虚拟内存的定义是基于对<a href=\"https://zh.m.wikipedia.org/wiki/%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4\">地址空间</a>的重定义的，即把地址空间定义为“连续的虚拟内存地址”，以借此“欺骗”程序，使它们以为自己正在使用一大块的“连续”地址。</p>\n<p>那些需要快速存取或者相应时间非常稳定的<a href=\"https://zh.m.wikipedia.org/wiki/%E5%B5%8C%E5%85%A5%E5%BC%8F\">嵌入式</a>系统，以及其他的具有特殊应用的计算机系统，可能会为了避免让<a href=\"https://zh.m.wikipedia.org/wiki/%E7%A1%AE%E5%AE%9A%E6%80%A7%E7%AE%97%E6%B3%95\">运算结果的可预测性</a>降低，而选择不使用虚拟内存。</p>\n</blockquote>\n<h2 id=\"How\"><a href=\"#How\" class=\"headerlink\" title=\"How\"></a>How</h2><blockquote>\n<p>虚拟内存技术是现代<a href=\"https://zh.m.wikipedia.org/wiki/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E7%BB%93%E6%9E%84\">计算机系统结构</a>中不可分割的一部分。现代所有用于一般应用的<a href=\"https://zh.m.wikipedia.org/wiki/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F\">操作系统</a>都对普通的应用程序使用虚拟内存技术，例如文字处理软件，电子制表软件，多媒体播放器等等。大部分架构通过<a href=\"https://zh.m.wikipedia.org/wiki/CPU\">CPU</a>中独立的硬件<strong>内存管理单元</strong>（英语：<strong>memory management unit</strong>，缩写为<strong>MMU</strong>），有时称作<strong>分页内存管理单元</strong>（英语：<strong>paged memory management unit</strong>，缩写为<strong>PMMU</strong>)来辅助实现这一功能。</p>\n</blockquote>\n<ul>\n<li><p>操作系统利用体系结构提供的VA到PA的转换机制实现虚拟内存管理。</p>\n<p>用<code>ps</code>命令查看当前终端下的进程，得知<code>bash</code>进程的id是27613，然后用<code>cat /proc/27613/maps</code>命令查看它的虚拟地址空间。<code>/proc</code>目录中的文件并不是真正的磁盘文件，而是由内核虚拟出来的文件系统，当前系统中运行的每个进程在<code>/proc</code>下都有一个子目录，目录名就是进程的id，查看目录下的文件可以得到该进程的相关信息。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@DESKTOP-KD33OT8:/home/demo# cat /proc/27613/maps</span><br><span class=\"line\">5589e9d2b000-5589e9d42000 r--p 00000000 08:10 225588                     /usr/bin/zsh</span><br><span class=\"line\">5589e9d42000-5589e9dd7000 r-xp 00017000 08:10 225588                     /usr/bin/zsh</span><br><span class=\"line\">5589e9dd7000-5589e9df9000 r--p 000ac000 08:10 225588                     /usr/bin/zsh</span><br><span class=\"line\">5589e9dfa000-5589e9dfc000 r--p 000ce000 08:10 225588                     /usr/bin/zsh</span><br><span class=\"line\">5589e9dfc000-5589e9e02000 rw-p 000d0000 08:10 225588                     /usr/bin/zsh</span><br><span class=\"line\">5589e9e02000-5589e9e16000 rw-p 00000000 00:00 0</span><br><span class=\"line\">5589eac55000-5589eb1af000 rw-p 00000000 00:00 0                          [heap]</span><br><span class=\"line\">7f90adfc6000-7f90adfc9000 r--p 00000000 08:10 225599                     /usr/lib/x86_64-linux-gnu/zsh/5.8/zsh/computil.so</span><br><span class=\"line\">7f90adfc9000-7f90adfd6000 r-xp 00003000 08:10 225599                     /usr/lib/x86_64-linux-gnu/zsh/5.8/zsh/computil.so</span><br><span class=\"line\">7f90adfd6000-7f90adfd8000 r--p 00010000 08:10 225599                     /usr/lib/x86_64-linux-gnu/zsh/5.8/zsh/computil.so</span><br><span class=\"line\">7f90adfd8000-7f90adfd9000 r--p 00011000 08:10 225599                     /usr/lib/x86_64-linux-gnu/zsh/5.8/zsh/computil.so</span><br><span class=\"line\">7f90adfd9000-7f90adfda000 rw-p 00012000 08:10 225599                     /usr/lib/x86_64-linux-gnu/zsh/5.8/zsh/computil.so</span><br><span class=\"line\">7f90adfda000-7f90ae25a000 r--s 00000000 08:10 225058                     /usr/share/zsh/functions/Completion/Unix.zwc</span><br><span class=\"line\">7f90ae265000-7f90ae28a000 r--s 00000000 08:10 225225                     /usr/share/zsh/functions/Completion/Zsh.zwc</span><br><span class=\"line\">7f90ae299000-7f90ae2b2000 r--s 00000000 08:10 225469                     /usr/share/zsh/functions/Zle.zwc</span><br><span class=\"line\">7f90ae2b6000-7f90ae2da000 rw-p 00000000 00:00 0</span><br><span class=\"line\">7f90ae325000-7f90ae331000 rw-p 00000000 00:00 0</span><br><span class=\"line\">7f90ae331000-7f90ae37d000 rw-p 00000000 00:00 0</span><br><span class=\"line\">7f90ae37d000-7f90ae381000 r--p 00000000 08:10 225596                     /usr/lib/x86_64-linux-gnu/zsh/5.8/zsh/compctl.so</span><br><span class=\"line\">7f90ae381000-7f90ae38d000 r-xp 00004000 08:10 225596                     /usr/lib/x86_64-linux-gnu/zsh/5.8/zsh/compctl.so</span><br><span class=\"line\">7f90ae38d000-7f90ae38f000 r--p 00010000 08:10 225596                     /usr/lib/x86_64-linux-gnu/zsh/5.8/zsh/compctl.so</span><br><span class=\"line\">7f90ae38f000-7f90ae390000 r--p 00011000 08:10 225596                     /usr/lib/x86_64-linux-gnu/zsh/5.8/zsh/compctl.so</span><br><span class=\"line\">7f90ae390000-7f90ae391000 rw-p 00012000 08:10 225596                     /usr/lib/x86_64-linux-gnu/zsh/5.8/zsh/compctl.so</span><br><span class=\"line\">7f90aecf3000-7f90aecf5000 rw-p 00000000 00:00 0</span><br><span class=\"line\">7f90aecf5000-7f90aecf6000 r--p 00000000 08:10 2985                       /usr/lib/locale/C.UTF-8/LC_TELEPHONE</span><br><span class=\"line\">7f90aecf6000-7f90aecf7000 r--p 00000000 08:10 2978                       /usr/lib/locale/C.UTF-8/LC_MEASUREMENT</span><br><span class=\"line\">7f90aecf7000-7f90aecfe000 r--s 00000000 08:10 264854                     /usr/lib/x86_64-linux-gnu/gconv/gconv-modules.cache</span><br><span class=\"line\">7f90aecfe000-7f90aecff000 r--p 00000000 08:10 38549                      /usr/lib/x86_64-linux-gnu/ld-2.31.so</span><br><span class=\"line\">7f90aecff000-7f90aed22000 r-xp 00001000 08:10 38549                      /usr/lib/x86_64-linux-gnu/ld-2.31.so</span><br><span class=\"line\">7f90aed22000-7f90aed2a000 r--p 00024000 08:10 38549                      /usr/lib/x86_64-linux-gnu/ld-2.31.so</span><br><span class=\"line\">7f90aed2a000-7f90aed2b000 r--p 00000000 08:10 2977                       /usr/lib/locale/C.UTF-8/LC_IDENTIFICATION</span><br><span class=\"line\">7f90aed2b000-7f90aed2c000 r--p 0002c000 08:10 38549                      /usr/lib/x86_64-linux-gnu/ld-2.31.so</span><br><span class=\"line\">7f90aed2c000-7f90aed2d000 rw-p 0002d000 08:10 38549                      /usr/lib/x86_64-linux-gnu/ld-2.31.so</span><br><span class=\"line\">7f90aed2d000-7f90aed2e000 rw-p 00000000 00:00 0</span><br><span class=\"line\">7ffeb1e2d000-7ffeb1e7c000 rw-p 00000000 00:00 0                          [stack]</span><br><span class=\"line\">7ffeb1f0c000-7ffeb1f10000 r--p 00000000 00:00 0                          [vvar]</span><br><span class=\"line\">7ffeb1f10000-7ffeb1f11000 r-xp 00000000 00:00 0                          [vdso]</span><br></pre></td></tr></table></figure></li>\n</ul>\n<h2 id=\"Why-为什么需要虚拟内存\"><a href=\"#Why-为什么需要虚拟内存\" class=\"headerlink\" title=\"Why-为什么需要虚拟内存\"></a>Why-为什么需要虚拟内存</h2><h3 id=\"第一，虚拟内存管理可以控制物理内存的访问权限。\"><a href=\"#第一，虚拟内存管理可以控制物理内存的访问权限。\" class=\"headerlink\" title=\"第一，虚拟内存管理可以控制物理内存的访问权限。\"></a>第一，虚拟内存管理可以控制物理内存的访问权限。</h3><p><strong>物理内存本身是不限制访问的，任何地址都可以读写，而操作系统要求不同的页面具有不同的访问权限，这是利用CPU模式和MMU的内存保护机制实现的。</strong>例如，Text Segment被只读保护起来，防止被错误的指令意外改写，内核地址空间也被保护起来，防止在用户模式下执行错误的指令意外改写内核数据。这样，执行错误指令或恶意代码的破坏能力受到了限制，顶多使当前进程因段错误终止，而不会影响整个系统的稳定性。</p>\n<h3 id=\"第二，虚拟内存管理最主要的作用是让每个进程有独立的地址空间。\"><a href=\"#第二，虚拟内存管理最主要的作用是让每个进程有独立的地址空间。\" class=\"headerlink\" title=\"第二，虚拟内存管理最主要的作用是让每个进程有独立的地址空间。\"></a>第二，虚拟内存管理最主要的作用是让每个进程有独立的地址空间。</h3><p><strong>所谓独立的地址空间是指，不同进程中的同一个VA被MMU映射到不同的PA，并且在某一个进程中访问任何地址都不可能访问到另外一个进程的数据，这样使得任何一个进程由于执行错误指令或恶意代码导致的非法内存访问都不会意外改写其它进程的数据，不会影响其它进程的运行，从而保证整个系统的稳定性。</strong>另一方面，每个进程都认为自己独占整个虚拟地址空间，这样链接器和加载器的实现会比较容易，不必考虑各进程的地址范围是否冲突。</p>\n<p>继续前面的实验，再打开一个终端窗口，看一下这个新的<code>bash</code>进程的地址空间，可以发现和先前的<code>bash</code>进程地址空间的布局差不多：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\">$ </span><span class=\"language-bash\">ps</span></span><br><span class=\"line\">  PID TTY          TIME CMD</span><br><span class=\"line\">30697 pts/1    00:00:00 bash</span><br><span class=\"line\">30749 pts/1    00:00:00 ps</span><br><span class=\"line\"><span class=\"meta prompt_\">$ </span><span class=\"language-bash\"><span class=\"built_in\">cat</span> /proc/30697/maps</span></span><br><span class=\"line\">08048000-080f4000 r-xp 00000000 08:15 688142     /bin/bash</span><br><span class=\"line\">080f4000-080f9000 rw-p 000ac000 08:15 688142     /bin/bash</span><br><span class=\"line\">080f9000-080fe000 rw-p 080f9000 00:00 0 </span><br><span class=\"line\">082d7000-084f9000 rw-p 082d7000 00:00 0          [heap]</span><br><span class=\"line\">b7cf1000-b7cfb000 r-xp 00000000 08:15 581665     /lib/tls/i686/cmov/libnss_files-2.8.90.so</span><br><span class=\"line\">b7cfb000-b7cfc000 r--p 00009000 08:15 581665     /lib/tls/i686/cmov/libnss_files-2.8.90.so</span><br><span class=\"line\">b7cfc000-b7cfd000 rw-p 0000a000 08:15 581665     /lib/tls/i686/cmov/libnss_files-2.8.90.so</span><br><span class=\"line\">...</span><br><span class=\"line\">b7e5e000-b7fb6000 r-xp 00000000 08:15 581656     /lib/tls/i686/cmov/libc-2.8.90.so</span><br><span class=\"line\">b7fb6000-b7fb8000 r--p 00158000 08:15 581656     /lib/tls/i686/cmov/libc-2.8.90.so</span><br><span class=\"line\">b7fb8000-b7fb9000 rw-p 0015a000 08:15 581656     /lib/tls/i686/cmov/libc-2.8.90.so</span><br><span class=\"line\">...</span><br><span class=\"line\">b8006000-b8020000 r-xp 00000000 08:15 565466     /lib/ld-2.8.90.so</span><br><span class=\"line\">b8020000-b8021000 r-xp b8020000 00:00 0          [vdso]</span><br><span class=\"line\">b8021000-b8022000 r--p 0001a000 08:15 565466     /lib/ld-2.8.90.so</span><br><span class=\"line\">b8022000-b8023000 rw-p 0001b000 08:15 565466     /lib/ld-2.8.90.so</span><br><span class=\"line\">bff0e000-bff23000 rw-p bffeb000 00:00 0          [stack]</span><br></pre></td></tr></table></figure>\n\n<p>该进程也占用了0x0000 0000-0xbfff ffff的地址空间，Text Segment也是0x0804 8000-0x080f 4000，Data Segment也是0x080f 4000-0x080f 9000，和先前的进程一模一样，因为这些地址是在编译链接时写进<code>/bin/bash</code>这个可执行文件的，两个进程都加载它。这两个进程在同一个系统中同时运行着，它们的Data Segment占用相同的VA，但是两个进程各自干各自的事情，显然Data Segment中的数据应该是不同的，相同的VA怎么会有不同的数据呢？因为它们被映射到不同的PA。如下图所示。</p>\n<p><strong>图 20.5. 进程地址空间是独立的</strong></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1665229505062-380026ae-9136-4837-ac8c-28e7d794a3d6.png\" alt=\"img\"></p>\n<p>从图中还可以看到，两个进程都是<code>bash</code>进程，Text Segment是一样的，并且Text Segment是只读的，不会被改写，因此操作系统会安排两个进程的Text Segment共享相同的物理页面。由于每个进程都有自己的一套VA到PA的映射表，整个地址空间中的任何VA都在每个进程自己的映射表中查找相应的PA，因此不可能访问到其它进程的地址，也就没有可能意外改写其它进程的数据。</p>\n<p>另外，注意到两个进程的共享库加载地址并不相同，共享库的加载地址是在运行时决定的，而不是写在<code>/bin/bash</code>这个可执行文件中。但即使如此，也不影响两个进程共享相同物理页面中的共享库，当然，只有只读的部分是共享的，可读可写的部分不共享。</p>\n<p><strong>使用共享库可以大大节省内存。比如<code>libc</code>，系统中几乎所有的进程都映射<code>libc</code>到自己的进程地址空间，而<code>libc</code>的只读部分在物理内存中只需要存在一份，就可以被所有进程共享，这就是“共享库”这个名称的由来了。</strong></p>\n<p>现在我们也可以理解为什么共享库必须是位置无关代码了。比如<code>libc</code>，不同的进程虽然共享<code>libc</code>所在的物理页面，但这些物理页面被映射到各进程的虚拟地址空间时却位于不同的地址，所以要求<code>libc</code>的代码不管加载到什么地址都能正确执行。</p>\n<h3 id=\"第三，VA到PA的映射会给分配和释放内存带来方便，物理地址不连续的几块内存可以映射成虚拟地址连续的一块内存。\"><a href=\"#第三，VA到PA的映射会给分配和释放内存带来方便，物理地址不连续的几块内存可以映射成虚拟地址连续的一块内存。\" class=\"headerlink\" title=\"第三，VA到PA的映射会给分配和释放内存带来方便，物理地址不连续的几块内存可以映射成虚拟地址连续的一块内存。\"></a>第三，VA到PA的映射会给分配和释放内存带来方便，物理地址不连续的几块内存可以映射成虚拟地址连续的一块内存。</h3><p>比如要用<code>malloc</code>分配一块很大的内存空间，虽然有足够多的空闲物理内存，却没有足够大的<em>连续</em>空闲内存，这时就可以分配多个不连续的物理页面而映射到连续的虚拟地址范围。如下图所示。</p>\n<p><strong>图 20.6. 不连续的PA可以映射为连续的VA</strong></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1665229512867-30829a8c-dc36-47c3-a300-9afec24b0b0a.png\" alt=\"img\"></p>\n<h3 id=\"四，一个系统如果同时运行着很多进程，为各进程分配的内存之和可能会大于实际可用的物理内存，虚拟内存管理使得这种情况下各进程仍然能够正常运行。\"><a href=\"#四，一个系统如果同时运行着很多进程，为各进程分配的内存之和可能会大于实际可用的物理内存，虚拟内存管理使得这种情况下各进程仍然能够正常运行。\" class=\"headerlink\" title=\"四，一个系统如果同时运行着很多进程，为各进程分配的内存之和可能会大于实际可用的物理内存，虚拟内存管理使得这种情况下各进程仍然能够正常运行。\"></a>四，一个系统如果同时运行着很多进程，为各进程分配的内存之和可能会大于实际可用的物理内存，虚拟内存管理使得这种情况下各进程仍然能够正常运行。</h3><p>因为各进程分配的只不过是虚拟内存的页面，这些页面的数据可以映射到物理页面，也可以临时保存到磁盘上而不占用物理页面，在磁盘上临时保存虚拟内存页面的可能是一个磁盘分区，也可能是一个磁盘文件，称为<strong>交换设备（Swap Device）</strong>。当物理内存不够用时，将一些不常用的物理页面中的数据临时保存到交换设备，然后这个物理页面就认为是空闲的了，可以重新分配给进程使用，这个过程称为<strong>换出（Page out）</strong>。如果进程要用到被换出的页面，就从交换设备再加载回物理内存，这称为<strong>换入（Page in）</strong>。换出和换入操作统称为换页（Paging），因此：</p>\n<p><strong>系统中可分配的内存总量 &#x3D; 物理内存的大小 + 交换设备的大小</strong></p>\n<p>如下图所示。第一张图是换出，将物理页面中的数据保存到磁盘，并解除地址映射，释放物理页面。第二张图是换入，从空闲的物理页面中分配一个，将磁盘暂存的页面加载回内存，并建立地址映射。</p>\n<p><strong>图 20.7. 换页</strong></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1665229520142-3901c155-5c01-4e50-b706-6f68f98236c6.png\" alt=\"image.png\"></p>\n","site":{"data":{"link":[{"class_name":"友情链接","class_desc":"那些人，那些事","link_list":[{"name":"张洪Heo","link":"https://blog.zhheo.com/","avatar":"https://npm.elemecdn.com/guli-heo/img/avatar2.png","descr":"分享设计与科技生活"},{"name":"瞬間の筆記","link":"https://hikki.site","descr":"喜欢的东西就努力去追求，万一成功了呢!","avatar":"https://cdn.jsdelivr.net/gh/0000rookie/imgs/202206120315.png"}]}]}},"excerpt":"","more":"<blockquote>\n<h4 id=\"虚拟内存可以提高系统的稳定性和安全性，主要通过以下两点：\"><a href=\"#虚拟内存可以提高系统的稳定性和安全性，主要通过以下两点：\" class=\"headerlink\" title=\"虚拟内存可以提高系统的稳定性和安全性，主要通过以下两点：\"></a>虚拟内存可以提高系统的稳定性和安全性，主要通过以下两点：</h4><ul>\n<li><p>1、控制物理内存的访问权限。</p>\n<p>例如，Text Segment被只读保护起来，防止被错误的指令意外改写，内核地址空间也被保护起来，防止在用户模式下执行错误的指令意外改写内核数据。这样，执行错误指令或恶意代码的破坏能力受到了限制，顶多使当前进程因段错误终止，而不会影响整个系统的稳定性。</p>\n</li>\n<li><p>2、让每个进程有独立的地址空间。</p>\n<p>所谓独立的地址空间是指，不同进程中的同一个VA被MMU映射到不同的PA，并且在某一个进程中访问任何地址都不可能访问到另外一个进程的数据，这样使得任何一个进程由于执行错误指令或恶意代码导致的非法内存访问都不会意外改写其它进程的数据，不会影响其它进程的运行，从而保证整个系统的稳定性。</p>\n</li>\n</ul>\n<h4 id=\"虚拟内存-共享库可以大大节省内存。\"><a href=\"#虚拟内存-共享库可以大大节省内存。\" class=\"headerlink\" title=\"虚拟内存 + 共享库可以大大节省内存。\"></a>虚拟内存 + 共享库可以大大节省内存。</h4><p>比如<code>libc</code>共享库，系统中几乎所有的进程都映射<code>libc</code>到自己的进程地址空间，而<code>libc</code>的只读部分在物理内存中只需要存在一份，就可以被所有进程共享，这就是“共享库”这个名称的由来了。    </p>\n<h4 id=\"虚拟内存方便给分配和释放内存带来方便，物理地址不连续的几块内存可以映射成虚拟地址连续的一块内存。\"><a href=\"#虚拟内存方便给分配和释放内存带来方便，物理地址不连续的几块内存可以映射成虚拟地址连续的一块内存。\" class=\"headerlink\" title=\"虚拟内存方便给分配和释放内存带来方便，物理地址不连续的几块内存可以映射成虚拟地址连续的一块内存。\"></a>虚拟内存方便给分配和释放内存带来方便，物理地址不连续的几块内存可以映射成虚拟地址连续的一块内存。</h4><h4 id=\"虚拟内存带来了交换分区。这样就提高了系统中可分配的内存总量，可以运行更多进程。\"><a href=\"#虚拟内存带来了交换分区。这样就提高了系统中可分配的内存总量，可以运行更多进程。\" class=\"headerlink\" title=\"虚拟内存带来了交换分区。这样就提高了系统中可分配的内存总量，可以运行更多进程。\"></a>虚拟内存带来了交换分区。这样就提高了系统中可分配的内存总量，可以运行更多进程。</h4><p>比如要用<code>malloc</code>分配一块很大的内存空间，虽然有足够多的空闲物理内存，却没有足够大的<em>连续</em>空闲内存，这时就可以分配多个不连续的物理页面而映射到连续的虚拟地址范围。</p>\n</blockquote>\n<h2 id=\"What-什么是虚拟内存\"><a href=\"#What-什么是虚拟内存\" class=\"headerlink\" title=\"What-什么是虚拟内存\"></a>What-什么是虚拟内存</h2><blockquote>\n<p><strong>虚拟内存</strong>是计算机系统内存管理的一种技术。它使得应用程序认为它拥有连续可用的内存（一个连续完整的地址空间），而实际上<a href=\"https://zh.m.wikipedia.org/wiki/%E7%89%A9%E7%90%86%E5%86%85%E5%AD%98\">物理内存</a>通常被分隔成多个<a href=\"https://zh.m.wikipedia.org/wiki/%E7%A2%8E%E7%89%87%E5%8C%96\">内存碎片</a>，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。与没有使用虚拟内存技术的系统相比，使用这种技术使得大型程序的编写变得更容易，对真正的物理内存（例如<a href=\"https://zh.m.wikipedia.org/wiki/%E9%9A%A8%E6%A9%9F%E5%AD%98%E5%8F%96%E8%A8%98%E6%86%B6%E9%AB%94\">RAM</a>）的使用也更有效率。此外，虚拟内存技术可以使多个<a href=\"https://zh.m.wikipedia.org/wiki/%E8%A1%8C%E7%A8%8B\">进程</a>共享同一个<a href=\"https://zh.m.wikipedia.org/wiki/%E5%87%BD%E5%BC%8F%E5%BA%AB\">运行库</a>，并通过分割不同进程的内存空间来提高系统的安全性。</p>\n<p>注意：<strong>虚拟内存</strong>不只是“用磁盘空间来扩展物理内存”的意思——这只是扩充<a href=\"https://zh.m.wikipedia.org/wiki/%E8%A8%98%E6%86%B6%E9%AB%94%E9%9A%8E%E5%B1%A4\">内存级别</a>以使其包含<a href=\"https://zh.m.wikipedia.org/wiki/%E7%A1%AC%E7%9B%98%E9%A9%B1%E5%8A%A8%E5%99%A8\">硬盘驱动器</a>而已。把内存扩展到磁盘只是使用虚拟内存技术的一个结果，它的作用也可以通过<a href=\"https://zh.m.wikipedia.org/wiki/%E8%A6%86%E7%9B%96_(%E7%BC%96%E7%A8%8B)\">覆盖</a>或者把处于不活动状态的程序以及它们的数据全部交换到磁盘上等方式来实现。对虚拟内存的定义是基于对<a href=\"https://zh.m.wikipedia.org/wiki/%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4\">地址空间</a>的重定义的，即把地址空间定义为“连续的虚拟内存地址”，以借此“欺骗”程序，使它们以为自己正在使用一大块的“连续”地址。</p>\n<p>那些需要快速存取或者相应时间非常稳定的<a href=\"https://zh.m.wikipedia.org/wiki/%E5%B5%8C%E5%85%A5%E5%BC%8F\">嵌入式</a>系统，以及其他的具有特殊应用的计算机系统，可能会为了避免让<a href=\"https://zh.m.wikipedia.org/wiki/%E7%A1%AE%E5%AE%9A%E6%80%A7%E7%AE%97%E6%B3%95\">运算结果的可预测性</a>降低，而选择不使用虚拟内存。</p>\n</blockquote>\n<h2 id=\"How\"><a href=\"#How\" class=\"headerlink\" title=\"How\"></a>How</h2><blockquote>\n<p>虚拟内存技术是现代<a href=\"https://zh.m.wikipedia.org/wiki/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E7%BB%93%E6%9E%84\">计算机系统结构</a>中不可分割的一部分。现代所有用于一般应用的<a href=\"https://zh.m.wikipedia.org/wiki/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F\">操作系统</a>都对普通的应用程序使用虚拟内存技术，例如文字处理软件，电子制表软件，多媒体播放器等等。大部分架构通过<a href=\"https://zh.m.wikipedia.org/wiki/CPU\">CPU</a>中独立的硬件<strong>内存管理单元</strong>（英语：<strong>memory management unit</strong>，缩写为<strong>MMU</strong>），有时称作<strong>分页内存管理单元</strong>（英语：<strong>paged memory management unit</strong>，缩写为<strong>PMMU</strong>)来辅助实现这一功能。</p>\n</blockquote>\n<ul>\n<li><p>操作系统利用体系结构提供的VA到PA的转换机制实现虚拟内存管理。</p>\n<p>用<code>ps</code>命令查看当前终端下的进程，得知<code>bash</code>进程的id是27613，然后用<code>cat /proc/27613/maps</code>命令查看它的虚拟地址空间。<code>/proc</code>目录中的文件并不是真正的磁盘文件，而是由内核虚拟出来的文件系统，当前系统中运行的每个进程在<code>/proc</code>下都有一个子目录，目录名就是进程的id，查看目录下的文件可以得到该进程的相关信息。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@DESKTOP-KD33OT8:/home/demo# cat /proc/27613/maps</span><br><span class=\"line\">5589e9d2b000-5589e9d42000 r--p 00000000 08:10 225588                     /usr/bin/zsh</span><br><span class=\"line\">5589e9d42000-5589e9dd7000 r-xp 00017000 08:10 225588                     /usr/bin/zsh</span><br><span class=\"line\">5589e9dd7000-5589e9df9000 r--p 000ac000 08:10 225588                     /usr/bin/zsh</span><br><span class=\"line\">5589e9dfa000-5589e9dfc000 r--p 000ce000 08:10 225588                     /usr/bin/zsh</span><br><span class=\"line\">5589e9dfc000-5589e9e02000 rw-p 000d0000 08:10 225588                     /usr/bin/zsh</span><br><span class=\"line\">5589e9e02000-5589e9e16000 rw-p 00000000 00:00 0</span><br><span class=\"line\">5589eac55000-5589eb1af000 rw-p 00000000 00:00 0                          [heap]</span><br><span class=\"line\">7f90adfc6000-7f90adfc9000 r--p 00000000 08:10 225599                     /usr/lib/x86_64-linux-gnu/zsh/5.8/zsh/computil.so</span><br><span class=\"line\">7f90adfc9000-7f90adfd6000 r-xp 00003000 08:10 225599                     /usr/lib/x86_64-linux-gnu/zsh/5.8/zsh/computil.so</span><br><span class=\"line\">7f90adfd6000-7f90adfd8000 r--p 00010000 08:10 225599                     /usr/lib/x86_64-linux-gnu/zsh/5.8/zsh/computil.so</span><br><span class=\"line\">7f90adfd8000-7f90adfd9000 r--p 00011000 08:10 225599                     /usr/lib/x86_64-linux-gnu/zsh/5.8/zsh/computil.so</span><br><span class=\"line\">7f90adfd9000-7f90adfda000 rw-p 00012000 08:10 225599                     /usr/lib/x86_64-linux-gnu/zsh/5.8/zsh/computil.so</span><br><span class=\"line\">7f90adfda000-7f90ae25a000 r--s 00000000 08:10 225058                     /usr/share/zsh/functions/Completion/Unix.zwc</span><br><span class=\"line\">7f90ae265000-7f90ae28a000 r--s 00000000 08:10 225225                     /usr/share/zsh/functions/Completion/Zsh.zwc</span><br><span class=\"line\">7f90ae299000-7f90ae2b2000 r--s 00000000 08:10 225469                     /usr/share/zsh/functions/Zle.zwc</span><br><span class=\"line\">7f90ae2b6000-7f90ae2da000 rw-p 00000000 00:00 0</span><br><span class=\"line\">7f90ae325000-7f90ae331000 rw-p 00000000 00:00 0</span><br><span class=\"line\">7f90ae331000-7f90ae37d000 rw-p 00000000 00:00 0</span><br><span class=\"line\">7f90ae37d000-7f90ae381000 r--p 00000000 08:10 225596                     /usr/lib/x86_64-linux-gnu/zsh/5.8/zsh/compctl.so</span><br><span class=\"line\">7f90ae381000-7f90ae38d000 r-xp 00004000 08:10 225596                     /usr/lib/x86_64-linux-gnu/zsh/5.8/zsh/compctl.so</span><br><span class=\"line\">7f90ae38d000-7f90ae38f000 r--p 00010000 08:10 225596                     /usr/lib/x86_64-linux-gnu/zsh/5.8/zsh/compctl.so</span><br><span class=\"line\">7f90ae38f000-7f90ae390000 r--p 00011000 08:10 225596                     /usr/lib/x86_64-linux-gnu/zsh/5.8/zsh/compctl.so</span><br><span class=\"line\">7f90ae390000-7f90ae391000 rw-p 00012000 08:10 225596                     /usr/lib/x86_64-linux-gnu/zsh/5.8/zsh/compctl.so</span><br><span class=\"line\">7f90aecf3000-7f90aecf5000 rw-p 00000000 00:00 0</span><br><span class=\"line\">7f90aecf5000-7f90aecf6000 r--p 00000000 08:10 2985                       /usr/lib/locale/C.UTF-8/LC_TELEPHONE</span><br><span class=\"line\">7f90aecf6000-7f90aecf7000 r--p 00000000 08:10 2978                       /usr/lib/locale/C.UTF-8/LC_MEASUREMENT</span><br><span class=\"line\">7f90aecf7000-7f90aecfe000 r--s 00000000 08:10 264854                     /usr/lib/x86_64-linux-gnu/gconv/gconv-modules.cache</span><br><span class=\"line\">7f90aecfe000-7f90aecff000 r--p 00000000 08:10 38549                      /usr/lib/x86_64-linux-gnu/ld-2.31.so</span><br><span class=\"line\">7f90aecff000-7f90aed22000 r-xp 00001000 08:10 38549                      /usr/lib/x86_64-linux-gnu/ld-2.31.so</span><br><span class=\"line\">7f90aed22000-7f90aed2a000 r--p 00024000 08:10 38549                      /usr/lib/x86_64-linux-gnu/ld-2.31.so</span><br><span class=\"line\">7f90aed2a000-7f90aed2b000 r--p 00000000 08:10 2977                       /usr/lib/locale/C.UTF-8/LC_IDENTIFICATION</span><br><span class=\"line\">7f90aed2b000-7f90aed2c000 r--p 0002c000 08:10 38549                      /usr/lib/x86_64-linux-gnu/ld-2.31.so</span><br><span class=\"line\">7f90aed2c000-7f90aed2d000 rw-p 0002d000 08:10 38549                      /usr/lib/x86_64-linux-gnu/ld-2.31.so</span><br><span class=\"line\">7f90aed2d000-7f90aed2e000 rw-p 00000000 00:00 0</span><br><span class=\"line\">7ffeb1e2d000-7ffeb1e7c000 rw-p 00000000 00:00 0                          [stack]</span><br><span class=\"line\">7ffeb1f0c000-7ffeb1f10000 r--p 00000000 00:00 0                          [vvar]</span><br><span class=\"line\">7ffeb1f10000-7ffeb1f11000 r-xp 00000000 00:00 0                          [vdso]</span><br></pre></td></tr></table></figure></li>\n</ul>\n<h2 id=\"Why-为什么需要虚拟内存\"><a href=\"#Why-为什么需要虚拟内存\" class=\"headerlink\" title=\"Why-为什么需要虚拟内存\"></a>Why-为什么需要虚拟内存</h2><h3 id=\"第一，虚拟内存管理可以控制物理内存的访问权限。\"><a href=\"#第一，虚拟内存管理可以控制物理内存的访问权限。\" class=\"headerlink\" title=\"第一，虚拟内存管理可以控制物理内存的访问权限。\"></a>第一，虚拟内存管理可以控制物理内存的访问权限。</h3><p><strong>物理内存本身是不限制访问的，任何地址都可以读写，而操作系统要求不同的页面具有不同的访问权限，这是利用CPU模式和MMU的内存保护机制实现的。</strong>例如，Text Segment被只读保护起来，防止被错误的指令意外改写，内核地址空间也被保护起来，防止在用户模式下执行错误的指令意外改写内核数据。这样，执行错误指令或恶意代码的破坏能力受到了限制，顶多使当前进程因段错误终止，而不会影响整个系统的稳定性。</p>\n<h3 id=\"第二，虚拟内存管理最主要的作用是让每个进程有独立的地址空间。\"><a href=\"#第二，虚拟内存管理最主要的作用是让每个进程有独立的地址空间。\" class=\"headerlink\" title=\"第二，虚拟内存管理最主要的作用是让每个进程有独立的地址空间。\"></a>第二，虚拟内存管理最主要的作用是让每个进程有独立的地址空间。</h3><p><strong>所谓独立的地址空间是指，不同进程中的同一个VA被MMU映射到不同的PA，并且在某一个进程中访问任何地址都不可能访问到另外一个进程的数据，这样使得任何一个进程由于执行错误指令或恶意代码导致的非法内存访问都不会意外改写其它进程的数据，不会影响其它进程的运行，从而保证整个系统的稳定性。</strong>另一方面，每个进程都认为自己独占整个虚拟地址空间，这样链接器和加载器的实现会比较容易，不必考虑各进程的地址范围是否冲突。</p>\n<p>继续前面的实验，再打开一个终端窗口，看一下这个新的<code>bash</code>进程的地址空间，可以发现和先前的<code>bash</code>进程地址空间的布局差不多：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\">$ </span><span class=\"language-bash\">ps</span></span><br><span class=\"line\">  PID TTY          TIME CMD</span><br><span class=\"line\">30697 pts/1    00:00:00 bash</span><br><span class=\"line\">30749 pts/1    00:00:00 ps</span><br><span class=\"line\"><span class=\"meta prompt_\">$ </span><span class=\"language-bash\"><span class=\"built_in\">cat</span> /proc/30697/maps</span></span><br><span class=\"line\">08048000-080f4000 r-xp 00000000 08:15 688142     /bin/bash</span><br><span class=\"line\">080f4000-080f9000 rw-p 000ac000 08:15 688142     /bin/bash</span><br><span class=\"line\">080f9000-080fe000 rw-p 080f9000 00:00 0 </span><br><span class=\"line\">082d7000-084f9000 rw-p 082d7000 00:00 0          [heap]</span><br><span class=\"line\">b7cf1000-b7cfb000 r-xp 00000000 08:15 581665     /lib/tls/i686/cmov/libnss_files-2.8.90.so</span><br><span class=\"line\">b7cfb000-b7cfc000 r--p 00009000 08:15 581665     /lib/tls/i686/cmov/libnss_files-2.8.90.so</span><br><span class=\"line\">b7cfc000-b7cfd000 rw-p 0000a000 08:15 581665     /lib/tls/i686/cmov/libnss_files-2.8.90.so</span><br><span class=\"line\">...</span><br><span class=\"line\">b7e5e000-b7fb6000 r-xp 00000000 08:15 581656     /lib/tls/i686/cmov/libc-2.8.90.so</span><br><span class=\"line\">b7fb6000-b7fb8000 r--p 00158000 08:15 581656     /lib/tls/i686/cmov/libc-2.8.90.so</span><br><span class=\"line\">b7fb8000-b7fb9000 rw-p 0015a000 08:15 581656     /lib/tls/i686/cmov/libc-2.8.90.so</span><br><span class=\"line\">...</span><br><span class=\"line\">b8006000-b8020000 r-xp 00000000 08:15 565466     /lib/ld-2.8.90.so</span><br><span class=\"line\">b8020000-b8021000 r-xp b8020000 00:00 0          [vdso]</span><br><span class=\"line\">b8021000-b8022000 r--p 0001a000 08:15 565466     /lib/ld-2.8.90.so</span><br><span class=\"line\">b8022000-b8023000 rw-p 0001b000 08:15 565466     /lib/ld-2.8.90.so</span><br><span class=\"line\">bff0e000-bff23000 rw-p bffeb000 00:00 0          [stack]</span><br></pre></td></tr></table></figure>\n\n<p>该进程也占用了0x0000 0000-0xbfff ffff的地址空间，Text Segment也是0x0804 8000-0x080f 4000，Data Segment也是0x080f 4000-0x080f 9000，和先前的进程一模一样，因为这些地址是在编译链接时写进<code>/bin/bash</code>这个可执行文件的，两个进程都加载它。这两个进程在同一个系统中同时运行着，它们的Data Segment占用相同的VA，但是两个进程各自干各自的事情，显然Data Segment中的数据应该是不同的，相同的VA怎么会有不同的数据呢？因为它们被映射到不同的PA。如下图所示。</p>\n<p><strong>图 20.5. 进程地址空间是独立的</strong></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1665229505062-380026ae-9136-4837-ac8c-28e7d794a3d6.png\" alt=\"img\"></p>\n<p>从图中还可以看到，两个进程都是<code>bash</code>进程，Text Segment是一样的，并且Text Segment是只读的，不会被改写，因此操作系统会安排两个进程的Text Segment共享相同的物理页面。由于每个进程都有自己的一套VA到PA的映射表，整个地址空间中的任何VA都在每个进程自己的映射表中查找相应的PA，因此不可能访问到其它进程的地址，也就没有可能意外改写其它进程的数据。</p>\n<p>另外，注意到两个进程的共享库加载地址并不相同，共享库的加载地址是在运行时决定的，而不是写在<code>/bin/bash</code>这个可执行文件中。但即使如此，也不影响两个进程共享相同物理页面中的共享库，当然，只有只读的部分是共享的，可读可写的部分不共享。</p>\n<p><strong>使用共享库可以大大节省内存。比如<code>libc</code>，系统中几乎所有的进程都映射<code>libc</code>到自己的进程地址空间，而<code>libc</code>的只读部分在物理内存中只需要存在一份，就可以被所有进程共享，这就是“共享库”这个名称的由来了。</strong></p>\n<p>现在我们也可以理解为什么共享库必须是位置无关代码了。比如<code>libc</code>，不同的进程虽然共享<code>libc</code>所在的物理页面，但这些物理页面被映射到各进程的虚拟地址空间时却位于不同的地址，所以要求<code>libc</code>的代码不管加载到什么地址都能正确执行。</p>\n<h3 id=\"第三，VA到PA的映射会给分配和释放内存带来方便，物理地址不连续的几块内存可以映射成虚拟地址连续的一块内存。\"><a href=\"#第三，VA到PA的映射会给分配和释放内存带来方便，物理地址不连续的几块内存可以映射成虚拟地址连续的一块内存。\" class=\"headerlink\" title=\"第三，VA到PA的映射会给分配和释放内存带来方便，物理地址不连续的几块内存可以映射成虚拟地址连续的一块内存。\"></a>第三，VA到PA的映射会给分配和释放内存带来方便，物理地址不连续的几块内存可以映射成虚拟地址连续的一块内存。</h3><p>比如要用<code>malloc</code>分配一块很大的内存空间，虽然有足够多的空闲物理内存，却没有足够大的<em>连续</em>空闲内存，这时就可以分配多个不连续的物理页面而映射到连续的虚拟地址范围。如下图所示。</p>\n<p><strong>图 20.6. 不连续的PA可以映射为连续的VA</strong></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1665229512867-30829a8c-dc36-47c3-a300-9afec24b0b0a.png\" alt=\"img\"></p>\n<h3 id=\"四，一个系统如果同时运行着很多进程，为各进程分配的内存之和可能会大于实际可用的物理内存，虚拟内存管理使得这种情况下各进程仍然能够正常运行。\"><a href=\"#四，一个系统如果同时运行着很多进程，为各进程分配的内存之和可能会大于实际可用的物理内存，虚拟内存管理使得这种情况下各进程仍然能够正常运行。\" class=\"headerlink\" title=\"四，一个系统如果同时运行着很多进程，为各进程分配的内存之和可能会大于实际可用的物理内存，虚拟内存管理使得这种情况下各进程仍然能够正常运行。\"></a>四，一个系统如果同时运行着很多进程，为各进程分配的内存之和可能会大于实际可用的物理内存，虚拟内存管理使得这种情况下各进程仍然能够正常运行。</h3><p>因为各进程分配的只不过是虚拟内存的页面，这些页面的数据可以映射到物理页面，也可以临时保存到磁盘上而不占用物理页面，在磁盘上临时保存虚拟内存页面的可能是一个磁盘分区，也可能是一个磁盘文件，称为<strong>交换设备（Swap Device）</strong>。当物理内存不够用时，将一些不常用的物理页面中的数据临时保存到交换设备，然后这个物理页面就认为是空闲的了，可以重新分配给进程使用，这个过程称为<strong>换出（Page out）</strong>。如果进程要用到被换出的页面，就从交换设备再加载回物理内存，这称为<strong>换入（Page in）</strong>。换出和换入操作统称为换页（Paging），因此：</p>\n<p><strong>系统中可分配的内存总量 &#x3D; 物理内存的大小 + 交换设备的大小</strong></p>\n<p>如下图所示。第一张图是换出，将物理页面中的数据保存到磁盘，并解除地址映射，释放物理页面。第二张图是换入，从空闲的物理页面中分配一个，将磁盘暂存的页面加载回内存，并建立地址映射。</p>\n<p><strong>图 20.7. 换页</strong></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2022/png/2500465/1665229520142-3901c155-5c01-4e50-b706-6f68f98236c6.png\" alt=\"image.png\"></p>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"cl9y38ds2000kfwuih8vq6lc5","category_id":"cl9y38ds1000jfwuibc7zbrui","_id":"cl9y38ds7000tfwui9b3gfvgg"},{"post_id":"cl9y38dru0009fwuiclnb4y8p","category_id":"cl9y38ds1000jfwuibc7zbrui","_id":"cl9y38ds8000wfwuia4ejbehr"},{"post_id":"cl9y38dri0001fwuibowu94rx","category_id":"cl9y38drt0007fwuieqt2g39m","_id":"cl9y38dsa0010fwui7h9bfmqc"},{"post_id":"cl9y38dri0001fwuibowu94rx","category_id":"cl9y38ds4000ofwui4jfcd7w4","_id":"cl9y38dsa0013fwui65e2f7ke"},{"post_id":"cl9y38drw000bfwuih4u57kr1","category_id":"cl9y38ds7000ufwui15hb6p8f","_id":"cl9y38dse001afwui3zc3at49"},{"post_id":"cl9y38drz000gfwuihdgpad2t","category_id":"cl9y38ds9000zfwuig1pggx5h","_id":"cl9y38dsg001gfwuig1k66eac"},{"post_id":"cl9y38ds0000hfwui24z3f3i9","category_id":"cl9y38ds1000jfwuibc7zbrui","_id":"cl9y38dsh001ifwuifiiz943t"},{"post_id":"cl9y38drs0006fwuieh3p1a97","category_id":"cl9y38drx000dfwui54bt0vwh","_id":"cl9y38dsl001qfwuicr30fqjp"},{"post_id":"cl9y38drs0006fwuieh3p1a97","category_id":"cl9y38dsf001dfwui00d9gnzb","_id":"cl9y38dsm001tfwuidi212owj"},{"post_id":"cl9y38ds5000pfwui8zd33j5t","category_id":"cl9y38drt0007fwuieqt2g39m","_id":"cl9y38dso001zfwui59m30fvk"},{"post_id":"cl9y38ds5000pfwui8zd33j5t","category_id":"cl9y38dsh001jfwuidp7c44ot","_id":"cl9y38dsp0021fwui6ziofs5o"},{"post_id":"cl9y38ds6000qfwuidtpbfbg1","category_id":"cl9y38dsk001pfwuib0m9dt13","_id":"cl9y38dsq0026fwui29271jkx"},{"post_id":"cl9y38dso0020fwui2i26b3ll","category_id":"cl9y38drt0007fwuieqt2g39m","_id":"cl9y38dst002cfwuice0v3kar"},{"post_id":"cl9y38dso0020fwui2i26b3ll","category_id":"cl9y38dsn001xfwui00vt63t3","_id":"cl9y38dsu002ffwui90b61hq6"},{"post_id":"cl9y38ds7000sfwui2julcsst","category_id":"cl9y38drt0007fwuieqt2g39m","_id":"cl9y38dsv002kfwuibtlohfnm"},{"post_id":"cl9y38ds7000sfwui2julcsst","category_id":"cl9y38dsn001xfwui00vt63t3","_id":"cl9y38dsy002nfwui062latpa"},{"post_id":"cl9y38ds8000vfwui8tf4g64t","category_id":"cl9y38drt0007fwuieqt2g39m","_id":"cl9y38dt1002sfwui33ntdz9k"},{"post_id":"cl9y38ds8000vfwui8tf4g64t","category_id":"cl9y38dsn001xfwui00vt63t3","_id":"cl9y38dt1002ufwuiec0a7uun"},{"post_id":"cl9y38ds9000xfwuicz9h5xkl","category_id":"cl9y38drt0007fwuieqt2g39m","_id":"cl9y38dt2002yfwuifw7xg6gr"},{"post_id":"cl9y38ds9000xfwuicz9h5xkl","category_id":"cl9y38dsn001xfwui00vt63t3","_id":"cl9y38dt2002zfwui36q222ez"},{"post_id":"cl9y38dst002dfwuiabw17p2u","category_id":"cl9y38ds1000jfwuibc7zbrui","_id":"cl9y38dt30032fwui6pnwex5d"},{"post_id":"cl9y38dsv002ifwui5f684xp3","category_id":"cl9y38ds1000jfwuibc7zbrui","_id":"cl9y38dt30033fwuigafi42ps"},{"post_id":"cl9y38dsa0012fwui3s268d47","category_id":"cl9y38drt0007fwuieqt2g39m","_id":"cl9y38dt30034fwuigjtqf6qc"},{"post_id":"cl9y38dsa0012fwui3s268d47","category_id":"cl9y38dsu002hfwui5vpe4ouq","_id":"cl9y38dt40037fwuic4xnbgvp"},{"post_id":"cl9y38dsb0015fwui6j6wap6g","category_id":"cl9y38drt0007fwuieqt2g39m","_id":"cl9y38dt40038fwuieyzp1492"},{"post_id":"cl9y38dsb0015fwui6j6wap6g","category_id":"cl9y38dsu002hfwui5vpe4ouq","_id":"cl9y38dt5003bfwuih9ejhevs"},{"post_id":"cl9y38dsd0019fwui7ax57un2","category_id":"cl9y38drt0007fwuieqt2g39m","_id":"cl9y38dt5003dfwuidltsbt41"},{"post_id":"cl9y38dsd0019fwui7ax57un2","category_id":"cl9y38dt1002vfwui85hsdkhu","_id":"cl9y38dt7003hfwui8fc16x5n"},{"post_id":"cl9y38dse001cfwuib946eogz","category_id":"cl9y38drt0007fwuieqt2g39m","_id":"cl9y38dt7003jfwui06oz9rvo"},{"post_id":"cl9y38dse001cfwuib946eogz","category_id":"cl9y38dt20030fwuif2983mr6","_id":"cl9y38dt7003nfwuieum3hlmx"},{"post_id":"cl9y38dsf001ffwuihhin3n5o","category_id":"cl9y38dsk001pfwuib0m9dt13","_id":"cl9y38dt8003pfwuig5bc3mdo"},{"post_id":"cl9y38dsg001hfwuidmlwdi2m","category_id":"cl9y38drt0007fwuieqt2g39m","_id":"cl9y38dt9003tfwuih3mxa45v"},{"post_id":"cl9y38dsg001hfwuidmlwdi2m","category_id":"cl9y38dsn001xfwui00vt63t3","_id":"cl9y38dt9003vfwui7n7kcorm"},{"post_id":"cl9y38dsh001lfwuidu7cd6fs","category_id":"cl9y38drt0007fwuieqt2g39m","_id":"cl9y38dt9003yfwui9bm46qly"},{"post_id":"cl9y38dsh001lfwuidu7cd6fs","category_id":"cl9y38dt5003efwuihcmb2d95","_id":"cl9y38dta003zfwui6jeq3h35"},{"post_id":"cl9y38dsi001mfwui8a63cqyt","category_id":"cl9y38drt0007fwuieqt2g39m","_id":"cl9y38dta0042fwuia06x8tqc"},{"post_id":"cl9y38dsi001mfwui8a63cqyt","category_id":"cl9y38dt7003lfwuicetu2n37","_id":"cl9y38dta0044fwui32308zi3"},{"post_id":"cl9y38dsk001ofwuibzi58kdn","category_id":"cl9y38drt0007fwuieqt2g39m","_id":"cl9y38dtb0047fwuic70pcc5j"},{"post_id":"cl9y38dsk001ofwuibzi58kdn","category_id":"cl9y38dsu002hfwui5vpe4ouq","_id":"cl9y38dtc004afwui02rk5p8h"},{"post_id":"cl9y38dsl001sfwui416a53so","category_id":"cl9y38drt0007fwuieqt2g39m","_id":"cl9y38dtc004cfwuidnq2h8th"},{"post_id":"cl9y38dsl001sfwui416a53so","category_id":"cl9y38dsn001xfwui00vt63t3","_id":"cl9y38dtd004efwuidajzbw39"},{"post_id":"cl9y38dsn001wfwuigta4aut2","category_id":"cl9y38drt0007fwuieqt2g39m","_id":"cl9y38dtd004gfwui03se3lhm"},{"post_id":"cl9y38dsn001wfwuigta4aut2","category_id":"cl9y38dsu002hfwui5vpe4ouq","_id":"cl9y38dte004ifwui03l6bvcj"},{"post_id":"cl9y38dsp0022fwuiam7u0ub1","category_id":"cl9y38drt0007fwuieqt2g39m","_id":"cl9y38dte004kfwuifzgn6urs"},{"post_id":"cl9y38dsp0022fwuiam7u0ub1","category_id":"cl9y38dtb0045fwuib8da84or","_id":"cl9y38dtf004ofwuierdxg1f8"},{"post_id":"cl9y38dsq0025fwui0szl7rra","category_id":"cl9y38drt0007fwuieqt2g39m","_id":"cl9y38dtf004pfwuiev6te8vg"},{"post_id":"cl9y38dsq0025fwui0szl7rra","category_id":"cl9y38dsu002hfwui5vpe4ouq","_id":"cl9y38dtg004sfwui619o2lzx"},{"post_id":"cl9y38dss002afwuidni0cozt","category_id":"cl9y38dtd004ffwuiejmegwpi","_id":"cl9y38dtg004ufwui2y3ybp4d"},{"post_id":"cl9y38dt0002qfwuieoeodxzt","category_id":"cl9y38dtg004qfwui2fsy1g08","_id":"cl9y38dth0050fwuibpmk1rg5"},{"post_id":"cl9y38dsw002lfwuibj480wcd","category_id":"cl9y38dte004lfwui9yfs6zen","_id":"cl9y38dti0053fwuiao421bdk"},{"post_id":"cl9y38dsw002lfwuibj480wcd","category_id":"cl9y38dtg004vfwui15ur3yks","_id":"cl9y38dti0055fwui00ds2hgm"},{"post_id":"cl9y38dtr005tfwuidykid4jv","category_id":"cl9y38dtg004qfwui2fsy1g08","_id":"cl9y38dts005vfwuihu9t2fr0"}],"PostTag":[{"post_id":"cl9y38dri0001fwuibowu94rx","tag_id":"cl9y38drq0004fwuia2bff0gy","_id":"cl9y38drx000efwuic14nante"},{"post_id":"cl9y38drs0006fwuieh3p1a97","tag_id":"cl9y38drw000cfwuie2hg1t0h","_id":"cl9y38ds2000lfwui05op2h9e"},{"post_id":"cl9y38dru0009fwuiclnb4y8p","tag_id":"cl9y38ds1000ifwuiccfv53py","_id":"cl9y38dsa0011fwuied1b5nzj"},{"post_id":"cl9y38dru0009fwuiclnb4y8p","tag_id":"cl9y38ds4000nfwuictykajo3","_id":"cl9y38dsa0014fwuibsmf9er1"},{"post_id":"cl9y38dru0009fwuiclnb4y8p","tag_id":"cl9y38ds6000rfwuigco104cp","_id":"cl9y38dsd0018fwuibvuv8cjn"},{"post_id":"cl9y38drw000bfwuih4u57kr1","tag_id":"cl9y38ds9000yfwui6m4x7db2","_id":"cl9y38dse001bfwui37xof8i0"},{"post_id":"cl9y38drz000gfwuihdgpad2t","tag_id":"cl9y38dsb0016fwuid6cu89pu","_id":"cl9y38dsl001rfwui0jc6ge8x"},{"post_id":"cl9y38drz000gfwuihdgpad2t","tag_id":"cl9y38dsf001efwui85jm8sr2","_id":"cl9y38dsm001ufwui8wa10ore"},{"post_id":"cl9y38drz000gfwuihdgpad2t","tag_id":"cl9y38ds4000nfwuictykajo3","_id":"cl9y38dso001yfwui627qgeyq"},{"post_id":"cl9y38ds0000hfwui24z3f3i9","tag_id":"cl9y38ds4000nfwuictykajo3","_id":"cl9y38dst002bfwui04miaff5"},{"post_id":"cl9y38ds0000hfwui24z3f3i9","tag_id":"cl9y38dsm001vfwuifbuo9okz","_id":"cl9y38dsu002efwui1k1zb2yk"},{"post_id":"cl9y38ds0000hfwui24z3f3i9","tag_id":"cl9y38dsp0023fwuih2nx0w72","_id":"cl9y38dsv002jfwuigiwr442m"},{"post_id":"cl9y38ds2000kfwuih8vq6lc5","tag_id":"cl9y38ds4000nfwuictykajo3","_id":"cl9y38dsy002mfwuid0vo9f66"},{"post_id":"cl9y38dst002dfwuiabw17p2u","tag_id":"cl9y38ds4000nfwuictykajo3","_id":"cl9y38dt1002rfwuigv3f7q6u"},{"post_id":"cl9y38dsv002ifwui5f684xp3","tag_id":"cl9y38ds4000nfwuictykajo3","_id":"cl9y38dt1002tfwuie5rr2pzz"},{"post_id":"cl9y38ds3000mfwui7mnidfjp","tag_id":"cl9y38dsu002gfwuifx0ehm57","_id":"cl9y38dt2002xfwui2xu950rp"},{"post_id":"cl9y38ds5000pfwui8zd33j5t","tag_id":"cl9y38dsz002ofwuidt093t81","_id":"cl9y38dt5003cfwuiep0bew4y"},{"post_id":"cl9y38ds5000pfwui8zd33j5t","tag_id":"cl9y38dt2002wfwuicrec4371","_id":"cl9y38dt6003ffwuihvfyc80m"},{"post_id":"cl9y38ds5000pfwui8zd33j5t","tag_id":"cl9y38dt20031fwui9ley24b6","_id":"cl9y38dt7003ifwuicgf927nz"},{"post_id":"cl9y38ds5000pfwui8zd33j5t","tag_id":"cl9y38dt30036fwuif0586bfq","_id":"cl9y38dt7003kfwui1hav8fti"},{"post_id":"cl9y38ds6000qfwuidtpbfbg1","tag_id":"cl9y38dt5003afwuigc1c4l27","_id":"cl9y38dt8003ofwuihphu90gp"},{"post_id":"cl9y38ds7000sfwui2julcsst","tag_id":"cl9y38dt5003afwuigc1c4l27","_id":"cl9y38dt8003qfwui2cl67s5i"},{"post_id":"cl9y38ds8000vfwui8tf4g64t","tag_id":"cl9y38dt5003afwuigc1c4l27","_id":"cl9y38dt9003ufwui1oxe74ov"},{"post_id":"cl9y38ds9000xfwuicz9h5xkl","tag_id":"cl9y38dt5003afwuigc1c4l27","_id":"cl9y38dta0043fwui31309z7g"},{"post_id":"cl9y38ds9000xfwuicz9h5xkl","tag_id":"cl9y38dt9003xfwui6q3kht23","_id":"cl9y38dtb0046fwui8x387wsx"},{"post_id":"cl9y38dsa0012fwui3s268d47","tag_id":"cl9y38dta0041fwui8gc1e079","_id":"cl9y38dtb0049fwui6ghp0k7u"},{"post_id":"cl9y38dsb0015fwui6j6wap6g","tag_id":"cl9y38dta0041fwui8gc1e079","_id":"cl9y38dte004jfwui080u0avc"},{"post_id":"cl9y38dsb0015fwui6j6wap6g","tag_id":"cl9y38dtc004dfwuig85razfc","_id":"cl9y38dtf004mfwui6ifpdv87"},{"post_id":"cl9y38dsd0019fwui7ax57un2","tag_id":"cl9y38dte004hfwui0edxb1hk","_id":"cl9y38dtg004tfwui4y800oyc"},{"post_id":"cl9y38dsd0019fwui7ax57un2","tag_id":"cl9y38dtf004nfwui292r8286","_id":"cl9y38dth004wfwui13w6hski"},{"post_id":"cl9y38dse001cfwuib946eogz","tag_id":"cl9y38dtg004rfwui4wixfgj5","_id":"cl9y38dth004yfwuigqek6cdd"},{"post_id":"cl9y38dsf001ffwuihhin3n5o","tag_id":"cl9y38dt5003afwuigc1c4l27","_id":"cl9y38dti0051fwui34hk8ifv"},{"post_id":"cl9y38dsg001hfwuidmlwdi2m","tag_id":"cl9y38dt5003afwuigc1c4l27","_id":"cl9y38dti0054fwuiedu2d9v5"},{"post_id":"cl9y38dsh001lfwuidu7cd6fs","tag_id":"cl9y38dti0052fwuidvjq9dk9","_id":"cl9y38dtj0058fwuieq5va90h"},{"post_id":"cl9y38dsh001lfwuidu7cd6fs","tag_id":"cl9y38dti0056fwui64gycv7q","_id":"cl9y38dtj0059fwuifz8aa32j"},{"post_id":"cl9y38dsi001mfwui8a63cqyt","tag_id":"cl9y38dti0057fwui7l93fhcw","_id":"cl9y38dtj005bfwui7732e5fx"},{"post_id":"cl9y38dsk001ofwuibzi58kdn","tag_id":"cl9y38dta0041fwui8gc1e079","_id":"cl9y38dtj005dfwuicm7z92wc"},{"post_id":"cl9y38dsl001sfwui416a53so","tag_id":"cl9y38dt5003afwuigc1c4l27","_id":"cl9y38dtk005ffwui9it4ge81"},{"post_id":"cl9y38dsn001wfwuigta4aut2","tag_id":"cl9y38dta0041fwui8gc1e079","_id":"cl9y38dtl005hfwuig8c931vz"},{"post_id":"cl9y38dso0020fwui2i26b3ll","tag_id":"cl9y38dt5003afwuigc1c4l27","_id":"cl9y38dtl005jfwuicfwv5m52"},{"post_id":"cl9y38dsp0022fwuiam7u0ub1","tag_id":"cl9y38dtl005ifwui6o6c9452","_id":"cl9y38dtl005lfwui157dghio"},{"post_id":"cl9y38dsq0025fwui0szl7rra","tag_id":"cl9y38dta0041fwui8gc1e079","_id":"cl9y38dtm005nfwuignm8ek4c"},{"post_id":"cl9y38dss002afwuidni0cozt","tag_id":"cl9y38dtl005mfwui5473h73c","_id":"cl9y38dtm005pfwui5r6y0hra"},{"post_id":"cl9y38dsw002lfwuibj480wcd","tag_id":"cl9y38dtm005ofwuienos9a0d","_id":"cl9y38dtm005rfwuid4xf10ii"},{"post_id":"cl9y38dt0002qfwuieoeodxzt","tag_id":"cl9y38dtm005qfwui49vs7nc9","_id":"cl9y38dtn005sfwui6kivczye"},{"post_id":"cl9y38dtr005tfwuidykid4jv","tag_id":"cl9y38dtm005qfwui49vs7nc9","_id":"cl9y38dtr005ufwuidbivcn65"}],"Tag":[{"name":"hudi","_id":"cl9y38drq0004fwuia2bff0gy"},{"name":"dns","_id":"cl9y38drw000cfwuie2hg1t0h"},{"name":"CDN","_id":"cl9y38ds1000ifwuiccfv53py"},{"name":"hexo","_id":"cl9y38ds4000nfwuictykajo3"},{"name":"cloudflare","_id":"cl9y38ds6000rfwuigco104cp"},{"name":"SEO","_id":"cl9y38ds9000yfwui6m4x7db2"},{"name":"WSL","_id":"cl9y38dsb0016fwuid6cu89pu"},{"name":"Linxu","_id":"cl9y38dsf001efwui85jm8sr2"},{"name":"github pages","_id":"cl9y38dsm001vfwuifbuo9okz"},{"name":"CFW","_id":"cl9y38dsp0023fwuih2nx0w72"},{"name":"EMO语录","_id":"cl9y38dsu002gfwuifx0ehm57"},{"name":"Kylin","_id":"cl9y38dsz002ofwuidt093t81"},{"name":"JVM","_id":"cl9y38dt2002wfwuicrec4371"},{"name":"MAT","_id":"cl9y38dt20031fwui9ley24b6"},{"name":"Arthas","_id":"cl9y38dt30036fwuif0586bfq"},{"name":"Doris","_id":"cl9y38dt5003afwuigc1c4l27"},{"name":"数据中台","_id":"cl9y38dt9003xfwui6q3kht23"},{"name":"Flink","_id":"cl9y38dta0041fwui8gc1e079"},{"name":"调优","_id":"cl9y38dtc004dfwuig85razfc"},{"name":"HBase","_id":"cl9y38dte004hfwui0edxb1hk"},{"name":"MVCC","_id":"cl9y38dtf004nfwui292r8286"},{"name":"Kyuubi","_id":"cl9y38dtg004rfwui4wixfgj5"},{"name":"yarn","_id":"cl9y38dti0052fwuidvjq9dk9"},{"name":"hadoop","_id":"cl9y38dti0056fwui64gycv7q"},{"name":"kudu","_id":"cl9y38dti0057fwui7l93fhcw"},{"name":"用户画像","_id":"cl9y38dtl005ifwui6o6c9452"},{"name":"LSM-Tree","_id":"cl9y38dtl005mfwui5473h73c"},{"name":"thrift","_id":"cl9y38dtm005ofwuienos9a0d"},{"name":"os","_id":"cl9y38dtm005qfwui49vs7nc9"}]}}